  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 09:24:17,864 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:04:52,  1.32it/s][INFO|trainer.py:4226] 2025-01-21 09:24:21,959 >>
{'loss': 2.7322, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 2.6553902626037598, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 3.0957, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.012371301651001, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 3.0858, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.016918897628784, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 2.6849, 'grad_norm': 138.12490844726562, 'learning_rate': 2.999418604651163e-05, 'loss_1': 2.6182749271392822, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 3.0046, 'grad_norm': 136.41091918945312, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 2.9357943534851074, 'loss_2': 0.06884765625, 'loss_3': -13.664815902709961, 'loss_4': 9.646829605102539, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:21,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:21,960 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:07<1:04:52,  1.32it/s][INFO|trainer.py:3910] 2025-01-21 09:24:25,738 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 09:24:25,739 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-5/config.json                                                                                
{'eval_loss': 1.239497184753418, 'eval_runtime': 3.7766, 'eval_samples_per_second': 271.145, 'eval_steps_per_second': 4.237, 'eval_loss_1': 1.1850558519363403, 'eval_loss_2': 0.05444145202636719, 'eval_loss_3': -17.857099533081055, 'eval_loss_4': 9.346065521240234, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:26,221 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:26,222 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:26,222 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-5/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:27,107 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-60] due to args.save_total_limit
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:34:26,  1.10s/it][INFO|trainer.py:4226] 2025-01-21 09:24:30,722 >>
{'loss': 2.6527, 'grad_norm': 127.36512756347656, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 2.5958502292633057, 'loss_2': 0.056854248046875, 'loss_3': -14.096738815307617, 'loss_4': 9.57455062866211, 'epoch': 0.03}
{'loss': 2.2854, 'grad_norm': 122.2479019165039, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 2.2336714267730713, 'loss_2': 0.051727294921875, 'loss_3': -14.571680068969727, 'loss_4': 10.017372131347656, 'epoch': 0.04}
{'loss': 2.2623, 'grad_norm': 135.41348266601562, 'learning_rate': 2.997093023255814e-05, 'loss_1': 2.2161147594451904, 'loss_2': 0.04620361328125, 'loss_3': -14.804889678955078, 'loss_4': 9.513501167297363, 'epoch': 0.05}
{'loss': 2.2195, 'grad_norm': 123.79914093017578, 'learning_rate': 2.996511627906977e-05, 'loss_1': 2.1836681365966797, 'loss_2': 0.035858154296875, 'loss_3': -15.04675006866455, 'loss_4': 10.90312385559082, 'epoch': 0.05}
{'loss': 2.0578, 'grad_norm': 128.6710968017578, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.0305638313293457, 'loss_2': 0.02728271484375, 'loss_3': -15.142717361450195, 'loss_4': 10.9385986328125, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:30,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:30,723 >>   Batch size = 64
  0%|▎                                                                                                                                               | 10/5160 [00:16<1:34:26,  1.10s/it][INFO|trainer.py:3910] 2025-01-21 09:24:34,512 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 09:24:34,514 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-10/config.json                                                                               
{'eval_loss': 0.7671265602111816, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.301, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.7591603994369507, 'eval_loss_2': 0.007966160774230957, 'eval_loss_3': -18.181560516357422, 'eval_loss_4': 10.535643577575684, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:34,959 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:34,960 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:34,960 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:35,775 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-5] due to args.save_total_limit
  0%|▍                                                                                                                                               | 15/5160 [00:21<1:38:09,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:24:39,413 >>
{'loss': 1.7346, 'grad_norm': 127.12548065185547, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 1.7252405881881714, 'loss_2': 0.00933837890625, 'loss_3': -15.233024597167969, 'loss_4': 10.958259582519531, 'epoch': 0.06}
{'loss': 1.5966, 'grad_norm': 117.2958755493164, 'learning_rate': 2.994767441860465e-05, 'loss_1': 1.5964977741241455, 'loss_2': 6.181001663208008e-05, 'loss_3': -15.143885612487793, 'loss_4': 10.294647216796875, 'epoch': 0.07}
{'loss': 1.47, 'grad_norm': 109.11693572998047, 'learning_rate': 2.994186046511628e-05, 'loss_1': 1.4640992879867554, 'loss_2': 0.0059356689453125, 'loss_3': -15.0408935546875, 'loss_4': 10.434975624084473, 'epoch': 0.08}
{'loss': 1.3233, 'grad_norm': 105.45940399169922, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 1.3082818984985352, 'loss_2': 0.014984130859375, 'loss_3': -15.176136016845703, 'loss_4': 9.71533489227295, 'epoch': 0.08}
{'loss': 1.027, 'grad_norm': 103.43467712402344, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.0262093544006348, 'loss_2': 0.0008234977722167969, 'loss_3': -15.246833801269531, 'loss_4': 10.421792984008789, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:39,413 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:39,413 >>   Batch size = 64
  0%|▍                                                                                                                                               | 15/5160 [00:25<1:38:09,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 09:24:43,217 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 09:24:43,218 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-15/config.json  
{'eval_loss': 0.3167320191860199, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.31394219398498535, 'eval_loss_2': 0.0027898550033569336, 'eval_loss_3': -18.024887084960938, 'eval_loss_4': 9.934603691101074, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:43,695 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:43,697 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:43,697 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:44,592 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:39:22,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:24:48,207 >>
{'loss': 1.0405, 'grad_norm': 98.21244812011719, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.0301042795181274, 'loss_2': 0.01043701171875, 'loss_3': -14.909005165100098, 'loss_4': 10.102853775024414, 'epoch': 0.09}
{'loss': 1.0646, 'grad_norm': 101.2044677734375, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.062984824180603, 'loss_2': 0.00165557861328125, 'loss_3': -15.120417594909668, 'loss_4': 10.811729431152344, 'epoch': 0.1}
{'loss': 0.8368, 'grad_norm': 82.62934112548828, 'learning_rate': 2.991279069767442e-05, 'loss_1': 0.8163383603096008, 'loss_2': 0.020477294921875, 'loss_3': -15.104018211364746, 'loss_4': 11.14438247680664, 'epoch': 0.1}
{'loss': 0.7345, 'grad_norm': 88.08451843261719, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 0.7292608022689819, 'loss_2': 0.00525665283203125, 'loss_3': -14.918302536010742, 'loss_4': 9.878826141357422, 'epoch': 0.11}
{'loss': 0.5068, 'grad_norm': 74.16165161132812, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 0.4978301227092743, 'loss_2': 0.0089263916015625, 'loss_3': -15.226543426513672, 'loss_4': 9.304647445678711, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:48,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:48,207 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:39:22,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 09:24:52,000 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 09:24:52,002 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-20/config.json                                                                               
{'eval_loss': 0.17123842239379883, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.039, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.1642778068780899, 'eval_loss_2': 0.006960630416870117, 'eval_loss_3': -17.969844818115234, 'eval_loss_4': 9.512227058410645, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:52,486 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:52,487 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:52,487 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:53,345 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:39<1:39:19,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:24:56,985 >>
{'loss': 0.5575, 'grad_norm': 71.9649887084961, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 0.5488853454589844, 'loss_2': 0.00861358642578125, 'loss_3': -15.039670944213867, 'loss_4': 8.986899375915527, 'epoch': 0.12}
{'loss': 0.4019, 'grad_norm': 58.23655700683594, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.3798450231552124, 'loss_2': 0.0220184326171875, 'loss_3': -15.329584121704102, 'loss_4': 9.271025657653809, 'epoch': 0.13}
{'loss': 0.3815, 'grad_norm': 53.637855529785156, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.3698205351829529, 'loss_2': 0.01171875, 'loss_3': -15.18074893951416, 'loss_4': 8.655784606933594, 'epoch': 0.13}
{'loss': 0.5496, 'grad_norm': 70.8321533203125, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.5320757031440735, 'loss_2': 0.017486572265625, 'loss_3': -14.902555465698242, 'loss_4': 9.206714630126953, 'epoch': 0.14}
{'loss': 0.3537, 'grad_norm': 55.898223876953125, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.34954389929771423, 'loss_2': 0.004123687744140625, 'loss_3': -15.229339599609375, 'loss_4': 8.606966018676758, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:56,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:56,986 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:42<1:39:19,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 09:25:00,764 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 09:25:00,766 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-25/config.json                                                                               
{'eval_loss': 0.13002413511276245, 'eval_runtime': 3.7774, 'eval_samples_per_second': 271.089, 'eval_steps_per_second': 4.236, 'eval_loss_1': 0.11499303579330444, 'eval_loss_2': 0.015031099319458008, 'eval_loss_3': -18.033573150634766, 'eval_loss_4': 9.188551902770996, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:01,233 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:01,234 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:01,234 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:02,127 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:47<1:39:09,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:25:05,755 >>
{'loss': 0.3645, 'grad_norm': 52.681392669677734, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.349203497171402, 'loss_2': 0.0152740478515625, 'loss_3': -15.231679916381836, 'loss_4': 8.817422866821289, 'epoch': 0.15}
{'loss': 0.396, 'grad_norm': 58.61442947387695, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.3786638081073761, 'loss_2': 0.017303466796875, 'loss_3': -15.378986358642578, 'loss_4': 9.512725830078125, 'epoch': 0.16}
{'loss': 0.3358, 'grad_norm': 56.1463508605957, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.3219301402568817, 'loss_2': 0.0138702392578125, 'loss_3': -15.020572662353516, 'loss_4': 8.05002212524414, 'epoch': 0.16}
{'loss': 0.3844, 'grad_norm': 55.56438064575195, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.36083337664604187, 'loss_2': 0.0236053466796875, 'loss_3': -15.36170768737793, 'loss_4': 8.073573112487793, 'epoch': 0.17}
{'loss': 0.2525, 'grad_norm': 42.215476989746094, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.23037660121917725, 'loss_2': 0.0220794677734375, 'loss_3': -15.229264259338379, 'loss_4': 9.478181838989258, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:05,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:05,755 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:51<1:39:09,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 09:25:09,536 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 09:25:09,538 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-30/config.json                                                                               
{'eval_loss': 0.08693735301494598, 'eval_runtime': 3.7801, 'eval_samples_per_second': 270.894, 'eval_steps_per_second': 4.233, 'eval_loss_1': 0.06450789421796799, 'eval_loss_2': 0.022429466247558594, 'eval_loss_3': -18.134220123291016, 'eval_loss_4': 9.584429740905762, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:10,017 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:10,018 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:10,018 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:10,937 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:56<1:39:17,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:25:14,559 >>
{'loss': 0.4074, 'grad_norm': 64.40411376953125, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.3818526566028595, 'loss_2': 0.0255126953125, 'loss_3': -14.99112319946289, 'loss_4': 10.48104476928711, 'epoch': 0.18}
{'loss': 0.219, 'grad_norm': 43.95608139038086, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.2040003538131714, 'loss_2': 0.01495361328125, 'loss_3': -15.042682647705078, 'loss_4': 9.201823234558105, 'epoch': 0.19}
{'loss': 0.2592, 'grad_norm': 48.037322998046875, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.23880897462368011, 'loss_2': 0.020355224609375, 'loss_3': -15.270406723022461, 'loss_4': 10.215450286865234, 'epoch': 0.19}
{'loss': 0.1672, 'grad_norm': 37.17743682861328, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.15802091360092163, 'loss_2': 0.0091705322265625, 'loss_3': -15.274599075317383, 'loss_4': 9.444526672363281, 'epoch': 0.2}
{'loss': 0.2829, 'grad_norm': 54.332881927490234, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.280760258436203, 'loss_2': 0.0020904541015625, 'loss_3': -14.933305740356445, 'loss_4': 10.311725616455078, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:14,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:14,560 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [01:00<1:39:17,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 09:25:18,371 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 09:25:18,372 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-35/config.json                                                                               
{'eval_loss': 0.046984776854515076, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.769, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.043724175542593, 'eval_loss_2': 0.003260597586631775, 'eval_loss_3': -18.16819953918457, 'eval_loss_4': 9.903809547424316, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:18,844 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:18,845 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:18,845 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:19,739 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:05<1:39:17,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:25:23,357 >>
{'loss': 0.2095, 'grad_norm': 44.0265998840332, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.20909422636032104, 'loss_2': 0.0004291534423828125, 'loss_3': -15.155134201049805, 'loss_4': 9.95833969116211, 'epoch': 0.21}
{'loss': 0.1739, 'grad_norm': 36.384517669677734, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.17159728705883026, 'loss_2': 0.002254486083984375, 'loss_3': -15.065963745117188, 'loss_4': 9.816884994506836, 'epoch': 0.22}
{'loss': 0.1749, 'grad_norm': 36.89330291748047, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.16435791552066803, 'loss_2': 0.0105438232421875, 'loss_3': -14.98045825958252, 'loss_4': 9.509380340576172, 'epoch': 0.22}
{'loss': 0.1518, 'grad_norm': 26.169933319091797, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.13741090893745422, 'loss_2': 0.014434814453125, 'loss_3': -15.153182983398438, 'loss_4': 8.626565933227539, 'epoch': 0.23}
{'loss': 0.1563, 'grad_norm': 30.92939567565918, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.14289934933185577, 'loss_2': 0.0134429931640625, 'loss_3': -15.100088119506836, 'loss_4': 8.985372543334961, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:23,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:23,358 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:12<1:30:12,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:25:30,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.053818024694919586, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.836, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.033827584236860275, 'eval_loss_2': 0.01999044418334961, 'eval_loss_3': -18.227832794189453, 'eval_loss_4': 8.685491561889648, 'epoch': 0.23}
{'loss': 0.2166, 'grad_norm': 40.98482894897461, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.1970103532075882, 'loss_2': 0.019622802734375, 'loss_3': -15.055398941040039, 'loss_4': 8.789228439331055, 'epoch': 0.24}
{'loss': 0.181, 'grad_norm': 39.527530670166016, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.16578327119350433, 'loss_2': 0.0152130126953125, 'loss_3': -15.025800704956055, 'loss_4': 7.355599403381348, 'epoch': 0.24}
{'loss': 0.2217, 'grad_norm': 41.07899475097656, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.20067735016345978, 'loss_2': 0.0210418701171875, 'loss_3': -14.949109077453613, 'loss_4': 7.861080169677734, 'epoch': 0.25}
{'loss': 0.2911, 'grad_norm': 34.9738655090332, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.27945202589035034, 'loss_2': 0.01165771484375, 'loss_3': -14.78465461730957, 'loss_4': 8.056596755981445, 'epoch': 0.26}
{'loss': 0.2106, 'grad_norm': 42.68656539916992, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.20728756487369537, 'loss_2': 0.003299713134765625, 'loss_3': -14.833982467651367, 'loss_4': 7.540444374084473, 'epoch': 0.26}
[INFO|trainer.py:4228] 2025-01-21 09:25:30,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:30,697 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:16<1:30:12,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 09:25:34,489 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 09:25:34,490 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-45/config.json                                                                               
{'eval_loss': 0.03206844627857208, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.085, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.029075032100081444, 'eval_loss_2': 0.0029934123158454895, 'eval_loss_3': -18.192338943481445, 'eval_loss_4': 7.470352649688721, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:34,959 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:34,960 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:34,961 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:35,843 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-35] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:21<1:37:30,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:25:39,485 >>
{'loss': 0.2098, 'grad_norm': 45.07666015625, 'learning_rate': 2.975e-05, 'loss_1': 0.20636272430419922, 'loss_2': 0.003459930419921875, 'loss_3': -14.772525787353516, 'loss_4': 7.254175186157227, 'epoch': 0.27}
{'loss': 0.2212, 'grad_norm': 44.23357009887695, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.2166609913110733, 'loss_2': 0.0045013427734375, 'loss_3': -14.821718215942383, 'loss_4': 6.868587493896484, 'epoch': 0.27}
{'loss': 0.1904, 'grad_norm': 46.285640716552734, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.18029625713825226, 'loss_2': 0.0100860595703125, 'loss_3': -14.941503524780273, 'loss_4': 7.209462642669678, 'epoch': 0.28}
{'loss': 0.2572, 'grad_norm': 46.294395446777344, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.24209409952163696, 'loss_2': 0.01507568359375, 'loss_3': -14.7720947265625, 'loss_4': 7.80905818939209, 'epoch': 0.28}
{'loss': 0.2319, 'grad_norm': 35.24596405029297, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.20690223574638367, 'loss_2': 0.0250244140625, 'loss_3': -14.760356903076172, 'loss_4': 7.026653289794922, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:39,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:39,485 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:28<1:29:49,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:25:46,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.044240646064281464, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.435, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.028680497780442238, 'eval_loss_2': 0.015560150146484375, 'eval_loss_3': -18.139097213745117, 'eval_loss_4': 6.92746114730835, 'epoch': 0.29}
{'loss': 0.2241, 'grad_norm': 45.4349479675293, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.20433077216148376, 'loss_2': 0.019775390625, 'loss_3': -14.830266952514648, 'loss_4': 6.508305549621582, 'epoch': 0.3}
{'loss': 0.1641, 'grad_norm': 35.94048309326172, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.1553880274295807, 'loss_2': 0.0087127685546875, 'loss_3': -14.829973220825195, 'loss_4': 7.252001762390137, 'epoch': 0.3}
{'loss': 0.1689, 'grad_norm': 35.099945068359375, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.1606181412935257, 'loss_2': 0.008331298828125, 'loss_3': -14.991303443908691, 'loss_4': 6.930891990661621, 'epoch': 0.31}
{'loss': 0.1848, 'grad_norm': 41.72781753540039, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.17337475717067719, 'loss_2': 0.0114288330078125, 'loss_3': -14.98977279663086, 'loss_4': 7.338527679443359, 'epoch': 0.31}
{'loss': 0.1909, 'grad_norm': 39.4797248840332, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.18126337230205536, 'loss_2': 0.009613037109375, 'loss_3': -14.984254837036133, 'loss_4': 6.808352470397949, 'epoch': 0.32}
[INFO|trainer.py:4228] 2025-01-21 09:25:46,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:46,819 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:36<1:28:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:25:54,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03345852345228195, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.918, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.030342210084199905, 'eval_loss_2': 0.003116309642791748, 'eval_loss_3': -18.163686752319336, 'eval_loss_4': 7.337362289428711, 'epoch': 0.32}
{'loss': 0.1136, 'grad_norm': 23.75261116027832, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.11349087953567505, 'loss_2': 6.961822509765625e-05, 'loss_3': -15.210260391235352, 'loss_4': 6.575235843658447, 'epoch': 0.33}
{'loss': 0.2507, 'grad_norm': 52.22456741333008, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.24835427105426788, 'loss_2': 0.0023956298828125, 'loss_3': -14.886611938476562, 'loss_4': 7.328057765960693, 'epoch': 0.33}
{'loss': 0.206, 'grad_norm': 44.55483627319336, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.20347608625888824, 'loss_2': 0.0025482177734375, 'loss_3': -14.787126541137695, 'loss_4': 7.580691814422607, 'epoch': 0.34}
{'loss': 0.227, 'grad_norm': 43.37122344970703, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.2236485332250595, 'loss_2': 0.003398895263671875, 'loss_3': -14.91551399230957, 'loss_4': 7.565375328063965, 'epoch': 0.34}
{'loss': 0.1489, 'grad_norm': 36.94654846191406, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.14792920649051666, 'loss_2': 0.0009317398071289062, 'loss_3': -15.007804870605469, 'loss_4': 7.165475368499756, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 09:25:54,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:54,169 >>   Batch size = 64
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:43<1:28:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:01,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04674151539802551, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.08, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.035679131746292114, 'eval_loss_2': 0.011062383651733398, 'eval_loss_3': -18.144100189208984, 'eval_loss_4': 7.5755157470703125, 'epoch': 0.35}
{'loss': 0.2363, 'grad_norm': 44.23420333862305, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.2276299148797989, 'loss_2': 0.0086822509765625, 'loss_3': -15.015008926391602, 'loss_4': 7.866358757019043, 'epoch': 0.35}
{'loss': 0.2229, 'grad_norm': 39.67840576171875, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.21329425275325775, 'loss_2': 0.00963592529296875, 'loss_3': -15.039871215820312, 'loss_4': 8.235115051269531, 'epoch': 0.36}
{'loss': 0.1138, 'grad_norm': 27.92351531982422, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.09928108751773834, 'loss_2': 0.01451873779296875, 'loss_3': -14.9590482711792, 'loss_4': 7.226735591888428, 'epoch': 0.37}
{'loss': 0.1599, 'grad_norm': 32.03504943847656, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.14858926832675934, 'loss_2': 0.01136016845703125, 'loss_3': -15.104434967041016, 'loss_4': 7.847620487213135, 'epoch': 0.37}
{'loss': 0.2006, 'grad_norm': 44.51914978027344, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.18634766340255737, 'loss_2': 0.0142669677734375, 'loss_3': -14.840872764587402, 'loss_4': 7.904242038726807, 'epoch': 0.38}
[INFO|trainer.py:4228] 2025-01-21 09:26:01,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:01,513 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:51<1:28:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:08,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03641527518630028, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.703, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.031435828655958176, 'eval_loss_2': 0.004979446530342102, 'eval_loss_3': -18.183055877685547, 'eval_loss_4': 7.621556758880615, 'epoch': 0.38}
{'loss': 0.1308, 'grad_norm': 37.753173828125, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.11852376908063889, 'loss_2': 0.0122528076171875, 'loss_3': -15.258121490478516, 'loss_4': 7.716431617736816, 'epoch': 0.38}
{'loss': 0.1187, 'grad_norm': 24.4793758392334, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.10936564952135086, 'loss_2': 0.00931549072265625, 'loss_3': -14.753408432006836, 'loss_4': 7.199163913726807, 'epoch': 0.39}
{'loss': 0.1858, 'grad_norm': 41.09149169921875, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.18466100096702576, 'loss_2': 0.0011749267578125, 'loss_3': -14.860101699829102, 'loss_4': 7.080765247344971, 'epoch': 0.4}
{'loss': 0.1337, 'grad_norm': 23.76888084411621, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.12836666405200958, 'loss_2': 0.005321502685546875, 'loss_3': -15.004678726196289, 'loss_4': 7.905648708343506, 'epoch': 0.4}
{'loss': 0.0776, 'grad_norm': 18.8132381439209, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.07354465126991272, 'loss_2': 0.00408172607421875, 'loss_3': -14.91137981414795, 'loss_4': 6.356983661651611, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 09:26:08,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:08,874 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [01:58<1:28:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:16,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032920025289058685, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.247, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.025289084762334824, 'eval_loss_2': 0.00763094425201416, 'eval_loss_3': -18.26347541809082, 'eval_loss_4': 7.505902290344238, 'epoch': 0.41}
{'loss': 0.1162, 'grad_norm': 25.87030601501465, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.1141408309340477, 'loss_2': 0.002048492431640625, 'loss_3': -14.942075729370117, 'loss_4': 7.12716007232666, 'epoch': 0.41}
{'loss': 0.1879, 'grad_norm': 36.186153411865234, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.17132613062858582, 'loss_2': 0.0165252685546875, 'loss_3': -15.014081001281738, 'loss_4': 7.265389919281006, 'epoch': 0.42}
{'loss': 0.1738, 'grad_norm': 31.046348571777344, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.15292508900165558, 'loss_2': 0.020843505859375, 'loss_3': -15.187227249145508, 'loss_4': 8.542819023132324, 'epoch': 0.42}
{'loss': 0.0936, 'grad_norm': 19.527088165283203, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.074435755610466, 'loss_2': 0.0191650390625, 'loss_3': -14.986392974853516, 'loss_4': 6.618653774261475, 'epoch': 0.43}
{'loss': 0.1586, 'grad_norm': 33.927513122558594, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.14017611742019653, 'loss_2': 0.018463134765625, 'loss_3': -15.140295028686523, 'loss_4': 7.164538383483887, 'epoch': 0.44}
[INFO|trainer.py:4228] 2025-01-21 09:26:16,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:16,224 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:05<1:28:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:23,574 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03883091360330582, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.112, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.02708069235086441, 'eval_loss_2': 0.011750221252441406, 'eval_loss_3': -18.2736873626709, 'eval_loss_4': 7.375399589538574, 'epoch': 0.44}
{'loss': 0.1039, 'grad_norm': 18.435272216796875, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.09453574568033218, 'loss_2': 0.0093994140625, 'loss_3': -15.365888595581055, 'loss_4': 8.221874237060547, 'epoch': 0.44}
{'loss': 0.1326, 'grad_norm': 31.52557373046875, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.12873326241970062, 'loss_2': 0.00391387939453125, 'loss_3': -15.034333229064941, 'loss_4': 6.404619216918945, 'epoch': 0.45}
{'loss': 0.1433, 'grad_norm': 29.91544532775879, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.1410847306251526, 'loss_2': 0.0021915435791015625, 'loss_3': -14.805279731750488, 'loss_4': 6.601751327514648, 'epoch': 0.45}
{'loss': 0.1569, 'grad_norm': 39.17040252685547, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.15646211802959442, 'loss_2': 0.00041294097900390625, 'loss_3': -14.96604061126709, 'loss_4': 7.051955223083496, 'epoch': 0.46}
{'loss': 0.1857, 'grad_norm': 40.94819641113281, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.18177297711372375, 'loss_2': 0.00390625, 'loss_3': -15.071024894714355, 'loss_4': 6.493225574493408, 'epoch': 0.47}
[INFO|trainer.py:4228] 2025-01-21 09:26:23,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:23,574 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:28:01,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:26:27,368 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-80
[INFO|configuration_utils.py:420] 2025-01-21 09:26:27,369 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-80/config.json                                                                               
{'eval_loss': 0.03170105069875717, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.006, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.025491077452898026, 'eval_loss_2': 0.006209969520568848, 'eval_loss_3': -18.270544052124023, 'eval_loss_4': 6.551488876342773, 'epoch': 0.47}
[INFO|modeling_utils.py:2988] 2025-01-21 09:26:27,858 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-80/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:26:27,860 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-80/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:26:27,860 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-80/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:26:28,750 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-45] due to args.save_total_limit
[INFO|trainer.py:4002] 2025-01-21 09:26:28,838 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-65] due to args.save_total_limit
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:14<1:37:23,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:26:32,478 >>
{'loss': 0.1361, 'grad_norm': 27.778804779052734, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.135896697640419, 'loss_2': 0.00015938282012939453, 'loss_3': -15.133545875549316, 'loss_4': 6.835853576660156, 'epoch': 0.47}
{'loss': 0.1448, 'grad_norm': 40.741519927978516, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.14292140305042267, 'loss_2': 0.0018358230590820312, 'loss_3': -15.049964904785156, 'loss_4': 6.047647476196289, 'epoch': 0.48}
{'loss': 0.0912, 'grad_norm': 23.42730712890625, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.08979418873786926, 'loss_2': 0.0014257431030273438, 'loss_3': -15.46721076965332, 'loss_4': 6.384211540222168, 'epoch': 0.48}
{'loss': 0.1435, 'grad_norm': 37.12110137939453, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.14185050129890442, 'loss_2': 0.001613616943359375, 'loss_3': -15.066685676574707, 'loss_4': 5.146093368530273, 'epoch': 0.49}
{'loss': 0.12, 'grad_norm': 25.45574378967285, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.1154213547706604, 'loss_2': 0.004573822021484375, 'loss_3': -14.994236946105957, 'loss_4': 5.86517858505249, 'epoch': 0.49}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:26:32,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:32,478 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:22<1:29:37,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:26:39,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03892985358834267, 'eval_runtime': 3.8355, 'eval_samples_per_second': 266.977, 'eval_steps_per_second': 4.172, 'eval_loss_1': 0.029458675533533096, 'eval_loss_2': 0.00947117805480957, 'eval_loss_3': -18.187456130981445, 'eval_loss_4': 5.002561569213867, 'epoch': 0.49}
{'loss': 0.1612, 'grad_norm': 29.5097599029541, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.15696699917316437, 'loss_2': 0.004276275634765625, 'loss_3': -15.12922477722168, 'loss_4': 5.571329116821289, 'epoch': 0.5}
{'loss': 0.1139, 'grad_norm': 23.658592224121094, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.1032981127500534, 'loss_2': 0.01056671142578125, 'loss_3': -15.277759552001953, 'loss_4': 5.94476318359375, 'epoch': 0.51}
{'loss': 0.1619, 'grad_norm': 36.83082580566406, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.1553172916173935, 'loss_2': 0.006557464599609375, 'loss_3': -14.834991455078125, 'loss_4': 4.401078224182129, 'epoch': 0.51}
{'loss': 0.1603, 'grad_norm': 33.2908935546875, 'learning_rate': 2.95e-05, 'loss_1': 0.14479051530361176, 'loss_2': 0.01552581787109375, 'loss_3': -15.062653541564941, 'loss_4': 4.86600399017334, 'epoch': 0.52}
{'loss': 0.0965, 'grad_norm': 23.72869300842285, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.0861266553401947, 'loss_2': 0.0103607177734375, 'loss_3': -15.19331169128418, 'loss_4': 4.543426990509033, 'epoch': 0.52}
[INFO|trainer.py:4228] 2025-01-21 09:26:39,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:39,864 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:29<1:28:13,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:26:47,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035101741552352905, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.218, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.026982635259628296, 'eval_loss_2': 0.00811910629272461, 'eval_loss_3': -18.245372772216797, 'eval_loss_4': 4.3639678955078125, 'epoch': 0.52}
{'loss': 0.1783, 'grad_norm': 50.479862213134766, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.17156481742858887, 'loss_2': 0.00670623779296875, 'loss_3': -15.146373748779297, 'loss_4': 4.767696380615234, 'epoch': 0.53}
{'loss': 0.0667, 'grad_norm': 17.29344940185547, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.06552647799253464, 'loss_2': 0.0011615753173828125, 'loss_3': -15.180631637573242, 'loss_4': 4.981601715087891, 'epoch': 0.53}
{'loss': 0.1212, 'grad_norm': 31.27381134033203, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.11853370815515518, 'loss_2': 0.0026397705078125, 'loss_3': -15.074793815612793, 'loss_4': 4.503944396972656, 'epoch': 0.54}
{'loss': 0.117, 'grad_norm': 30.008573532104492, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.1103024035692215, 'loss_2': 0.0067138671875, 'loss_3': -15.133821487426758, 'loss_4': 4.758703231811523, 'epoch': 0.55}
{'loss': 0.1032, 'grad_norm': 25.469280242919922, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.0876040905714035, 'loss_2': 0.01560211181640625, 'loss_3': -14.90151596069336, 'loss_4': 4.817240238189697, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 09:26:47,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:47,244 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:36<1:27:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:54,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0376286655664444, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.447, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.028604287654161453, 'eval_loss_2': 0.009024381637573242, 'eval_loss_3': -18.182079315185547, 'eval_loss_4': 4.913275718688965, 'epoch': 0.55}
{'loss': 0.1028, 'grad_norm': 26.544517517089844, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.09066120535135269, 'loss_2': 0.0121002197265625, 'loss_3': -14.898544311523438, 'loss_4': 4.952387809753418, 'epoch': 0.56}
{'loss': 0.1427, 'grad_norm': 36.361549377441406, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.13599751889705658, 'loss_2': 0.006744384765625, 'loss_3': -14.92151927947998, 'loss_4': 5.012028694152832, 'epoch': 0.56}
{'loss': 0.1052, 'grad_norm': 23.759511947631836, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.1004553809762001, 'loss_2': 0.004730224609375, 'loss_3': -14.869867324829102, 'loss_4': 4.686665058135986, 'epoch': 0.57}
{'loss': 0.1121, 'grad_norm': 26.530179977416992, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.09816763550043106, 'loss_2': 0.013916015625, 'loss_3': -14.703997611999512, 'loss_4': 5.791500091552734, 'epoch': 0.58}
{'loss': 0.1439, 'grad_norm': 31.756532669067383, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.14337515830993652, 'loss_2': 0.000514984130859375, 'loss_3': -14.947671890258789, 'loss_4': 6.022960662841797, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 09:26:54,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:54,615 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:44<1:27:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:01,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.047557808458805084, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.04152202606201172, 'eval_loss_2': 0.0060357749462127686, 'eval_loss_3': -18.055368423461914, 'eval_loss_4': 5.396620273590088, 'epoch': 0.58}
{'loss': 0.1023, 'grad_norm': 27.5924015045166, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.10147669166326523, 'loss_2': 0.0007796287536621094, 'loss_3': -14.929126739501953, 'loss_4': 5.422840118408203, 'epoch': 0.59}
{'loss': 0.1622, 'grad_norm': 39.39031219482422, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.15925803780555725, 'loss_2': 0.00298309326171875, 'loss_3': -14.810766220092773, 'loss_4': 5.272542953491211, 'epoch': 0.59}
{'loss': 0.1575, 'grad_norm': 37.00169372558594, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.1497681736946106, 'loss_2': 0.00775146484375, 'loss_3': -14.958313941955566, 'loss_4': 7.369414329528809, 'epoch': 0.6}
{'loss': 0.1418, 'grad_norm': 35.938812255859375, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.1345156878232956, 'loss_2': 0.00727081298828125, 'loss_3': -14.92922592163086, 'loss_4': 6.103765487670898, 'epoch': 0.6}
{'loss': 0.0963, 'grad_norm': 29.089914321899414, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.08749575167894363, 'loss_2': 0.0087738037109375, 'loss_3': -15.11790657043457, 'loss_4': 6.183413982391357, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 09:27:01,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:01,990 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:51<1:27:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:09,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03310132026672363, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.805, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.024290261790156364, 'eval_loss_2': 0.00881105661392212, 'eval_loss_3': -18.105268478393555, 'eval_loss_4': 5.657905578613281, 'epoch': 0.61}
{'loss': 0.0965, 'grad_norm': 28.769338607788086, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.09229859709739685, 'loss_2': 0.0041961669921875, 'loss_3': -14.785813331604004, 'loss_4': 5.911513328552246, 'epoch': 0.62}
{'loss': 0.1001, 'grad_norm': 27.976905822753906, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.0966644287109375, 'loss_2': 0.003444671630859375, 'loss_3': -14.822502136230469, 'loss_4': 6.106104373931885, 'epoch': 0.62}
{'loss': 0.1198, 'grad_norm': 24.638093948364258, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.10375478118658066, 'loss_2': 0.0160369873046875, 'loss_3': -14.767003059387207, 'loss_4': 6.1130690574646, 'epoch': 0.63}
{'loss': 0.0878, 'grad_norm': 25.770248413085938, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.0842321366071701, 'loss_2': 0.00354766845703125, 'loss_3': -14.754373550415039, 'loss_4': 6.289975643157959, 'epoch': 0.63}
{'loss': 0.0796, 'grad_norm': 19.70258140563965, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.07529901713132858, 'loss_2': 0.00432586669921875, 'loss_3': -14.891090393066406, 'loss_4': 6.742220878601074, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 09:27:09,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:09,367 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:55<1:27:48,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:27:13,174 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-110
[INFO|configuration_utils.py:420] 2025-01-21 09:27:13,176 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-110/config.json                                                                              
{'eval_loss': 0.023418456315994263, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.046, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013233211822807789, 'eval_loss_2': 0.01018524169921875, 'eval_loss_3': -18.220317840576172, 'eval_loss_4': 6.608080863952637, 'epoch': 0.64}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:13,625 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-110/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:13,626 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-110/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:13,626 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-110/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:14,474 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-80] due to args.save_total_limit
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:00<1:36:04,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:27:18,129 >>
{'loss': 0.1644, 'grad_norm': 39.6655158996582, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.15492290258407593, 'loss_2': 0.0094757080078125, 'loss_3': -14.739171981811523, 'loss_4': 7.0469512939453125, 'epoch': 0.65}
{'loss': 0.1007, 'grad_norm': 29.67112159729004, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.09466034919023514, 'loss_2': 0.006053924560546875, 'loss_3': -14.958388328552246, 'loss_4': 7.674160003662109, 'epoch': 0.65}
{'loss': 0.091, 'grad_norm': 25.3930606842041, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.07868387550115585, 'loss_2': 0.0123291015625, 'loss_3': -14.860408782958984, 'loss_4': 6.760807991027832, 'epoch': 0.66}
{'loss': 0.0515, 'grad_norm': 13.293017387390137, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.047805096954107285, 'loss_2': 0.0036773681640625, 'loss_3': -15.125160217285156, 'loss_4': 7.039305210113525, 'epoch': 0.66}
{'loss': 0.069, 'grad_norm': 17.293699264526367, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.06737120449542999, 'loss_2': 0.0016117095947265625, 'loss_3': -15.018196105957031, 'loss_4': 6.109958171844482, 'epoch': 0.67}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:18,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:18,129 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:04<1:36:04,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 09:27:21,936 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-115
[INFO|configuration_utils.py:420] 2025-01-21 09:27:21,937 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-115/config.json                                                                              
{'eval_loss': 0.017687637358903885, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.071, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013218183070421219, 'eval_loss_2': 0.004469454288482666, 'eval_loss_3': -18.25786781311035, 'eval_loss_4': 6.160764694213867, 'epoch': 0.67}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:22,421 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-115/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:22,422 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-115/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:22,423 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-115/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:23,338 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-110] due to args.save_total_limit
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:09<1:37:53,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 09:27:26,986 >>
{'loss': 0.0861, 'grad_norm': 19.60814666748047, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.07573644816875458, 'loss_2': 0.0103302001953125, 'loss_3': -15.031901359558105, 'loss_4': 7.583651542663574, 'epoch': 0.67}
{'loss': 0.0824, 'grad_norm': 27.220155715942383, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.07337847352027893, 'loss_2': 0.0090179443359375, 'loss_3': -14.808938980102539, 'loss_4': 6.238068580627441, 'epoch': 0.68}
{'loss': 0.0802, 'grad_norm': 24.287731170654297, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.06304038316011429, 'loss_2': 0.0171661376953125, 'loss_3': -14.822919845581055, 'loss_4': 6.147229194641113, 'epoch': 0.69}
{'loss': 0.0857, 'grad_norm': 17.888261795043945, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.06833942234516144, 'loss_2': 0.0174102783203125, 'loss_3': -14.743271827697754, 'loss_4': 5.99924373626709, 'epoch': 0.69}
{'loss': 0.0936, 'grad_norm': 29.071292877197266, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.08430556952953339, 'loss_2': 0.0092620849609375, 'loss_3': -14.828176498413086, 'loss_4': 5.964430809020996, 'epoch': 0.7}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:26,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:26,986 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:16<1:29:11,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:27:34,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029100676998496056, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.643, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.016643542796373367, 'eval_loss_2': 0.012457132339477539, 'eval_loss_3': -18.084827423095703, 'eval_loss_4': 5.391696453094482, 'epoch': 0.7}
{'loss': 0.0669, 'grad_norm': 17.447723388671875, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.054664645344018936, 'loss_2': 0.01226806640625, 'loss_3': -14.912206649780273, 'loss_4': 5.017617702484131, 'epoch': 0.7}
{'loss': 0.0627, 'grad_norm': 14.062850952148438, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.04944800212979317, 'loss_2': 0.0132293701171875, 'loss_3': -14.909624099731445, 'loss_4': 5.63423490524292, 'epoch': 0.71}
{'loss': 0.0663, 'grad_norm': 16.80912208557129, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.06468436866998672, 'loss_2': 0.0016031265258789062, 'loss_3': -14.675168991088867, 'loss_4': 5.763355731964111, 'epoch': 0.72}
{'loss': 0.0638, 'grad_norm': 15.567666053771973, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.05029637739062309, 'loss_2': 0.013458251953125, 'loss_3': -14.957321166992188, 'loss_4': 4.957171440124512, 'epoch': 0.72}
{'loss': 0.046, 'grad_norm': 12.18802547454834, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.04497549310326576, 'loss_2': 0.00102996826171875, 'loss_3': -14.97899055480957, 'loss_4': 5.559664249420166, 'epoch': 0.73}
[INFO|trainer.py:4228] 2025-01-21 09:27:34,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:34,359 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:23<1:27:39,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:27:41,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05041050165891647, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.358, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.04436459764838219, 'eval_loss_2': 0.006045907735824585, 'eval_loss_3': -17.99810028076172, 'eval_loss_4': 6.5592522621154785, 'epoch': 0.73}
{'loss': 0.0706, 'grad_norm': 24.447221755981445, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.06668096780776978, 'loss_2': 0.003894805908203125, 'loss_3': -15.004501342773438, 'loss_4': 5.891347408294678, 'epoch': 0.73}
{'loss': 0.1212, 'grad_norm': 29.4061222076416, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.11076220870018005, 'loss_2': 0.01044464111328125, 'loss_3': -14.720565795898438, 'loss_4': 6.66949987411499, 'epoch': 0.74}
{'loss': 0.1304, 'grad_norm': 25.355606079101562, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.11514264345169067, 'loss_2': 0.0152435302734375, 'loss_3': -14.834224700927734, 'loss_4': 6.645717620849609, 'epoch': 0.74}
{'loss': 0.1393, 'grad_norm': 33.787227630615234, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.12599672377109528, 'loss_2': 0.013275146484375, 'loss_3': -15.224157333374023, 'loss_4': 7.416288375854492, 'epoch': 0.75}
{'loss': 0.2302, 'grad_norm': 38.395416259765625, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.2037448137998581, 'loss_2': 0.026458740234375, 'loss_3': -15.149713516235352, 'loss_4': 7.469770431518555, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 09:27:41,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:41,727 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:31<1:27:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:49,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07169417291879654, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0570547953248024, 'eval_loss_2': 0.01463937759399414, 'eval_loss_3': -17.98511505126953, 'eval_loss_4': 7.316303730010986, 'epoch': 0.76}
{'loss': 0.1495, 'grad_norm': 40.811092376708984, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.13953404128551483, 'loss_2': 0.0099334716796875, 'loss_3': -15.13007926940918, 'loss_4': 6.828120708465576, 'epoch': 0.76}
{'loss': 0.1094, 'grad_norm': 26.454906463623047, 'learning_rate': 2.925e-05, 'loss_1': 0.10192299634218216, 'loss_2': 0.00745391845703125, 'loss_3': -14.766390800476074, 'loss_4': 6.570767402648926, 'epoch': 0.77}
{'loss': 0.1114, 'grad_norm': 23.541772842407227, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.1082790344953537, 'loss_2': 0.003078460693359375, 'loss_3': -15.09408187866211, 'loss_4': 6.804459571838379, 'epoch': 0.77}
{'loss': 0.1311, 'grad_norm': 28.58628273010254, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.12860895693302155, 'loss_2': 0.0025348663330078125, 'loss_3': -14.9825439453125, 'loss_4': 6.640763282775879, 'epoch': 0.78}
{'loss': 0.0678, 'grad_norm': 14.730037689208984, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.06160528585314751, 'loss_2': 0.00616455078125, 'loss_3': -15.106139183044434, 'loss_4': 6.858305931091309, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 09:27:49,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:49,092 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:38<1:27:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:56,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.043511323630809784, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.032728154212236404, 'eval_loss_2': 0.010783165693283081, 'eval_loss_3': -18.05519676208496, 'eval_loss_4': 6.345579147338867, 'epoch': 0.78}
{'loss': 0.0841, 'grad_norm': 20.945167541503906, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.0685795322060585, 'loss_2': 0.01549530029296875, 'loss_3': -15.339637756347656, 'loss_4': 6.796160697937012, 'epoch': 0.79}
{'loss': 0.0964, 'grad_norm': 22.724809646606445, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.07591985166072845, 'loss_2': 0.0205078125, 'loss_3': -15.257268905639648, 'loss_4': 6.4617919921875, 'epoch': 0.8}
{'loss': 0.0929, 'grad_norm': 20.052165985107422, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.08105290681123734, 'loss_2': 0.011810302734375, 'loss_3': -15.158223152160645, 'loss_4': 6.480950355529785, 'epoch': 0.8}
{'loss': 0.0574, 'grad_norm': 13.763049125671387, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.04396659508347511, 'loss_2': 0.01338958740234375, 'loss_3': -14.968978881835938, 'loss_4': 5.168851375579834, 'epoch': 0.81}
{'loss': 0.0674, 'grad_norm': 34.10614013671875, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.05918411538004875, 'loss_2': 0.00824737548828125, 'loss_3': -15.054474830627441, 'loss_4': 5.858392715454102, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 09:27:56,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:56,461 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:46<1:27:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:03,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02689063362777233, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.429, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0173755194991827, 'eval_loss_2': 0.00951511412858963, 'eval_loss_3': -18.211904525756836, 'eval_loss_4': 5.774293422698975, 'epoch': 0.81}
{'loss': 0.0781, 'grad_norm': 16.240663528442383, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.06155644357204437, 'loss_2': 0.01654052734375, 'loss_3': -15.028810501098633, 'loss_4': 5.444832801818848, 'epoch': 0.82}
{'loss': 0.0598, 'grad_norm': 16.77230453491211, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.05605781450867653, 'loss_2': 0.00371551513671875, 'loss_3': -15.166932106018066, 'loss_4': 6.045670986175537, 'epoch': 0.83}
{'loss': 0.0762, 'grad_norm': 22.793903350830078, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.07451102137565613, 'loss_2': 0.0017223358154296875, 'loss_3': -14.939251899719238, 'loss_4': 5.356255531311035, 'epoch': 0.83}
{'loss': 0.0549, 'grad_norm': 16.42658233642578, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.05295291170477867, 'loss_2': 0.001964569091796875, 'loss_3': -15.186750411987305, 'loss_4': 6.251690864562988, 'epoch': 0.84}
{'loss': 0.0634, 'grad_norm': 20.295507431030273, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.06112291291356087, 'loss_2': 0.002231597900390625, 'loss_3': -15.269379615783691, 'loss_4': 7.1078290939331055, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 09:28:03,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:03,843 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:53<1:27:24,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:28:11,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020049747079610825, 'eval_runtime': 3.8209, 'eval_samples_per_second': 268.001, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.012268478982150555, 'eval_loss_2': 0.007781267166137695, 'eval_loss_3': -18.345947265625, 'eval_loss_4': 6.346548080444336, 'epoch': 0.84}
{'loss': 0.0813, 'grad_norm': 22.479482650756836, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.07404989749193192, 'loss_2': 0.007282257080078125, 'loss_3': -15.182541847229004, 'loss_4': 6.606380462646484, 'epoch': 0.85}
{'loss': 0.0994, 'grad_norm': 29.700620651245117, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.09426752477884293, 'loss_2': 0.005157470703125, 'loss_3': -15.118255615234375, 'loss_4': 8.11372184753418, 'epoch': 0.85}
{'loss': 0.0841, 'grad_norm': 21.064796447753906, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.07057454437017441, 'loss_2': 0.01354217529296875, 'loss_3': -15.286111831665039, 'loss_4': 7.404841899871826, 'epoch': 0.86}
{'loss': 0.0557, 'grad_norm': 11.420830726623535, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.039967361837625504, 'loss_2': 0.0157470703125, 'loss_3': -15.465869903564453, 'loss_4': 7.510404586791992, 'epoch': 0.87}
{'loss': 0.0658, 'grad_norm': 15.411728858947754, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.051247697323560715, 'loss_2': 0.01454925537109375, 'loss_3': -15.246818542480469, 'loss_4': 7.850613117218018, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 09:28:11,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:11,246 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:00<1:27:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:18,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024362947791814804, 'eval_runtime': 3.8234, 'eval_samples_per_second': 267.822, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.016022633761167526, 'eval_loss_2': 0.008340314030647278, 'eval_loss_3': -18.416688919067383, 'eval_loss_4': 6.977259635925293, 'epoch': 0.87}
{'loss': 0.0606, 'grad_norm': 14.473542213439941, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.05718878656625748, 'loss_2': 0.003452301025390625, 'loss_3': -15.330705642700195, 'loss_4': 7.339570045471191, 'epoch': 0.88}
{'loss': 0.1192, 'grad_norm': 31.12625503540039, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.10377199202775955, 'loss_2': 0.01540374755859375, 'loss_3': -15.396949768066406, 'loss_4': 6.936294078826904, 'epoch': 0.88}
{'loss': 0.0999, 'grad_norm': 24.408632278442383, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.09159190952777863, 'loss_2': 0.0083465576171875, 'loss_3': -15.18855094909668, 'loss_4': 6.034747123718262, 'epoch': 0.89}
{'loss': 0.079, 'grad_norm': 21.359909057617188, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.07818228006362915, 'loss_2': 0.0007829666137695312, 'loss_3': -15.336410522460938, 'loss_4': 7.566801071166992, 'epoch': 0.9}
{'loss': 0.068, 'grad_norm': 15.133197784423828, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.06710272282361984, 'loss_2': 0.0009112358093261719, 'loss_3': -15.224372863769531, 'loss_4': 6.2905120849609375, 'epoch': 0.9}
[INFO|trainer.py:4228] 2025-01-21 09:28:18,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:18,628 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:08<1:26:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:25,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02065606415271759, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014180256053805351, 'eval_loss_2': 0.00647580623626709, 'eval_loss_3': -18.415424346923828, 'eval_loss_4': 5.377678871154785, 'epoch': 0.9}
{'loss': 0.0511, 'grad_norm': 12.997286796569824, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.04677976667881012, 'loss_2': 0.004364013671875, 'loss_3': -15.449705123901367, 'loss_4': 4.974721431732178, 'epoch': 0.91}
{'loss': 0.0951, 'grad_norm': 20.14742088317871, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.08469989150762558, 'loss_2': 0.0103759765625, 'loss_3': -15.196463584899902, 'loss_4': 6.581815719604492, 'epoch': 0.91}
{'loss': 0.0655, 'grad_norm': 13.195328712463379, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.05329694598913193, 'loss_2': 0.01224517822265625, 'loss_3': -15.406085014343262, 'loss_4': 5.371610641479492, 'epoch': 0.92}
{'loss': 0.0785, 'grad_norm': 17.454858779907227, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.06835544109344482, 'loss_2': 0.0101776123046875, 'loss_3': -15.241207122802734, 'loss_4': 5.145060062408447, 'epoch': 0.92}
{'loss': 0.0884, 'grad_norm': 20.618406295776367, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.07604487240314484, 'loss_2': 0.0123748779296875, 'loss_3': -15.375221252441406, 'loss_4': 3.7987794876098633, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 09:28:25,999 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:25,999 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:15<1:26:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:33,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03211965784430504, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.772, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.015417957678437233, 'eval_loss_2': 0.016701698303222656, 'eval_loss_3': -18.36277198791504, 'eval_loss_4': 3.871591567993164, 'epoch': 0.93}
{'loss': 0.0831, 'grad_norm': 16.563013076782227, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.06508073955774307, 'loss_2': 0.018035888671875, 'loss_3': -15.256330490112305, 'loss_4': 3.963994264602661, 'epoch': 0.94}
{'loss': 0.0353, 'grad_norm': 8.735383987426758, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.02776762656867504, 'loss_2': 0.0074920654296875, 'loss_3': -15.297161102294922, 'loss_4': 4.276683330535889, 'epoch': 0.94}
{'loss': 0.0476, 'grad_norm': 15.499823570251465, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.04670430347323418, 'loss_2': 0.0009226799011230469, 'loss_3': -15.125361442565918, 'loss_4': 3.9114620685577393, 'epoch': 0.95}
{'loss': 0.0319, 'grad_norm': 12.70283031463623, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.028129281476140022, 'loss_2': 0.003787994384765625, 'loss_3': -15.265190124511719, 'loss_4': 4.408974647521973, 'epoch': 0.95}
{'loss': 0.0528, 'grad_norm': 13.840462684631348, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.046936653554439545, 'loss_2': 0.0058746337890625, 'loss_3': -15.178980827331543, 'loss_4': 3.611314535140991, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 09:28:33,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:33,372 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:22<1:26:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:40,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022882871329784393, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.872, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015428830869495869, 'eval_loss_2': 0.007454037666320801, 'eval_loss_3': -18.21457290649414, 'eval_loss_4': 4.068775177001953, 'epoch': 0.96}
{'loss': 0.043, 'grad_norm': 10.105852127075195, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.031151054427027702, 'loss_2': 0.011871337890625, 'loss_3': -15.354513168334961, 'loss_4': 4.339190483093262, 'epoch': 0.97}
{'loss': 0.0919, 'grad_norm': 21.542478561401367, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.07212968170642853, 'loss_2': 0.019775390625, 'loss_3': -15.157015800476074, 'loss_4': 4.288966655731201, 'epoch': 0.97}
{'loss': 0.0351, 'grad_norm': 10.294641494750977, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.0331357903778553, 'loss_2': 0.0019512176513671875, 'loss_3': -15.436887741088867, 'loss_4': 4.61616325378418, 'epoch': 0.98}
{'loss': 0.0783, 'grad_norm': 24.886384963989258, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.07031194120645523, 'loss_2': 0.0079803466796875, 'loss_3': -15.21015739440918, 'loss_4': 4.062231063842773, 'epoch': 0.98}
{'loss': 0.0595, 'grad_norm': 16.47807502746582, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.053755730390548706, 'loss_2': 0.00577545166015625, 'loss_3': -15.432696342468262, 'loss_4': 4.9633026123046875, 'epoch': 0.99}
[INFO|trainer.py:4228] 2025-01-21 09:28:40,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:40,738 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:29<1:24:12,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 09:28:47,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028933551162481308, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.501, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.019813891500234604, 'eval_loss_2': 0.009119659662246704, 'eval_loss_3': -18.195472717285156, 'eval_loss_4': 4.648837089538574, 'epoch': 0.99}
{'loss': 0.0302, 'grad_norm': 11.582005500793457, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.02976287342607975, 'loss_2': 0.0004782676696777344, 'loss_3': -15.381608963012695, 'loss_4': 4.173358917236328, 'epoch': 0.99}
{'loss': 0.0354, 'grad_norm': 13.146417617797852, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.022245341911911964, 'loss_2': 0.0131378173828125, 'loss_3': -15.430523872375488, 'loss_4': 5.586114406585693, 'epoch': 1.0}
{'loss': 0.0644, 'grad_norm': 20.83986473083496, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.04868807643651962, 'loss_2': 0.015716552734375, 'loss_3': -15.378844261169434, 'loss_4': 5.116121292114258, 'epoch': 1.01}
{'loss': 0.0837, 'grad_norm': 36.60295104980469, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.07774589955806732, 'loss_2': 0.005962371826171875, 'loss_3': -15.177216529846191, 'loss_4': 4.8950395584106445, 'epoch': 1.01}
{'loss': 0.0845, 'grad_norm': 22.01769256591797, 'learning_rate': 2.9e-05, 'loss_1': 0.07214979827404022, 'loss_2': 0.0123748779296875, 'loss_3': -15.374001502990723, 'loss_4': 5.449780464172363, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 09:28:47,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:47,807 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:37<1:26:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:55,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029359200969338417, 'eval_runtime': 3.8196, 'eval_samples_per_second': 268.088, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.017724376171827316, 'eval_loss_2': 0.01163482666015625, 'eval_loss_3': -18.238122940063477, 'eval_loss_4': 5.069995880126953, 'epoch': 1.02}
{'loss': 0.0894, 'grad_norm': 24.91448402404785, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.07905828952789307, 'loss_2': 0.01032257080078125, 'loss_3': -15.724709510803223, 'loss_4': 5.99991512298584, 'epoch': 1.02}
{'loss': 0.0368, 'grad_norm': 8.116703033447266, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.03306785970926285, 'loss_2': 0.0037689208984375, 'loss_3': -15.42397403717041, 'loss_4': 5.304653167724609, 'epoch': 1.03}
{'loss': 0.0766, 'grad_norm': 26.45147132873535, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.06821668893098831, 'loss_2': 0.0084075927734375, 'loss_3': -15.545112609863281, 'loss_4': 5.073193550109863, 'epoch': 1.03}
{'loss': 0.0519, 'grad_norm': 15.119357109069824, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.047643452882766724, 'loss_2': 0.00429534912109375, 'loss_3': -15.442673683166504, 'loss_4': 4.810826301574707, 'epoch': 1.04}
{'loss': 0.0735, 'grad_norm': 18.99198341369629, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.06446069478988647, 'loss_2': 0.00907135009765625, 'loss_3': -15.477502822875977, 'loss_4': 5.38999605178833, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 09:28:55,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:55,191 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:44<1:26:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:02,561 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023238256573677063, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.018078433349728584, 'eval_loss_2': 0.005159825086593628, 'eval_loss_3': -18.241390228271484, 'eval_loss_4': 5.773685455322266, 'epoch': 1.05}
{'loss': 0.083, 'grad_norm': 20.171096801757812, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.06961444765329361, 'loss_2': 0.0133514404296875, 'loss_3': -15.434926986694336, 'loss_4': 5.813118934631348, 'epoch': 1.05}
{'loss': 0.0634, 'grad_norm': 20.50585174560547, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.0597878135740757, 'loss_2': 0.00360107421875, 'loss_3': -15.702911376953125, 'loss_4': 5.885590553283691, 'epoch': 1.06}
{'loss': 0.0697, 'grad_norm': 18.006690979003906, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.060215216130018234, 'loss_2': 0.009521484375, 'loss_3': -15.499914169311523, 'loss_4': 6.420193195343018, 'epoch': 1.06}
{'loss': 0.0641, 'grad_norm': 19.873348236083984, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.06319630146026611, 'loss_2': 0.0008993148803710938, 'loss_3': -15.176702499389648, 'loss_4': 6.198361396789551, 'epoch': 1.07}
{'loss': 0.0448, 'grad_norm': 16.687725067138672, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.044466372579336166, 'loss_2': 0.0003070831298828125, 'loss_3': -15.543107032775879, 'loss_4': 5.861942768096924, 'epoch': 1.08}
[INFO|trainer.py:4228] 2025-01-21 09:29:02,561 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:02,561 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [04:52<1:26:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:09,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019951757043600082, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.753, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013933803886175156, 'eval_loss_2': 0.006017953157424927, 'eval_loss_3': -18.3037109375, 'eval_loss_4': 6.2247843742370605, 'epoch': 1.08}
{'loss': 0.0665, 'grad_norm': 17.158029556274414, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.062170300632715225, 'loss_2': 0.004291534423828125, 'loss_3': -15.342744827270508, 'loss_4': 6.394279479980469, 'epoch': 1.08}
{'loss': 0.0488, 'grad_norm': 18.023191452026367, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.041641537100076675, 'loss_2': 0.00714874267578125, 'loss_3': -15.388360977172852, 'loss_4': 6.081448554992676, 'epoch': 1.09}
{'loss': 0.0789, 'grad_norm': 20.326732635498047, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.07419145852327347, 'loss_2': 0.004695892333984375, 'loss_3': -15.287690162658691, 'loss_4': 6.380045413970947, 'epoch': 1.09}
{'loss': 0.0705, 'grad_norm': 17.959590911865234, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.06059924140572548, 'loss_2': 0.0099334716796875, 'loss_3': -15.467913627624512, 'loss_4': 6.215972423553467, 'epoch': 1.1}
{'loss': 0.0542, 'grad_norm': 14.118206977844238, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.04424579069018364, 'loss_2': 0.00994873046875, 'loss_3': -15.452882766723633, 'loss_4': 6.638860702514648, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 09:29:09,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:09,939 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [04:55<1:26:20,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:29:13,751 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-190
[INFO|configuration_utils.py:420] 2025-01-21 09:29:13,752 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-190/config.json                                                                              
{'eval_loss': 0.01582048460841179, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.728, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01077174674719572, 'eval_loss_2': 0.005048736929893494, 'eval_loss_3': -18.353574752807617, 'eval_loss_4': 6.424534797668457, 'epoch': 1.1}
[INFO|modeling_utils.py:2988] 2025-01-21 09:29:14,231 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-190/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:29:14,232 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-190/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:29:14,233 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-190/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:29:15,187 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-115] due to args.save_total_limit
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:00<1:35:18,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:29:18,832 >>
{'loss': 0.056, 'grad_norm': 14.83144760131836, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.053473636507987976, 'loss_2': 0.00254058837890625, 'loss_3': -15.462992668151855, 'loss_4': 6.526589870452881, 'epoch': 1.11}
{'loss': 0.0706, 'grad_norm': 15.565816879272461, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.0661746934056282, 'loss_2': 0.004421234130859375, 'loss_3': -15.494489669799805, 'loss_4': 7.3656415939331055, 'epoch': 1.12}
{'loss': 0.0624, 'grad_norm': 18.28716278076172, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.05415356159210205, 'loss_2': 0.008270263671875, 'loss_3': -15.555086135864258, 'loss_4': 6.6972246170043945, 'epoch': 1.12}
{'loss': 0.043, 'grad_norm': 11.3441801071167, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.03931930288672447, 'loss_2': 0.0037097930908203125, 'loss_3': -15.594018936157227, 'loss_4': 6.275758743286133, 'epoch': 1.13}
{'loss': 0.0479, 'grad_norm': 19.938783645629883, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.04720970243215561, 'loss_2': 0.0007004737854003906, 'loss_3': -15.223129272460938, 'loss_4': 6.197668075561523, 'epoch': 1.13}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:29:18,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:18,833 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:04<1:35:18,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:29:22,648 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-195
[INFO|configuration_utils.py:420] 2025-01-21 09:29:22,649 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-195/config.json                                                                              
{'eval_loss': 0.015368213877081871, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.423, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009751608595252037, 'eval_loss_2': 0.005616605281829834, 'eval_loss_3': -18.295255661010742, 'eval_loss_4': 5.981459140777588, 'epoch': 1.13}
[INFO|modeling_utils.py:2988] 2025-01-21 09:29:23,124 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-195/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:29:23,125 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-195/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:29:23,126 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-195/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:29:24,013 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-190] due to args.save_total_limit
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:09<1:36:18,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 09:29:27,664 >>
{'loss': 0.0609, 'grad_norm': 17.026926040649414, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.05014572665095329, 'loss_2': 0.0107421875, 'loss_3': -15.31192398071289, 'loss_4': 5.64166784286499, 'epoch': 1.14}
{'loss': 0.0696, 'grad_norm': 19.161975860595703, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.06672139465808868, 'loss_2': 0.0029277801513671875, 'loss_3': -15.483220100402832, 'loss_4': 6.801866054534912, 'epoch': 1.15}
{'loss': 0.0663, 'grad_norm': 19.60551643371582, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.057977911084890366, 'loss_2': 0.00827789306640625, 'loss_3': -15.471187591552734, 'loss_4': 5.870147228240967, 'epoch': 1.15}
{'loss': 0.0582, 'grad_norm': 16.42865562438965, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.052188921719789505, 'loss_2': 0.00605010986328125, 'loss_3': -15.343685150146484, 'loss_4': 5.653623580932617, 'epoch': 1.16}
{'loss': 0.0527, 'grad_norm': 13.231521606445312, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.04972425103187561, 'loss_2': 0.003025054931640625, 'loss_3': -15.367998123168945, 'loss_4': 5.972513198852539, 'epoch': 1.16}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:29:27,664 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:27,664 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:17<1:27:40,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:29:35,029 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017760109156370163, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.931, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013265112414956093, 'eval_loss_2': 0.004494994878768921, 'eval_loss_3': -18.23429298400879, 'eval_loss_4': 5.632404804229736, 'epoch': 1.16}
{'loss': 0.0404, 'grad_norm': 10.487680435180664, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.0346815399825573, 'loss_2': 0.00574493408203125, 'loss_3': -15.328481674194336, 'loss_4': 6.002594947814941, 'epoch': 1.17}
{'loss': 0.04, 'grad_norm': 12.150315284729004, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.03984580188989639, 'loss_2': 0.0001971721649169922, 'loss_3': -15.322150230407715, 'loss_4': 5.846381664276123, 'epoch': 1.17}
{'loss': 0.0452, 'grad_norm': 14.23204517364502, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.04412704333662987, 'loss_2': 0.001026153564453125, 'loss_3': -15.422351837158203, 'loss_4': 5.97728157043457, 'epoch': 1.18}
{'loss': 0.0927, 'grad_norm': 25.26925277709961, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.08688095211982727, 'loss_2': 0.0058441162109375, 'loss_3': -15.436177253723145, 'loss_4': 5.90572452545166, 'epoch': 1.19}
{'loss': 0.0596, 'grad_norm': 15.926925659179688, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.057814568281173706, 'loss_2': 0.00177764892578125, 'loss_3': -15.491373062133789, 'loss_4': 5.700748443603516, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 09:29:35,029 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:35,029 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:24<1:26:13,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:29:42,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02674306556582451, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.334, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02294072136282921, 'eval_loss_2': 0.0038023442029953003, 'eval_loss_3': -18.124910354614258, 'eval_loss_4': 5.79728364944458, 'epoch': 1.19}
{'loss': 0.0968, 'grad_norm': 24.525856018066406, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.09016658365726471, 'loss_2': 0.0066680908203125, 'loss_3': -15.343682289123535, 'loss_4': 5.614987373352051, 'epoch': 1.2}
{'loss': 0.1118, 'grad_norm': 30.24515724182129, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.10581158846616745, 'loss_2': 0.00598907470703125, 'loss_3': -15.247142791748047, 'loss_4': 5.980928897857666, 'epoch': 1.2}
{'loss': 0.0994, 'grad_norm': 22.775541305541992, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.09483089298009872, 'loss_2': 0.004543304443359375, 'loss_3': -15.390933990478516, 'loss_4': 5.990194320678711, 'epoch': 1.21}
{'loss': 0.1017, 'grad_norm': 27.427776336669922, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.09645427018404007, 'loss_2': 0.005237579345703125, 'loss_3': -15.326929092407227, 'loss_4': 5.873358726501465, 'epoch': 1.22}
{'loss': 0.0666, 'grad_norm': 15.101933479309082, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.06567425280809402, 'loss_2': 0.0009493827819824219, 'loss_3': -15.545978546142578, 'loss_4': 6.059604644775391, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 09:29:42,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:42,394 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:31<1:25:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:49,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02602265402674675, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.97, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02259848639369011, 'eval_loss_2': 0.0034241676330566406, 'eval_loss_3': -18.166484832763672, 'eval_loss_4': 5.893482208251953, 'epoch': 1.22}
{'loss': 0.1241, 'grad_norm': 38.98100662231445, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.12103014439344406, 'loss_2': 0.003078460693359375, 'loss_3': -15.404245376586914, 'loss_4': 5.904980182647705, 'epoch': 1.23}
{'loss': 0.0869, 'grad_norm': 21.340248107910156, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.0785970389842987, 'loss_2': 0.0083160400390625, 'loss_3': -15.534632682800293, 'loss_4': 5.976467132568359, 'epoch': 1.23}
{'loss': 0.0777, 'grad_norm': 15.657562255859375, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.06717073172330856, 'loss_2': 0.0105438232421875, 'loss_3': -15.521439552307129, 'loss_4': 5.392091274261475, 'epoch': 1.24}
{'loss': 0.0956, 'grad_norm': 21.6898250579834, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.08800958096981049, 'loss_2': 0.00756072998046875, 'loss_3': -15.453042030334473, 'loss_4': 5.8012237548828125, 'epoch': 1.24}
{'loss': 0.0437, 'grad_norm': 10.403203964233398, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.037331756204366684, 'loss_2': 0.006351470947265625, 'loss_3': -15.551528930664062, 'loss_4': 5.749443054199219, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 09:29:49,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:49,765 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:39<1:25:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:57,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024280834943056107, 'eval_runtime': 3.8243, 'eval_samples_per_second': 267.76, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.019572455435991287, 'eval_loss_2': 0.004708379507064819, 'eval_loss_3': -18.214832305908203, 'eval_loss_4': 5.890334129333496, 'epoch': 1.25}
{'loss': 0.0674, 'grad_norm': 16.868404388427734, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.060561224818229675, 'loss_2': 0.00684356689453125, 'loss_3': -15.593332290649414, 'loss_4': 5.80235481262207, 'epoch': 1.26}
{'loss': 0.0594, 'grad_norm': 11.930756568908691, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.05181298777461052, 'loss_2': 0.007549285888671875, 'loss_3': -15.64480209350586, 'loss_4': 6.5500359535217285, 'epoch': 1.26}
{'loss': 0.0834, 'grad_norm': 17.916906356811523, 'learning_rate': 2.875e-05, 'loss_1': 0.07248884439468384, 'loss_2': 0.0108795166015625, 'loss_3': -15.343661308288574, 'loss_4': 6.412570953369141, 'epoch': 1.27}
{'loss': 0.0798, 'grad_norm': 33.04173278808594, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.07259541749954224, 'loss_2': 0.007183074951171875, 'loss_3': -15.40933895111084, 'loss_4': 6.611078262329102, 'epoch': 1.27}
{'loss': 0.0288, 'grad_norm': 10.17003059387207, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.025980917736887932, 'loss_2': 0.0028553009033203125, 'loss_3': -15.474262237548828, 'loss_4': 5.647688865661621, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 09:29:57,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:57,151 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:46<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:04,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02307107485830784, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.702, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01886020600795746, 'eval_loss_2': 0.004210866987705231, 'eval_loss_3': -18.255191802978516, 'eval_loss_4': 6.18739652633667, 'epoch': 1.28}
{'loss': 0.0519, 'grad_norm': 13.267915725708008, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.0479566715657711, 'loss_2': 0.00396728515625, 'loss_3': -15.49806022644043, 'loss_4': 5.271882057189941, 'epoch': 1.28}
{'loss': 0.1298, 'grad_norm': 34.36668014526367, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.11737841367721558, 'loss_2': 0.012451171875, 'loss_3': -15.37004566192627, 'loss_4': 6.490237236022949, 'epoch': 1.29}
{'loss': 0.0479, 'grad_norm': 12.591012954711914, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.044939085841178894, 'loss_2': 0.002948760986328125, 'loss_3': -15.677974700927734, 'loss_4': 6.078078269958496, 'epoch': 1.3}
{'loss': 0.1082, 'grad_norm': 27.954689025878906, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.10174037516117096, 'loss_2': 0.00650787353515625, 'loss_3': -15.372525215148926, 'loss_4': 5.853728771209717, 'epoch': 1.3}
{'loss': 0.1777, 'grad_norm': 37.4243049621582, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.17316266894340515, 'loss_2': 0.004489898681640625, 'loss_3': -15.447298049926758, 'loss_4': 6.033393859863281, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 09:30:04,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:04,526 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [05:54<1:25:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:11,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032444026321172714, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.337, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.024323252961039543, 'eval_loss_2': 0.00812077522277832, 'eval_loss_3': -18.29124641418457, 'eval_loss_4': 6.410377502441406, 'epoch': 1.31}
{'loss': 0.0717, 'grad_norm': 16.9349308013916, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.0637742429971695, 'loss_2': 0.007965087890625, 'loss_3': -15.48100471496582, 'loss_4': 6.517245292663574, 'epoch': 1.31}
{'loss': 0.1503, 'grad_norm': 32.503692626953125, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.1480475515127182, 'loss_2': 0.002292633056640625, 'loss_3': -15.472522735595703, 'loss_4': 6.661417007446289, 'epoch': 1.32}
{'loss': 0.0592, 'grad_norm': 14.965849876403809, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.059060875326395035, 'loss_2': 9.119510650634766e-05, 'loss_3': -15.462623596191406, 'loss_4': 6.436158657073975, 'epoch': 1.33}
{'loss': 0.081, 'grad_norm': 19.1545467376709, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.068334199488163, 'loss_2': 0.0126800537109375, 'loss_3': -15.870689392089844, 'loss_4': 6.864227294921875, 'epoch': 1.33}
{'loss': 0.0976, 'grad_norm': 20.67243003845215, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.09122338145971298, 'loss_2': 0.00641632080078125, 'loss_3': -15.456087112426758, 'loss_4': 6.160577774047852, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 09:30:11,915 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:11,915 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:01<1:25:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:19,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024098236113786697, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.205, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.020673923194408417, 'eval_loss_2': 0.0034243129193782806, 'eval_loss_3': -18.311052322387695, 'eval_loss_4': 6.348114967346191, 'epoch': 1.34}
{'loss': 0.0863, 'grad_norm': 20.727689743041992, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.07822613418102264, 'loss_2': 0.008026123046875, 'loss_3': -15.535469055175781, 'loss_4': 6.670299053192139, 'epoch': 1.34}
{'loss': 0.1768, 'grad_norm': 26.214139938354492, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.17530082166194916, 'loss_2': 0.0015115737915039062, 'loss_3': -15.245203018188477, 'loss_4': 5.986706733703613, 'epoch': 1.35}
{'loss': 0.0718, 'grad_norm': 16.798709869384766, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.06698240339756012, 'loss_2': 0.00482177734375, 'loss_3': -15.309944152832031, 'loss_4': 6.292193412780762, 'epoch': 1.35}
{'loss': 0.0532, 'grad_norm': 17.339645385742188, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.05162744224071503, 'loss_2': 0.001567840576171875, 'loss_3': -15.694637298583984, 'loss_4': 6.642276763916016, 'epoch': 1.36}
{'loss': 0.0467, 'grad_norm': 10.096508026123047, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.038646865636110306, 'loss_2': 0.008026123046875, 'loss_3': -15.496970176696777, 'loss_4': 6.52175235748291, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 09:30:19,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:19,286 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:08<1:25:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:26,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018892450258135796, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.909, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015017352066934109, 'eval_loss_2': 0.0038750991225242615, 'eval_loss_3': -18.347471237182617, 'eval_loss_4': 6.006509304046631, 'epoch': 1.37}
{'loss': 0.0764, 'grad_norm': 21.78685760498047, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.07559528201818466, 'loss_2': 0.0008001327514648438, 'loss_3': -15.471277236938477, 'loss_4': 6.316277980804443, 'epoch': 1.37}
{'loss': 0.0509, 'grad_norm': 13.021332740783691, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.04547236114740372, 'loss_2': 0.005405426025390625, 'loss_3': -15.640905380249023, 'loss_4': 5.998885631561279, 'epoch': 1.38}
{'loss': 0.0685, 'grad_norm': 18.727725982666016, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.06421778351068497, 'loss_2': 0.0042877197265625, 'loss_3': -15.66972827911377, 'loss_4': 6.358452796936035, 'epoch': 1.38}
{'loss': 0.0718, 'grad_norm': 16.930984497070312, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.05386212095618248, 'loss_2': 0.017913818359375, 'loss_3': -15.261873245239258, 'loss_4': 5.358067512512207, 'epoch': 1.39}
{'loss': 0.0581, 'grad_norm': 11.922727584838867, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.03991454467177391, 'loss_2': 0.0182037353515625, 'loss_3': -15.699575424194336, 'loss_4': 5.585030555725098, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 09:30:26,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:26,661 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:16<1:25:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:34,032 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027246301993727684, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011420074850320816, 'eval_loss_2': 0.01582622528076172, 'eval_loss_3': -18.355920791625977, 'eval_loss_4': 5.001595497131348, 'epoch': 1.4}
{'loss': 0.0916, 'grad_norm': 21.490070343017578, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.07252325862646103, 'loss_2': 0.01910400390625, 'loss_3': -15.69760513305664, 'loss_4': 5.561171531677246, 'epoch': 1.4}
{'loss': 0.0615, 'grad_norm': 17.154380798339844, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.04726630821824074, 'loss_2': 0.01422119140625, 'loss_3': -15.96186351776123, 'loss_4': 4.817045211791992, 'epoch': 1.41}
{'loss': 0.0919, 'grad_norm': 20.703418731689453, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.07575110346078873, 'loss_2': 0.01611328125, 'loss_3': -15.441625595092773, 'loss_4': 5.410445690155029, 'epoch': 1.41}
{'loss': 0.0541, 'grad_norm': 10.464292526245117, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.0360906720161438, 'loss_2': 0.0180511474609375, 'loss_3': -15.68575382232666, 'loss_4': 4.703539848327637, 'epoch': 1.42}
{'loss': 0.046, 'grad_norm': 12.582453727722168, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.031279295682907104, 'loss_2': 0.0147705078125, 'loss_3': -15.609262466430664, 'loss_4': 4.512170791625977, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 09:30:34,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:34,032 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:23<1:25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:41,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015430319122970104, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.762, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.012442098930478096, 'eval_loss_2': 0.0029882192611694336, 'eval_loss_3': -18.325532913208008, 'eval_loss_4': 4.748228549957275, 'epoch': 1.42}
{'loss': 0.0398, 'grad_norm': 12.881357192993164, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.03841118514537811, 'loss_2': 0.0013494491577148438, 'loss_3': -15.572896003723145, 'loss_4': 4.895991325378418, 'epoch': 1.43}
{'loss': 0.0635, 'grad_norm': 20.341527938842773, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.05913589149713516, 'loss_2': 0.0044097900390625, 'loss_3': -15.588918685913086, 'loss_4': 4.8745808601379395, 'epoch': 1.44}
{'loss': 0.0481, 'grad_norm': 12.803218841552734, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.047333672642707825, 'loss_2': 0.0008139610290527344, 'loss_3': -15.526611328125, 'loss_4': 5.137179374694824, 'epoch': 1.44}
{'loss': 0.0952, 'grad_norm': 30.75359535217285, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.08771003782749176, 'loss_2': 0.007526397705078125, 'loss_3': -15.622261047363281, 'loss_4': 5.503491401672363, 'epoch': 1.45}
{'loss': 0.0814, 'grad_norm': 15.97887897491455, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.04914749041199684, 'loss_2': 0.03228759765625, 'loss_3': -15.714180946350098, 'loss_4': 5.434603214263916, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 09:30:41,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:41,402 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:30<1:25:29,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:30:48,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03549608588218689, 'eval_runtime': 3.8407, 'eval_samples_per_second': 266.618, 'eval_steps_per_second': 4.166, 'eval_loss_1': 0.01318392064422369, 'eval_loss_2': 0.022312164306640625, 'eval_loss_3': -18.3341064453125, 'eval_loss_4': 5.078621864318848, 'epoch': 1.45}
{'loss': 0.0641, 'grad_norm': 13.140954971313477, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.03908872976899147, 'loss_2': 0.024993896484375, 'loss_3': -15.388238906860352, 'loss_4': 5.874421119689941, 'epoch': 1.46}
{'loss': 0.0754, 'grad_norm': 14.710474014282227, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.05400864779949188, 'loss_2': 0.0213470458984375, 'loss_3': -15.731562614440918, 'loss_4': 4.976485252380371, 'epoch': 1.47}
{'loss': 0.0521, 'grad_norm': 6.489574432373047, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.019064655527472496, 'loss_2': 0.0330810546875, 'loss_3': -15.651904106140137, 'loss_4': 5.423096179962158, 'epoch': 1.47}
{'loss': 0.1036, 'grad_norm': 20.68010711669922, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.07879794389009476, 'loss_2': 0.0247650146484375, 'loss_3': -15.678471565246582, 'loss_4': 5.5699357986450195, 'epoch': 1.48}
{'loss': 0.0471, 'grad_norm': 12.343446731567383, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.032783281058073044, 'loss_2': 0.01432037353515625, 'loss_3': -15.611007690429688, 'loss_4': 4.538119792938232, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 09:30:48,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:48,814 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:38<1:25:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:56,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027355823665857315, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.758, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.015062248334288597, 'eval_loss_2': 0.012293577194213867, 'eval_loss_3': -18.313735961914062, 'eval_loss_4': 4.68765115737915, 'epoch': 1.48}
{'loss': 0.0554, 'grad_norm': 11.962953567504883, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.04107103496789932, 'loss_2': 0.014373779296875, 'loss_3': -15.615707397460938, 'loss_4': 5.051300525665283, 'epoch': 1.49}
{'loss': 0.03, 'grad_norm': 10.332902908325195, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.02929515950381756, 'loss_2': 0.0007166862487792969, 'loss_3': -15.79903793334961, 'loss_4': 4.628881454467773, 'epoch': 1.49}
{'loss': 0.0512, 'grad_norm': 17.25459861755371, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.04601913318037987, 'loss_2': 0.005176544189453125, 'loss_3': -15.54580020904541, 'loss_4': 4.467405319213867, 'epoch': 1.5}
{'loss': 0.1165, 'grad_norm': 25.009801864624023, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.11498720943927765, 'loss_2': 0.00150299072265625, 'loss_3': -15.279539108276367, 'loss_4': 4.98480224609375, 'epoch': 1.51}
{'loss': 0.0519, 'grad_norm': 17.53105926513672, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.041518986225128174, 'loss_2': 0.0103607177734375, 'loss_3': -15.433856964111328, 'loss_4': 4.226968288421631, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 09:30:56,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:56,188 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:45<1:24:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:03,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021554753184318542, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012777730822563171, 'eval_loss_2': 0.008777022361755371, 'eval_loss_3': -18.310176849365234, 'eval_loss_4': 4.20315408706665, 'epoch': 1.51}
{'loss': 0.0446, 'grad_norm': 11.022197723388672, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.03622374311089516, 'loss_2': 0.0083465576171875, 'loss_3': -15.753396987915039, 'loss_4': 4.7688446044921875, 'epoch': 1.52}
{'loss': 0.0497, 'grad_norm': 21.34499168395996, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.04351474344730377, 'loss_2': 0.00616455078125, 'loss_3': -15.635168075561523, 'loss_4': 4.452058792114258, 'epoch': 1.52}
{'loss': 0.0615, 'grad_norm': 14.468737602233887, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.0499972403049469, 'loss_2': 0.01153564453125, 'loss_3': -15.599807739257812, 'loss_4': 4.203056812286377, 'epoch': 1.53}
{'loss': 0.0466, 'grad_norm': 12.504223823547363, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.045172590762376785, 'loss_2': 0.0014715194702148438, 'loss_3': -15.532217979431152, 'loss_4': 4.118093490600586, 'epoch': 1.53}
{'loss': 0.0331, 'grad_norm': 9.959197998046875, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.024632003158330917, 'loss_2': 0.00843048095703125, 'loss_3': -15.660558700561523, 'loss_4': 3.9659488201141357, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 09:31:03,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:03,553 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:49<1:24:56,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:31:07,356 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-265
[INFO|configuration_utils.py:420] 2025-01-21 09:31:07,357 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-265/config.json                                                                              
{'eval_loss': 0.014637310057878494, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.317, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010807354934513569, 'eval_loss_2': 0.0038299560546875, 'eval_loss_3': -18.35213279724121, 'eval_loss_4': 4.430115699768066, 'epoch': 1.54}
[INFO|modeling_utils.py:2988] 2025-01-21 09:31:07,850 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-265/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:31:07,851 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-265/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:31:07,852 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-265/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:31:08,809 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-195] due to args.save_total_limit
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [06:54<1:33:47,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:31:12,440 >>
{'loss': 0.1272, 'grad_norm': 28.6666259765625, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.12313143163919449, 'loss_2': 0.004116058349609375, 'loss_3': -15.312795639038086, 'loss_4': 5.321280479431152, 'epoch': 1.55}
{'loss': 0.0649, 'grad_norm': 14.621095657348633, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.06120162084698677, 'loss_2': 0.0036945343017578125, 'loss_3': -15.545356750488281, 'loss_4': 5.071124076843262, 'epoch': 1.55}
{'loss': 0.065, 'grad_norm': 20.251401901245117, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.05722864717245102, 'loss_2': 0.0078125, 'loss_3': -15.606922149658203, 'loss_4': 5.316789627075195, 'epoch': 1.56}
{'loss': 0.0487, 'grad_norm': 21.5887508392334, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.04730044677853584, 'loss_2': 0.0014057159423828125, 'loss_3': -15.613523483276367, 'loss_4': 5.4923014640808105, 'epoch': 1.56}
{'loss': 0.0347, 'grad_norm': 8.941475868225098, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.029842209070920944, 'loss_2': 0.004852294921875, 'loss_3': -15.643722534179688, 'loss_4': 5.596621036529541, 'epoch': 1.57}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:31:12,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:12,440 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:01<1:26:17,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:31:19,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018081719055771828, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.16, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013180920854210854, 'eval_loss_2': 0.004900798201560974, 'eval_loss_3': -18.412111282348633, 'eval_loss_4': 5.718654632568359, 'epoch': 1.57}
{'loss': 0.0436, 'grad_norm': 10.247346878051758, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.03518705815076828, 'loss_2': 0.00836944580078125, 'loss_3': -15.64664077758789, 'loss_4': 5.464059829711914, 'epoch': 1.58}
{'loss': 0.0475, 'grad_norm': 16.77423667907715, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.04604008048772812, 'loss_2': 0.001415252685546875, 'loss_3': -15.583270072937012, 'loss_4': 5.827077865600586, 'epoch': 1.58}
{'loss': 0.0644, 'grad_norm': 16.14193344116211, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.05805177986621857, 'loss_2': 0.0063629150390625, 'loss_3': -15.503625869750977, 'loss_4': 6.929952621459961, 'epoch': 1.59}
{'loss': 0.0534, 'grad_norm': 13.533951759338379, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.04529668763279915, 'loss_2': 0.008087158203125, 'loss_3': -15.876176834106445, 'loss_4': 7.315033912658691, 'epoch': 1.59}
{'loss': 0.0667, 'grad_norm': 15.588021278381348, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.055674124509096146, 'loss_2': 0.010986328125, 'loss_3': -15.301403045654297, 'loss_4': 5.9995856285095215, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 09:31:19,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:19,813 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:09<1:25:05,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:31:27,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025890421122312546, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.137, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012770246714353561, 'eval_loss_2': 0.013120174407958984, 'eval_loss_3': -18.412342071533203, 'eval_loss_4': 5.829525947570801, 'epoch': 1.6}
{'loss': 0.0749, 'grad_norm': 18.488985061645508, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.06343775987625122, 'loss_2': 0.01142120361328125, 'loss_3': -15.549470901489258, 'loss_4': 6.7171173095703125, 'epoch': 1.6}
{'loss': 0.0733, 'grad_norm': 15.21165943145752, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.059988174587488174, 'loss_2': 0.01326751708984375, 'loss_3': -15.649273872375488, 'loss_4': 6.177180290222168, 'epoch': 1.61}
{'loss': 0.032, 'grad_norm': 7.699837684631348, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.02385645918548107, 'loss_2': 0.00809478759765625, 'loss_3': -15.664268493652344, 'loss_4': 6.337777137756348, 'epoch': 1.62}
{'loss': 0.0495, 'grad_norm': 12.718855857849121, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.03757364675402641, 'loss_2': 0.01190948486328125, 'loss_3': -15.51959228515625, 'loss_4': 5.827027320861816, 'epoch': 1.62}
{'loss': 0.0863, 'grad_norm': 25.472511291503906, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.08443997800350189, 'loss_2': 0.00185394287109375, 'loss_3': -15.541406631469727, 'loss_4': 5.683832168579102, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 09:31:27,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:27,191 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:16<1:24:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:34,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015281127765774727, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.635, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011568729765713215, 'eval_loss_2': 0.0037123970687389374, 'eval_loss_3': -18.377696990966797, 'eval_loss_4': 4.933160781860352, 'epoch': 1.63}
{'loss': 0.0638, 'grad_norm': 15.040209770202637, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.05461132898926735, 'loss_2': 0.0091552734375, 'loss_3': -15.529458045959473, 'loss_4': 4.818504333496094, 'epoch': 1.63}
{'loss': 0.0285, 'grad_norm': 11.945783615112305, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.027990838512778282, 'loss_2': 0.0005221366882324219, 'loss_3': -15.619036674499512, 'loss_4': 4.927194595336914, 'epoch': 1.64}
{'loss': 0.0812, 'grad_norm': 23.09844398498535, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.06511480361223221, 'loss_2': 0.016082763671875, 'loss_3': -15.514782905578613, 'loss_4': 4.829152584075928, 'epoch': 1.65}
{'loss': 0.0808, 'grad_norm': 18.376426696777344, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.07022701948881149, 'loss_2': 0.0106048583984375, 'loss_3': -15.486743927001953, 'loss_4': 5.905328273773193, 'epoch': 1.65}
{'loss': 0.1408, 'grad_norm': 33.66986846923828, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.11466455459594727, 'loss_2': 0.02618408203125, 'loss_3': -15.261181831359863, 'loss_4': 5.232748031616211, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 09:31:34,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:34,567 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:24<1:24:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:41,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028065841645002365, 'eval_runtime': 3.8194, 'eval_samples_per_second': 268.104, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.012203855440020561, 'eval_loss_2': 0.015861988067626953, 'eval_loss_3': -18.35478973388672, 'eval_loss_4': 5.506069183349609, 'epoch': 1.66}
{'loss': 0.056, 'grad_norm': 11.745526313781738, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.0429840050637722, 'loss_2': 0.013031005859375, 'loss_3': -15.613665580749512, 'loss_4': 5.918379783630371, 'epoch': 1.66}
{'loss': 0.0681, 'grad_norm': 15.537386894226074, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.04093170166015625, 'loss_2': 0.0271453857421875, 'loss_3': -15.531508445739746, 'loss_4': 5.5256805419921875, 'epoch': 1.67}
{'loss': 0.0561, 'grad_norm': 10.901517868041992, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.03744855150580406, 'loss_2': 0.01861572265625, 'loss_3': -15.644569396972656, 'loss_4': 5.674247741699219, 'epoch': 1.67}
{'loss': 0.055, 'grad_norm': 13.689624786376953, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.040656931698322296, 'loss_2': 0.014373779296875, 'loss_3': -15.487822532653809, 'loss_4': 6.4319963455200195, 'epoch': 1.68}
{'loss': 0.0808, 'grad_norm': 21.181949615478516, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.059930309653282166, 'loss_2': 0.0208282470703125, 'loss_3': -15.557340621948242, 'loss_4': 6.426393985748291, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 09:31:41,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:41,946 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:31<1:24:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:49,331 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01920079067349434, 'eval_runtime': 3.8227, 'eval_samples_per_second': 267.877, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.016362102702260017, 'eval_loss_2': 0.0028386861085891724, 'eval_loss_3': -18.321060180664062, 'eval_loss_4': 6.3169074058532715, 'epoch': 1.69}
{'loss': 0.0952, 'grad_norm': 22.250995635986328, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.08862587064504623, 'loss_2': 0.00659942626953125, 'loss_3': -15.597311019897461, 'loss_4': 6.885409355163574, 'epoch': 1.69}
{'loss': 0.0844, 'grad_norm': 22.686185836791992, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.0790214017033577, 'loss_2': 0.0054168701171875, 'loss_3': -15.716930389404297, 'loss_4': 6.583860397338867, 'epoch': 1.7}
{'loss': 0.0797, 'grad_norm': 19.816877365112305, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.07874014228582382, 'loss_2': 0.0009517669677734375, 'loss_3': -15.510979652404785, 'loss_4': 6.353697299957275, 'epoch': 1.7}
{'loss': 0.0901, 'grad_norm': 23.847774505615234, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.07889389246702194, 'loss_2': 0.0112152099609375, 'loss_3': -15.732699394226074, 'loss_4': 6.523254871368408, 'epoch': 1.71}
{'loss': 0.0605, 'grad_norm': 19.827634811401367, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.049932584166526794, 'loss_2': 0.01061248779296875, 'loss_3': -15.76184368133545, 'loss_4': 6.081663608551025, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 09:31:49,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:49,331 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:39<1:25:28,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:31:56,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032975614070892334, 'eval_runtime': 3.994, 'eval_samples_per_second': 256.384, 'eval_steps_per_second': 4.006, 'eval_loss_1': 0.014599737711250782, 'eval_loss_2': 0.018375873565673828, 'eval_loss_3': -18.302406311035156, 'eval_loss_4': 6.120692253112793, 'epoch': 1.72}
{'loss': 0.0964, 'grad_norm': 27.61092758178711, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.09076636284589767, 'loss_2': 0.005645751953125, 'loss_3': -15.75291919708252, 'loss_4': 6.800307273864746, 'epoch': 1.72}
{'loss': 0.0752, 'grad_norm': 24.066452026367188, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.05873900279402733, 'loss_2': 0.0164947509765625, 'loss_3': -15.871914863586426, 'loss_4': 6.154417037963867, 'epoch': 1.73}
{'loss': 0.0473, 'grad_norm': 10.117950439453125, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.03162739798426628, 'loss_2': 0.015655517578125, 'loss_3': -15.73682975769043, 'loss_4': 6.025964736938477, 'epoch': 1.73}
{'loss': 0.0431, 'grad_norm': 11.965813636779785, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.032509028911590576, 'loss_2': 0.010589599609375, 'loss_3': -15.681629180908203, 'loss_4': 6.129441261291504, 'epoch': 1.74}
{'loss': 0.0515, 'grad_norm': 24.62356948852539, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.03968929871916771, 'loss_2': 0.0117950439453125, 'loss_3': -15.529348373413086, 'loss_4': 5.697864055633545, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 09:31:56,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:56,889 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:46<1:24:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:04,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01918761059641838, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.97, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011190218850970268, 'eval_loss_2': 0.007997393608093262, 'eval_loss_3': -18.280017852783203, 'eval_loss_4': 5.56335973739624, 'epoch': 1.74}
{'loss': 0.0382, 'grad_norm': 14.136274337768555, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.03560036048293114, 'loss_2': 0.002582550048828125, 'loss_3': -15.668693542480469, 'loss_4': 6.016915798187256, 'epoch': 1.75}
{'loss': 0.0378, 'grad_norm': 11.895190238952637, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.034429389983415604, 'loss_2': 0.003345489501953125, 'loss_3': -15.845479011535645, 'loss_4': 5.594396591186523, 'epoch': 1.76}
{'loss': 0.0396, 'grad_norm': 10.406783103942871, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.0386933870613575, 'loss_2': 0.0008640289306640625, 'loss_3': -15.543694496154785, 'loss_4': 5.521963119506836, 'epoch': 1.76}
{'loss': 0.051, 'grad_norm': 15.267909049987793, 'learning_rate': 2.825e-05, 'loss_1': 0.04923056811094284, 'loss_2': 0.0017242431640625, 'loss_3': -15.66519546508789, 'loss_4': 5.233011722564697, 'epoch': 1.77}
{'loss': 0.0477, 'grad_norm': 15.767240524291992, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.046220239251852036, 'loss_2': 0.0014448165893554688, 'loss_3': -15.806928634643555, 'loss_4': 5.018324375152588, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 09:32:04,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:04,253 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:50<1:24:23,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:32:08,107 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-305
[INFO|configuration_utils.py:420] 2025-01-21 09:32:08,108 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-305/config.json                                                                              
{'eval_loss': 0.013847415335476398, 'eval_runtime': 3.8529, 'eval_samples_per_second': 265.775, 'eval_steps_per_second': 4.153, 'eval_loss_1': 0.008892213925719261, 'eval_loss_2': 0.004955202341079712, 'eval_loss_3': -18.302692413330078, 'eval_loss_4': 4.681736469268799, 'epoch': 1.77}
[INFO|modeling_utils.py:2988] 2025-01-21 09:32:08,629 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-305/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:32:08,630 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-305/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:32:08,630 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-305/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:32:09,591 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-265] due to args.save_total_limit
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [07:55<1:33:40,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:32:13,241 >>
{'loss': 0.0656, 'grad_norm': 20.052852630615234, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.060533974319696426, 'loss_2': 0.0050201416015625, 'loss_3': -15.513510704040527, 'loss_4': 4.930227756500244, 'epoch': 1.78}
{'loss': 0.0615, 'grad_norm': 20.074331283569336, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.05543239042162895, 'loss_2': 0.00611114501953125, 'loss_3': -15.662425994873047, 'loss_4': 4.75892448425293, 'epoch': 1.78}
{'loss': 0.0632, 'grad_norm': 20.522451400756836, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.05408244580030441, 'loss_2': 0.00914764404296875, 'loss_3': -15.578107833862305, 'loss_4': 4.541871070861816, 'epoch': 1.79}
{'loss': 0.0313, 'grad_norm': 12.16944694519043, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.02696871943771839, 'loss_2': 0.00434112548828125, 'loss_3': -15.758472442626953, 'loss_4': 4.4091668128967285, 'epoch': 1.8}
{'loss': 0.0348, 'grad_norm': 8.534443855285645, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.028014350682497025, 'loss_2': 0.00678253173828125, 'loss_3': -15.670381546020508, 'loss_4': 3.848330020904541, 'epoch': 1.8}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:32:13,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:13,241 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [07:59<1:33:40,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 09:32:17,053 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-310
[INFO|configuration_utils.py:420] 2025-01-21 09:32:17,054 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-310/config.json                                                                              
{'eval_loss': 0.01105493027716875, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.82, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0072350408881902695, 'eval_loss_2': 0.003819890320301056, 'eval_loss_3': -18.35760498046875, 'eval_loss_4': 4.440601348876953, 'epoch': 1.8}
[INFO|modeling_utils.py:2988] 2025-01-21 09:32:17,547 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-310/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:32:17,548 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-310/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:32:17,549 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-310/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:32:18,467 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-305] due to args.save_total_limit
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:04<1:34:32,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 09:32:22,133 >>
{'loss': 0.0233, 'grad_norm': 6.640102863311768, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.021264811977744102, 'loss_2': 0.00202178955078125, 'loss_3': -15.767820358276367, 'loss_4': 4.879472255706787, 'epoch': 1.81}
{'loss': 0.0258, 'grad_norm': 9.131353378295898, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.02270255796611309, 'loss_2': 0.0030651092529296875, 'loss_3': -15.813084602355957, 'loss_4': 4.6576080322265625, 'epoch': 1.81}
{'loss': 0.0355, 'grad_norm': 12.808841705322266, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.030428532510995865, 'loss_2': 0.005077362060546875, 'loss_3': -15.665863990783691, 'loss_4': 4.6236891746521, 'epoch': 1.82}
{'loss': 0.0639, 'grad_norm': 29.544166564941406, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.05750526115298271, 'loss_2': 0.006378173828125, 'loss_3': -15.604935646057129, 'loss_4': 4.609880447387695, 'epoch': 1.83}
{'loss': 0.043, 'grad_norm': 12.433195114135742, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.038806602358818054, 'loss_2': 0.00418853759765625, 'loss_3': -15.732831001281738, 'loss_4': 4.964350700378418, 'epoch': 1.83}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:32:22,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:22,133 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:11<1:25:39,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:32:29,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011303422972559929, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.223, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006653731223195791, 'eval_loss_2': 0.00464969128370285, 'eval_loss_3': -18.36798095703125, 'eval_loss_4': 4.0922417640686035, 'epoch': 1.83}
{'loss': 0.0505, 'grad_norm': 13.516562461853027, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.03694175183773041, 'loss_2': 0.01358795166015625, 'loss_3': -15.55150032043457, 'loss_4': 4.770886421203613, 'epoch': 1.84}
{'loss': 0.035, 'grad_norm': 10.443922996520996, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.02822325937449932, 'loss_2': 0.00677490234375, 'loss_3': -15.626747131347656, 'loss_4': 4.523793697357178, 'epoch': 1.84}
{'loss': 0.027, 'grad_norm': 10.996243476867676, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.02658948116004467, 'loss_2': 0.00045490264892578125, 'loss_3': -15.502442359924316, 'loss_4': 4.168638229370117, 'epoch': 1.85}
{'loss': 0.0309, 'grad_norm': 11.2343168258667, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.028407124802470207, 'loss_2': 0.002468109130859375, 'loss_3': -15.602783203125, 'loss_4': 4.654955863952637, 'epoch': 1.85}
{'loss': 0.1046, 'grad_norm': 23.8958740234375, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.10375463962554932, 'loss_2': 0.0008707046508789062, 'loss_3': -15.499052047729492, 'loss_4': 4.732334136962891, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 09:32:29,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:29,491 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:19<1:24:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:36,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017037199810147285, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.123, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007254886440932751, 'eval_loss_2': 0.00978231430053711, 'eval_loss_3': -18.34008026123047, 'eval_loss_4': 3.8095619678497314, 'epoch': 1.86}
{'loss': 0.0235, 'grad_norm': 6.41669225692749, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.012950032018125057, 'loss_2': 0.01056671142578125, 'loss_3': -15.806964874267578, 'loss_4': 3.87168288230896, 'epoch': 1.87}
{'loss': 0.0345, 'grad_norm': 9.014787673950195, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.023058926686644554, 'loss_2': 0.011474609375, 'loss_3': -15.661887168884277, 'loss_4': 3.9238686561584473, 'epoch': 1.87}
{'loss': 0.0511, 'grad_norm': 16.547374725341797, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.04001367837190628, 'loss_2': 0.0111083984375, 'loss_3': -15.688080787658691, 'loss_4': 3.633131504058838, 'epoch': 1.88}
{'loss': 0.0908, 'grad_norm': 28.107486724853516, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.0848265215754509, 'loss_2': 0.005954742431640625, 'loss_3': -15.703695297241211, 'loss_4': 4.501772880554199, 'epoch': 1.88}
{'loss': 0.047, 'grad_norm': 19.504383087158203, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.041204676032066345, 'loss_2': 0.005748748779296875, 'loss_3': -15.849472045898438, 'loss_4': 4.045243740081787, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 09:32:36,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:36,852 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:26<1:23:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:44,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01354330312460661, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007245267741382122, 'eval_loss_2': 0.006298035383224487, 'eval_loss_3': -18.377403259277344, 'eval_loss_4': 3.4437503814697266, 'epoch': 1.89}
{'loss': 0.0211, 'grad_norm': 7.870569705963135, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.019110379740595818, 'loss_2': 0.001983642578125, 'loss_3': -15.521896362304688, 'loss_4': 3.8929660320281982, 'epoch': 1.9}
{'loss': 0.0391, 'grad_norm': 9.97030258178711, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.027671677991747856, 'loss_2': 0.01145172119140625, 'loss_3': -15.740131378173828, 'loss_4': 3.7445602416992188, 'epoch': 1.9}
{'loss': 0.03, 'grad_norm': 10.852398872375488, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.024701006710529327, 'loss_2': 0.00533294677734375, 'loss_3': -15.631134986877441, 'loss_4': 3.7477664947509766, 'epoch': 1.91}
{'loss': 0.0255, 'grad_norm': 8.94272232055664, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.02349022775888443, 'loss_2': 0.00196075439453125, 'loss_3': -15.790599822998047, 'loss_4': 2.9946482181549072, 'epoch': 1.91}
{'loss': 0.0217, 'grad_norm': 7.539769172668457, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.02126607857644558, 'loss_2': 0.0004277229309082031, 'loss_3': -15.86667251586914, 'loss_4': 4.183542728424072, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 09:32:44,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:44,217 >>   Batch size = 64
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:33<1:23:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:51,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01320849172770977, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.704, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008880330249667168, 'eval_loss_2': 0.0043281614780426025, 'eval_loss_3': -18.384140014648438, 'eval_loss_4': 2.998413324356079, 'epoch': 1.92}
{'loss': 0.0373, 'grad_norm': 10.191336631774902, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.02585715986788273, 'loss_2': 0.0114898681640625, 'loss_3': -15.640605926513672, 'loss_4': 3.3035507202148438, 'epoch': 1.92}
{'loss': 0.066, 'grad_norm': 20.829526901245117, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.04778103157877922, 'loss_2': 0.0181884765625, 'loss_3': -15.74285888671875, 'loss_4': 3.297393798828125, 'epoch': 1.93}
{'loss': 0.1375, 'grad_norm': 27.903295516967773, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.12791189551353455, 'loss_2': 0.0095672607421875, 'loss_3': -15.641921997070312, 'loss_4': 3.702512741088867, 'epoch': 1.94}
{'loss': 0.0497, 'grad_norm': 16.759069442749023, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.03573913872241974, 'loss_2': 0.013916015625, 'loss_3': -15.713214874267578, 'loss_4': 3.307929277420044, 'epoch': 1.94}
{'loss': 0.0456, 'grad_norm': 8.516373634338379, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.031345851719379425, 'loss_2': 0.0142974853515625, 'loss_3': -15.808942794799805, 'loss_4': 2.9668052196502686, 'epoch': 1.95}
[INFO|trainer.py:4228] 2025-01-21 09:32:51,578 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:51,578 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:41<1:23:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:58,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01750142127275467, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.678, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0083316033706069, 'eval_loss_2': 0.009169816970825195, 'eval_loss_3': -18.380468368530273, 'eval_loss_4': 2.6285016536712646, 'epoch': 1.95}
{'loss': 0.0787, 'grad_norm': 16.181907653808594, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.055018350481987, 'loss_2': 0.023681640625, 'loss_3': -15.837337493896484, 'loss_4': 3.117157220840454, 'epoch': 1.95}
{'loss': 0.0479, 'grad_norm': 9.324570655822754, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.032883986830711365, 'loss_2': 0.0150146484375, 'loss_3': -15.832884788513184, 'loss_4': 2.8505654335021973, 'epoch': 1.96}
{'loss': 0.0436, 'grad_norm': 15.73896312713623, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.039309240877628326, 'loss_2': 0.004306793212890625, 'loss_3': -15.799302101135254, 'loss_4': 3.030520439147949, 'epoch': 1.97}
{'loss': 0.0703, 'grad_norm': 30.764751434326172, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.06905436515808105, 'loss_2': 0.001251220703125, 'loss_3': -15.592225074768066, 'loss_4': 3.104811429977417, 'epoch': 1.97}
{'loss': 0.0353, 'grad_norm': 13.985276222229004, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.03219592943787575, 'loss_2': 0.0031299591064453125, 'loss_3': -15.63768196105957, 'loss_4': 3.655134916305542, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 09:32:58,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:58,942 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:48<1:18:31,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 09:33:05,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02207326330244541, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009801858104765415, 'eval_loss_2': 0.012271404266357422, 'eval_loss_3': -18.319660186767578, 'eval_loss_4': 2.6403934955596924, 'epoch': 1.98}
{'loss': 0.0333, 'grad_norm': 7.767847061157227, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.019841551780700684, 'loss_2': 0.0134124755859375, 'loss_3': -15.844779968261719, 'loss_4': 2.844147205352783, 'epoch': 1.98}
{'loss': 0.0401, 'grad_norm': 14.847792625427246, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.02357347682118416, 'loss_2': 0.0164947509765625, 'loss_3': -15.710369110107422, 'loss_4': 2.8741836547851562, 'epoch': 1.99}
{'loss': 0.0622, 'grad_norm': 17.683740615844727, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.04153738543391228, 'loss_2': 0.02069091796875, 'loss_3': -15.731515884399414, 'loss_4': 3.0636491775512695, 'epoch': 1.99}
{'loss': 0.0391, 'grad_norm': 8.74244213104248, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.019510943442583084, 'loss_2': 0.01959228515625, 'loss_3': -15.867119789123535, 'loss_4': 3.999131679534912, 'epoch': 2.0}
{'loss': 0.0629, 'grad_norm': 12.888994216918945, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.04299473017454147, 'loss_2': 0.0199432373046875, 'loss_3': -15.759541511535645, 'loss_4': 3.038499355316162, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 09:33:05,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:05,988 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [08:55<1:22:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:33:13,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024240508675575256, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009639275260269642, 'eval_loss_2': 0.01460123062133789, 'eval_loss_3': -18.29517364501953, 'eval_loss_4': 2.7684133052825928, 'epoch': 2.01}
{'loss': 0.0463, 'grad_norm': 16.779991149902344, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.030440349131822586, 'loss_2': 0.0158233642578125, 'loss_3': -15.905254364013672, 'loss_4': 2.671363353729248, 'epoch': 2.01}
{'loss': 0.0374, 'grad_norm': 10.473257064819336, 'learning_rate': 2.8e-05, 'loss_1': 0.026308638975024223, 'loss_2': 0.0110931396484375, 'loss_3': -15.87176513671875, 'loss_4': 3.521737813949585, 'epoch': 2.02}
{'loss': 0.0383, 'grad_norm': 15.47873306274414, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.03254164010286331, 'loss_2': 0.005767822265625, 'loss_3': -15.850205421447754, 'loss_4': 2.102928638458252, 'epoch': 2.02}
{'loss': 0.0177, 'grad_norm': 6.836874008178711, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.015863291919231415, 'loss_2': 0.0018062591552734375, 'loss_3': -15.875261306762695, 'loss_4': 2.4459259510040283, 'epoch': 2.03}
{'loss': 0.0332, 'grad_norm': 10.231363296508789, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.030985243618488312, 'loss_2': 0.00225830078125, 'loss_3': -15.832197189331055, 'loss_4': 2.4697930812835693, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 09:33:13,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:13,339 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:02<1:23:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:20,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013853372074663639, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.524, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009911970235407352, 'eval_loss_2': 0.003941401839256287, 'eval_loss_3': -18.31918716430664, 'eval_loss_4': 2.756227493286133, 'epoch': 2.03}
{'loss': 0.0473, 'grad_norm': 20.163076400756836, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.042465340346097946, 'loss_2': 0.004795074462890625, 'loss_3': -15.798625946044922, 'loss_4': 2.9479293823242188, 'epoch': 2.04}
{'loss': 0.072, 'grad_norm': 19.959213256835938, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.06360621005296707, 'loss_2': 0.008392333984375, 'loss_3': -15.60769271850586, 'loss_4': 4.242720603942871, 'epoch': 2.05}
{'loss': 0.0509, 'grad_norm': 19.67209243774414, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.048763785511255264, 'loss_2': 0.0021076202392578125, 'loss_3': -15.763395309448242, 'loss_4': 2.8477871417999268, 'epoch': 2.05}
{'loss': 0.0666, 'grad_norm': 16.512462615966797, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.06019633635878563, 'loss_2': 0.00635528564453125, 'loss_3': -15.696329116821289, 'loss_4': 2.9100677967071533, 'epoch': 2.06}
{'loss': 0.0387, 'grad_norm': 15.171219825744629, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.033793773502111435, 'loss_2': 0.00492095947265625, 'loss_3': -15.831960678100586, 'loss_4': 3.056215524673462, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 09:33:20,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:20,708 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:10<1:23:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:28,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018228944391012192, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.529, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012470658868551254, 'eval_loss_2': 0.0057582855224609375, 'eval_loss_3': -18.336782455444336, 'eval_loss_4': 2.689467191696167, 'epoch': 2.06}
{'loss': 0.0427, 'grad_norm': 8.29532527923584, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.02793130651116371, 'loss_2': 0.01480865478515625, 'loss_3': -15.892333984375, 'loss_4': 2.9468026161193848, 'epoch': 2.07}
{'loss': 0.0552, 'grad_norm': 18.339153289794922, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.04815995320677757, 'loss_2': 0.00699615478515625, 'loss_3': -15.76119613647461, 'loss_4': 2.949122428894043, 'epoch': 2.08}
{'loss': 0.0251, 'grad_norm': 10.18565559387207, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.023906011134386063, 'loss_2': 0.0011463165283203125, 'loss_3': -15.976449966430664, 'loss_4': 3.28763484954834, 'epoch': 2.08}
{'loss': 0.0398, 'grad_norm': 9.704922676086426, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.03520393371582031, 'loss_2': 0.00460052490234375, 'loss_3': -15.932872772216797, 'loss_4': 3.3134865760803223, 'epoch': 2.09}
{'loss': 0.0344, 'grad_norm': 10.562755584716797, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.03289574384689331, 'loss_2': 0.0015048980712890625, 'loss_3': -16.078529357910156, 'loss_4': 3.179628849029541, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 09:33:28,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:28,082 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:17<1:23:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:35,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016375314444303513, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.48, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.012821417301893234, 'eval_loss_2': 0.0035538971424102783, 'eval_loss_3': -18.405393600463867, 'eval_loss_4': 2.5071372985839844, 'epoch': 2.09}
{'loss': 0.059, 'grad_norm': 14.812324523925781, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.054275695234537125, 'loss_2': 0.004703521728515625, 'loss_3': -15.87730884552002, 'loss_4': 3.0550267696380615, 'epoch': 2.1}
{'loss': 0.039, 'grad_norm': 12.104462623596191, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.03501911461353302, 'loss_2': 0.0040283203125, 'loss_3': -16.0887451171875, 'loss_4': 2.90887713432312, 'epoch': 2.1}
{'loss': 0.0456, 'grad_norm': 10.42326545715332, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.0426371693611145, 'loss_2': 0.003002166748046875, 'loss_3': -15.894826889038086, 'loss_4': 2.9583170413970947, 'epoch': 2.11}
{'loss': 0.0243, 'grad_norm': 8.683810234069824, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.023951778188347816, 'loss_2': 0.0003752708435058594, 'loss_3': -15.89906120300293, 'loss_4': 2.657895565032959, 'epoch': 2.12}
{'loss': 0.051, 'grad_norm': 14.638296127319336, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.05075779929757118, 'loss_2': 0.00021255016326904297, 'loss_3': -15.806659698486328, 'loss_4': 2.328132152557373, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 09:33:35,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:35,453 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:24<1:23:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:42,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016276206821203232, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.508, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.012960519641637802, 'eval_loss_2': 0.0033156871795654297, 'eval_loss_3': -18.41128921508789, 'eval_loss_4': 2.4615478515625, 'epoch': 2.12}
{'loss': 0.0852, 'grad_norm': 25.693164825439453, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.08403510600328445, 'loss_2': 0.0011968612670898438, 'loss_3': -16.05274200439453, 'loss_4': 2.8699541091918945, 'epoch': 2.13}
{'loss': 0.0472, 'grad_norm': 11.608155250549316, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.04077287018299103, 'loss_2': 0.00640869140625, 'loss_3': -16.14543342590332, 'loss_4': 3.0964300632476807, 'epoch': 2.13}
{'loss': 0.0758, 'grad_norm': 26.842056274414062, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.0726907029747963, 'loss_2': 0.003147125244140625, 'loss_3': -15.844391822814941, 'loss_4': 3.2161941528320312, 'epoch': 2.14}
{'loss': 0.0652, 'grad_norm': 22.455495834350586, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.05890423804521561, 'loss_2': 0.006290435791015625, 'loss_3': -15.84117603302002, 'loss_4': 2.9083175659179688, 'epoch': 2.15}
{'loss': 0.0349, 'grad_norm': 11.028891563415527, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.0332350917160511, 'loss_2': 0.0016918182373046875, 'loss_3': -15.782142639160156, 'loss_4': 3.1070384979248047, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 09:33:42,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:42,820 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:32<1:22:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:50,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016466498374938965, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.899, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01258528046309948, 'eval_loss_2': 0.003881216049194336, 'eval_loss_3': -18.42854118347168, 'eval_loss_4': 2.475074529647827, 'epoch': 2.15}
{'loss': 0.0399, 'grad_norm': 10.190315246582031, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.03865468502044678, 'loss_2': 0.001277923583984375, 'loss_3': -15.874696731567383, 'loss_4': 2.4339516162872314, 'epoch': 2.16}
{'loss': 0.2328, 'grad_norm': 30.180280685424805, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.2253011167049408, 'loss_2': 0.007537841796875, 'loss_3': -15.788544654846191, 'loss_4': 2.62890362739563, 'epoch': 2.16}
{'loss': 0.1074, 'grad_norm': 24.845857620239258, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.09927413612604141, 'loss_2': 0.008087158203125, 'loss_3': -16.036556243896484, 'loss_4': 3.13238525390625, 'epoch': 2.17}
{'loss': 0.0212, 'grad_norm': 6.941904067993164, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.02051600068807602, 'loss_2': 0.0006427764892578125, 'loss_3': -16.209125518798828, 'loss_4': 3.1747732162475586, 'epoch': 2.17}
{'loss': 0.051, 'grad_norm': 11.684168815612793, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.04053260758519173, 'loss_2': 0.0104827880859375, 'loss_3': -15.927772521972656, 'loss_4': 3.103794813156128, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 09:33:50,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:50,180 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:39<1:22:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:57,543 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023612407967448235, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012081529945135117, 'eval_loss_2': 0.011530876159667969, 'eval_loss_3': -18.423192977905273, 'eval_loss_4': 2.7539703845977783, 'epoch': 2.18}
{'loss': 0.033, 'grad_norm': 7.94919490814209, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.02338395267724991, 'loss_2': 0.0096435546875, 'loss_3': -15.941271781921387, 'loss_4': 3.011378526687622, 'epoch': 2.19}
{'loss': 0.0492, 'grad_norm': 9.446639060974121, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.03738142549991608, 'loss_2': 0.0118255615234375, 'loss_3': -15.967350006103516, 'loss_4': 3.100574016571045, 'epoch': 2.19}
{'loss': 0.0803, 'grad_norm': 25.87553596496582, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.07568596303462982, 'loss_2': 0.004611968994140625, 'loss_3': -15.984174728393555, 'loss_4': 3.1668128967285156, 'epoch': 2.2}
{'loss': 0.0387, 'grad_norm': 13.433618545532227, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.03609775751829147, 'loss_2': 0.00257110595703125, 'loss_3': -15.841687202453613, 'loss_4': 3.1191091537475586, 'epoch': 2.2}
{'loss': 0.0471, 'grad_norm': 15.616584777832031, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.04605184867978096, 'loss_2': 0.0010614395141601562, 'loss_3': -15.799674987792969, 'loss_4': 3.4595487117767334, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 09:33:57,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:57,543 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:47<1:22:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:04,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016112949699163437, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011985596269369125, 'eval_loss_2': 0.0041273534297943115, 'eval_loss_3': -18.41216278076172, 'eval_loss_4': 2.9365344047546387, 'epoch': 2.21}
{'loss': 0.0245, 'grad_norm': 9.512460708618164, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.02412450686097145, 'loss_2': 0.00042176246643066406, 'loss_3': -15.767566680908203, 'loss_4': 3.3088622093200684, 'epoch': 2.22}
{'loss': 0.0435, 'grad_norm': 12.550397872924805, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.03356629237532616, 'loss_2': 0.00991058349609375, 'loss_3': -15.875116348266602, 'loss_4': 2.6825575828552246, 'epoch': 2.22}
{'loss': 0.0576, 'grad_norm': 22.799510955810547, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.05662273243069649, 'loss_2': 0.0009312629699707031, 'loss_3': -15.59112548828125, 'loss_4': 2.9748756885528564, 'epoch': 2.23}
{'loss': 0.037, 'grad_norm': 12.969999313354492, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.03115602768957615, 'loss_2': 0.00583648681640625, 'loss_3': -15.968414306640625, 'loss_4': 3.2793002128601074, 'epoch': 2.23}
{'loss': 0.0412, 'grad_norm': 10.643190383911133, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.033964864909648895, 'loss_2': 0.00722503662109375, 'loss_3': -16.092199325561523, 'loss_4': 2.956008195877075, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 09:34:04,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:04,910 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [09:54<1:22:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:12,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01909957081079483, 'eval_runtime': 3.8252, 'eval_samples_per_second': 267.701, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.01123211532831192, 'eval_loss_2': 0.00786745548248291, 'eval_loss_3': -18.364601135253906, 'eval_loss_4': 2.766813278198242, 'epoch': 2.24}
{'loss': 0.0317, 'grad_norm': 7.995291709899902, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.027451425790786743, 'loss_2': 0.0042877197265625, 'loss_3': -15.896337509155273, 'loss_4': 2.589932680130005, 'epoch': 2.24}
{'loss': 0.0511, 'grad_norm': 13.678279876708984, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.038247402757406235, 'loss_2': 0.012847900390625, 'loss_3': -15.675966262817383, 'loss_4': 2.845010757446289, 'epoch': 2.25}
{'loss': 0.0334, 'grad_norm': 9.471598625183105, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.02886689454317093, 'loss_2': 0.004547119140625, 'loss_3': -15.83673095703125, 'loss_4': 2.88391375541687, 'epoch': 2.26}
{'loss': 0.0359, 'grad_norm': 15.289633750915527, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.03368145972490311, 'loss_2': 0.00218963623046875, 'loss_3': -16.009239196777344, 'loss_4': 3.348710060119629, 'epoch': 2.26}
{'loss': 0.0331, 'grad_norm': 7.92553186416626, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.025933992117643356, 'loss_2': 0.007137298583984375, 'loss_3': -15.971235275268555, 'loss_4': 2.8146138191223145, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 09:34:12,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:12,303 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:01<1:22:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:19,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017586126923561096, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.572, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012989088892936707, 'eval_loss_2': 0.00459703803062439, 'eval_loss_3': -18.366477966308594, 'eval_loss_4': 2.728022575378418, 'epoch': 2.27}
{'loss': 0.0667, 'grad_norm': 18.236854553222656, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.06652379035949707, 'loss_2': 0.0001316070556640625, 'loss_3': -15.988883972167969, 'loss_4': 2.7871181964874268, 'epoch': 2.27}
{'loss': 0.0295, 'grad_norm': 11.054969787597656, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.02412957325577736, 'loss_2': 0.0054168701171875, 'loss_3': -15.813648223876953, 'loss_4': 2.8504889011383057, 'epoch': 2.28}
{'loss': 0.0326, 'grad_norm': 9.544543266296387, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.026657909154891968, 'loss_2': 0.00591278076171875, 'loss_3': -15.821348190307617, 'loss_4': 3.1655189990997314, 'epoch': 2.28}
{'loss': 0.0302, 'grad_norm': 9.577882766723633, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.029871821403503418, 'loss_2': 0.0003147125244140625, 'loss_3': -15.970011711120605, 'loss_4': 3.687680244445801, 'epoch': 2.29}
{'loss': 0.06, 'grad_norm': 18.83531951904297, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.0563482865691185, 'loss_2': 0.003604888916015625, 'loss_3': -15.792014122009277, 'loss_4': 2.8562979698181152, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 09:34:19,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:19,671 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:09<1:22:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:27,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01718973182141781, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.777, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011523595079779625, 'eval_loss_2': 0.005666136741638184, 'eval_loss_3': -18.40019416809082, 'eval_loss_4': 2.7581372261047363, 'epoch': 2.3}
{'loss': 0.0475, 'grad_norm': 11.924083709716797, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.040998633950948715, 'loss_2': 0.006549835205078125, 'loss_3': -15.822815895080566, 'loss_4': 3.468001365661621, 'epoch': 2.3}
{'loss': 0.0378, 'grad_norm': 6.267293453216553, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.020527156069874763, 'loss_2': 0.017242431640625, 'loss_3': -16.011890411376953, 'loss_4': 2.5834999084472656, 'epoch': 2.31}
{'loss': 0.0424, 'grad_norm': 13.68877124786377, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.038996074348688126, 'loss_2': 0.003360748291015625, 'loss_3': -15.927665710449219, 'loss_4': 3.3958725929260254, 'epoch': 2.31}
{'loss': 0.0601, 'grad_norm': 17.61984634399414, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.05007233843207359, 'loss_2': 0.00998687744140625, 'loss_3': -15.731722831726074, 'loss_4': 3.470829963684082, 'epoch': 2.32}
{'loss': 0.0729, 'grad_norm': 21.55998420715332, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.06828140467405319, 'loss_2': 0.004638671875, 'loss_3': -15.866958618164062, 'loss_4': 3.200742244720459, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 09:34:27,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:27,035 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:16<1:22:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:34,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01824406161904335, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.605, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009979519993066788, 'eval_loss_2': 0.008264541625976562, 'eval_loss_3': -18.382402420043945, 'eval_loss_4': 2.794966220855713, 'epoch': 2.33}
{'loss': 0.0544, 'grad_norm': 11.280985832214355, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.04155433177947998, 'loss_2': 0.0128936767578125, 'loss_3': -16.063928604125977, 'loss_4': 3.5240657329559326, 'epoch': 2.33}
{'loss': 0.062, 'grad_norm': 15.119880676269531, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.046207599341869354, 'loss_2': 0.0157623291015625, 'loss_3': -15.740225791931152, 'loss_4': 3.2094922065734863, 'epoch': 2.34}
{'loss': 0.0355, 'grad_norm': 8.120255470275879, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.024754595011472702, 'loss_2': 0.01070404052734375, 'loss_3': -15.878021240234375, 'loss_4': 2.9877495765686035, 'epoch': 2.34}
{'loss': 0.0671, 'grad_norm': 15.111188888549805, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.05311337858438492, 'loss_2': 0.014007568359375, 'loss_3': -15.708364486694336, 'loss_4': 3.538370132446289, 'epoch': 2.35}
{'loss': 0.038, 'grad_norm': 9.029587745666504, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.029599405825138092, 'loss_2': 0.00843048095703125, 'loss_3': -15.932708740234375, 'loss_4': 3.42116379737854, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 09:34:34,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:34,408 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:23<1:22:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:41,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01614481955766678, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.725, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010433144867420197, 'eval_loss_2': 0.005711674690246582, 'eval_loss_3': -18.363046646118164, 'eval_loss_4': 2.613154888153076, 'epoch': 2.35}
{'loss': 0.0476, 'grad_norm': 16.73868179321289, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.045839328318834305, 'loss_2': 0.0017976760864257812, 'loss_3': -15.889732360839844, 'loss_4': 3.585381507873535, 'epoch': 2.36}
{'loss': 0.0469, 'grad_norm': 11.729742050170898, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.03603160381317139, 'loss_2': 0.01082611083984375, 'loss_3': -15.918689727783203, 'loss_4': 2.984881639480591, 'epoch': 2.37}
{'loss': 0.045, 'grad_norm': 12.469393730163574, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.03623110428452492, 'loss_2': 0.00872039794921875, 'loss_3': -15.738304138183594, 'loss_4': 2.7136499881744385, 'epoch': 2.37}
{'loss': 0.0361, 'grad_norm': 9.287694931030273, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.03113345243036747, 'loss_2': 0.00495147705078125, 'loss_3': -15.777353286743164, 'loss_4': 3.0950934886932373, 'epoch': 2.38}
{'loss': 0.029, 'grad_norm': 7.830456733703613, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.02510085515677929, 'loss_2': 0.00394439697265625, 'loss_3': -15.792505264282227, 'loss_4': 3.319666862487793, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 09:34:41,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:41,768 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:31<1:22:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:49,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01744813844561577, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.692, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01280362531542778, 'eval_loss_2': 0.004644513130187988, 'eval_loss_3': -18.28804588317871, 'eval_loss_4': 2.8756611347198486, 'epoch': 2.38}
{'loss': 0.0221, 'grad_norm': 7.136175155639648, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.02062961645424366, 'loss_2': 0.0014257431030273438, 'loss_3': -15.62939453125, 'loss_4': 3.7303519248962402, 'epoch': 2.39}
{'loss': 0.0508, 'grad_norm': 13.317464828491211, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.0452132411301136, 'loss_2': 0.00555419921875, 'loss_3': -15.96961784362793, 'loss_4': 3.5461716651916504, 'epoch': 2.4}
{'loss': 0.039, 'grad_norm': 7.638321876525879, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.023197051137685776, 'loss_2': 0.0157928466796875, 'loss_3': -15.733781814575195, 'loss_4': 3.163102865219116, 'epoch': 2.4}
{'loss': 0.0407, 'grad_norm': 14.021705627441406, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.03416763246059418, 'loss_2': 0.006500244140625, 'loss_3': -15.763946533203125, 'loss_4': 3.4977242946624756, 'epoch': 2.41}
{'loss': 0.0559, 'grad_norm': 15.295452117919922, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.05239585041999817, 'loss_2': 0.003467559814453125, 'loss_3': -15.757242202758789, 'loss_4': 3.878926992416382, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 09:34:49,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:49,130 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:38<1:22:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:56,501 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017059557139873505, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.244, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013446979224681854, 'eval_loss_2': 0.0036125779151916504, 'eval_loss_3': -18.230714797973633, 'eval_loss_4': 3.6185171604156494, 'epoch': 2.41}
{'loss': 0.0228, 'grad_norm': 7.798200607299805, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.022624118253588676, 'loss_2': 0.00017523765563964844, 'loss_3': -15.804369926452637, 'loss_4': 3.5920042991638184, 'epoch': 2.42}
{'loss': 0.0288, 'grad_norm': 7.167907238006592, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.021619124338030815, 'loss_2': 0.0071868896484375, 'loss_3': -15.606067657470703, 'loss_4': 4.008814811706543, 'epoch': 2.42}
{'loss': 0.0232, 'grad_norm': 8.78323745727539, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.019122745841741562, 'loss_2': 0.004055023193359375, 'loss_3': -15.76816463470459, 'loss_4': 4.443347454071045, 'epoch': 2.43}
{'loss': 0.0208, 'grad_norm': 7.738468170166016, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.020131975412368774, 'loss_2': 0.0006952285766601562, 'loss_3': -15.822555541992188, 'loss_4': 4.750706672668457, 'epoch': 2.44}
{'loss': 0.0739, 'grad_norm': 25.808332443237305, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.07043497264385223, 'loss_2': 0.0034637451171875, 'loss_3': -15.635835647583008, 'loss_4': 4.313462734222412, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 09:34:56,502 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:56,502 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:46<1:22:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:03,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016604578122496605, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.862, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013056963682174683, 'eval_loss_2': 0.0035476163029670715, 'eval_loss_3': -18.225624084472656, 'eval_loss_4': 4.40518856048584, 'epoch': 2.44}
{'loss': 0.0341, 'grad_norm': 13.988816261291504, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.03405516594648361, 'loss_2': 6.4373016357421875e-06, 'loss_3': -15.757586479187012, 'loss_4': 5.023186683654785, 'epoch': 2.45}
{'loss': 0.0246, 'grad_norm': 7.7139177322387695, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.023601645603775978, 'loss_2': 0.00102996826171875, 'loss_3': -15.724584579467773, 'loss_4': 4.733372688293457, 'epoch': 2.45}
{'loss': 0.0351, 'grad_norm': 11.171370506286621, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.034609001129865646, 'loss_2': 0.00048542022705078125, 'loss_3': -15.718210220336914, 'loss_4': 4.2844109535217285, 'epoch': 2.46}
{'loss': 0.0988, 'grad_norm': 24.87704849243164, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.08357323706150055, 'loss_2': 0.01526641845703125, 'loss_3': -15.540264129638672, 'loss_4': 4.9719977378845215, 'epoch': 2.47}
{'loss': 0.0645, 'grad_norm': 18.72887420654297, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.05084404721856117, 'loss_2': 0.0136566162109375, 'loss_3': -15.660612106323242, 'loss_4': 5.035167694091797, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 09:35:03,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:03,872 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [10:53<1:22:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:11,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026962004601955414, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011310303583741188, 'eval_loss_2': 0.015651702880859375, 'eval_loss_3': -18.26474952697754, 'eval_loss_4': 4.622924327850342, 'epoch': 2.47}
{'loss': 0.0581, 'grad_norm': 10.31119441986084, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.04442307725548744, 'loss_2': 0.01372528076171875, 'loss_3': -15.508894920349121, 'loss_4': 4.69964599609375, 'epoch': 2.48}
{'loss': 0.0582, 'grad_norm': 16.342613220214844, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.03773609548807144, 'loss_2': 0.02044677734375, 'loss_3': -15.554789543151855, 'loss_4': 4.9321088790893555, 'epoch': 2.48}
{'loss': 0.092, 'grad_norm': 18.338956832885742, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.07279042899608612, 'loss_2': 0.019256591796875, 'loss_3': -15.673056602478027, 'loss_4': 4.308151721954346, 'epoch': 2.49}
{'loss': 0.0678, 'grad_norm': 14.658709526062012, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.04745946079492569, 'loss_2': 0.0203399658203125, 'loss_3': -15.619343757629395, 'loss_4': 4.887188911437988, 'epoch': 2.49}
{'loss': 0.1436, 'grad_norm': 25.386173248291016, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.1254590004682541, 'loss_2': 0.018157958984375, 'loss_3': -15.526762962341309, 'loss_4': 5.290993690490723, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 09:35:11,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:11,232 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:00<1:22:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:18,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024495989084243774, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.799, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011578950099647045, 'eval_loss_2': 0.012917041778564453, 'eval_loss_3': -18.269201278686523, 'eval_loss_4': 5.055289268493652, 'epoch': 2.5}
{'loss': 0.0839, 'grad_norm': 13.608621597290039, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.06380854547023773, 'loss_2': 0.0201263427734375, 'loss_3': -15.787517547607422, 'loss_4': 6.22195291519165, 'epoch': 2.51}
{'loss': 0.0701, 'grad_norm': 22.30020523071289, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.0559043288230896, 'loss_2': 0.01419830322265625, 'loss_3': -15.639819145202637, 'loss_4': 5.383627891540527, 'epoch': 2.51}
{'loss': 0.0414, 'grad_norm': 10.880598068237305, 'learning_rate': 2.75e-05, 'loss_1': 0.03576413542032242, 'loss_2': 0.005596160888671875, 'loss_3': -15.830314636230469, 'loss_4': 5.403247833251953, 'epoch': 2.52}
{'loss': 0.0656, 'grad_norm': 21.006855010986328, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.06427975744009018, 'loss_2': 0.0012760162353515625, 'loss_3': -15.418481826782227, 'loss_4': 5.80056095123291, 'epoch': 2.52}
{'loss': 0.0437, 'grad_norm': 10.329570770263672, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.04267752915620804, 'loss_2': 0.0010509490966796875, 'loss_3': -15.237072944641113, 'loss_4': 5.136760234832764, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 09:35:18,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:18,611 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:08<1:22:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:25,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026472292840480804, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.014267407357692719, 'eval_loss_2': 0.012204885482788086, 'eval_loss_3': -18.254131317138672, 'eval_loss_4': 5.591158390045166, 'epoch': 2.53}
{'loss': 0.0856, 'grad_norm': 21.90740394592285, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.07717148214578629, 'loss_2': 0.00844573974609375, 'loss_3': -15.693195343017578, 'loss_4': 6.049866199493408, 'epoch': 2.53}
{'loss': 0.0551, 'grad_norm': 12.105491638183594, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.03824620693922043, 'loss_2': 0.0168609619140625, 'loss_3': -15.685235023498535, 'loss_4': 6.32479190826416, 'epoch': 2.54}
{'loss': 0.1336, 'grad_norm': 23.959447860717773, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.11897491663694382, 'loss_2': 0.014617919921875, 'loss_3': -15.784117698669434, 'loss_4': 6.444298267364502, 'epoch': 2.55}
{'loss': 0.0682, 'grad_norm': 15.361608505249023, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.04911190643906593, 'loss_2': 0.01904296875, 'loss_3': -15.47071647644043, 'loss_4': 6.226321220397949, 'epoch': 2.55}
{'loss': 0.1055, 'grad_norm': 21.127410888671875, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.10047229379415512, 'loss_2': 0.0050506591796875, 'loss_3': -15.855131149291992, 'loss_4': 5.7163567543029785, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 09:35:25,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:25,995 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:15<1:21:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:33,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03745554760098457, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.899, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01625155285000801, 'eval_loss_2': 0.021203994750976562, 'eval_loss_3': -18.237380981445312, 'eval_loss_4': 5.548262596130371, 'epoch': 2.56}
{'loss': 0.0804, 'grad_norm': 16.657026290893555, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.06226474791765213, 'loss_2': 0.0181427001953125, 'loss_3': -15.680143356323242, 'loss_4': 5.635811805725098, 'epoch': 2.56}
{'loss': 0.0901, 'grad_norm': 18.587242126464844, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.07414183765649796, 'loss_2': 0.0159149169921875, 'loss_3': -15.403593063354492, 'loss_4': 5.515557289123535, 'epoch': 2.57}
{'loss': 0.0675, 'grad_norm': 14.539778709411621, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.051326312124729156, 'loss_2': 0.0161590576171875, 'loss_3': -15.424829483032227, 'loss_4': 5.071169376373291, 'epoch': 2.58}
{'loss': 0.0662, 'grad_norm': 16.009241104125977, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.05567406862974167, 'loss_2': 0.0105133056640625, 'loss_3': -15.621262550354004, 'loss_4': 5.338936805725098, 'epoch': 2.58}
{'loss': 0.0585, 'grad_norm': 23.851043701171875, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.05787992477416992, 'loss_2': 0.0005750656127929688, 'loss_3': -15.64880084991455, 'loss_4': 5.121049404144287, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 09:35:33,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:33,368 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:22<1:21:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:40,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013659261167049408, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.156, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009444431401789188, 'eval_loss_2': 0.004214830696582794, 'eval_loss_3': -18.221982955932617, 'eval_loss_4': 4.810578346252441, 'epoch': 2.59}
{'loss': 0.027, 'grad_norm': 8.006430625915527, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.025315813720226288, 'loss_2': 0.0017108917236328125, 'loss_3': -15.893105506896973, 'loss_4': 5.419991493225098, 'epoch': 2.59}
{'loss': 0.0346, 'grad_norm': 11.666581153869629, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.031191721558570862, 'loss_2': 0.003368377685546875, 'loss_3': -15.742810249328613, 'loss_4': 5.2295684814453125, 'epoch': 2.6}
{'loss': 0.0452, 'grad_norm': 16.999366760253906, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.04035476967692375, 'loss_2': 0.004825592041015625, 'loss_3': -15.652486801147461, 'loss_4': 5.45125675201416, 'epoch': 2.6}
{'loss': 0.0368, 'grad_norm': 11.72883129119873, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.03323492780327797, 'loss_2': 0.003551483154296875, 'loss_3': -15.634765625, 'loss_4': 4.6642680168151855, 'epoch': 2.61}
{'loss': 0.0698, 'grad_norm': 18.2747802734375, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.06109844893217087, 'loss_2': 0.0086669921875, 'loss_3': -15.66390609741211, 'loss_4': 5.450796127319336, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 09:35:40,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:40,742 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:30<1:21:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:48,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0168648399412632, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.827, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01279357448220253, 'eval_loss_2': 0.004071265459060669, 'eval_loss_3': -18.213054656982422, 'eval_loss_4': 4.979704856872559, 'epoch': 2.62}
{'loss': 0.0378, 'grad_norm': 9.608221054077148, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.029842983931303024, 'loss_2': 0.00791168212890625, 'loss_3': -15.467659950256348, 'loss_4': 5.455609321594238, 'epoch': 2.62}
{'loss': 0.0378, 'grad_norm': 10.863024711608887, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.0377177819609642, 'loss_2': 6.0677528381347656e-05, 'loss_3': -15.69697380065918, 'loss_4': 6.02580451965332, 'epoch': 2.63}
{'loss': 0.0459, 'grad_norm': 19.408855438232422, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.0402674600481987, 'loss_2': 0.0055999755859375, 'loss_3': -15.680351257324219, 'loss_4': 5.561550140380859, 'epoch': 2.63}
{'loss': 0.0504, 'grad_norm': 10.92080307006836, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.041156746447086334, 'loss_2': 0.0092315673828125, 'loss_3': -15.632925033569336, 'loss_4': 5.77780294418335, 'epoch': 2.64}
{'loss': 0.032, 'grad_norm': 11.865219116210938, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.031935565173625946, 'loss_2': 9.524822235107422e-05, 'loss_3': -15.596657752990723, 'loss_4': 5.491148471832275, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 09:35:48,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:48,115 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:37<1:21:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:55,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017554910853505135, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013218777254223824, 'eval_loss_2': 0.004336133599281311, 'eval_loss_3': -18.188274383544922, 'eval_loss_4': 5.065686225891113, 'epoch': 2.65}
{'loss': 0.0435, 'grad_norm': 18.74448585510254, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.042914774268865585, 'loss_2': 0.0006351470947265625, 'loss_3': -15.672409057617188, 'loss_4': 5.0401458740234375, 'epoch': 2.65}
{'loss': 0.0267, 'grad_norm': 11.069439888000488, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.024898910894989967, 'loss_2': 0.0018024444580078125, 'loss_3': -15.475988388061523, 'loss_4': 5.216547012329102, 'epoch': 2.66}
{'loss': 0.0291, 'grad_norm': 7.630588531494141, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.026773158460855484, 'loss_2': 0.002300262451171875, 'loss_3': -15.739663124084473, 'loss_4': 5.907769680023193, 'epoch': 2.66}
{'loss': 0.0418, 'grad_norm': 11.120007514953613, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.041589003056287766, 'loss_2': 0.00019288063049316406, 'loss_3': -15.500368118286133, 'loss_4': 5.649887561798096, 'epoch': 2.67}
{'loss': 0.0767, 'grad_norm': 17.373573303222656, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.06573005020618439, 'loss_2': 0.0110015869140625, 'loss_3': -15.707704544067383, 'loss_4': 5.1498565673828125, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 09:35:55,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:55,488 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:45<1:21:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:02,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01975226402282715, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.713, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.014073588885366917, 'eval_loss_2': 0.005678676068782806, 'eval_loss_3': -18.181453704833984, 'eval_loss_4': 4.947163105010986, 'epoch': 2.67}
{'loss': 0.0139, 'grad_norm': 5.5840253829956055, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.011987607926130295, 'loss_2': 0.0019283294677734375, 'loss_3': -15.563100814819336, 'loss_4': 4.628208637237549, 'epoch': 2.68}
{'loss': 0.036, 'grad_norm': 9.859278678894043, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.02769635058939457, 'loss_2': 0.00832366943359375, 'loss_3': -15.779658317565918, 'loss_4': 5.251216411590576, 'epoch': 2.69}
{'loss': 0.0293, 'grad_norm': 10.620404243469238, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.02782229334115982, 'loss_2': 0.0014820098876953125, 'loss_3': -15.745594024658203, 'loss_4': 4.523223400115967, 'epoch': 2.69}
{'loss': 0.0346, 'grad_norm': 9.6166353225708, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.02776871994137764, 'loss_2': 0.0068206787109375, 'loss_3': -15.498991012573242, 'loss_4': 4.899039268493652, 'epoch': 2.7}
{'loss': 0.036, 'grad_norm': 10.88839054107666, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.029412677511572838, 'loss_2': 0.006580352783203125, 'loss_3': -15.71133041381836, 'loss_4': 4.100132942199707, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 09:36:02,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:02,861 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [11:52<1:21:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:10,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014034198597073555, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.185, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.008044258691370487, 'eval_loss_2': 0.005989938974380493, 'eval_loss_3': -18.184310913085938, 'eval_loss_4': 4.224760055541992, 'epoch': 2.7}
{'loss': 0.0412, 'grad_norm': 13.6370267868042, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.03660653531551361, 'loss_2': 0.00457000732421875, 'loss_3': -15.723546981811523, 'loss_4': 4.6156768798828125, 'epoch': 2.71}
{'loss': 0.0277, 'grad_norm': 11.029824256896973, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.022364353761076927, 'loss_2': 0.00531005859375, 'loss_3': -15.624059677124023, 'loss_4': 4.5871381759643555, 'epoch': 2.72}
{'loss': 0.03, 'grad_norm': 13.726296424865723, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.02871512435376644, 'loss_2': 0.0013265609741210938, 'loss_3': -15.623247146606445, 'loss_4': 4.143664836883545, 'epoch': 2.72}
{'loss': 0.0458, 'grad_norm': 18.884248733520508, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.0438956581056118, 'loss_2': 0.001934051513671875, 'loss_3': -15.810037612915039, 'loss_4': 4.057852745056152, 'epoch': 2.73}
{'loss': 0.0312, 'grad_norm': 19.859302520751953, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.02654057927429676, 'loss_2': 0.00469970703125, 'loss_3': -15.497335433959961, 'loss_4': 3.7426888942718506, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 09:36:10,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:10,238 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [11:59<1:21:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:17,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01267450675368309, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.695, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008003409951925278, 'eval_loss_2': 0.0046710968017578125, 'eval_loss_3': -18.153827667236328, 'eval_loss_4': 3.796874523162842, 'epoch': 2.73}
{'loss': 0.0761, 'grad_norm': 24.59347152709961, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.07125968486070633, 'loss_2': 0.00487518310546875, 'loss_3': -15.60859489440918, 'loss_4': 4.437539100646973, 'epoch': 2.74}
{'loss': 0.0234, 'grad_norm': 6.07692813873291, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.01421706285327673, 'loss_2': 0.009185791015625, 'loss_3': -15.59533405303955, 'loss_4': 4.014273166656494, 'epoch': 2.74}
{'loss': 0.0541, 'grad_norm': 17.10092544555664, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.049203623086214066, 'loss_2': 0.00493621826171875, 'loss_3': -15.574031829833984, 'loss_4': 4.098031044006348, 'epoch': 2.75}
{'loss': 0.0396, 'grad_norm': 15.785326957702637, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.03854710981249809, 'loss_2': 0.0010709762573242188, 'loss_3': -15.584657669067383, 'loss_4': 3.2212843894958496, 'epoch': 2.76}
{'loss': 0.0301, 'grad_norm': 11.404864311218262, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.02948939986526966, 'loss_2': 0.0006351470947265625, 'loss_3': -15.735870361328125, 'loss_4': 3.5916337966918945, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 09:36:17,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:17,603 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:07<1:21:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:24,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018139220774173737, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.639, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011406519450247288, 'eval_loss_2': 0.0067327022552490234, 'eval_loss_3': -18.096147537231445, 'eval_loss_4': 3.508338689804077, 'epoch': 2.76}
{'loss': 0.0426, 'grad_norm': 9.927162170410156, 'learning_rate': 2.725e-05, 'loss_1': 0.027016006410121918, 'loss_2': 0.01556396484375, 'loss_3': -15.669719696044922, 'loss_4': 3.912266254425049, 'epoch': 2.77}
{'loss': 0.0609, 'grad_norm': 18.561660766601562, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.05494537204504013, 'loss_2': 0.00592803955078125, 'loss_3': -15.490062713623047, 'loss_4': 4.028059005737305, 'epoch': 2.77}
{'loss': 0.0786, 'grad_norm': 21.76922607421875, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.06832718104124069, 'loss_2': 0.01031494140625, 'loss_3': -15.625807762145996, 'loss_4': 4.027859210968018, 'epoch': 2.78}
{'loss': 0.0527, 'grad_norm': 36.65443420410156, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.04058654233813286, 'loss_2': 0.0121002197265625, 'loss_3': -15.59726333618164, 'loss_4': 3.6942248344421387, 'epoch': 2.78}
{'loss': 0.0138, 'grad_norm': 5.680814266204834, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.009374539367854595, 'loss_2': 0.004428863525390625, 'loss_3': -15.669707298278809, 'loss_4': 3.4566633701324463, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 09:36:24,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:24,976 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:14<1:21:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:32,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011461110785603523, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008809956721961498, 'eval_loss_2': 0.0026511549949645996, 'eval_loss_3': -18.112689971923828, 'eval_loss_4': 3.261488437652588, 'epoch': 2.79}
{'loss': 0.0366, 'grad_norm': 11.810805320739746, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.03195187449455261, 'loss_2': 0.00466156005859375, 'loss_3': -15.661267280578613, 'loss_4': 3.232774257659912, 'epoch': 2.8}
{'loss': 0.0379, 'grad_norm': 13.207449913024902, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.03095332719385624, 'loss_2': 0.00696563720703125, 'loss_3': -15.60183334350586, 'loss_4': 4.021091461181641, 'epoch': 2.8}
{'loss': 0.0241, 'grad_norm': 8.77868366241455, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.018497809767723083, 'loss_2': 0.005645751953125, 'loss_3': -15.795156478881836, 'loss_4': 3.805284023284912, 'epoch': 2.81}
{'loss': 0.0662, 'grad_norm': 21.535709381103516, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.06167925149202347, 'loss_2': 0.0045623779296875, 'loss_3': -15.463553428649902, 'loss_4': 4.108458518981934, 'epoch': 2.81}
{'loss': 0.0407, 'grad_norm': 9.049835205078125, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.032120246440172195, 'loss_2': 0.00861358642578125, 'loss_3': -15.726963996887207, 'loss_4': 4.075045585632324, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 09:36:32,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:32,337 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:21<1:21:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:39,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014752620831131935, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.525, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005334610119462013, 'eval_loss_2': 0.009418010711669922, 'eval_loss_3': -18.18844223022461, 'eval_loss_4': 4.017621994018555, 'epoch': 2.82}
{'loss': 0.0565, 'grad_norm': 26.505319595336914, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.05024676024913788, 'loss_2': 0.00626373291015625, 'loss_3': -15.506336212158203, 'loss_4': 5.16234016418457, 'epoch': 2.83}
{'loss': 0.0164, 'grad_norm': 6.580988883972168, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.012901052832603455, 'loss_2': 0.00348663330078125, 'loss_3': -15.691303253173828, 'loss_4': 4.381638050079346, 'epoch': 2.83}
{'loss': 0.0299, 'grad_norm': 12.38150405883789, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.024212779477238655, 'loss_2': 0.005649566650390625, 'loss_3': -15.648123741149902, 'loss_4': 5.082551956176758, 'epoch': 2.84}
{'loss': 0.0417, 'grad_norm': 10.484336853027344, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.03317089378833771, 'loss_2': 0.008514404296875, 'loss_3': -15.58898639678955, 'loss_4': 4.333073139190674, 'epoch': 2.84}
{'loss': 0.0266, 'grad_norm': 11.988560676574707, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.023991191759705544, 'loss_2': 0.0026092529296875, 'loss_3': -15.573189735412598, 'loss_4': 4.961496353149414, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 09:36:39,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:39,713 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:25<1:21:09,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:36:43,533 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-490
[INFO|configuration_utils.py:420] 2025-01-21 09:36:43,534 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-490/config.json                                                                              
{'eval_loss': 0.008819563314318657, 'eval_runtime': 3.819, 'eval_samples_per_second': 268.132, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.005416078492999077, 'eval_loss_2': 0.00340348482131958, 'eval_loss_3': -18.22816276550293, 'eval_loss_4': 4.855062484741211, 'epoch': 2.85}
[INFO|modeling_utils.py:2988] 2025-01-21 09:36:44,047 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-490/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:36:44,048 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-490/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:36:44,049 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-490/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:36:45,019 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-310] due to args.save_total_limit
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:30<1:29:55,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:36:48,672 >>
{'loss': 0.021, 'grad_norm': 10.227381706237793, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.019948679953813553, 'loss_2': 0.0010328292846679688, 'loss_3': -15.675169944763184, 'loss_4': 4.582108497619629, 'epoch': 2.85}
{'loss': 0.0179, 'grad_norm': 7.643651008605957, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.01758650504052639, 'loss_2': 0.00033593177795410156, 'loss_3': -15.660276412963867, 'loss_4': 5.3948974609375, 'epoch': 2.86}
{'loss': 0.063, 'grad_norm': 15.80759334564209, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.056821733713150024, 'loss_2': 0.0062103271484375, 'loss_3': -15.793901443481445, 'loss_4': 5.947901725769043, 'epoch': 2.87}
{'loss': 0.0321, 'grad_norm': 12.63920783996582, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.026393139734864235, 'loss_2': 0.00569915771484375, 'loss_3': -15.569856643676758, 'loss_4': 5.226661682128906, 'epoch': 2.87}
{'loss': 0.0357, 'grad_norm': 9.605342864990234, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.030529504641890526, 'loss_2': 0.0051727294921875, 'loss_3': -15.51441478729248, 'loss_4': 4.891783714294434, 'epoch': 2.88}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:36:48,672 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:48,672 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:38<1:22:23,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:36:56,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010690867900848389, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006298900581896305, 'eval_loss_2': 0.004391968250274658, 'eval_loss_3': -18.263477325439453, 'eval_loss_4': 4.7230424880981445, 'epoch': 2.88}
{'loss': 0.031, 'grad_norm': 11.98788070678711, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.02592519484460354, 'loss_2': 0.00510406494140625, 'loss_3': -15.874951362609863, 'loss_4': 4.951404094696045, 'epoch': 2.88}
{'loss': 0.0468, 'grad_norm': 14.18795394897461, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.04096811264753342, 'loss_2': 0.005878448486328125, 'loss_3': -15.695002555847168, 'loss_4': 5.9607415199279785, 'epoch': 2.89}
{'loss': 0.0274, 'grad_norm': 10.422855377197266, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.026454832404851913, 'loss_2': 0.0009813308715820312, 'loss_3': -15.805733680725098, 'loss_4': 5.24058723449707, 'epoch': 2.9}
{'loss': 0.0269, 'grad_norm': 7.048836708068848, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.02012794092297554, 'loss_2': 0.006778717041015625, 'loss_3': -15.800853729248047, 'loss_4': 5.42197847366333, 'epoch': 2.9}
{'loss': 0.0379, 'grad_norm': 12.041340827941895, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.030907832086086273, 'loss_2': 0.00704193115234375, 'loss_3': -15.806997299194336, 'loss_4': 5.161674499511719, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 09:36:56,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:56,039 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:45<1:21:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:03,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0097594503313303, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.937, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0070067280903458595, 'eval_loss_2': 0.0027527213096618652, 'eval_loss_3': -18.31934928894043, 'eval_loss_4': 3.952056884765625, 'epoch': 2.91}
{'loss': 0.0193, 'grad_norm': 6.675241470336914, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.016964511945843697, 'loss_2': 0.00234222412109375, 'loss_3': -15.670997619628906, 'loss_4': 3.948747158050537, 'epoch': 2.91}
{'loss': 0.0215, 'grad_norm': 6.971853733062744, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.020234230905771255, 'loss_2': 0.001232147216796875, 'loss_3': -15.728919982910156, 'loss_4': 4.200466632843018, 'epoch': 2.92}
{'loss': 0.0499, 'grad_norm': 12.442094802856445, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.04591614753007889, 'loss_2': 0.00394439697265625, 'loss_3': -15.792230606079102, 'loss_4': 3.675837993621826, 'epoch': 2.92}
{'loss': 0.0487, 'grad_norm': 14.087432861328125, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.036612819880247116, 'loss_2': 0.0121002197265625, 'loss_3': -15.870343208312988, 'loss_4': 3.509288787841797, 'epoch': 2.93}
{'loss': 0.0366, 'grad_norm': 9.55688762664795, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.030618401244282722, 'loss_2': 0.00597381591796875, 'loss_3': -15.76573657989502, 'loss_4': 4.014078617095947, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 09:37:03,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:03,402 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [12:52<1:20:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:10,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013023298233747482, 'eval_runtime': 3.8276, 'eval_samples_per_second': 267.531, 'eval_steps_per_second': 4.18, 'eval_loss_1': 0.008470931090414524, 'eval_loss_2': 0.004552368074655533, 'eval_loss_3': -18.314838409423828, 'eval_loss_4': 3.067863702774048, 'epoch': 2.94}
{'loss': 0.0465, 'grad_norm': 8.741107940673828, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.03055734746158123, 'loss_2': 0.0159454345703125, 'loss_3': -15.755370140075684, 'loss_4': 3.3405487537384033, 'epoch': 2.94}
{'loss': 0.042, 'grad_norm': 10.76520824432373, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.037998445332050323, 'loss_2': 0.0040130615234375, 'loss_3': -15.651196479797363, 'loss_4': 2.8964428901672363, 'epoch': 2.95}
{'loss': 0.0404, 'grad_norm': 9.90390396118164, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.0332222543656826, 'loss_2': 0.007167816162109375, 'loss_3': -15.752023696899414, 'loss_4': 3.500947952270508, 'epoch': 2.95}
{'loss': 0.0884, 'grad_norm': 29.835636138916016, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.08643519878387451, 'loss_2': 0.0019378662109375, 'loss_3': -15.663553237915039, 'loss_4': 2.7565174102783203, 'epoch': 2.96}
{'loss': 0.0657, 'grad_norm': 36.9278450012207, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.0641729012131691, 'loss_2': 0.0015745162963867188, 'loss_3': -15.678167343139648, 'loss_4': 3.81573486328125, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 09:37:10,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:10,782 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:00<1:20:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:37:18,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01586577668786049, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.889, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007750246673822403, 'eval_loss_2': 0.008115530014038086, 'eval_loss_3': -18.287607192993164, 'eval_loss_4': 2.858180522918701, 'epoch': 2.97}
{'loss': 0.0321, 'grad_norm': 8.236103057861328, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.02456880919635296, 'loss_2': 0.00754547119140625, 'loss_3': -15.640436172485352, 'loss_4': 3.046628475189209, 'epoch': 2.97}
{'loss': 0.0273, 'grad_norm': 9.053767204284668, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.02694573998451233, 'loss_2': 0.0003304481506347656, 'loss_3': -15.772058486938477, 'loss_4': 3.619349718093872, 'epoch': 2.98}
{'loss': 0.0591, 'grad_norm': 19.972583770751953, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.05541631951928139, 'loss_2': 0.0037288665771484375, 'loss_3': -15.849150657653809, 'loss_4': 4.165010929107666, 'epoch': 2.98}
{'loss': 0.0551, 'grad_norm': 15.329046249389648, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.05104723200201988, 'loss_2': 0.004058837890625, 'loss_3': -15.638473510742188, 'loss_4': 2.6035873889923096, 'epoch': 2.99}
{'loss': 0.0382, 'grad_norm': 9.675125122070312, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.036169879138469696, 'loss_2': 0.002002716064453125, 'loss_3': -15.952373504638672, 'loss_4': 3.3375084400177, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 09:37:18,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:18,122 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:07<1:18:53,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:37:25,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012666856870055199, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007662985473871231, 'eval_loss_2': 0.005003869533538818, 'eval_loss_3': -18.308700561523438, 'eval_loss_4': 2.993861198425293, 'epoch': 2.99}
{'loss': 0.0128, 'grad_norm': 6.360278129577637, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.00939265638589859, 'loss_2': 0.003368377685546875, 'loss_3': -15.914178848266602, 'loss_4': 3.1884665489196777, 'epoch': 3.0}
{'loss': 0.0299, 'grad_norm': 7.456550598144531, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.024053964763879776, 'loss_2': 0.005886077880859375, 'loss_3': -16.032913208007812, 'loss_4': 3.4718048572540283, 'epoch': 3.01}
{'loss': 0.0366, 'grad_norm': 9.432324409484863, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.03267892077565193, 'loss_2': 0.0038928985595703125, 'loss_3': -15.690144538879395, 'loss_4': 3.82114315032959, 'epoch': 3.01}
{'loss': 0.0346, 'grad_norm': 9.417489051818848, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.03298386558890343, 'loss_2': 0.0016269683837890625, 'loss_3': -15.914791107177734, 'loss_4': 3.0528411865234375, 'epoch': 3.02}
{'loss': 0.0906, 'grad_norm': 20.241594314575195, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.08016680181026459, 'loss_2': 0.010467529296875, 'loss_3': -15.894837379455566, 'loss_4': 4.020285129547119, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 09:37:25,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:25,194 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:14<1:20:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:32,561 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014132272452116013, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.285, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008048886433243752, 'eval_loss_2': 0.006083384156227112, 'eval_loss_3': -18.29977798461914, 'eval_loss_4': 2.8880653381347656, 'epoch': 3.02}
{'loss': 0.0532, 'grad_norm': 10.932183265686035, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.04274573177099228, 'loss_2': 0.01043701171875, 'loss_3': -15.749378204345703, 'loss_4': 3.1689772605895996, 'epoch': 3.03}
{'loss': 0.041, 'grad_norm': 12.312028884887695, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.03875136747956276, 'loss_2': 0.00228118896484375, 'loss_3': -15.857919692993164, 'loss_4': 3.1549532413482666, 'epoch': 3.03}
{'loss': 0.0314, 'grad_norm': 14.512866020202637, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.030917957425117493, 'loss_2': 0.0005178451538085938, 'loss_3': -15.986419677734375, 'loss_4': 3.526836395263672, 'epoch': 3.04}
{'loss': 0.0273, 'grad_norm': 9.148140907287598, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.020452365279197693, 'loss_2': 0.0068511962890625, 'loss_3': -15.796306610107422, 'loss_4': 3.688641309738159, 'epoch': 3.05}
{'loss': 0.0484, 'grad_norm': 14.526175498962402, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.03705667331814766, 'loss_2': 0.01136016845703125, 'loss_3': -15.855780601501465, 'loss_4': 3.063054084777832, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 09:37:32,561 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:32,561 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:22<1:20:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:39,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014067813754081726, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008124304935336113, 'eval_loss_2': 0.005943506956100464, 'eval_loss_3': -18.292236328125, 'eval_loss_4': 2.6937615871429443, 'epoch': 3.05}
{'loss': 0.0517, 'grad_norm': 10.891449928283691, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.04341450706124306, 'loss_2': 0.00823974609375, 'loss_3': -15.916784286499023, 'loss_4': 3.405144214630127, 'epoch': 3.06}
{'loss': 0.0329, 'grad_norm': 8.75747299194336, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.025252213701605797, 'loss_2': 0.00766754150390625, 'loss_3': -15.763042449951172, 'loss_4': 3.6655941009521484, 'epoch': 3.06}
{'loss': 0.0523, 'grad_norm': 15.501057624816895, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.04836802929639816, 'loss_2': 0.003887176513671875, 'loss_3': -15.917737007141113, 'loss_4': 3.48818302154541, 'epoch': 3.07}
{'loss': 0.0323, 'grad_norm': 10.557645797729492, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.03005797602236271, 'loss_2': 0.00223541259765625, 'loss_3': -15.945930480957031, 'loss_4': 3.464081048965454, 'epoch': 3.08}
{'loss': 0.0309, 'grad_norm': 10.374184608459473, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.02613988146185875, 'loss_2': 0.00473785400390625, 'loss_3': -16.092235565185547, 'loss_4': 3.5212972164154053, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 09:37:39,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:39,929 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:29<1:20:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:47,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014824135228991508, 'eval_runtime': 3.8258, 'eval_samples_per_second': 267.658, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.008005483075976372, 'eval_loss_2': 0.006818652153015137, 'eval_loss_3': -18.265531539916992, 'eval_loss_4': 2.3969783782958984, 'epoch': 3.08}
{'loss': 0.044, 'grad_norm': 14.26872730255127, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.036217059940099716, 'loss_2': 0.00774383544921875, 'loss_3': -15.991286277770996, 'loss_4': 2.7189993858337402, 'epoch': 3.09}
{'loss': 0.0166, 'grad_norm': 5.914783477783203, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.015516571700572968, 'loss_2': 0.001064300537109375, 'loss_3': -15.71947956085205, 'loss_4': 3.3779563903808594, 'epoch': 3.09}
{'loss': 0.0563, 'grad_norm': 15.582539558410645, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.050887905061244965, 'loss_2': 0.00545501708984375, 'loss_3': -15.865047454833984, 'loss_4': 2.492412567138672, 'epoch': 3.1}
{'loss': 0.059, 'grad_norm': 12.317909240722656, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.04474269971251488, 'loss_2': 0.0142974853515625, 'loss_3': -15.930729866027832, 'loss_4': 2.022674083709717, 'epoch': 3.1}
{'loss': 0.0516, 'grad_norm': 13.149075508117676, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.04410086199641228, 'loss_2': 0.0075225830078125, 'loss_3': -15.848176956176758, 'loss_4': 2.7066197395324707, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 09:37:47,304 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:47,304 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:36<1:20:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:54,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017646711319684982, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.334, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0076107182539999485, 'eval_loss_2': 0.010035991668701172, 'eval_loss_3': -18.224096298217773, 'eval_loss_4': 1.975724220275879, 'epoch': 3.11}
{'loss': 0.0401, 'grad_norm': 9.00461483001709, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.03443031758069992, 'loss_2': 0.005706787109375, 'loss_3': -15.81782054901123, 'loss_4': 2.7334232330322266, 'epoch': 3.12}
{'loss': 0.0491, 'grad_norm': 14.714644432067871, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.045118462294340134, 'loss_2': 0.00402069091796875, 'loss_3': -15.893218994140625, 'loss_4': 2.1252617835998535, 'epoch': 3.12}
{'loss': 0.0308, 'grad_norm': 9.069864273071289, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.030278576537966728, 'loss_2': 0.0005259513854980469, 'loss_3': -15.978364944458008, 'loss_4': 2.682633399963379, 'epoch': 3.13}
{'loss': 0.0235, 'grad_norm': 8.411699295043945, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.022740483283996582, 'loss_2': 0.00072479248046875, 'loss_3': -15.970662117004395, 'loss_4': 1.6817282438278198, 'epoch': 3.13}
{'loss': 0.037, 'grad_norm': 12.929797172546387, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.03535224497318268, 'loss_2': 0.0016574859619140625, 'loss_3': -16.193096160888672, 'loss_4': 2.007784366607666, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 09:37:54,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:54,682 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:44<1:20:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:02,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015070279128849506, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.954, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009171923622488976, 'eval_loss_2': 0.0058983564376831055, 'eval_loss_3': -18.143980026245117, 'eval_loss_4': 1.7838854789733887, 'epoch': 3.14}
{'loss': 0.0482, 'grad_norm': 12.111196517944336, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.03952072933316231, 'loss_2': 0.00865936279296875, 'loss_3': -15.803289413452148, 'loss_4': 1.7215899229049683, 'epoch': 3.15}
{'loss': 0.0374, 'grad_norm': 11.164264678955078, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.03170228376984596, 'loss_2': 0.00566864013671875, 'loss_3': -15.840554237365723, 'loss_4': 2.2951526641845703, 'epoch': 3.15}
{'loss': 0.0437, 'grad_norm': 12.087180137634277, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.03880758956074715, 'loss_2': 0.004940032958984375, 'loss_3': -15.755890846252441, 'loss_4': 2.0328807830810547, 'epoch': 3.16}
{'loss': 0.0237, 'grad_norm': 7.117571830749512, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.017733685672283173, 'loss_2': 0.005985260009765625, 'loss_3': -15.801599502563477, 'loss_4': 1.9861449003219604, 'epoch': 3.16}
{'loss': 0.0384, 'grad_norm': 9.422869682312012, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.02962665632367134, 'loss_2': 0.00881195068359375, 'loss_3': -15.769796371459961, 'loss_4': 1.74756920337677, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 09:38:02,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:02,041 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [13:51<1:19:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:09,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015535593964159489, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011162728071212769, 'eval_loss_2': 0.0043728649616241455, 'eval_loss_3': -18.066728591918945, 'eval_loss_4': 1.7399451732635498, 'epoch': 3.17}
{'loss': 0.0497, 'grad_norm': 14.242278099060059, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.0472954697906971, 'loss_2': 0.002384185791015625, 'loss_3': -15.681077003479004, 'loss_4': 1.8344504833221436, 'epoch': 3.17}
{'loss': 0.0704, 'grad_norm': 18.32498550415039, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.06643699109554291, 'loss_2': 0.00391387939453125, 'loss_3': -15.683643341064453, 'loss_4': 1.6351804733276367, 'epoch': 3.18}
{'loss': 0.0403, 'grad_norm': 13.770102500915527, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.03350597247481346, 'loss_2': 0.006763458251953125, 'loss_3': -15.466161727905273, 'loss_4': 1.4922404289245605, 'epoch': 3.19}
{'loss': 0.0243, 'grad_norm': 7.020262718200684, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.01986396126449108, 'loss_2': 0.00443267822265625, 'loss_3': -15.747522354125977, 'loss_4': 1.412429690361023, 'epoch': 3.19}
{'loss': 0.0316, 'grad_norm': 10.049206733703613, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.02366502583026886, 'loss_2': 0.0079498291015625, 'loss_3': -15.779988288879395, 'loss_4': 1.4252817630767822, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 09:38:09,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:09,405 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [13:58<1:19:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:16,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020109890028834343, 'eval_runtime': 3.8314, 'eval_samples_per_second': 267.265, 'eval_steps_per_second': 4.176, 'eval_loss_1': 0.010698136873543262, 'eval_loss_2': 0.009411752223968506, 'eval_loss_3': -18.007808685302734, 'eval_loss_4': 1.6631929874420166, 'epoch': 3.2}
{'loss': 0.0287, 'grad_norm': 8.057745933532715, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.025593210011720657, 'loss_2': 0.003101348876953125, 'loss_3': -15.844947814941406, 'loss_4': 2.3152689933776855, 'epoch': 3.2}
{'loss': 0.0339, 'grad_norm': 14.176072120666504, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.031172772869467735, 'loss_2': 0.0027008056640625, 'loss_3': -15.487359046936035, 'loss_4': 1.713758945465088, 'epoch': 3.21}
{'loss': 0.0309, 'grad_norm': 12.930262565612793, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.0305092241615057, 'loss_2': 0.00038695335388183594, 'loss_3': -15.89925479888916, 'loss_4': 1.9100275039672852, 'epoch': 3.22}
{'loss': 0.0328, 'grad_norm': 16.574600219726562, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.03171609714627266, 'loss_2': 0.0011205673217773438, 'loss_3': -15.931256294250488, 'loss_4': 2.0882561206817627, 'epoch': 3.22}
{'loss': 0.0344, 'grad_norm': 13.25575065612793, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.031794674694538116, 'loss_2': 0.002628326416015625, 'loss_3': -15.577723503112793, 'loss_4': 2.0465054512023926, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 09:38:16,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:16,791 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:06<1:19:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:24,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014734506607055664, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.755, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009559348225593567, 'eval_loss_2': 0.005175158381462097, 'eval_loss_3': -18.10582733154297, 'eval_loss_4': 2.2109429836273193, 'epoch': 3.23}
{'loss': 0.0221, 'grad_norm': 7.257079601287842, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.01761854998767376, 'loss_2': 0.0044708251953125, 'loss_3': -15.67729377746582, 'loss_4': 2.6801133155822754, 'epoch': 3.23}
{'loss': 0.0281, 'grad_norm': 6.588537693023682, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.0172813069075346, 'loss_2': 0.0107879638671875, 'loss_3': -15.990671157836914, 'loss_4': 2.5942866802215576, 'epoch': 3.24}
{'loss': 0.0338, 'grad_norm': 16.308395385742188, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.02916194126009941, 'loss_2': 0.004638671875, 'loss_3': -15.920075416564941, 'loss_4': 2.8656673431396484, 'epoch': 3.24}
{'loss': 0.0332, 'grad_norm': 10.884824752807617, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.02796262875199318, 'loss_2': 0.0052490234375, 'loss_3': -15.795406341552734, 'loss_4': 2.870511531829834, 'epoch': 3.25}
{'loss': 0.0136, 'grad_norm': 4.885102272033691, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.009868755005300045, 'loss_2': 0.0037097930908203125, 'loss_3': -15.582033157348633, 'loss_4': 2.998838424682617, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 09:38:24,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:24,160 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:13<1:19:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:31,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012171086855232716, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.247, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.0077420733869075775, 'eval_loss_2': 0.0044290125370025635, 'eval_loss_3': -18.244930267333984, 'eval_loss_4': 2.86679744720459, 'epoch': 3.26}
{'loss': 0.0282, 'grad_norm': 6.566926002502441, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.023410895839333534, 'loss_2': 0.0048065185546875, 'loss_3': -15.866230010986328, 'loss_4': 3.567277431488037, 'epoch': 3.26}
{'loss': 0.0169, 'grad_norm': 6.08542537689209, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.013051125220954418, 'loss_2': 0.0038299560546875, 'loss_3': -15.558494567871094, 'loss_4': 2.939788341522217, 'epoch': 3.27}
{'loss': 0.0354, 'grad_norm': 13.341451644897461, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.03485872596502304, 'loss_2': 0.0005617141723632812, 'loss_3': -15.874422073364258, 'loss_4': 3.201572895050049, 'epoch': 3.27}
{'loss': 0.0192, 'grad_norm': 5.901205062866211, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.014764438383281231, 'loss_2': 0.00441741943359375, 'loss_3': -15.872621536254883, 'loss_4': 3.0313515663146973, 'epoch': 3.28}
{'loss': 0.0525, 'grad_norm': 24.35084342956543, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.05244875326752663, 'loss_2': 4.3511390686035156e-05, 'loss_3': -15.644074440002441, 'loss_4': 3.340740203857422, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 09:38:31,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:31,535 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:21<1:19:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:38,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013233231380581856, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.858, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008500203490257263, 'eval_loss_2': 0.004733026027679443, 'eval_loss_3': -18.313488006591797, 'eval_loss_4': 3.303372383117676, 'epoch': 3.28}
{'loss': 0.0345, 'grad_norm': 10.669112205505371, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.0272661242634058, 'loss_2': 0.0072784423828125, 'loss_3': -15.750655174255371, 'loss_4': 3.602259635925293, 'epoch': 3.29}
{'loss': 0.0635, 'grad_norm': 24.38494300842285, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.06310008466243744, 'loss_2': 0.0004210472106933594, 'loss_3': -15.801433563232422, 'loss_4': 2.99727725982666, 'epoch': 3.3}
{'loss': 0.0187, 'grad_norm': 5.494185447692871, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.013155078515410423, 'loss_2': 0.005504608154296875, 'loss_3': -15.889378547668457, 'loss_4': 4.089254379272461, 'epoch': 3.3}
{'loss': 0.0626, 'grad_norm': 17.122180938720703, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.058679305016994476, 'loss_2': 0.003910064697265625, 'loss_3': -15.768482208251953, 'loss_4': 3.5909383296966553, 'epoch': 3.31}
{'loss': 0.0442, 'grad_norm': 15.996866226196289, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.041832875460386276, 'loss_2': 0.00232696533203125, 'loss_3': -15.82582950592041, 'loss_4': 4.117184162139893, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 09:38:38,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:38,894 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:28<1:19:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:46,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013107536360621452, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.695, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008816836401820183, 'eval_loss_2': 0.0042906999588012695, 'eval_loss_3': -18.336854934692383, 'eval_loss_4': 3.3661699295043945, 'epoch': 3.31}
{'loss': 0.0359, 'grad_norm': 8.781291961669922, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.026511190459132195, 'loss_2': 0.0094146728515625, 'loss_3': -15.660512924194336, 'loss_4': 3.8577375411987305, 'epoch': 3.32}
{'loss': 0.0278, 'grad_norm': 10.91133975982666, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.016333283856511116, 'loss_2': 0.0114593505859375, 'loss_3': -15.897109031677246, 'loss_4': 3.408444404602051, 'epoch': 3.33}
{'loss': 0.0332, 'grad_norm': 8.380754470825195, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.02369176596403122, 'loss_2': 0.0095367431640625, 'loss_3': -15.827871322631836, 'loss_4': 3.1271674633026123, 'epoch': 3.33}
{'loss': 0.0898, 'grad_norm': 27.586210250854492, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.08719474077224731, 'loss_2': 0.0026454925537109375, 'loss_3': -15.722366333007812, 'loss_4': 3.244487762451172, 'epoch': 3.34}
{'loss': 0.0354, 'grad_norm': 11.596558570861816, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.03356928005814552, 'loss_2': 0.0018262863159179688, 'loss_3': -15.795135498046875, 'loss_4': 3.5401291847229004, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 09:38:46,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:46,265 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:35<1:19:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:53,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014986901544034481, 'eval_runtime': 3.838, 'eval_samples_per_second': 266.803, 'eval_steps_per_second': 4.169, 'eval_loss_1': 0.00862929131835699, 'eval_loss_2': 0.00635761022567749, 'eval_loss_3': -18.30801773071289, 'eval_loss_4': 3.418962240219116, 'epoch': 3.34}
{'loss': 0.0604, 'grad_norm': 16.345043182373047, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.04894685000181198, 'loss_2': 0.0114288330078125, 'loss_3': -15.820626258850098, 'loss_4': 3.93361234664917, 'epoch': 3.35}
{'loss': 0.0197, 'grad_norm': 9.533050537109375, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.019428065046668053, 'loss_2': 0.0003046989440917969, 'loss_3': -15.578219413757324, 'loss_4': 3.6334376335144043, 'epoch': 3.35}
{'loss': 0.0264, 'grad_norm': 6.51082181930542, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.012405401095747948, 'loss_2': 0.0139923095703125, 'loss_3': -16.088909149169922, 'loss_4': 3.301591396331787, 'epoch': 3.36}
{'loss': 0.0722, 'grad_norm': 23.14545440673828, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.0545884370803833, 'loss_2': 0.017578125, 'loss_3': -15.798622131347656, 'loss_4': 3.515981912612915, 'epoch': 3.37}
{'loss': 0.1155, 'grad_norm': 21.848237991333008, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.10401076078414917, 'loss_2': 0.011444091796875, 'loss_3': -15.873319625854492, 'loss_4': 3.3315577507019043, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 09:38:53,659 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:53,659 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:43<1:19:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:01,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01982453092932701, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.048, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008904362097382545, 'eval_loss_2': 0.010920166969299316, 'eval_loss_3': -18.339021682739258, 'eval_loss_4': 3.1056509017944336, 'epoch': 3.37}
{'loss': 0.0696, 'grad_norm': 25.524770736694336, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.0562635101377964, 'loss_2': 0.0132904052734375, 'loss_3': -15.84851360321045, 'loss_4': 3.192779064178467, 'epoch': 3.38}
{'loss': 0.0526, 'grad_norm': 19.658676147460938, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.05211920291185379, 'loss_2': 0.0004353523254394531, 'loss_3': -15.894639015197754, 'loss_4': 3.5053586959838867, 'epoch': 3.38}
{'loss': 0.0514, 'grad_norm': 11.322367668151855, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.0410764142870903, 'loss_2': 0.010284423828125, 'loss_3': -15.806407928466797, 'loss_4': 3.3447742462158203, 'epoch': 3.39}
{'loss': 0.0293, 'grad_norm': 7.544946670532227, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.023708853870630264, 'loss_2': 0.0055694580078125, 'loss_3': -15.990443229675293, 'loss_4': 3.4239606857299805, 'epoch': 3.4}
{'loss': 0.0533, 'grad_norm': 14.317551612854004, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.0471416637301445, 'loss_2': 0.00618743896484375, 'loss_3': -15.973724365234375, 'loss_4': 3.3732385635375977, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 09:39:01,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:01,017 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:50<1:19:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:08,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011653521098196507, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.847, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00888051837682724, 'eval_loss_2': 0.002773001790046692, 'eval_loss_3': -18.401561737060547, 'eval_loss_4': 3.141232967376709, 'epoch': 3.4}
{'loss': 0.0491, 'grad_norm': 22.085859298706055, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.048729781061410904, 'loss_2': 0.00040411949157714844, 'loss_3': -15.991838455200195, 'loss_4': 2.983912467956543, 'epoch': 3.41}
{'loss': 0.0418, 'grad_norm': 18.13905143737793, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.03726961091160774, 'loss_2': 0.004528045654296875, 'loss_3': -16.084514617919922, 'loss_4': 3.315784454345703, 'epoch': 3.41}
{'loss': 0.0645, 'grad_norm': 19.108489990234375, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.05766366049647331, 'loss_2': 0.0067901611328125, 'loss_3': -15.986053466796875, 'loss_4': 2.9912235736846924, 'epoch': 3.42}
{'loss': 0.0597, 'grad_norm': 21.973962783813477, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.0562513992190361, 'loss_2': 0.00344085693359375, 'loss_3': -15.871916770935059, 'loss_4': 4.029300689697266, 'epoch': 3.42}
{'loss': 0.0548, 'grad_norm': 12.482057571411133, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.04708176478743553, 'loss_2': 0.007732391357421875, 'loss_3': -15.994972229003906, 'loss_4': 3.8718318939208984, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 09:39:08,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:08,384 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [14:57<1:19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:15,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019245781004428864, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.325, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.01055452786386013, 'eval_loss_2': 0.008691251277923584, 'eval_loss_3': -18.4270076751709, 'eval_loss_4': 3.492593288421631, 'epoch': 3.43}
{'loss': 0.0653, 'grad_norm': 14.172057151794434, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.04482407122850418, 'loss_2': 0.02044677734375, 'loss_3': -16.31113624572754, 'loss_4': 3.234337329864502, 'epoch': 3.44}
{'loss': 0.0508, 'grad_norm': 13.021233558654785, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.042164430022239685, 'loss_2': 0.0086517333984375, 'loss_3': -16.189733505249023, 'loss_4': 3.5672056674957275, 'epoch': 3.44}
{'loss': 0.0409, 'grad_norm': 12.225370407104492, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.03383481502532959, 'loss_2': 0.007030487060546875, 'loss_3': -15.914734840393066, 'loss_4': 3.4971423149108887, 'epoch': 3.45}
{'loss': 0.0279, 'grad_norm': 8.904760360717773, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.023619554936885834, 'loss_2': 0.00429534912109375, 'loss_3': -15.976799011230469, 'loss_4': 3.111719846725464, 'epoch': 3.45}
{'loss': 0.0273, 'grad_norm': 6.656796932220459, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.020591022446751595, 'loss_2': 0.0067138671875, 'loss_3': -16.04998207092285, 'loss_4': 4.32964563369751, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 09:39:15,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:15,760 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:05<1:19:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:23,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0202082060277462, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.992, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010558568872511387, 'eval_loss_2': 0.00964963436126709, 'eval_loss_3': -18.370832443237305, 'eval_loss_4': 3.8473026752471924, 'epoch': 3.46}
{'loss': 0.0698, 'grad_norm': 16.170808792114258, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.05845184996724129, 'loss_2': 0.0113067626953125, 'loss_3': -15.90117073059082, 'loss_4': 3.980217933654785, 'epoch': 3.47}
{'loss': 0.0446, 'grad_norm': 11.771794319152832, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.03334594890475273, 'loss_2': 0.01126861572265625, 'loss_3': -15.912613868713379, 'loss_4': 4.38298225402832, 'epoch': 3.47}
{'loss': 0.076, 'grad_norm': 12.987378120422363, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.05539241433143616, 'loss_2': 0.0206298828125, 'loss_3': -16.096784591674805, 'loss_4': 4.450343132019043, 'epoch': 3.48}
{'loss': 0.0415, 'grad_norm': 9.302106857299805, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.02997238002717495, 'loss_2': 0.01148223876953125, 'loss_3': -15.840278625488281, 'loss_4': 3.152334451675415, 'epoch': 3.48}
{'loss': 0.0338, 'grad_norm': 6.537189960479736, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.015947746112942696, 'loss_2': 0.017852783203125, 'loss_3': -16.032577514648438, 'loss_4': 3.6301558017730713, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 09:39:23,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:23,122 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:12<1:19:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:30,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026537369936704636, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009295893833041191, 'eval_loss_2': 0.017241477966308594, 'eval_loss_3': -18.349069595336914, 'eval_loss_4': 4.073182106018066, 'epoch': 3.49}
{'loss': 0.0549, 'grad_norm': 11.346784591674805, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.032707296311855316, 'loss_2': 0.0221710205078125, 'loss_3': -15.921396255493164, 'loss_4': 3.6389589309692383, 'epoch': 3.49}
{'loss': 0.0363, 'grad_norm': 11.363431930541992, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.028696849942207336, 'loss_2': 0.00759124755859375, 'loss_3': -16.182781219482422, 'loss_4': 4.180649757385254, 'epoch': 3.5}
{'loss': 0.0733, 'grad_norm': 19.98250961303711, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.0679454356431961, 'loss_2': 0.00534820556640625, 'loss_3': -15.938016891479492, 'loss_4': 3.4502503871917725, 'epoch': 3.51}
{'loss': 0.0348, 'grad_norm': 13.798626899719238, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.03124871663749218, 'loss_2': 0.003589630126953125, 'loss_3': -15.989208221435547, 'loss_4': 3.5319957733154297, 'epoch': 3.51}
{'loss': 0.0215, 'grad_norm': 6.762760639190674, 'learning_rate': 2.65e-05, 'loss_1': 0.018437981605529785, 'loss_2': 0.0030536651611328125, 'loss_3': -15.94607925415039, 'loss_4': 4.298821449279785, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 09:39:30,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:30,490 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:20<1:18:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:37,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014186534099280834, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009783703833818436, 'eval_loss_2': 0.004402831196784973, 'eval_loss_3': -18.338146209716797, 'eval_loss_4': 3.600287437438965, 'epoch': 3.52}
{'loss': 0.0322, 'grad_norm': 10.502192497253418, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.0270245224237442, 'loss_2': 0.005138397216796875, 'loss_3': -15.909247398376465, 'loss_4': 2.779775381088257, 'epoch': 3.52}
{'loss': 0.0444, 'grad_norm': 9.913374900817871, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.03708403557538986, 'loss_2': 0.00728607177734375, 'loss_3': -15.817327499389648, 'loss_4': 3.3488073348999023, 'epoch': 3.53}
{'loss': 0.0287, 'grad_norm': 14.248937606811523, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.02617298997938633, 'loss_2': 0.0025348663330078125, 'loss_3': -16.13372230529785, 'loss_4': 3.3429908752441406, 'epoch': 3.53}
{'loss': 0.0571, 'grad_norm': 14.003266334533691, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.050802260637283325, 'loss_2': 0.00624847412109375, 'loss_3': -16.036474227905273, 'loss_4': 4.330102443695068, 'epoch': 3.54}
{'loss': 0.1044, 'grad_norm': 26.62497329711914, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.0938953310251236, 'loss_2': 0.010467529296875, 'loss_3': -15.632858276367188, 'loss_4': 4.114705562591553, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 09:39:37,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:37,851 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:27<1:18:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:45,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015542087145149708, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011398142203688622, 'eval_loss_2': 0.004143945872783661, 'eval_loss_3': -18.296606063842773, 'eval_loss_4': 4.090737342834473, 'epoch': 3.55}
{'loss': 0.0402, 'grad_norm': 11.817749977111816, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.036222442984580994, 'loss_2': 0.0039520263671875, 'loss_3': -16.061071395874023, 'loss_4': 3.8436930179595947, 'epoch': 3.55}
{'loss': 0.0383, 'grad_norm': 11.20259952545166, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.03470874950289726, 'loss_2': 0.003604888916015625, 'loss_3': -15.821149826049805, 'loss_4': 4.331353187561035, 'epoch': 3.56}
{'loss': 0.0223, 'grad_norm': 9.730113983154297, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.02214924432337284, 'loss_2': 0.00010216236114501953, 'loss_3': -15.900297164916992, 'loss_4': 3.9439663887023926, 'epoch': 3.56}
{'loss': 0.0264, 'grad_norm': 8.333417892456055, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.021927444264292717, 'loss_2': 0.00447845458984375, 'loss_3': -15.77546215057373, 'loss_4': 4.466270923614502, 'epoch': 3.57}
{'loss': 0.0365, 'grad_norm': 9.539543151855469, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.02893325686454773, 'loss_2': 0.007587432861328125, 'loss_3': -16.04678726196289, 'loss_4': 4.814367771148682, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 09:39:45,208 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:45,208 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:34<1:18:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:52,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019228987395763397, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.818, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.015238338150084019, 'eval_loss_2': 0.003990650177001953, 'eval_loss_3': -18.23555564880371, 'eval_loss_4': 4.490822792053223, 'epoch': 3.58}
{'loss': 0.0398, 'grad_norm': 9.25440502166748, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.026660611853003502, 'loss_2': 0.0131378173828125, 'loss_3': -15.747777938842773, 'loss_4': 3.813713550567627, 'epoch': 3.58}
{'loss': 0.0297, 'grad_norm': 7.9777936935424805, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.02319898083806038, 'loss_2': 0.006526947021484375, 'loss_3': -15.970956802368164, 'loss_4': 4.396658897399902, 'epoch': 3.59}
{'loss': 0.0615, 'grad_norm': 26.301464080810547, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.060589421540498734, 'loss_2': 0.0008707046508789062, 'loss_3': -15.814208030700684, 'loss_4': 4.422755241394043, 'epoch': 3.59}
{'loss': 0.0576, 'grad_norm': 19.67610740661621, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.044041309505701065, 'loss_2': 0.0135955810546875, 'loss_3': -16.00717544555664, 'loss_4': 4.378201961517334, 'epoch': 3.6}
{'loss': 0.0271, 'grad_norm': 8.586236000061035, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.020221395418047905, 'loss_2': 0.00687408447265625, 'loss_3': -16.004194259643555, 'loss_4': 3.829057216644287, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 09:39:52,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:52,577 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:42<1:18:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:59,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016473308205604553, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.465, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009859339334070683, 'eval_loss_2': 0.006613969802856445, 'eval_loss_3': -18.278427124023438, 'eval_loss_4': 4.371780872344971, 'epoch': 3.6}
{'loss': 0.0278, 'grad_norm': 7.063531875610352, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.020587867125868797, 'loss_2': 0.0072021484375, 'loss_3': -16.059234619140625, 'loss_4': 4.367952823638916, 'epoch': 3.61}
{'loss': 0.0619, 'grad_norm': 22.15235710144043, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.06177366152405739, 'loss_2': 0.0001430511474609375, 'loss_3': -15.848638534545898, 'loss_4': 4.320565700531006, 'epoch': 3.62}
{'loss': 0.0307, 'grad_norm': 6.79557466506958, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.016018619760870934, 'loss_2': 0.014678955078125, 'loss_3': -16.000076293945312, 'loss_4': 4.598119735717773, 'epoch': 3.62}
{'loss': 0.0576, 'grad_norm': 11.606667518615723, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.047712456434965134, 'loss_2': 0.0098419189453125, 'loss_3': -15.934996604919434, 'loss_4': 4.516468524932861, 'epoch': 3.63}
{'loss': 0.136, 'grad_norm': 24.6997127532959, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.1327497661113739, 'loss_2': 0.003253936767578125, 'loss_3': -15.93778133392334, 'loss_4': 4.370084762573242, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 09:39:59,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:59,950 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:49<1:18:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:07,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01352265477180481, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009120584465563297, 'eval_loss_2': 0.004402071237564087, 'eval_loss_3': -18.326574325561523, 'eval_loss_4': 4.869925022125244, 'epoch': 3.63}
{'loss': 0.035, 'grad_norm': 10.781299591064453, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.029416246339678764, 'loss_2': 0.0055389404296875, 'loss_3': -16.102968215942383, 'loss_4': 4.840743064880371, 'epoch': 3.64}
{'loss': 0.028, 'grad_norm': 7.667396545410156, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.019312260672450066, 'loss_2': 0.00872802734375, 'loss_3': -16.13334083557129, 'loss_4': 4.897016525268555, 'epoch': 3.65}
{'loss': 0.0323, 'grad_norm': 11.114660263061523, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.030437318608164787, 'loss_2': 0.0019092559814453125, 'loss_3': -16.017436981201172, 'loss_4': 5.282947540283203, 'epoch': 3.65}
{'loss': 0.0412, 'grad_norm': 9.100259780883789, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.034781478345394135, 'loss_2': 0.00641632080078125, 'loss_3': -16.018905639648438, 'loss_4': 6.113044738769531, 'epoch': 3.66}
{'loss': 0.0295, 'grad_norm': 8.414738655090332, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.027885280549526215, 'loss_2': 0.001590728759765625, 'loss_3': -15.879927635192871, 'loss_4': 5.768621921539307, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 09:40:07,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:07,311 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [15:56<1:18:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:14,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010971196927130222, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.039, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007936911657452583, 'eval_loss_2': 0.0030342862010002136, 'eval_loss_3': -18.333515167236328, 'eval_loss_4': 5.274543762207031, 'epoch': 3.66}
{'loss': 0.0388, 'grad_norm': 11.827814102172852, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.03476347029209137, 'loss_2': 0.00405120849609375, 'loss_3': -15.961652755737305, 'loss_4': 5.651195049285889, 'epoch': 3.67}
{'loss': 0.0247, 'grad_norm': 8.255575180053711, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.023632336407899857, 'loss_2': 0.001094818115234375, 'loss_3': -15.954488754272461, 'loss_4': 5.477788925170898, 'epoch': 3.67}
{'loss': 0.0355, 'grad_norm': 9.41749095916748, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.029343770816922188, 'loss_2': 0.006137847900390625, 'loss_3': -15.94312572479248, 'loss_4': 6.14602518081665, 'epoch': 3.68}
{'loss': 0.0424, 'grad_norm': 12.596943855285645, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.03381606191396713, 'loss_2': 0.00861358642578125, 'loss_3': -16.214874267578125, 'loss_4': 5.6121826171875, 'epoch': 3.69}
{'loss': 0.0183, 'grad_norm': 6.845359802246094, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.013874352909624577, 'loss_2': 0.004425048828125, 'loss_3': -16.09878158569336, 'loss_4': 5.550829887390137, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 09:40:14,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:14,679 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:04<1:19:21,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:40:22,225 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011018777266144753, 'eval_runtime': 3.9918, 'eval_samples_per_second': 256.526, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.0076806191354990005, 'eval_loss_2': 0.003338158130645752, 'eval_loss_3': -18.328411102294922, 'eval_loss_4': 5.070355415344238, 'epoch': 3.69}
{'loss': 0.0322, 'grad_norm': 19.778961181640625, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.024547943845391273, 'loss_2': 0.007671356201171875, 'loss_3': -15.872275352478027, 'loss_4': 5.412867546081543, 'epoch': 3.7}
{'loss': 0.0229, 'grad_norm': 8.293270111083984, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.021521804854273796, 'loss_2': 0.0013790130615234375, 'loss_3': -16.05521011352539, 'loss_4': 5.552225112915039, 'epoch': 3.7}
{'loss': 0.111, 'grad_norm': 18.645742416381836, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.1032884418964386, 'loss_2': 0.007678985595703125, 'loss_3': -15.642108917236328, 'loss_4': 5.420917987823486, 'epoch': 3.71}
{'loss': 0.0568, 'grad_norm': 30.11180305480957, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.05550577864050865, 'loss_2': 0.0012836456298828125, 'loss_3': -15.904769897460938, 'loss_4': 4.699954032897949, 'epoch': 3.72}
{'loss': 0.0448, 'grad_norm': 18.393991470336914, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.04192470759153366, 'loss_2': 0.00289154052734375, 'loss_3': -15.905098915100098, 'loss_4': 5.66971492767334, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 09:40:22,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:22,226 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:11<1:18:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:29,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010495701804757118, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.613, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007203488610684872, 'eval_loss_2': 0.003292214125394821, 'eval_loss_3': -18.334156036376953, 'eval_loss_4': 4.477480411529541, 'epoch': 3.72}
{'loss': 0.0404, 'grad_norm': 11.192983627319336, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.038213860243558884, 'loss_2': 0.002155303955078125, 'loss_3': -15.777517318725586, 'loss_4': 4.939661979675293, 'epoch': 3.73}
{'loss': 0.0167, 'grad_norm': 7.421104907989502, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.01372692734003067, 'loss_2': 0.00298309326171875, 'loss_3': -15.960165977478027, 'loss_4': 4.85196590423584, 'epoch': 3.73}
{'loss': 0.0614, 'grad_norm': 24.250688552856445, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.05164510756731033, 'loss_2': 0.009796142578125, 'loss_3': -15.991622924804688, 'loss_4': 4.374762535095215, 'epoch': 3.74}
{'loss': 0.0239, 'grad_norm': 6.273510932922363, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.015289051458239555, 'loss_2': 0.00858306884765625, 'loss_3': -16.152904510498047, 'loss_4': 4.479694366455078, 'epoch': 3.74}
{'loss': 0.0358, 'grad_norm': 9.71638298034668, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.02068982645869255, 'loss_2': 0.015106201171875, 'loss_3': -15.894006729125977, 'loss_4': 4.264828205108643, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 09:40:29,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:29,602 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:19<1:18:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:36,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010846354067325592, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.422, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007102646864950657, 'eval_loss_2': 0.0037437081336975098, 'eval_loss_3': -18.365966796875, 'eval_loss_4': 3.7195775508880615, 'epoch': 3.75}
{'loss': 0.0274, 'grad_norm': 7.884840965270996, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.020452100783586502, 'loss_2': 0.006927490234375, 'loss_3': -15.951597213745117, 'loss_4': 4.668933868408203, 'epoch': 3.76}
{'loss': 0.0367, 'grad_norm': 10.482961654663086, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.02666272222995758, 'loss_2': 0.0099945068359375, 'loss_3': -16.102115631103516, 'loss_4': 4.455106735229492, 'epoch': 3.76}
{'loss': 0.0394, 'grad_norm': 12.999604225158691, 'learning_rate': 2.625e-05, 'loss_1': 0.03626837208867073, 'loss_2': 0.003116607666015625, 'loss_3': -16.09393310546875, 'loss_4': 3.8672826290130615, 'epoch': 3.77}
{'loss': 0.0378, 'grad_norm': 12.505205154418945, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.03169562667608261, 'loss_2': 0.006084442138671875, 'loss_3': -15.889859199523926, 'loss_4': 4.399296760559082, 'epoch': 3.77}
{'loss': 0.0538, 'grad_norm': 12.462240219116211, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.04288766533136368, 'loss_2': 0.010955810546875, 'loss_3': -16.01003074645996, 'loss_4': 3.5527243614196777, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 09:40:36,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:36,972 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:26<1:18:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:44,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015609927475452423, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.895, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007050343789160252, 'eval_loss_2': 0.008559584617614746, 'eval_loss_3': -18.383338928222656, 'eval_loss_4': 3.0583102703094482, 'epoch': 3.78}
{'loss': 0.0327, 'grad_norm': 10.822200775146484, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.027773883193731308, 'loss_2': 0.004947662353515625, 'loss_3': -16.0177001953125, 'loss_4': 3.4914815425872803, 'epoch': 3.78}
{'loss': 0.0476, 'grad_norm': 12.418834686279297, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.037365879863500595, 'loss_2': 0.01026153564453125, 'loss_3': -15.9022798538208, 'loss_4': 3.151907444000244, 'epoch': 3.79}
{'loss': 0.0201, 'grad_norm': 6.921521186828613, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.01284902822226286, 'loss_2': 0.00722503662109375, 'loss_3': -16.13542938232422, 'loss_4': 3.9254908561706543, 'epoch': 3.8}
{'loss': 0.0322, 'grad_norm': 15.585026741027832, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.02979106828570366, 'loss_2': 0.002384185791015625, 'loss_3': -15.992744445800781, 'loss_4': 3.715492010116577, 'epoch': 3.8}
{'loss': 0.0346, 'grad_norm': 12.80529499053955, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.031261470168828964, 'loss_2': 0.0033054351806640625, 'loss_3': -16.165761947631836, 'loss_4': 3.720261573791504, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 09:40:44,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:44,336 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:33<1:18:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:51,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009855606593191624, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0069566452875733376, 'eval_loss_2': 0.002898961305618286, 'eval_loss_3': -18.3497257232666, 'eval_loss_4': 2.468923568725586, 'epoch': 3.81}
{'loss': 0.0222, 'grad_norm': 10.251381874084473, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.019300078973174095, 'loss_2': 0.0028896331787109375, 'loss_3': -15.920257568359375, 'loss_4': 3.055950164794922, 'epoch': 3.81}
{'loss': 0.063, 'grad_norm': 21.196266174316406, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.054818008095026016, 'loss_2': 0.00814056396484375, 'loss_3': -15.939783096313477, 'loss_4': 3.1626341342926025, 'epoch': 3.82}
{'loss': 0.0342, 'grad_norm': 7.589059829711914, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.021236447617411613, 'loss_2': 0.0129241943359375, 'loss_3': -15.817203521728516, 'loss_4': 3.129530906677246, 'epoch': 3.83}
{'loss': 0.0557, 'grad_norm': 15.770527839660645, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.048579029738903046, 'loss_2': 0.007080078125, 'loss_3': -15.840761184692383, 'loss_4': 3.3378822803497314, 'epoch': 3.83}
{'loss': 0.0295, 'grad_norm': 7.200563907623291, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.02433754689991474, 'loss_2': 0.00518035888671875, 'loss_3': -16.019315719604492, 'loss_4': 2.6710939407348633, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 09:40:51,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:51,695 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:41<1:17:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:59,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011304942891001701, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.078, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007095179054886103, 'eval_loss_2': 0.004209764301776886, 'eval_loss_3': -18.368009567260742, 'eval_loss_4': 1.9790964126586914, 'epoch': 3.84}
{'loss': 0.0243, 'grad_norm': 6.767705917358398, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.016332006081938744, 'loss_2': 0.0079193115234375, 'loss_3': -16.06531524658203, 'loss_4': 2.1940464973449707, 'epoch': 3.84}
{'loss': 0.0321, 'grad_norm': 9.603011131286621, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.02738339640200138, 'loss_2': 0.0047454833984375, 'loss_3': -15.953644752502441, 'loss_4': 2.601269245147705, 'epoch': 3.85}
{'loss': 0.031, 'grad_norm': 8.565534591674805, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.02108384110033512, 'loss_2': 0.009918212890625, 'loss_3': -15.988201141357422, 'loss_4': 2.4919824600219727, 'epoch': 3.85}
{'loss': 0.0461, 'grad_norm': 9.472461700439453, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.031160585582256317, 'loss_2': 0.0149383544921875, 'loss_3': -15.876140594482422, 'loss_4': 2.4065661430358887, 'epoch': 3.86}
{'loss': 0.0311, 'grad_norm': 11.607343673706055, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.02215716801583767, 'loss_2': 0.00893402099609375, 'loss_3': -16.039838790893555, 'loss_4': 1.825249433517456, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 09:40:59,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:59,053 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:48<1:17:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:06,410 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018981609493494034, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.902, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005664026364684105, 'eval_loss_2': 0.013317584991455078, 'eval_loss_3': -18.299850463867188, 'eval_loss_4': 2.113776206970215, 'epoch': 3.87}
{'loss': 0.031, 'grad_norm': 6.253690719604492, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.014225112274289131, 'loss_2': 0.01678466796875, 'loss_3': -15.92056941986084, 'loss_4': 2.29103946685791, 'epoch': 3.87}
{'loss': 0.037, 'grad_norm': 10.329863548278809, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.0227949358522892, 'loss_2': 0.01421356201171875, 'loss_3': -15.899490356445312, 'loss_4': 2.18330717086792, 'epoch': 3.88}
{'loss': 0.0382, 'grad_norm': 9.563921928405762, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.022855551913380623, 'loss_2': 0.0153045654296875, 'loss_3': -16.036741256713867, 'loss_4': 2.439743995666504, 'epoch': 3.88}
{'loss': 0.0465, 'grad_norm': 10.43873119354248, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.03784782811999321, 'loss_2': 0.008636474609375, 'loss_3': -15.958199501037598, 'loss_4': 2.4979662895202637, 'epoch': 3.89}
{'loss': 0.0341, 'grad_norm': 11.023881912231445, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.028378577902913094, 'loss_2': 0.00572967529296875, 'loss_3': -16.005966186523438, 'loss_4': 2.1773810386657715, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 09:41:06,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:06,410 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [16:55<1:17:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:13,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010173898190259933, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007926981896162033, 'eval_loss_2': 0.0022469162940979004, 'eval_loss_3': -18.245546340942383, 'eval_loss_4': 2.387094020843506, 'epoch': 3.9}
{'loss': 0.0205, 'grad_norm': 6.817782878875732, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.016485335305333138, 'loss_2': 0.004009246826171875, 'loss_3': -16.17152214050293, 'loss_4': 2.745820999145508, 'epoch': 3.9}
{'loss': 0.0401, 'grad_norm': 15.855375289916992, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.02738177962601185, 'loss_2': 0.01274871826171875, 'loss_3': -15.808749198913574, 'loss_4': 1.999443769454956, 'epoch': 3.91}
{'loss': 0.0591, 'grad_norm': 16.582321166992188, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.043595366179943085, 'loss_2': 0.01546478271484375, 'loss_3': -15.962536811828613, 'loss_4': 2.51347017288208, 'epoch': 3.91}
{'loss': 0.0512, 'grad_norm': 23.689212799072266, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.03879445046186447, 'loss_2': 0.0124053955078125, 'loss_3': -15.91158390045166, 'loss_4': 3.0687594413757324, 'epoch': 3.92}
{'loss': 0.0991, 'grad_norm': 30.344268798828125, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.07609224319458008, 'loss_2': 0.0229949951171875, 'loss_3': -15.801780700683594, 'loss_4': 2.2798988819122314, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 09:41:13,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:13,774 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:03<1:17:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:21,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0232674703001976, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.487, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006483754608780146, 'eval_loss_2': 0.016783714294433594, 'eval_loss_3': -18.27130699157715, 'eval_loss_4': 2.560112714767456, 'epoch': 3.92}
{'loss': 0.0492, 'grad_norm': 13.760025024414062, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.024816235527396202, 'loss_2': 0.02435302734375, 'loss_3': -15.97470760345459, 'loss_4': 2.7009201049804688, 'epoch': 3.93}
{'loss': 0.0494, 'grad_norm': 10.88071346282959, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.025272326543927193, 'loss_2': 0.024169921875, 'loss_3': -15.992712020874023, 'loss_4': 2.3808722496032715, 'epoch': 3.94}
{'loss': 0.0358, 'grad_norm': 10.599157333374023, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.017771154642105103, 'loss_2': 0.018035888671875, 'loss_3': -15.716710090637207, 'loss_4': 3.035088539123535, 'epoch': 3.94}
{'loss': 0.0309, 'grad_norm': 9.367931365966797, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.017643526196479797, 'loss_2': 0.01322174072265625, 'loss_3': -15.838547706604004, 'loss_4': 3.202122688293457, 'epoch': 3.95}
{'loss': 0.0286, 'grad_norm': 9.430754661560059, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.01667216420173645, 'loss_2': 0.01190185546875, 'loss_3': -16.14726448059082, 'loss_4': 4.013461112976074, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 09:41:21,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:21,145 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:10<1:17:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:28,510 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015257710590958595, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.953, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005180235020816326, 'eval_loss_2': 0.010077476501464844, 'eval_loss_3': -18.33704376220703, 'eval_loss_4': 3.1869163513183594, 'epoch': 3.95}
{'loss': 0.0364, 'grad_norm': 9.61251449584961, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.03617914766073227, 'loss_2': 0.00018715858459472656, 'loss_3': -15.838322639465332, 'loss_4': 3.759052276611328, 'epoch': 3.96}
{'loss': 0.0401, 'grad_norm': 24.553977966308594, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.034878917038440704, 'loss_2': 0.00518035888671875, 'loss_3': -15.781928062438965, 'loss_4': 3.926177501678467, 'epoch': 3.97}
{'loss': 0.033, 'grad_norm': 11.51695728302002, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.02367410622537136, 'loss_2': 0.0093231201171875, 'loss_3': -15.877391815185547, 'loss_4': 3.810070753097534, 'epoch': 3.97}
{'loss': 0.0317, 'grad_norm': 10.508668899536133, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.018209358677268028, 'loss_2': 0.01348114013671875, 'loss_3': -15.976093292236328, 'loss_4': 4.138141632080078, 'epoch': 3.98}
{'loss': 0.0292, 'grad_norm': 9.541885375976562, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.02522466890513897, 'loss_2': 0.00397491455078125, 'loss_3': -15.880027770996094, 'loss_4': 4.780981063842773, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 09:41:28,510 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:28,510 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:17<1:14:23,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 09:41:35,571 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009633004665374756, 'eval_runtime': 3.8221, 'eval_samples_per_second': 267.915, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.005877762567251921, 'eval_loss_2': 0.003755241632461548, 'eval_loss_3': -18.352203369140625, 'eval_loss_4': 3.678952932357788, 'epoch': 3.98}
{'loss': 0.031, 'grad_norm': 10.724872589111328, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.025597620755434036, 'loss_2': 0.00537109375, 'loss_3': -15.852542877197266, 'loss_4': 4.37176513671875, 'epoch': 3.99}
{'loss': 0.0258, 'grad_norm': 6.489804267883301, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.016871461644768715, 'loss_2': 0.0089111328125, 'loss_3': -16.019588470458984, 'loss_4': 4.921206951141357, 'epoch': 3.99}
{'loss': 0.0245, 'grad_norm': 8.818553924560547, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.01354083139449358, 'loss_2': 0.0110015869140625, 'loss_3': -15.717134475708008, 'loss_4': 5.428621768951416, 'epoch': 4.0}
{'loss': 0.0403, 'grad_norm': 12.211803436279297, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.03324633464217186, 'loss_2': 0.00708770751953125, 'loss_3': -15.853565216064453, 'loss_4': 4.5535993576049805, 'epoch': 4.01}
{'loss': 0.0576, 'grad_norm': 18.311084747314453, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.048534292727708817, 'loss_2': 0.0090179443359375, 'loss_3': -16.033226013183594, 'loss_4': 4.117720603942871, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 09:41:35,571 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:35,571 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:25<1:16:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:41:42,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015791956335306168, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007288297172635794, 'eval_loss_2': 0.008503660559654236, 'eval_loss_3': -18.362377166748047, 'eval_loss_4': 3.56329083442688, 'epoch': 4.01}
{'loss': 0.0652, 'grad_norm': 18.839414596557617, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.05372965335845947, 'loss_2': 0.01143646240234375, 'loss_3': -15.83719253540039, 'loss_4': 4.821463108062744, 'epoch': 4.02}
{'loss': 0.0688, 'grad_norm': 23.832653045654297, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.059644944965839386, 'loss_2': 0.0091705322265625, 'loss_3': -15.858378410339355, 'loss_4': 4.639862060546875, 'epoch': 4.02}
{'loss': 0.0479, 'grad_norm': 12.968177795410156, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.03515278920531273, 'loss_2': 0.012725830078125, 'loss_3': -15.750052452087402, 'loss_4': 3.616175651550293, 'epoch': 4.03}
{'loss': 0.0537, 'grad_norm': 17.815954208374023, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.04241770878434181, 'loss_2': 0.01131439208984375, 'loss_3': -15.957402229309082, 'loss_4': 4.031854152679443, 'epoch': 4.03}
{'loss': 0.0448, 'grad_norm': 13.724238395690918, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.03848560154438019, 'loss_2': 0.006320953369140625, 'loss_3': -15.68060302734375, 'loss_4': 3.894348621368408, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 09:41:42,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:42,936 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:32<1:17:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:50,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014489952474832535, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.035, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008208665996789932, 'eval_loss_2': 0.0062812864780426025, 'eval_loss_3': -18.39259147644043, 'eval_loss_4': 3.007293701171875, 'epoch': 4.04}
{'loss': 0.0514, 'grad_norm': 14.762353897094727, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.03954096511006355, 'loss_2': 0.0118560791015625, 'loss_3': -15.738432884216309, 'loss_4': 4.214496612548828, 'epoch': 4.05}
{'loss': 0.0371, 'grad_norm': 11.846951484680176, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.03385426104068756, 'loss_2': 0.003253936767578125, 'loss_3': -15.890508651733398, 'loss_4': 3.0102055072784424, 'epoch': 4.05}
{'loss': 0.031, 'grad_norm': 10.252787590026855, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.0269479937851429, 'loss_2': 0.00400543212890625, 'loss_3': -15.81208610534668, 'loss_4': 3.0123915672302246, 'epoch': 4.06}
{'loss': 0.0291, 'grad_norm': 8.843446731567383, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.02613031305372715, 'loss_2': 0.003009796142578125, 'loss_3': -16.001876831054688, 'loss_4': 3.9475831985473633, 'epoch': 4.06}
{'loss': 0.0444, 'grad_norm': 10.889970779418945, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.03224102780222893, 'loss_2': 0.01220703125, 'loss_3': -15.941032409667969, 'loss_4': 2.6923699378967285, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 09:41:50,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:50,298 >>   Batch size = 64
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:39<1:17:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:57,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019421424716711044, 'eval_runtime': 3.8162, 'eval_samples_per_second': 268.327, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007248486392199993, 'eval_loss_2': 0.012172937393188477, 'eval_loss_3': -18.39204978942871, 'eval_loss_4': 1.9726660251617432, 'epoch': 4.07}
{'loss': 0.0263, 'grad_norm': 8.574623107910156, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.018907735124230385, 'loss_2': 0.0074005126953125, 'loss_3': -15.964263916015625, 'loss_4': 2.885498523712158, 'epoch': 4.08}
{'loss': 0.0536, 'grad_norm': 12.926319122314453, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.0360381081700325, 'loss_2': 0.017547607421875, 'loss_3': -15.966897964477539, 'loss_4': 2.7087934017181396, 'epoch': 4.08}
{'loss': 0.05, 'grad_norm': 12.23080825805664, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.035324446856975555, 'loss_2': 0.01470947265625, 'loss_3': -15.853998184204102, 'loss_4': 2.361952304840088, 'epoch': 4.09}
{'loss': 0.0409, 'grad_norm': 8.166519165039062, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.022274255752563477, 'loss_2': 0.0186004638671875, 'loss_3': -15.851934432983398, 'loss_4': 1.5154638290405273, 'epoch': 4.09}
{'loss': 0.025, 'grad_norm': 6.570522785186768, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.015159482136368752, 'loss_2': 0.009796142578125, 'loss_3': -15.991101264953613, 'loss_4': 1.8459824323654175, 'epoch': 4.1}
[INFO|trainer.py:4228] 2025-01-21 09:41:57,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:57,667 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:47<1:17:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:05,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015620270743966103, 'eval_runtime': 3.82, 'eval_samples_per_second': 268.06, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007494339253753424, 'eval_loss_2': 0.008125931024551392, 'eval_loss_3': -18.37206268310547, 'eval_loss_4': 1.5177254676818848, 'epoch': 4.1}
{'loss': 0.0385, 'grad_norm': 10.653861045837402, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.02569502964615822, 'loss_2': 0.0128021240234375, 'loss_3': -15.813663482666016, 'loss_4': 1.4308123588562012, 'epoch': 4.1}
{'loss': 0.0284, 'grad_norm': 11.593110084533691, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.027333024889230728, 'loss_2': 0.0010585784912109375, 'loss_3': -15.872941970825195, 'loss_4': 2.4326703548431396, 'epoch': 4.11}
{'loss': 0.025, 'grad_norm': 6.7903947830200195, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.018209422007203102, 'loss_2': 0.0067901611328125, 'loss_3': -16.118324279785156, 'loss_4': 2.4985008239746094, 'epoch': 4.12}
{'loss': 0.0231, 'grad_norm': 7.120054721832275, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.01986798085272312, 'loss_2': 0.003269195556640625, 'loss_3': -15.950984954833984, 'loss_4': 1.4507378339767456, 'epoch': 4.12}
{'loss': 0.0385, 'grad_norm': 16.14373016357422, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.035511210560798645, 'loss_2': 0.003021240234375, 'loss_3': -15.858377456665039, 'loss_4': 2.4895567893981934, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 09:42:05,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:05,040 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [17:54<1:17:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:12,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017189273610711098, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007350871805101633, 'eval_loss_2': 0.009838402271270752, 'eval_loss_3': -18.349201202392578, 'eval_loss_4': 1.8096200227737427, 'epoch': 4.13}
{'loss': 0.0258, 'grad_norm': 8.070096015930176, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.024320829659700394, 'loss_2': 0.0015087127685546875, 'loss_3': -15.918728828430176, 'loss_4': 1.3650106191635132, 'epoch': 4.13}
{'loss': 0.0491, 'grad_norm': 14.353137969970703, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.03677443042397499, 'loss_2': 0.01233673095703125, 'loss_3': -16.056550979614258, 'loss_4': 2.5316896438598633, 'epoch': 4.14}
{'loss': 0.0377, 'grad_norm': 9.792824745178223, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.029754050076007843, 'loss_2': 0.00797271728515625, 'loss_3': -15.771246910095215, 'loss_4': 2.4060797691345215, 'epoch': 4.15}
{'loss': 0.0386, 'grad_norm': 10.792863845825195, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.02959209494292736, 'loss_2': 0.00905609130859375, 'loss_3': -15.90359115600586, 'loss_4': 1.9591236114501953, 'epoch': 4.15}
{'loss': 0.0241, 'grad_norm': 6.755322456359863, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.01616036705672741, 'loss_2': 0.0079193115234375, 'loss_3': -16.041362762451172, 'loss_4': 1.9036755561828613, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 09:42:12,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:12,398 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:01<1:16:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:19,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012698140926659107, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.638, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0074188075959682465, 'eval_loss_2': 0.005279332399368286, 'eval_loss_3': -18.294031143188477, 'eval_loss_4': 2.139390230178833, 'epoch': 4.16}
{'loss': 0.0361, 'grad_norm': 14.549652099609375, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.032095350325107574, 'loss_2': 0.00399017333984375, 'loss_3': -15.929605484008789, 'loss_4': 2.3251209259033203, 'epoch': 4.16}
{'loss': 0.0373, 'grad_norm': 16.027896881103516, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.03312951698899269, 'loss_2': 0.00417327880859375, 'loss_3': -15.883550643920898, 'loss_4': 2.21086049079895, 'epoch': 4.17}
{'loss': 0.0288, 'grad_norm': 7.031014919281006, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.014983586966991425, 'loss_2': 0.0137939453125, 'loss_3': -15.93647575378418, 'loss_4': 1.8962469100952148, 'epoch': 4.17}
{'loss': 0.0335, 'grad_norm': 10.281587600708008, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.02822686731815338, 'loss_2': 0.005275726318359375, 'loss_3': -16.057865142822266, 'loss_4': 2.5382132530212402, 'epoch': 4.18}
{'loss': 0.0134, 'grad_norm': 5.086921691894531, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.0119558060541749, 'loss_2': 0.0014858245849609375, 'loss_3': -15.817867279052734, 'loss_4': 1.9500868320465088, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 09:42:19,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:19,758 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:09<1:16:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:27,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010305019095540047, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.698, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006715805269777775, 'eval_loss_2': 0.0035892128944396973, 'eval_loss_3': -18.326492309570312, 'eval_loss_4': 2.3152096271514893, 'epoch': 4.19}
{'loss': 0.0308, 'grad_norm': 8.832093238830566, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.02620447427034378, 'loss_2': 0.004547119140625, 'loss_3': -15.94522476196289, 'loss_4': 2.4689321517944336, 'epoch': 4.19}
{'loss': 0.0246, 'grad_norm': 10.07761287689209, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.023521672934293747, 'loss_2': 0.0010700225830078125, 'loss_3': -15.932117462158203, 'loss_4': 2.3068673610687256, 'epoch': 4.2}
{'loss': 0.0342, 'grad_norm': 7.647699356079102, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.027099628001451492, 'loss_2': 0.007110595703125, 'loss_3': -15.944596290588379, 'loss_4': 2.4136953353881836, 'epoch': 4.2}
{'loss': 0.0405, 'grad_norm': 14.509913444519043, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.04001501947641373, 'loss_2': 0.00048065185546875, 'loss_3': -16.112363815307617, 'loss_4': 2.6204135417938232, 'epoch': 4.21}
{'loss': 0.0385, 'grad_norm': 23.106891632080078, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.03209744393825531, 'loss_2': 0.0064239501953125, 'loss_3': -15.886117935180664, 'loss_4': 2.5489039421081543, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 09:42:27,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:27,125 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:16<1:17:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:34,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015217598527669907, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00771760568022728, 'eval_loss_2': 0.007499992847442627, 'eval_loss_3': -18.265514373779297, 'eval_loss_4': 2.6613519191741943, 'epoch': 4.22}
{'loss': 0.0167, 'grad_norm': 7.622794151306152, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.01595868542790413, 'loss_2': 0.0007176399230957031, 'loss_3': -15.951987266540527, 'loss_4': 2.5988893508911133, 'epoch': 4.22}
{'loss': 0.0211, 'grad_norm': 11.194330215454102, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.017438426613807678, 'loss_2': 0.00368499755859375, 'loss_3': -15.884732246398926, 'loss_4': 2.5943965911865234, 'epoch': 4.23}
{'loss': 0.0593, 'grad_norm': 22.92647933959961, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.05573027580976486, 'loss_2': 0.003566741943359375, 'loss_3': -15.9750394821167, 'loss_4': 2.6948795318603516, 'epoch': 4.23}
{'loss': 0.0271, 'grad_norm': 7.455437660217285, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.019584257155656815, 'loss_2': 0.00748443603515625, 'loss_3': -15.918132781982422, 'loss_4': 2.9987940788269043, 'epoch': 4.24}
{'loss': 0.0267, 'grad_norm': 9.311543464660645, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.023320768028497696, 'loss_2': 0.0033721923828125, 'loss_3': -15.86299991607666, 'loss_4': 2.840155601501465, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 09:42:34,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:34,505 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:24<1:16:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:41,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016383981332182884, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.444, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.012128080241382122, 'eval_loss_2': 0.004255902022123337, 'eval_loss_3': -18.22329330444336, 'eval_loss_4': 3.1415748596191406, 'epoch': 4.24}
{'loss': 0.026, 'grad_norm': 8.508888244628906, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.022747669368982315, 'loss_2': 0.0032901763916015625, 'loss_3': -15.779136657714844, 'loss_4': 2.858506441116333, 'epoch': 4.25}
{'loss': 0.0213, 'grad_norm': 7.805200099945068, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.02006250061094761, 'loss_2': 0.0012674331665039062, 'loss_3': -15.839666366577148, 'loss_4': 3.143247604370117, 'epoch': 4.26}
{'loss': 0.0181, 'grad_norm': 6.88521146774292, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.01616154983639717, 'loss_2': 0.0019292831420898438, 'loss_3': -15.90614128112793, 'loss_4': 3.4727301597595215, 'epoch': 4.26}
{'loss': 0.0382, 'grad_norm': 22.101797103881836, 'learning_rate': 2.575e-05, 'loss_1': 0.03170642629265785, 'loss_2': 0.00644683837890625, 'loss_3': -15.722107887268066, 'loss_4': 3.0655627250671387, 'epoch': 4.27}
{'loss': 0.0191, 'grad_norm': 8.675389289855957, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.018575064837932587, 'loss_2': 0.0005598068237304688, 'loss_3': -15.794036865234375, 'loss_4': 3.102560043334961, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 09:42:41,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:41,874 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:31<1:16:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:49,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014663716778159142, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.809, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011353036388754845, 'eval_loss_2': 0.003310680389404297, 'eval_loss_3': -18.210445404052734, 'eval_loss_4': 3.522554397583008, 'epoch': 4.27}
{'loss': 0.0419, 'grad_norm': 12.522723197937012, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.03810947760939598, 'loss_2': 0.003818511962890625, 'loss_3': -15.802448272705078, 'loss_4': 2.9872429370880127, 'epoch': 4.28}
{'loss': 0.019, 'grad_norm': 6.69001579284668, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.015732910484075546, 'loss_2': 0.003269195556640625, 'loss_3': -15.920923233032227, 'loss_4': 4.20658540725708, 'epoch': 4.28}
{'loss': 0.0369, 'grad_norm': 13.845684051513672, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.031727295368909836, 'loss_2': 0.0051422119140625, 'loss_3': -15.982898712158203, 'loss_4': 3.749617576599121, 'epoch': 4.29}
{'loss': 0.034, 'grad_norm': 11.921561241149902, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.026554396376013756, 'loss_2': 0.00742340087890625, 'loss_3': -15.857484817504883, 'loss_4': 3.6989269256591797, 'epoch': 4.3}
{'loss': 0.0261, 'grad_norm': 7.619863033294678, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.01656215637922287, 'loss_2': 0.0095367431640625, 'loss_3': -16.160442352294922, 'loss_4': 3.4922070503234863, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 09:42:49,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:49,238 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:38<1:16:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:56,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019741930067539215, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.829, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00831154640763998, 'eval_loss_2': 0.01143038272857666, 'eval_loss_3': -18.287263870239258, 'eval_loss_4': 3.7014763355255127, 'epoch': 4.3}
{'loss': 0.0273, 'grad_norm': 6.754073619842529, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.01767589896917343, 'loss_2': 0.009674072265625, 'loss_3': -16.091760635375977, 'loss_4': 3.8922359943389893, 'epoch': 4.31}
{'loss': 0.0247, 'grad_norm': 9.251527786254883, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.018514590337872505, 'loss_2': 0.00621795654296875, 'loss_3': -16.00748634338379, 'loss_4': 3.3850955963134766, 'epoch': 4.31}
{'loss': 0.0183, 'grad_norm': 8.721027374267578, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.01645546779036522, 'loss_2': 0.001865386962890625, 'loss_3': -15.914066314697266, 'loss_4': 3.703280448913574, 'epoch': 4.32}
{'loss': 0.0868, 'grad_norm': 30.772340774536133, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.07651761919260025, 'loss_2': 0.01032257080078125, 'loss_3': -15.872539520263672, 'loss_4': 3.8642148971557617, 'epoch': 4.33}
{'loss': 0.0219, 'grad_norm': 6.5418596267700195, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.014329983852803707, 'loss_2': 0.007595062255859375, 'loss_3': -16.117542266845703, 'loss_4': 3.792013645172119, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 09:42:56,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:56,591 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:46<1:16:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:03,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012466873973608017, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.902, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007661979645490646, 'eval_loss_2': 0.004804894328117371, 'eval_loss_3': -18.279874801635742, 'eval_loss_4': 3.36637282371521, 'epoch': 4.33}
{'loss': 0.0219, 'grad_norm': 6.871915817260742, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.020579302683472633, 'loss_2': 0.0013036727905273438, 'loss_3': -15.969015121459961, 'loss_4': 3.6144378185272217, 'epoch': 4.34}
{'loss': 0.0108, 'grad_norm': 5.010838508605957, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.008537477813661098, 'loss_2': 0.00226593017578125, 'loss_3': -15.970123291015625, 'loss_4': 3.2103517055511475, 'epoch': 4.34}
{'loss': 0.0314, 'grad_norm': 12.905396461486816, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.029470151290297508, 'loss_2': 0.0019102096557617188, 'loss_3': -15.793415069580078, 'loss_4': 3.6006019115448, 'epoch': 4.35}
{'loss': 0.0488, 'grad_norm': 13.649147987365723, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.046333324164152145, 'loss_2': 0.0024852752685546875, 'loss_3': -15.941693305969238, 'loss_4': 3.1288390159606934, 'epoch': 4.35}
{'loss': 0.0393, 'grad_norm': 9.491673469543457, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.03639734536409378, 'loss_2': 0.00295257568359375, 'loss_3': -15.84412670135498, 'loss_4': 3.4356236457824707, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 09:43:03,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:03,956 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [18:53<1:16:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:11,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01025676354765892, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007262842264026403, 'eval_loss_2': 0.0029939189553260803, 'eval_loss_3': -18.281827926635742, 'eval_loss_4': 2.8205533027648926, 'epoch': 4.36}
{'loss': 0.0227, 'grad_norm': 7.611227989196777, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.016708306968212128, 'loss_2': 0.0059661865234375, 'loss_3': -16.159626007080078, 'loss_4': 3.6116864681243896, 'epoch': 4.37}
{'loss': 0.0185, 'grad_norm': 5.468813419342041, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.016005780547857285, 'loss_2': 0.002532958984375, 'loss_3': -16.12512969970703, 'loss_4': 2.757251501083374, 'epoch': 4.37}
{'loss': 0.0158, 'grad_norm': 6.54116153717041, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.014390980824828148, 'loss_2': 0.0014257431030273438, 'loss_3': -15.754890441894531, 'loss_4': 2.5199007987976074, 'epoch': 4.38}
{'loss': 0.0186, 'grad_norm': 7.37980318069458, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.01843302696943283, 'loss_2': 0.00012171268463134766, 'loss_3': -16.09468650817871, 'loss_4': 2.551516532897949, 'epoch': 4.38}
{'loss': 0.0167, 'grad_norm': 6.361514091491699, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.016147136688232422, 'loss_2': 0.0005960464477539062, 'loss_3': -16.031679153442383, 'loss_4': 2.865990161895752, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 09:43:11,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:11,327 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:00<1:16:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:18,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009500212967395782, 'eval_runtime': 3.8421, 'eval_samples_per_second': 266.518, 'eval_steps_per_second': 4.164, 'eval_loss_1': 0.006277002394199371, 'eval_loss_2': 0.003223210573196411, 'eval_loss_3': -18.263717651367188, 'eval_loss_4': 2.471609115600586, 'epoch': 4.39}
{'loss': 0.0168, 'grad_norm': 7.602230072021484, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.015558491460978985, 'loss_2': 0.00119781494140625, 'loss_3': -16.048789978027344, 'loss_4': 2.054272174835205, 'epoch': 4.4}
{'loss': 0.0286, 'grad_norm': 15.183552742004395, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.02823627181351185, 'loss_2': 0.0003218650817871094, 'loss_3': -16.027206420898438, 'loss_4': 2.2072598934173584, 'epoch': 4.4}
{'loss': 0.0321, 'grad_norm': 5.626402854919434, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.013213865458965302, 'loss_2': 0.0188751220703125, 'loss_3': -16.10294532775879, 'loss_4': 2.029130220413208, 'epoch': 4.41}
{'loss': 0.0419, 'grad_norm': 20.379972457885742, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.036770664155483246, 'loss_2': 0.005168914794921875, 'loss_3': -15.885008811950684, 'loss_4': 2.230424404144287, 'epoch': 4.41}
{'loss': 0.0383, 'grad_norm': 11.87427043914795, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.03535226359963417, 'loss_2': 0.00299072265625, 'loss_3': -15.796091079711914, 'loss_4': 2.086138963699341, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 09:43:18,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:18,730 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:08<1:16:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:26,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009302029386162758, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.816, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006056675687432289, 'eval_loss_2': 0.0032453536987304688, 'eval_loss_3': -18.272689819335938, 'eval_loss_4': 2.174508571624756, 'epoch': 4.42}
{'loss': 0.0195, 'grad_norm': 8.234033584594727, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.016583431512117386, 'loss_2': 0.0028781890869140625, 'loss_3': -16.0733699798584, 'loss_4': 2.2546277046203613, 'epoch': 4.42}
{'loss': 0.0227, 'grad_norm': 10.071568489074707, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.021838441491127014, 'loss_2': 0.0008525848388671875, 'loss_3': -15.91079044342041, 'loss_4': 2.5782852172851562, 'epoch': 4.43}
{'loss': 0.0457, 'grad_norm': 17.765756607055664, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.04224724322557449, 'loss_2': 0.0034122467041015625, 'loss_3': -15.886331558227539, 'loss_4': 2.702390670776367, 'epoch': 4.44}
{'loss': 0.0217, 'grad_norm': 7.396031856536865, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.01858355849981308, 'loss_2': 0.003131866455078125, 'loss_3': -16.011295318603516, 'loss_4': 2.644810438156128, 'epoch': 4.44}
{'loss': 0.0256, 'grad_norm': 8.172934532165527, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.021046355366706848, 'loss_2': 0.00458526611328125, 'loss_3': -16.028940200805664, 'loss_4': 2.4096615314483643, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 09:43:26,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:26,093 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:15<1:16:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:33,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014646066352725029, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007593510672450066, 'eval_loss_2': 0.007052555680274963, 'eval_loss_3': -18.24823570251465, 'eval_loss_4': 2.3711628913879395, 'epoch': 4.45}
{'loss': 0.0275, 'grad_norm': 6.386110305786133, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.02076105587184429, 'loss_2': 0.006744384765625, 'loss_3': -15.913389205932617, 'loss_4': 2.7713146209716797, 'epoch': 4.45}
{'loss': 0.0475, 'grad_norm': 22.591453552246094, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.04378528892993927, 'loss_2': 0.003673553466796875, 'loss_3': -15.782988548278809, 'loss_4': 2.121445417404175, 'epoch': 4.46}
{'loss': 0.0172, 'grad_norm': 5.529388427734375, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.01224819477647543, 'loss_2': 0.004978179931640625, 'loss_3': -15.927701950073242, 'loss_4': 2.219710350036621, 'epoch': 4.47}
{'loss': 0.0436, 'grad_norm': 22.761741638183594, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.0379258468747139, 'loss_2': 0.00563812255859375, 'loss_3': -15.942127227783203, 'loss_4': 2.1546452045440674, 'epoch': 4.47}
{'loss': 0.0225, 'grad_norm': 5.980874538421631, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.011287325993180275, 'loss_2': 0.01123809814453125, 'loss_3': -15.956785202026367, 'loss_4': 2.9408504962921143, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 09:43:33,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:33,450 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:22<1:15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:40,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01026795245707035, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.298, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0077041033655405045, 'eval_loss_2': 0.002563849091529846, 'eval_loss_3': -18.222370147705078, 'eval_loss_4': 2.6556642055511475, 'epoch': 4.48}
{'loss': 0.0199, 'grad_norm': 8.266846656799316, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.016032399609684944, 'loss_2': 0.003887176513671875, 'loss_3': -15.94239616394043, 'loss_4': 2.7968451976776123, 'epoch': 4.48}
{'loss': 0.0267, 'grad_norm': 7.959949493408203, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.017602775245904922, 'loss_2': 0.00909423828125, 'loss_3': -16.066869735717773, 'loss_4': 2.813699722290039, 'epoch': 4.49}
{'loss': 0.0428, 'grad_norm': 11.592973709106445, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.03583746775984764, 'loss_2': 0.006954193115234375, 'loss_3': -15.993847846984863, 'loss_4': 2.9025511741638184, 'epoch': 4.49}
{'loss': 0.0236, 'grad_norm': 6.84965705871582, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.01808532327413559, 'loss_2': 0.005523681640625, 'loss_3': -15.883556365966797, 'loss_4': 2.719881534576416, 'epoch': 4.5}
{'loss': 0.0204, 'grad_norm': 7.154163360595703, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.015399469062685966, 'loss_2': 0.0049896240234375, 'loss_3': -16.10234832763672, 'loss_4': 2.9485182762145996, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 09:43:40,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:40,803 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:30<1:15:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:48,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009679002687335014, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0075249504297971725, 'eval_loss_2': 0.002154052257537842, 'eval_loss_3': -18.264230728149414, 'eval_loss_4': 2.9818127155303955, 'epoch': 4.51}
{'loss': 0.0238, 'grad_norm': 6.572100639343262, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.013497063890099525, 'loss_2': 0.01025390625, 'loss_3': -15.82910442352295, 'loss_4': 3.018109083175659, 'epoch': 4.51}
{'loss': 0.0142, 'grad_norm': 6.067089080810547, 'learning_rate': 2.55e-05, 'loss_1': 0.01303522102534771, 'loss_2': 0.00115203857421875, 'loss_3': -16.060665130615234, 'loss_4': 2.694699287414551, 'epoch': 4.52}
{'loss': 0.0306, 'grad_norm': 11.528554916381836, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.026930715888738632, 'loss_2': 0.003662109375, 'loss_3': -15.988079071044922, 'loss_4': 2.9826955795288086, 'epoch': 4.52}
{'loss': 0.0606, 'grad_norm': 24.828405380249023, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.05711866542696953, 'loss_2': 0.003490447998046875, 'loss_3': -15.740978240966797, 'loss_4': 3.5463504791259766, 'epoch': 4.53}
{'loss': 0.0366, 'grad_norm': 7.989675998687744, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.02043861150741577, 'loss_2': 0.016204833984375, 'loss_3': -15.992090225219727, 'loss_4': 3.6375503540039062, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 09:43:48,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:48,156 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:37<1:15:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:55,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021092955023050308, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.867, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0077925375662744045, 'eval_loss_2': 0.013300418853759766, 'eval_loss_3': -18.292236328125, 'eval_loss_4': 3.284135341644287, 'epoch': 4.53}
{'loss': 0.0336, 'grad_norm': 12.619696617126465, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.025570081546902657, 'loss_2': 0.0080413818359375, 'loss_3': -16.25633430480957, 'loss_4': 3.6860146522521973, 'epoch': 4.54}
{'loss': 0.052, 'grad_norm': 19.021595001220703, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.04528389126062393, 'loss_2': 0.00669097900390625, 'loss_3': -15.991722106933594, 'loss_4': 3.928323268890381, 'epoch': 4.55}
{'loss': 0.0357, 'grad_norm': 6.791809558868408, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.01789291761815548, 'loss_2': 0.017852783203125, 'loss_3': -16.099763870239258, 'loss_4': 3.557823896408081, 'epoch': 4.55}
{'loss': 0.0409, 'grad_norm': 12.910263061523438, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.028715817257761955, 'loss_2': 0.012176513671875, 'loss_3': -15.982198715209961, 'loss_4': 3.212897777557373, 'epoch': 4.56}
{'loss': 0.027, 'grad_norm': 9.514583587646484, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.021379029378294945, 'loss_2': 0.00562286376953125, 'loss_3': -15.940117835998535, 'loss_4': 3.0805113315582275, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 09:43:55,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:55,524 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:45<1:15:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:02,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010774620808660984, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.26, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008192190900444984, 'eval_loss_2': 0.0025824308395385742, 'eval_loss_3': -18.3471736907959, 'eval_loss_4': 3.414438009262085, 'epoch': 4.56}
{'loss': 0.0209, 'grad_norm': 7.536403179168701, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.014121579937636852, 'loss_2': 0.00681304931640625, 'loss_3': -16.255542755126953, 'loss_4': 3.4843785762786865, 'epoch': 4.57}
{'loss': 0.0178, 'grad_norm': 6.1013054847717285, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.01218565646559, 'loss_2': 0.005573272705078125, 'loss_3': -16.280786514282227, 'loss_4': 3.4971323013305664, 'epoch': 4.58}
{'loss': 0.0359, 'grad_norm': 8.296709060668945, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.022711047902703285, 'loss_2': 0.0131683349609375, 'loss_3': -16.346839904785156, 'loss_4': 4.03057861328125, 'epoch': 4.58}
{'loss': 0.0334, 'grad_norm': 10.06406021118164, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.03035026788711548, 'loss_2': 0.003063201904296875, 'loss_3': -16.122095108032227, 'loss_4': 4.112292289733887, 'epoch': 4.59}
{'loss': 0.0409, 'grad_norm': 9.009480476379395, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.02797132357954979, 'loss_2': 0.01291656494140625, 'loss_3': -16.005613327026367, 'loss_4': 3.306492567062378, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 09:44:02,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:02,894 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [19:52<1:15:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:10,251 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012128101661801338, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0065451730042696, 'eval_loss_2': 0.005582928657531738, 'eval_loss_3': -18.389596939086914, 'eval_loss_4': 3.560122489929199, 'epoch': 4.59}
{'loss': 0.0211, 'grad_norm': 9.5222749710083, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.01971101388335228, 'loss_2': 0.00135040283203125, 'loss_3': -16.05414581298828, 'loss_4': 3.7946200370788574, 'epoch': 4.6}
{'loss': 0.0356, 'grad_norm': 11.530113220214844, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.03414538875222206, 'loss_2': 0.0015010833740234375, 'loss_3': -16.060529708862305, 'loss_4': 3.9541537761688232, 'epoch': 4.6}
{'loss': 0.0406, 'grad_norm': 9.541754722595215, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.03253405913710594, 'loss_2': 0.008026123046875, 'loss_3': -16.07731056213379, 'loss_4': 4.046785831451416, 'epoch': 4.61}
{'loss': 0.0173, 'grad_norm': 6.614117622375488, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.010424096137285233, 'loss_2': 0.00682830810546875, 'loss_3': -16.060781478881836, 'loss_4': 3.993108034133911, 'epoch': 4.62}
{'loss': 0.013, 'grad_norm': 5.340281009674072, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.009005332365632057, 'loss_2': 0.003963470458984375, 'loss_3': -16.312705993652344, 'loss_4': 4.074173927307129, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 09:44:10,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:10,251 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [19:59<1:15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:17,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013129614293575287, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.077, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006848535966128111, 'eval_loss_2': 0.006281077861785889, 'eval_loss_3': -18.368539810180664, 'eval_loss_4': 3.534327507019043, 'epoch': 4.62}
{'loss': 0.0414, 'grad_norm': 10.468783378601074, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.03518550843000412, 'loss_2': 0.00626373291015625, 'loss_3': -16.238929748535156, 'loss_4': 3.452481746673584, 'epoch': 4.63}
{'loss': 0.0337, 'grad_norm': 8.585416793823242, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.019836783409118652, 'loss_2': 0.013824462890625, 'loss_3': -15.976446151733398, 'loss_4': 3.7673797607421875, 'epoch': 4.63}
{'loss': 0.035, 'grad_norm': 11.036526679992676, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.027603857219219208, 'loss_2': 0.007415771484375, 'loss_3': -16.37206268310547, 'loss_4': 4.238529205322266, 'epoch': 4.64}
{'loss': 0.0432, 'grad_norm': 12.177157402038574, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.025918882340192795, 'loss_2': 0.0172882080078125, 'loss_3': -16.12889862060547, 'loss_4': 3.8821053504943848, 'epoch': 4.65}
{'loss': 0.0274, 'grad_norm': 7.394337177276611, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.014584114775061607, 'loss_2': 0.0128021240234375, 'loss_3': -16.104894638061523, 'loss_4': 3.392139434814453, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 09:44:17,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:17,613 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:07<1:15:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:24,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015882305800914764, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.115, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00737767806276679, 'eval_loss_2': 0.008504629135131836, 'eval_loss_3': -18.37466049194336, 'eval_loss_4': 3.388641119003296, 'epoch': 4.65}
{'loss': 0.0231, 'grad_norm': 7.775238513946533, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.013120101764798164, 'loss_2': 0.010009765625, 'loss_3': -16.095447540283203, 'loss_4': 3.5396623611450195, 'epoch': 4.66}
{'loss': 0.0445, 'grad_norm': 16.75494956970215, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.039045728743076324, 'loss_2': 0.00543975830078125, 'loss_3': -16.14254379272461, 'loss_4': 4.049020290374756, 'epoch': 4.66}
{'loss': 0.0391, 'grad_norm': 13.85128116607666, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.033533718436956406, 'loss_2': 0.005611419677734375, 'loss_3': -16.047929763793945, 'loss_4': 3.8558762073516846, 'epoch': 4.67}
{'loss': 0.0242, 'grad_norm': 9.56284236907959, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.020589100196957588, 'loss_2': 0.003570556640625, 'loss_3': -16.196056365966797, 'loss_4': 3.6189985275268555, 'epoch': 4.67}
{'loss': 0.088, 'grad_norm': 21.082855224609375, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.07722603529691696, 'loss_2': 0.01078033447265625, 'loss_3': -15.817020416259766, 'loss_4': 3.7977054119110107, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 09:44:24,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:24,980 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:14<1:15:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:32,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01010087225586176, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.578, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006723359227180481, 'eval_loss_2': 0.0033775120973587036, 'eval_loss_3': -18.345521926879883, 'eval_loss_4': 3.2112231254577637, 'epoch': 4.68}
{'loss': 0.0563, 'grad_norm': 14.622056007385254, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.045762382447719574, 'loss_2': 0.01055145263671875, 'loss_3': -16.07498550415039, 'loss_4': 4.003573417663574, 'epoch': 4.69}
{'loss': 0.0291, 'grad_norm': 14.583765983581543, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.02831142768263817, 'loss_2': 0.0007476806640625, 'loss_3': -16.12825584411621, 'loss_4': 3.688261032104492, 'epoch': 4.69}
{'loss': 0.0212, 'grad_norm': 6.607997417449951, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.016267457976937294, 'loss_2': 0.00493621826171875, 'loss_3': -15.975564956665039, 'loss_4': 3.4046688079833984, 'epoch': 4.7}
{'loss': 0.0241, 'grad_norm': 7.24027681350708, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.01805191859602928, 'loss_2': 0.0060882568359375, 'loss_3': -16.018953323364258, 'loss_4': 3.9948835372924805, 'epoch': 4.7}
{'loss': 0.0583, 'grad_norm': 19.46639060974121, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.04583892226219177, 'loss_2': 0.012481689453125, 'loss_3': -16.1700382232666, 'loss_4': 2.636796712875366, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 09:44:32,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:32,349 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:18<1:15:29,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:44:36,162 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-810
[INFO|configuration_utils.py:420] 2025-01-21 09:44:36,163 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-810/config.json                                                                              
{'eval_loss': 0.008623339235782623, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.675, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005623340606689453, 'eval_loss_2': 0.00299999862909317, 'eval_loss_3': -18.350614547729492, 'eval_loss_4': 3.1195952892303467, 'epoch': 4.71}
[INFO|modeling_utils.py:2988] 2025-01-21 09:44:36,659 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-810/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:44:36,661 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-810/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:44:36,661 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-810/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:44:37,606 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-490] due to args.save_total_limit
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:23<1:23:22,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:44:41,254 >>
{'loss': 0.0461, 'grad_norm': 16.288774490356445, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.041562262922525406, 'loss_2': 0.00453948974609375, 'loss_3': -15.996549606323242, 'loss_4': 2.959038257598877, 'epoch': 4.72}
{'loss': 0.0341, 'grad_norm': 18.489337921142578, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.027414150536060333, 'loss_2': 0.00672149658203125, 'loss_3': -16.26744842529297, 'loss_4': 3.4610400199890137, 'epoch': 4.72}
{'loss': 0.0134, 'grad_norm': 4.764386177062988, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.007891399785876274, 'loss_2': 0.005550384521484375, 'loss_3': -16.134464263916016, 'loss_4': 3.606172800064087, 'epoch': 4.73}
{'loss': 0.023, 'grad_norm': 10.63537883758545, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.020929789170622826, 'loss_2': 0.002040863037109375, 'loss_3': -16.187646865844727, 'loss_4': 3.299877166748047, 'epoch': 4.73}
{'loss': 0.0205, 'grad_norm': 8.053930282592773, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.017914699390530586, 'loss_2': 0.002605438232421875, 'loss_3': -15.970806121826172, 'loss_4': 2.8140130043029785, 'epoch': 4.74}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:44:41,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:41,254 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:30<1:16:29,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:44:48,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013023566454648972, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.658, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005162905901670456, 'eval_loss_2': 0.007860660552978516, 'eval_loss_3': -18.3587703704834, 'eval_loss_4': 3.1293742656707764, 'epoch': 4.74}
{'loss': 0.0451, 'grad_norm': 10.25189208984375, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.039059657603502274, 'loss_2': 0.006084442138671875, 'loss_3': -15.96966552734375, 'loss_4': 3.426530361175537, 'epoch': 4.74}
{'loss': 0.0181, 'grad_norm': 7.121718406677246, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.014889795333147049, 'loss_2': 0.003215789794921875, 'loss_3': -16.12853240966797, 'loss_4': 3.158482313156128, 'epoch': 4.75}
{'loss': 0.0128, 'grad_norm': 5.78513765335083, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.009627101011574268, 'loss_2': 0.00313568115234375, 'loss_3': -16.12421226501465, 'loss_4': 3.5333738327026367, 'epoch': 4.76}
{'loss': 0.0182, 'grad_norm': 6.8947014808654785, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.01814098283648491, 'loss_2': 7.539987564086914e-05, 'loss_3': -15.901074409484863, 'loss_4': 3.291147232055664, 'epoch': 4.76}
{'loss': 0.0184, 'grad_norm': 9.63746452331543, 'learning_rate': 2.525e-05, 'loss_1': 0.017880482599139214, 'loss_2': 0.000492095947265625, 'loss_3': -15.94005012512207, 'loss_4': 3.4933674335479736, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 09:44:48,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:48,603 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:38<1:15:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:55,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011828280054032803, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.525, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005301391705870628, 'eval_loss_2': 0.0065268874168396, 'eval_loss_3': -18.344430923461914, 'eval_loss_4': 3.0770468711853027, 'epoch': 4.77}
{'loss': 0.0388, 'grad_norm': 8.3554105758667, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.02311691828072071, 'loss_2': 0.0157318115234375, 'loss_3': -15.987844467163086, 'loss_4': 3.624126434326172, 'epoch': 4.77}
{'loss': 0.027, 'grad_norm': 8.913206100463867, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.016072340309619904, 'loss_2': 0.010894775390625, 'loss_3': -16.232378005981445, 'loss_4': 3.2415218353271484, 'epoch': 4.78}
{'loss': 0.0536, 'grad_norm': 12.073771476745605, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.03143228217959404, 'loss_2': 0.022125244140625, 'loss_3': -16.103408813476562, 'loss_4': 3.581043004989624, 'epoch': 4.78}
{'loss': 0.0242, 'grad_norm': 7.844759464263916, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.013666192069649696, 'loss_2': 0.0105133056640625, 'loss_3': -16.097793579101562, 'loss_4': 2.5704398155212402, 'epoch': 4.79}
{'loss': 0.049, 'grad_norm': 12.00216007232666, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.03731493651866913, 'loss_2': 0.01171875, 'loss_3': -15.9757661819458, 'loss_4': 3.0490469932556152, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 09:44:55,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:55,954 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:45<1:14:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:03,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016171511262655258, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005835112649947405, 'eval_loss_2': 0.01033639907836914, 'eval_loss_3': -18.328033447265625, 'eval_loss_4': 2.6306889057159424, 'epoch': 4.8}
{'loss': 0.0344, 'grad_norm': 7.237035751342773, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.015526685863733292, 'loss_2': 0.0188751220703125, 'loss_3': -16.00564193725586, 'loss_4': 2.357844591140747, 'epoch': 4.8}
{'loss': 0.0463, 'grad_norm': 14.037496566772461, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.037433475255966187, 'loss_2': 0.00890350341796875, 'loss_3': -15.922355651855469, 'loss_4': 3.086230993270874, 'epoch': 4.81}
{'loss': 0.0299, 'grad_norm': 10.3809175491333, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.020004671066999435, 'loss_2': 0.00989532470703125, 'loss_3': -15.920915603637695, 'loss_4': 3.5158300399780273, 'epoch': 4.81}
{'loss': 0.0786, 'grad_norm': 22.866580963134766, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.07432995736598969, 'loss_2': 0.00431060791015625, 'loss_3': -16.046979904174805, 'loss_4': 3.042198657989502, 'epoch': 4.82}
{'loss': 0.0232, 'grad_norm': 8.92241096496582, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.016741104423999786, 'loss_2': 0.006500244140625, 'loss_3': -15.952879905700684, 'loss_4': 3.183898687362671, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 09:45:03,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:03,307 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [20:52<1:14:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:10,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011890600435435772, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005585561506450176, 'eval_loss_2': 0.006305038928985596, 'eval_loss_3': -18.340316772460938, 'eval_loss_4': 2.314724922180176, 'epoch': 4.83}
{'loss': 0.0264, 'grad_norm': 12.814162254333496, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.020970137789845467, 'loss_2': 0.005382537841796875, 'loss_3': -16.035747528076172, 'loss_4': 2.490960121154785, 'epoch': 4.83}
{'loss': 0.045, 'grad_norm': 15.075270652770996, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.03482425585389137, 'loss_2': 0.01021575927734375, 'loss_3': -15.997049331665039, 'loss_4': 2.6710259914398193, 'epoch': 4.84}
{'loss': 0.0417, 'grad_norm': 14.619010925292969, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.031558796763420105, 'loss_2': 0.010101318359375, 'loss_3': -15.941930770874023, 'loss_4': 1.949232816696167, 'epoch': 4.84}
{'loss': 0.0501, 'grad_norm': 11.624788284301758, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.04840059578418732, 'loss_2': 0.001659393310546875, 'loss_3': -16.03996467590332, 'loss_4': 2.013347864151001, 'epoch': 4.85}
{'loss': 0.0586, 'grad_norm': 14.978049278259277, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.05281045287847519, 'loss_2': 0.005794525146484375, 'loss_3': -16.026504516601562, 'loss_4': 2.2732255458831787, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 09:45:10,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:10,654 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:00<1:14:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:18,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011191973462700844, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00590313458815217, 'eval_loss_2': 0.005288839340209961, 'eval_loss_3': -18.339839935302734, 'eval_loss_4': 1.7245569229125977, 'epoch': 4.85}
{'loss': 0.0252, 'grad_norm': 10.546067237854004, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.025108182802796364, 'loss_2': 0.00013446807861328125, 'loss_3': -15.992938995361328, 'loss_4': 2.1536014080047607, 'epoch': 4.86}
{'loss': 0.0187, 'grad_norm': 5.7118964195251465, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.014652224257588387, 'loss_2': 0.00400543212890625, 'loss_3': -16.090944290161133, 'loss_4': 2.1986188888549805, 'epoch': 4.87}
{'loss': 0.1107, 'grad_norm': 27.81064224243164, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.10369499027729034, 'loss_2': 0.00696563720703125, 'loss_3': -15.912016868591309, 'loss_4': 2.331303834915161, 'epoch': 4.87}
{'loss': 0.0497, 'grad_norm': 20.028833389282227, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.04899200052022934, 'loss_2': 0.0007004737854003906, 'loss_3': -16.067367553710938, 'loss_4': 2.234267234802246, 'epoch': 4.88}
{'loss': 0.0334, 'grad_norm': 12.10506820678711, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.02915576472878456, 'loss_2': 0.0041961669921875, 'loss_3': -16.305892944335938, 'loss_4': 1.4969253540039062, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 09:45:18,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:18,011 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:07<1:14:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:25,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012780334800481796, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.686, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00545897800475359, 'eval_loss_2': 0.007321357727050781, 'eval_loss_3': -18.37066650390625, 'eval_loss_4': 1.5899386405944824, 'epoch': 4.88}
{'loss': 0.0734, 'grad_norm': 21.43528175354004, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.06599155813455582, 'loss_2': 0.00742340087890625, 'loss_3': -15.959145545959473, 'loss_4': 2.3974781036376953, 'epoch': 4.89}
{'loss': 0.0525, 'grad_norm': 13.060108184814453, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.03674040362238884, 'loss_2': 0.01580810546875, 'loss_3': -16.29766273498535, 'loss_4': 1.0993397235870361, 'epoch': 4.9}
{'loss': 0.054, 'grad_norm': 10.654102325439453, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.031884629279375076, 'loss_2': 0.0221405029296875, 'loss_3': -16.28838348388672, 'loss_4': 1.8450759649276733, 'epoch': 4.9}
{'loss': 0.0323, 'grad_norm': 10.192627906799316, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.024674739688634872, 'loss_2': 0.00757598876953125, 'loss_3': -16.293270111083984, 'loss_4': 1.6165246963500977, 'epoch': 4.91}
{'loss': 0.0733, 'grad_norm': 22.160400390625, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.0698045864701271, 'loss_2': 0.00345611572265625, 'loss_3': -15.929359436035156, 'loss_4': 2.0310873985290527, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 09:45:25,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:25,369 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:14<1:14:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:32,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010594905354082584, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.403, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006135465111583471, 'eval_loss_2': 0.0044594407081604, 'eval_loss_3': -18.338153839111328, 'eval_loss_4': 1.5803780555725098, 'epoch': 4.91}
{'loss': 0.0269, 'grad_norm': 7.742620468139648, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.01704050600528717, 'loss_2': 0.0098114013671875, 'loss_3': -16.059524536132812, 'loss_4': 1.2824656963348389, 'epoch': 4.92}
{'loss': 0.041, 'grad_norm': 11.891165733337402, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.03787633031606674, 'loss_2': 0.003154754638671875, 'loss_3': -16.080686569213867, 'loss_4': 2.290377378463745, 'epoch': 4.92}
{'loss': 0.0231, 'grad_norm': 7.78660774230957, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.020291881635785103, 'loss_2': 0.002796173095703125, 'loss_3': -16.356489181518555, 'loss_4': 1.7739338874816895, 'epoch': 4.93}
{'loss': 0.0326, 'grad_norm': 12.388591766357422, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.031171228736639023, 'loss_2': 0.001392364501953125, 'loss_3': -16.146095275878906, 'loss_4': 1.7762975692749023, 'epoch': 4.94}
{'loss': 0.0204, 'grad_norm': 6.384530067443848, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.014422359876334667, 'loss_2': 0.006008148193359375, 'loss_3': -15.892717361450195, 'loss_4': 1.6372933387756348, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 09:45:32,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:32,718 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:22<1:14:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:40,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010555470362305641, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.962, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00645858608186245, 'eval_loss_2': 0.0040968842804431915, 'eval_loss_3': -18.297218322753906, 'eval_loss_4': 1.7372431755065918, 'epoch': 4.94}
{'loss': 0.0657, 'grad_norm': 17.823787689208984, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.06101122498512268, 'loss_2': 0.00473785400390625, 'loss_3': -16.06452751159668, 'loss_4': 1.8068349361419678, 'epoch': 4.95}
{'loss': 0.0316, 'grad_norm': 14.096809387207031, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.026794038712978363, 'loss_2': 0.00479888916015625, 'loss_3': -16.1618595123291, 'loss_4': 1.8066363334655762, 'epoch': 4.95}
{'loss': 0.024, 'grad_norm': 7.332956790924072, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.021485064178705215, 'loss_2': 0.0025177001953125, 'loss_3': -16.192039489746094, 'loss_4': 1.8932173252105713, 'epoch': 4.96}
{'loss': 0.0243, 'grad_norm': 9.770008087158203, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.0228826105594635, 'loss_2': 0.001373291015625, 'loss_3': -15.991613388061523, 'loss_4': 2.2703003883361816, 'epoch': 4.97}
{'loss': 0.0355, 'grad_norm': 16.367311477661133, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.030534666031599045, 'loss_2': 0.004970550537109375, 'loss_3': -16.269088745117188, 'loss_4': 2.061253547668457, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 09:45:40,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:40,071 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:29<1:06:56,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 09:45:47,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011221212334930897, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006177110131829977, 'eval_loss_2': 0.005044102668762207, 'eval_loss_3': -18.3153018951416, 'eval_loss_4': 1.9288376569747925, 'epoch': 4.97}
{'loss': 0.0315, 'grad_norm': 11.115042686462402, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.025625398382544518, 'loss_2': 0.00588226318359375, 'loss_3': -16.187101364135742, 'loss_4': 2.165125608444214, 'epoch': 4.98}
{'loss': 0.0321, 'grad_norm': 9.343729972839355, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.022893888875842094, 'loss_2': 0.0092010498046875, 'loss_3': -16.242809295654297, 'loss_4': 2.2450945377349854, 'epoch': 4.98}
{'loss': 0.0242, 'grad_norm': 6.5611653327941895, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.013345143757760525, 'loss_2': 0.01085662841796875, 'loss_3': -16.094409942626953, 'loss_4': 2.1288716793060303, 'epoch': 4.99}
{'loss': 0.025, 'grad_norm': 8.17851734161377, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.021434403955936432, 'loss_2': 0.0035400390625, 'loss_3': -16.06222152709961, 'loss_4': 2.7775521278381348, 'epoch': 4.99}
{'loss': 0.0209, 'grad_norm': 14.908693313598633, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.018849391490221024, 'loss_2': 0.002002716064453125, 'loss_3': -16.193050384521484, 'loss_4': 2.201467990875244, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 09:45:47,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:47,070 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:36<1:13:21,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:45:54,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012516411021351814, 'eval_runtime': 3.8181, 'eval_samples_per_second': 268.197, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.0069395313039422035, 'eval_loss_2': 0.005576878786087036, 'eval_loss_3': -18.347545623779297, 'eval_loss_4': 1.9717979431152344, 'epoch': 5.0}
{'loss': 0.0284, 'grad_norm': 9.34622573852539, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.022838935256004333, 'loss_2': 0.005527496337890625, 'loss_3': -15.991814613342285, 'loss_4': 2.624530792236328, 'epoch': 5.01}
{'loss': 0.0295, 'grad_norm': 6.8485426902771, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.019502529874444008, 'loss_2': 0.00995635986328125, 'loss_3': -16.193634033203125, 'loss_4': 2.729865074157715, 'epoch': 5.01}
{'loss': 0.0189, 'grad_norm': 6.549003601074219, 'learning_rate': 2.5e-05, 'loss_1': 0.015904447063803673, 'loss_2': 0.002956390380859375, 'loss_3': -16.175189971923828, 'loss_4': 1.9594618082046509, 'epoch': 5.02}
{'loss': 0.0263, 'grad_norm': 6.879772186279297, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.024220265448093414, 'loss_2': 0.00212860107421875, 'loss_3': -16.163572311401367, 'loss_4': 2.311884880065918, 'epoch': 5.02}
{'loss': 0.023, 'grad_norm': 7.244045734405518, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.016694318503141403, 'loss_2': 0.006317138671875, 'loss_3': -16.352333068847656, 'loss_4': 2.4695651531219482, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 09:45:54,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:54,476 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:44<1:14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:01,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01036095805466175, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.489, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006440224125981331, 'eval_loss_2': 0.00392073392868042, 'eval_loss_3': -18.380111694335938, 'eval_loss_4': 2.281208038330078, 'epoch': 5.03}
{'loss': 0.021, 'grad_norm': 6.9133734703063965, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.015409308485686779, 'loss_2': 0.00559234619140625, 'loss_3': -16.415863037109375, 'loss_4': 2.7192158699035645, 'epoch': 5.03}
{'loss': 0.0243, 'grad_norm': 11.777832984924316, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.02228594943881035, 'loss_2': 0.0020294189453125, 'loss_3': -16.26155662536621, 'loss_4': 2.669076681137085, 'epoch': 5.04}
{'loss': 0.0183, 'grad_norm': 5.676243305206299, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.014154346659779549, 'loss_2': 0.00417327880859375, 'loss_3': -16.069198608398438, 'loss_4': 3.053096294403076, 'epoch': 5.05}
{'loss': 0.0449, 'grad_norm': 16.52869987487793, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.03711794316768646, 'loss_2': 0.007785797119140625, 'loss_3': -16.09344482421875, 'loss_4': 3.548928737640381, 'epoch': 5.05}
{'loss': 0.0441, 'grad_norm': 17.04566192626953, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.043474383652210236, 'loss_2': 0.000644683837890625, 'loss_3': -15.997694969177246, 'loss_4': 3.1902270317077637, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 09:46:01,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:01,841 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [21:51<1:14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:09,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009666800498962402, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.831, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00643574446439743, 'eval_loss_2': 0.003231056034564972, 'eval_loss_3': -18.37729263305664, 'eval_loss_4': 2.4895687103271484, 'epoch': 5.06}
{'loss': 0.0381, 'grad_norm': 12.095379829406738, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.03386211022734642, 'loss_2': 0.00426483154296875, 'loss_3': -16.14858627319336, 'loss_4': 2.62654447555542, 'epoch': 5.06}
{'loss': 0.0592, 'grad_norm': 16.701488494873047, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.05365053936839104, 'loss_2': 0.00553131103515625, 'loss_3': -16.167705535888672, 'loss_4': 2.712045669555664, 'epoch': 5.07}
{'loss': 0.0285, 'grad_norm': 9.152778625488281, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.026991210877895355, 'loss_2': 0.0015354156494140625, 'loss_3': -16.160991668701172, 'loss_4': 2.9730377197265625, 'epoch': 5.08}
{'loss': 0.0235, 'grad_norm': 8.414122581481934, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.022775929421186447, 'loss_2': 0.0007719993591308594, 'loss_3': -16.14063262939453, 'loss_4': 2.665381908416748, 'epoch': 5.08}
{'loss': 0.0344, 'grad_norm': 17.824485778808594, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.03307546675205231, 'loss_2': 0.0013294219970703125, 'loss_3': -16.208024978637695, 'loss_4': 3.742985486984253, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 09:46:09,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:09,200 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [21:58<1:14:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:16,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010586589574813843, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.034, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006413310766220093, 'eval_loss_2': 0.00417327880859375, 'eval_loss_3': -18.33930015563965, 'eval_loss_4': 2.772294759750366, 'epoch': 5.09}
{'loss': 0.0258, 'grad_norm': 15.19030475616455, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.020372293889522552, 'loss_2': 0.005382537841796875, 'loss_3': -16.27130126953125, 'loss_4': 2.745460033416748, 'epoch': 5.09}
{'loss': 0.0236, 'grad_norm': 10.7239408493042, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.021129440516233444, 'loss_2': 0.002460479736328125, 'loss_3': -16.433027267456055, 'loss_4': 3.213684320449829, 'epoch': 5.1}
{'loss': 0.0501, 'grad_norm': 18.729463577270508, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.04811416193842888, 'loss_2': 0.00197601318359375, 'loss_3': -15.943809509277344, 'loss_4': 3.3395304679870605, 'epoch': 5.1}
{'loss': 0.027, 'grad_norm': 11.548892974853516, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.020252397283911705, 'loss_2': 0.00678253173828125, 'loss_3': -16.118019104003906, 'loss_4': 3.2289042472839355, 'epoch': 5.11}
{'loss': 0.017, 'grad_norm': 6.126208782196045, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.013480481691658497, 'loss_2': 0.003482818603515625, 'loss_3': -16.328887939453125, 'loss_4': 3.1269736289978027, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 09:46:16,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:16,560 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:06<1:14:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:23,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010832407511770725, 'eval_runtime': 3.8258, 'eval_samples_per_second': 267.655, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.007957646623253822, 'eval_loss_2': 0.0028747618198394775, 'eval_loss_3': -18.32659149169922, 'eval_loss_4': 3.2779881954193115, 'epoch': 5.12}
{'loss': 0.0324, 'grad_norm': 7.389847278594971, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.020555930212140083, 'loss_2': 0.011810302734375, 'loss_3': -16.17984962463379, 'loss_4': 3.4797675609588623, 'epoch': 5.12}
{'loss': 0.0545, 'grad_norm': 22.5407772064209, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.04743986576795578, 'loss_2': 0.00702667236328125, 'loss_3': -16.178993225097656, 'loss_4': 3.9154248237609863, 'epoch': 5.13}
{'loss': 0.0473, 'grad_norm': 15.29080867767334, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.044263262301683426, 'loss_2': 0.002986907958984375, 'loss_3': -16.06239891052246, 'loss_4': 4.077517032623291, 'epoch': 5.13}
{'loss': 0.0493, 'grad_norm': 18.737110137939453, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.0439877063035965, 'loss_2': 0.00531768798828125, 'loss_3': -16.101552963256836, 'loss_4': 3.729793071746826, 'epoch': 5.14}
{'loss': 0.0419, 'grad_norm': 21.5263671875, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.038335926830768585, 'loss_2': 0.00360870361328125, 'loss_3': -16.018199920654297, 'loss_4': 2.8762054443359375, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 09:46:23,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:23,946 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:13<1:14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:31,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01319902203977108, 'eval_runtime': 3.8199, 'eval_samples_per_second': 268.066, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.009234999306499958, 'eval_loss_2': 0.003964021801948547, 'eval_loss_3': -18.303970336914062, 'eval_loss_4': 3.742992639541626, 'epoch': 5.15}
{'loss': 0.0425, 'grad_norm': 15.146097183227539, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.039847299456596375, 'loss_2': 0.002620697021484375, 'loss_3': -16.26689910888672, 'loss_4': 4.158082962036133, 'epoch': 5.15}
{'loss': 0.042, 'grad_norm': 13.5421781539917, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.03681550920009613, 'loss_2': 0.005191802978515625, 'loss_3': -16.21526527404785, 'loss_4': 4.150523662567139, 'epoch': 5.16}
{'loss': 0.0342, 'grad_norm': 10.864922523498535, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.03068610467016697, 'loss_2': 0.0035400390625, 'loss_3': -16.08791160583496, 'loss_4': 3.8823914527893066, 'epoch': 5.16}
{'loss': 0.02, 'grad_norm': 6.28480339050293, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.019438577815890312, 'loss_2': 0.0005702972412109375, 'loss_3': -16.277725219726562, 'loss_4': 4.115638732910156, 'epoch': 5.17}
{'loss': 0.0325, 'grad_norm': 6.373292922973633, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.01811007224023342, 'loss_2': 0.0143585205078125, 'loss_3': -16.13495445251465, 'loss_4': 3.810781955718994, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 09:46:31,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:31,327 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:20<1:13:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:38,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02117167040705681, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.346, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011923771351575851, 'eval_loss_2': 0.009247899055480957, 'eval_loss_3': -18.26055145263672, 'eval_loss_4': 3.910017251968384, 'epoch': 5.17}
{'loss': 0.0253, 'grad_norm': 5.896801471710205, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.015610964968800545, 'loss_2': 0.009735107421875, 'loss_3': -16.06688690185547, 'loss_4': 3.766051769256592, 'epoch': 5.18}
{'loss': 0.0268, 'grad_norm': 6.355048179626465, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.015474564395844936, 'loss_2': 0.011322021484375, 'loss_3': -16.264095306396484, 'loss_4': 4.024301528930664, 'epoch': 5.19}
{'loss': 0.0247, 'grad_norm': 8.947784423828125, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.02121940813958645, 'loss_2': 0.003444671630859375, 'loss_3': -16.208988189697266, 'loss_4': 3.912066698074341, 'epoch': 5.19}
{'loss': 0.0331, 'grad_norm': 6.165833950042725, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.023051973432302475, 'loss_2': 0.010009765625, 'loss_3': -15.970954895019531, 'loss_4': 4.287990570068359, 'epoch': 5.2}
{'loss': 0.0247, 'grad_norm': 7.249688148498535, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.022576922550797462, 'loss_2': 0.002140045166015625, 'loss_3': -16.006731033325195, 'loss_4': 3.723206043243408, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 09:46:38,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:38,680 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:28<1:13:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:46,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02058817818760872, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.603, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01512830425053835, 'eval_loss_2': 0.005459874868392944, 'eval_loss_3': -18.184064865112305, 'eval_loss_4': 3.9159960746765137, 'epoch': 5.2}
{'loss': 0.0268, 'grad_norm': 8.414146423339844, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.020429173484444618, 'loss_2': 0.00640106201171875, 'loss_3': -15.98666763305664, 'loss_4': 3.6193108558654785, 'epoch': 5.21}
{'loss': 0.0651, 'grad_norm': 19.42732810974121, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.05651986598968506, 'loss_2': 0.0085906982421875, 'loss_3': -16.001201629638672, 'loss_4': 4.2180070877075195, 'epoch': 5.22}
{'loss': 0.0286, 'grad_norm': 7.199216842651367, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.019626883789896965, 'loss_2': 0.0089263916015625, 'loss_3': -16.073131561279297, 'loss_4': 3.573254108428955, 'epoch': 5.22}
{'loss': 0.1203, 'grad_norm': 27.70782470703125, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.10409294813871384, 'loss_2': 0.016204833984375, 'loss_3': -15.949789047241211, 'loss_4': 4.167995452880859, 'epoch': 5.23}
{'loss': 0.0657, 'grad_norm': 17.303312301635742, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.043316733092069626, 'loss_2': 0.0223541259765625, 'loss_3': -15.992205619812012, 'loss_4': 3.6060190200805664, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 09:46:46,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:46,052 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:35<1:13:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:53,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024489538744091988, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.307, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013452189043164253, 'eval_loss_2': 0.011037349700927734, 'eval_loss_3': -18.1469669342041, 'eval_loss_4': 3.4676880836486816, 'epoch': 5.23}
{'loss': 0.0248, 'grad_norm': 5.802496910095215, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.014942482113838196, 'loss_2': 0.0098114013671875, 'loss_3': -16.027767181396484, 'loss_4': 3.999025344848633, 'epoch': 5.24}
{'loss': 0.0292, 'grad_norm': 9.256061553955078, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.024270666763186455, 'loss_2': 0.00492095947265625, 'loss_3': -15.845146179199219, 'loss_4': 3.2377352714538574, 'epoch': 5.24}
{'loss': 0.016, 'grad_norm': 5.927083492279053, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.011587969027459621, 'loss_2': 0.00440216064453125, 'loss_3': -16.169673919677734, 'loss_4': 3.894190549850464, 'epoch': 5.25}
{'loss': 0.0352, 'grad_norm': 9.250795364379883, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.03151495009660721, 'loss_2': 0.0037078857421875, 'loss_3': -16.125574111938477, 'loss_4': 3.224620819091797, 'epoch': 5.26}
{'loss': 0.0443, 'grad_norm': 13.67312240600586, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.03763065114617348, 'loss_2': 0.00669097900390625, 'loss_3': -16.023990631103516, 'loss_4': 2.6676530838012695, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 09:46:53,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:53,399 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:42<1:13:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:00,751 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012706389650702477, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0074137356132268906, 'eval_loss_2': 0.005292654037475586, 'eval_loss_3': -18.17868995666504, 'eval_loss_4': 3.0000221729278564, 'epoch': 5.26}
{'loss': 0.0217, 'grad_norm': 5.621134281158447, 'learning_rate': 2.475e-05, 'loss_1': 0.015845810994505882, 'loss_2': 0.005817413330078125, 'loss_3': -16.207273483276367, 'loss_4': 2.6264681816101074, 'epoch': 5.27}
{'loss': 0.0264, 'grad_norm': 7.875515937805176, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.017262252047657967, 'loss_2': 0.0091094970703125, 'loss_3': -16.111682891845703, 'loss_4': 3.187669277191162, 'epoch': 5.27}
{'loss': 0.0325, 'grad_norm': 6.167466163635254, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.011984871700406075, 'loss_2': 0.0205230712890625, 'loss_3': -16.130428314208984, 'loss_4': 2.9506144523620605, 'epoch': 5.28}
{'loss': 0.0288, 'grad_norm': 12.445687294006348, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.02078299969434738, 'loss_2': 0.0080108642578125, 'loss_3': -16.05007553100586, 'loss_4': 3.0884933471679688, 'epoch': 5.28}
{'loss': 0.0227, 'grad_norm': 6.888889789581299, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.01850159466266632, 'loss_2': 0.004161834716796875, 'loss_3': -16.17062759399414, 'loss_4': 3.0862479209899902, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 09:47:00,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:00,751 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [22:50<1:13:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:08,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011378196999430656, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007586431689560413, 'eval_loss_2': 0.0037917643785476685, 'eval_loss_3': -18.29743194580078, 'eval_loss_4': 2.9632315635681152, 'epoch': 5.29}
{'loss': 0.0395, 'grad_norm': 12.5645170211792, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.03753962740302086, 'loss_2': 0.00199127197265625, 'loss_3': -16.11208152770996, 'loss_4': 3.861528158187866, 'epoch': 5.3}
{'loss': 0.0878, 'grad_norm': 29.49372673034668, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.08266538381576538, 'loss_2': 0.00513458251953125, 'loss_3': -15.990804672241211, 'loss_4': 3.212779998779297, 'epoch': 5.3}
{'loss': 0.0356, 'grad_norm': 12.497292518615723, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.03265295550227165, 'loss_2': 0.0029354095458984375, 'loss_3': -16.202505111694336, 'loss_4': 3.7510979175567627, 'epoch': 5.31}
{'loss': 0.033, 'grad_norm': 9.055475234985352, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.024622393772006035, 'loss_2': 0.0084075927734375, 'loss_3': -16.04173469543457, 'loss_4': 3.61348819732666, 'epoch': 5.31}
{'loss': 0.0251, 'grad_norm': 9.559965133666992, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.02232009544968605, 'loss_2': 0.002758026123046875, 'loss_3': -16.141115188598633, 'loss_4': 4.171845436096191, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 09:47:08,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:08,111 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [22:57<1:13:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:15,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012206140905618668, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.993, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007844958454370499, 'eval_loss_2': 0.004361182451248169, 'eval_loss_3': -18.34625244140625, 'eval_loss_4': 3.3582565784454346, 'epoch': 5.32}
{'loss': 0.0208, 'grad_norm': 5.89686918258667, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.015302644111216068, 'loss_2': 0.00548553466796875, 'loss_3': -16.332504272460938, 'loss_4': 3.7375035285949707, 'epoch': 5.33}
{'loss': 0.0243, 'grad_norm': 8.762558937072754, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.02056656964123249, 'loss_2': 0.00376129150390625, 'loss_3': -16.26214027404785, 'loss_4': 3.485337972640991, 'epoch': 5.33}
{'loss': 0.0426, 'grad_norm': 15.340600967407227, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.037896592170000076, 'loss_2': 0.0047149658203125, 'loss_3': -16.313613891601562, 'loss_4': 4.2613630294799805, 'epoch': 5.34}
{'loss': 0.0202, 'grad_norm': 5.88557243347168, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.01687406376004219, 'loss_2': 0.003299713134765625, 'loss_3': -16.215625762939453, 'loss_4': 3.873310089111328, 'epoch': 5.34}
{'loss': 0.0281, 'grad_norm': 11.173829078674316, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.02398350089788437, 'loss_2': 0.00414276123046875, 'loss_3': -16.165611267089844, 'loss_4': 3.6379995346069336, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 09:47:15,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:15,473 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:05<1:13:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:22,840 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016380034387111664, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.761, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010249217972159386, 'eval_loss_2': 0.006130814552307129, 'eval_loss_3': -18.319141387939453, 'eval_loss_4': 3.9553072452545166, 'epoch': 5.35}
{'loss': 0.0254, 'grad_norm': 8.116936683654785, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.020941779017448425, 'loss_2': 0.0044708251953125, 'loss_3': -16.235572814941406, 'loss_4': 4.505593299865723, 'epoch': 5.35}
{'loss': 0.0319, 'grad_norm': 11.532740592956543, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.020767953246831894, 'loss_2': 0.0110931396484375, 'loss_3': -16.365432739257812, 'loss_4': 4.465532302856445, 'epoch': 5.36}
{'loss': 0.0304, 'grad_norm': 8.086021423339844, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.018713368102908134, 'loss_2': 0.0117340087890625, 'loss_3': -16.37287139892578, 'loss_4': 4.9628448486328125, 'epoch': 5.37}
{'loss': 0.0271, 'grad_norm': 6.460553169250488, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.01691676862537861, 'loss_2': 0.0102081298828125, 'loss_3': -16.236623764038086, 'loss_4': 5.101238250732422, 'epoch': 5.37}
{'loss': 0.0417, 'grad_norm': 11.974366188049316, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.028792068362236023, 'loss_2': 0.012908935546875, 'loss_3': -16.46881103515625, 'loss_4': 4.988316535949707, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 09:47:22,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:22,840 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:12<1:13:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:30,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012387027032673359, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.783, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009321686811745167, 'eval_loss_2': 0.003065340220928192, 'eval_loss_3': -18.31456756591797, 'eval_loss_4': 4.556429386138916, 'epoch': 5.38}
{'loss': 0.0259, 'grad_norm': 6.757396697998047, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.02169700711965561, 'loss_2': 0.00423431396484375, 'loss_3': -16.28484535217285, 'loss_4': 4.832390308380127, 'epoch': 5.38}
{'loss': 0.0172, 'grad_norm': 6.510832786560059, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.015917548909783363, 'loss_2': 0.0012960433959960938, 'loss_3': -16.450084686279297, 'loss_4': 5.265048027038574, 'epoch': 5.39}
{'loss': 0.0292, 'grad_norm': 9.336616516113281, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.020265240222215652, 'loss_2': 0.00896453857421875, 'loss_3': -16.263622283935547, 'loss_4': 5.281711101531982, 'epoch': 5.4}
{'loss': 0.0307, 'grad_norm': 6.384211540222168, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.020062798634171486, 'loss_2': 0.01065826416015625, 'loss_3': -16.280454635620117, 'loss_4': 4.954737663269043, 'epoch': 5.4}
{'loss': 0.0272, 'grad_norm': 7.791980743408203, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.015327028930187225, 'loss_2': 0.0118865966796875, 'loss_3': -16.260902404785156, 'loss_4': 5.245345592498779, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 09:47:30,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:30,206 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:19<1:13:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:37,570 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01973675936460495, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008483401499688625, 'eval_loss_2': 0.01125335693359375, 'eval_loss_3': -18.26069450378418, 'eval_loss_4': 4.400369167327881, 'epoch': 5.41}
{'loss': 0.0498, 'grad_norm': 12.770734786987305, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.03472954407334328, 'loss_2': 0.01507568359375, 'loss_3': -16.38343620300293, 'loss_4': 4.344715595245361, 'epoch': 5.41}
{'loss': 0.0318, 'grad_norm': 7.636763095855713, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.02080470137298107, 'loss_2': 0.011016845703125, 'loss_3': -16.123369216918945, 'loss_4': 4.452286243438721, 'epoch': 5.42}
{'loss': 0.0241, 'grad_norm': 6.595617771148682, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.016857903450727463, 'loss_2': 0.0072479248046875, 'loss_3': -16.262752532958984, 'loss_4': 4.574341297149658, 'epoch': 5.42}
{'loss': 0.0312, 'grad_norm': 10.335896492004395, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.01658221147954464, 'loss_2': 0.01462554931640625, 'loss_3': -16.15350341796875, 'loss_4': 4.343800067901611, 'epoch': 5.43}
{'loss': 0.018, 'grad_norm': 6.743579387664795, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.012930568307638168, 'loss_2': 0.00505828857421875, 'loss_3': -16.19577980041504, 'loss_4': 4.0368804931640625, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 09:47:37,571 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:37,571 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:27<1:13:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:44,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013801570981740952, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009566287510097027, 'eval_loss_2': 0.00423528254032135, 'eval_loss_3': -18.248655319213867, 'eval_loss_4': 4.024248123168945, 'epoch': 5.44}
{'loss': 0.0458, 'grad_norm': 19.117767333984375, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.04152989387512207, 'loss_2': 0.004306793212890625, 'loss_3': -16.225059509277344, 'loss_4': 4.417951583862305, 'epoch': 5.44}
{'loss': 0.0121, 'grad_norm': 5.3329644203186035, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.008895471692085266, 'loss_2': 0.00316619873046875, 'loss_3': -16.391536712646484, 'loss_4': 4.085256576538086, 'epoch': 5.45}
{'loss': 0.0472, 'grad_norm': 14.331084251403809, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.045014988631010056, 'loss_2': 0.00213623046875, 'loss_3': -16.308879852294922, 'loss_4': 4.341973304748535, 'epoch': 5.45}
{'loss': 0.06, 'grad_norm': 17.5235652923584, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.05796846002340317, 'loss_2': 0.0020351409912109375, 'loss_3': -15.99510383605957, 'loss_4': 3.378145933151245, 'epoch': 5.46}
{'loss': 0.0283, 'grad_norm': 7.0476861000061035, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.016158219426870346, 'loss_2': 0.012176513671875, 'loss_3': -16.635543823242188, 'loss_4': 4.543837070465088, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 09:47:44,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:44,932 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:34<1:13:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:52,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015353307127952576, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.105, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007379637099802494, 'eval_loss_2': 0.007973670959472656, 'eval_loss_3': -18.27834701538086, 'eval_loss_4': 3.8222784996032715, 'epoch': 5.47}
{'loss': 0.03, 'grad_norm': 9.892186164855957, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.024574600160121918, 'loss_2': 0.00545501708984375, 'loss_3': -16.102067947387695, 'loss_4': 4.6465840339660645, 'epoch': 5.47}
{'loss': 0.0119, 'grad_norm': 5.269949913024902, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.008519532158970833, 'loss_2': 0.00342559814453125, 'loss_3': -16.371387481689453, 'loss_4': 4.129786491394043, 'epoch': 5.48}
{'loss': 0.0175, 'grad_norm': 5.6554155349731445, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.009785347618162632, 'loss_2': 0.00774383544921875, 'loss_3': -16.29702377319336, 'loss_4': 4.442991256713867, 'epoch': 5.48}
{'loss': 0.0227, 'grad_norm': 11.890714645385742, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.020605765283107758, 'loss_2': 0.0021343231201171875, 'loss_3': -16.316490173339844, 'loss_4': 3.91103458404541, 'epoch': 5.49}
{'loss': 0.0084, 'grad_norm': 5.3219380378723145, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.007995625026524067, 'loss_2': 0.00042176246643066406, 'loss_3': -16.466720581054688, 'loss_4': 3.886139392852783, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 09:47:52,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:52,301 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:41<1:13:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:59,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01154779177159071, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.15, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007053824607282877, 'eval_loss_2': 0.004493966698646545, 'eval_loss_3': -18.263904571533203, 'eval_loss_4': 3.6598472595214844, 'epoch': 5.49}
{'loss': 0.0281, 'grad_norm': 11.816454887390137, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.015033768489956856, 'loss_2': 0.0131072998046875, 'loss_3': -16.3539981842041, 'loss_4': 3.9104080200195312, 'epoch': 5.5}
{'loss': 0.0284, 'grad_norm': 11.877997398376465, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.021950583904981613, 'loss_2': 0.00646209716796875, 'loss_3': -16.308979034423828, 'loss_4': 3.9268651008605957, 'epoch': 5.51}
{'loss': 0.0317, 'grad_norm': 11.086199760437012, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.022536126896739006, 'loss_2': 0.00911712646484375, 'loss_3': -16.24203109741211, 'loss_4': 3.4506657123565674, 'epoch': 5.51}
{'loss': 0.0301, 'grad_norm': 8.329328536987305, 'learning_rate': 2.45e-05, 'loss_1': 0.018455293029546738, 'loss_2': 0.0116119384765625, 'loss_3': -16.14715576171875, 'loss_4': 3.8195173740386963, 'epoch': 5.52}
{'loss': 0.0408, 'grad_norm': 12.905355453491211, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.0287168025970459, 'loss_2': 0.0120391845703125, 'loss_3': -16.364402770996094, 'loss_4': 3.964120864868164, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 09:47:59,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:59,662 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [23:49<1:12:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:07,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01435938011854887, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.581, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006955648772418499, 'eval_loss_2': 0.007403731346130371, 'eval_loss_3': -18.299129486083984, 'eval_loss_4': 3.5972402095794678, 'epoch': 5.52}
{'loss': 0.0484, 'grad_norm': 15.073389053344727, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.03567112237215042, 'loss_2': 0.01274871826171875, 'loss_3': -16.458250045776367, 'loss_4': 4.52147102355957, 'epoch': 5.53}
{'loss': 0.0315, 'grad_norm': 8.907194137573242, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.015066535212099552, 'loss_2': 0.01641845703125, 'loss_3': -16.249561309814453, 'loss_4': 3.5117673873901367, 'epoch': 5.53}
{'loss': 0.0371, 'grad_norm': 17.246706008911133, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.031657710671424866, 'loss_2': 0.00547027587890625, 'loss_3': -16.11990737915039, 'loss_4': 3.7406249046325684, 'epoch': 5.54}
{'loss': 0.0142, 'grad_norm': 5.289243698120117, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.009387794882059097, 'loss_2': 0.0048065185546875, 'loss_3': -16.25704574584961, 'loss_4': 3.597003221511841, 'epoch': 5.55}
{'loss': 0.0197, 'grad_norm': 6.957122325897217, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.014957383275032043, 'loss_2': 0.004772186279296875, 'loss_3': -16.3702392578125, 'loss_4': 4.195120811462402, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 09:48:07,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:07,033 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [23:56<1:12:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:14,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013513032346963882, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007362727541476488, 'eval_loss_2': 0.006150305271148682, 'eval_loss_3': -18.265827178955078, 'eval_loss_4': 3.4007554054260254, 'epoch': 5.55}
{'loss': 0.0187, 'grad_norm': 5.236873149871826, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.008528642356395721, 'loss_2': 0.0101776123046875, 'loss_3': -16.180282592773438, 'loss_4': 3.172041654586792, 'epoch': 5.56}
{'loss': 0.0369, 'grad_norm': 10.758194923400879, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.025446973741054535, 'loss_2': 0.0114593505859375, 'loss_3': -16.294204711914062, 'loss_4': 3.3474016189575195, 'epoch': 5.56}
{'loss': 0.0327, 'grad_norm': 8.753604888916016, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.021869251504540443, 'loss_2': 0.0108184814453125, 'loss_3': -16.173843383789062, 'loss_4': 3.830033302307129, 'epoch': 5.57}
{'loss': 0.0312, 'grad_norm': 8.242734909057617, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.025001587346196175, 'loss_2': 0.00620269775390625, 'loss_3': -16.177688598632812, 'loss_4': 4.007530689239502, 'epoch': 5.58}
{'loss': 0.0235, 'grad_norm': 7.697601795196533, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.01683356985449791, 'loss_2': 0.006683349609375, 'loss_3': -16.186723709106445, 'loss_4': 3.6678333282470703, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 09:48:14,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:14,397 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:03<1:12:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:21,751 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011873476207256317, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.074, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006495706737041473, 'eval_loss_2': 0.005377769470214844, 'eval_loss_3': -18.24933433532715, 'eval_loss_4': 3.2731945514678955, 'epoch': 5.58}
{'loss': 0.0143, 'grad_norm': 6.718437194824219, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.013653547503054142, 'loss_2': 0.0006165504455566406, 'loss_3': -16.31320571899414, 'loss_4': 3.6672427654266357, 'epoch': 5.59}
{'loss': 0.0298, 'grad_norm': 12.3418607711792, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.026916421949863434, 'loss_2': 0.0028972625732421875, 'loss_3': -15.966901779174805, 'loss_4': 3.2766027450561523, 'epoch': 5.59}
{'loss': 0.0196, 'grad_norm': 7.872535705566406, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.01676141656935215, 'loss_2': 0.0027923583984375, 'loss_3': -16.133861541748047, 'loss_4': 3.3879055976867676, 'epoch': 5.6}
{'loss': 0.0176, 'grad_norm': 5.616918087005615, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.012927048839628696, 'loss_2': 0.00466156005859375, 'loss_3': -16.001750946044922, 'loss_4': 2.744551420211792, 'epoch': 5.6}
{'loss': 0.033, 'grad_norm': 19.27718162536621, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.03220143914222717, 'loss_2': 0.0007696151733398438, 'loss_3': -16.041683197021484, 'loss_4': 3.1070244312286377, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 09:48:21,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:21,751 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:11<1:12:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:29,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009878769516944885, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.194, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005869955290108919, 'eval_loss_2': 0.004008814692497253, 'eval_loss_3': -18.291549682617188, 'eval_loss_4': 2.9399771690368652, 'epoch': 5.61}
{'loss': 0.0284, 'grad_norm': 11.5743989944458, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.024497270584106445, 'loss_2': 0.003887176513671875, 'loss_3': -16.17676544189453, 'loss_4': 3.6417958736419678, 'epoch': 5.62}
{'loss': 0.0242, 'grad_norm': 7.257630825042725, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.016897333785891533, 'loss_2': 0.007293701171875, 'loss_3': -16.142738342285156, 'loss_4': 3.2630772590637207, 'epoch': 5.62}
{'loss': 0.0199, 'grad_norm': 6.974973201751709, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.016426002606749535, 'loss_2': 0.003490447998046875, 'loss_3': -16.084672927856445, 'loss_4': 3.5010995864868164, 'epoch': 5.63}
{'loss': 0.015, 'grad_norm': 8.360688209533691, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.013567455112934113, 'loss_2': 0.00144195556640625, 'loss_3': -15.912992477416992, 'loss_4': 3.2079885005950928, 'epoch': 5.63}
{'loss': 0.0187, 'grad_norm': 7.152690410614014, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.01407245546579361, 'loss_2': 0.004638671875, 'loss_3': -16.13324546813965, 'loss_4': 3.401097297668457, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 09:48:29,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:29,101 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:15<1:12:32,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:48:32,910 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-970
[INFO|configuration_utils.py:420] 2025-01-21 09:48:32,911 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-970/config.json                                                                              
{'eval_loss': 0.007406660355627537, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.909, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004558512009680271, 'eval_loss_2': 0.0028481483459472656, 'eval_loss_3': -18.32781982421875, 'eval_loss_4': 3.0029640197753906, 'epoch': 5.64}
[INFO|modeling_utils.py:2988] 2025-01-21 09:48:33,400 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-970/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:48:33,402 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-970/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:48:33,402 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-970/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:48:34,345 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-810] due to args.save_total_limit
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:20<1:20:10,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:48:37,991 >>
{'loss': 0.0478, 'grad_norm': 19.2559757232666, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.0448811836540699, 'loss_2': 0.00296783447265625, 'loss_3': -15.941162109375, 'loss_4': 3.5122132301330566, 'epoch': 5.65}
{'loss': 0.0322, 'grad_norm': 11.161831855773926, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.02832481823861599, 'loss_2': 0.003849029541015625, 'loss_3': -15.838177680969238, 'loss_4': 3.50614595413208, 'epoch': 5.65}
{'loss': 0.0216, 'grad_norm': 6.336289882659912, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.012123661115765572, 'loss_2': 0.00946044921875, 'loss_3': -16.00645637512207, 'loss_4': 3.1463375091552734, 'epoch': 5.66}
{'loss': 0.0131, 'grad_norm': 6.210442543029785, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.01136736385524273, 'loss_2': 0.001720428466796875, 'loss_3': -15.820411682128906, 'loss_4': 3.1631014347076416, 'epoch': 5.66}
{'loss': 0.0228, 'grad_norm': 10.047551155090332, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.018382107838988304, 'loss_2': 0.004428863525390625, 'loss_3': -16.125932693481445, 'loss_4': 3.6580681800842285, 'epoch': 5.67}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:48:37,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:37,991 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:27<1:14:44,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 09:48:45,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007995514199137688, 'eval_runtime': 3.9948, 'eval_samples_per_second': 256.332, 'eval_steps_per_second': 4.005, 'eval_loss_1': 0.004347709473222494, 'eval_loss_2': 0.0036478042602539062, 'eval_loss_3': -18.301071166992188, 'eval_loss_4': 2.990602970123291, 'epoch': 5.67}
{'loss': 0.0324, 'grad_norm': 10.126111030578613, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.023393729701638222, 'loss_2': 0.00897216796875, 'loss_3': -16.042028427124023, 'loss_4': 3.7301526069641113, 'epoch': 5.67}
{'loss': 0.0098, 'grad_norm': 5.361359119415283, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.00933703500777483, 'loss_2': 0.0004639625549316406, 'loss_3': -15.900463104248047, 'loss_4': 3.3930351734161377, 'epoch': 5.68}
{'loss': 0.0319, 'grad_norm': 11.915044784545898, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.029212534427642822, 'loss_2': 0.002704620361328125, 'loss_3': -16.130874633789062, 'loss_4': 3.5767836570739746, 'epoch': 5.69}
{'loss': 0.0278, 'grad_norm': 10.363487243652344, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.02525375224649906, 'loss_2': 0.0025730133056640625, 'loss_3': -15.89642333984375, 'loss_4': 3.4893641471862793, 'epoch': 5.69}
{'loss': 0.0156, 'grad_norm': 11.409403800964355, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.014443164691329002, 'loss_2': 0.0011138916015625, 'loss_3': -15.945140838623047, 'loss_4': 2.8879551887512207, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 09:48:45,545 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:45,545 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:35<1:12:46,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:48:52,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00825868546962738, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.455, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004993543028831482, 'eval_loss_2': 0.0032651424407958984, 'eval_loss_3': -18.304561614990234, 'eval_loss_4': 2.6834592819213867, 'epoch': 5.7}
{'loss': 0.026, 'grad_norm': 10.613595008850098, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.023704469203948975, 'loss_2': 0.002338409423828125, 'loss_3': -16.078073501586914, 'loss_4': 3.2522292137145996, 'epoch': 5.7}
{'loss': 0.0202, 'grad_norm': 9.065960884094238, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.015772057697176933, 'loss_2': 0.0044097900390625, 'loss_3': -16.20465850830078, 'loss_4': 3.2470149993896484, 'epoch': 5.71}
{'loss': 0.0365, 'grad_norm': 11.315910339355469, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.025438964366912842, 'loss_2': 0.01107025146484375, 'loss_3': -16.047597885131836, 'loss_4': 2.6354613304138184, 'epoch': 5.72}
{'loss': 0.0092, 'grad_norm': 5.115755558013916, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.006964442320168018, 'loss_2': 0.002262115478515625, 'loss_3': -16.134540557861328, 'loss_4': 2.5734939575195312, 'epoch': 5.72}
{'loss': 0.0194, 'grad_norm': 8.287376403808594, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.018183937296271324, 'loss_2': 0.0012578964233398438, 'loss_3': -15.912911415100098, 'loss_4': 2.9209253787994385, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 09:48:52,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:52,910 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:42<1:12:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:00,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007584482431411743, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004622429143637419, 'eval_loss_2': 0.002962052822113037, 'eval_loss_3': -18.26557731628418, 'eval_loss_4': 2.1270809173583984, 'epoch': 5.73}
{'loss': 0.0215, 'grad_norm': 7.250913143157959, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.01932523213326931, 'loss_2': 0.00212860107421875, 'loss_3': -15.900949478149414, 'loss_4': 2.3383030891418457, 'epoch': 5.73}
{'loss': 0.012, 'grad_norm': 5.291139602661133, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.00874642189592123, 'loss_2': 0.0032939910888671875, 'loss_3': -15.953903198242188, 'loss_4': 2.867800235748291, 'epoch': 5.74}
{'loss': 0.0147, 'grad_norm': 5.122735500335693, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.009678827598690987, 'loss_2': 0.005035400390625, 'loss_3': -15.965790748596191, 'loss_4': 2.0335049629211426, 'epoch': 5.74}
{'loss': 0.0223, 'grad_norm': 8.779038429260254, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.021874945610761642, 'loss_2': 0.00039124488830566406, 'loss_3': -16.009111404418945, 'loss_4': 1.971081018447876, 'epoch': 5.75}
{'loss': 0.0322, 'grad_norm': 15.13674259185791, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.028802670538425446, 'loss_2': 0.003383636474609375, 'loss_3': -15.81522274017334, 'loss_4': 2.3280210494995117, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 09:49:00,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:00,258 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [24:49<1:12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:07,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008747011423110962, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.755, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006215082015842199, 'eval_loss_2': 0.0025319308042526245, 'eval_loss_3': -18.214622497558594, 'eval_loss_4': 1.9206743240356445, 'epoch': 5.76}
{'loss': 0.0114, 'grad_norm': 7.290738105773926, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.011317404918372631, 'loss_2': 4.011392593383789e-05, 'loss_3': -15.86422348022461, 'loss_4': 1.8160371780395508, 'epoch': 5.76}
{'loss': 0.0166, 'grad_norm': 6.981791019439697, 'learning_rate': 2.425e-05, 'loss_1': 0.014396500773727894, 'loss_2': 0.0021820068359375, 'loss_3': -16.00137710571289, 'loss_4': 2.459071636199951, 'epoch': 5.77}
{'loss': 0.0213, 'grad_norm': 10.464974403381348, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.018805144354701042, 'loss_2': 0.0024852752685546875, 'loss_3': -16.018484115600586, 'loss_4': 1.6955480575561523, 'epoch': 5.77}
{'loss': 0.0207, 'grad_norm': 9.259196281433105, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.019419651478528976, 'loss_2': 0.001323699951171875, 'loss_3': -16.165651321411133, 'loss_4': 2.0446393489837646, 'epoch': 5.78}
{'loss': 0.0241, 'grad_norm': 7.7625532150268555, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.019646095111966133, 'loss_2': 0.00441741943359375, 'loss_3': -16.06334686279297, 'loss_4': 2.6755316257476807, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 09:49:07,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:07,618 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [24:57<1:12:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:14,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009507149457931519, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.873, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007177295628935099, 'eval_loss_2': 0.002329852432012558, 'eval_loss_3': -18.148893356323242, 'eval_loss_4': 1.997147798538208, 'epoch': 5.78}
{'loss': 0.0208, 'grad_norm': 5.990754127502441, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.012162642553448677, 'loss_2': 0.008636474609375, 'loss_3': -15.737617492675781, 'loss_4': 2.4929635524749756, 'epoch': 5.79}
{'loss': 0.0178, 'grad_norm': 6.502852916717529, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.014608383178710938, 'loss_2': 0.0031585693359375, 'loss_3': -15.795502662658691, 'loss_4': 2.12156343460083, 'epoch': 5.8}
{'loss': 0.0175, 'grad_norm': 5.9839043617248535, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.011997897177934647, 'loss_2': 0.00545501708984375, 'loss_3': -15.986035346984863, 'loss_4': 1.9441560506820679, 'epoch': 5.8}
{'loss': 0.0137, 'grad_norm': 7.323379039764404, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.01271613035351038, 'loss_2': 0.000988006591796875, 'loss_3': -15.918581008911133, 'loss_4': 1.8485362529754639, 'epoch': 5.81}
{'loss': 0.048, 'grad_norm': 11.779068946838379, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.04225863516330719, 'loss_2': 0.00576019287109375, 'loss_3': -15.983424186706543, 'loss_4': 2.060016393661499, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 09:49:14,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:14,975 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:04<1:11:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:22,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014138334430754185, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.475, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009175115264952183, 'eval_loss_2': 0.004963219165802002, 'eval_loss_3': -18.095598220825195, 'eval_loss_4': 2.277831792831421, 'epoch': 5.81}
{'loss': 0.059, 'grad_norm': 18.003599166870117, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.05782146751880646, 'loss_2': 0.0011444091796875, 'loss_3': -15.866923332214355, 'loss_4': 2.1955618858337402, 'epoch': 5.82}
{'loss': 0.018, 'grad_norm': 9.357889175415039, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.01732724718749523, 'loss_2': 0.0006399154663085938, 'loss_3': -16.035358428955078, 'loss_4': 2.244450092315674, 'epoch': 5.83}
{'loss': 0.0591, 'grad_norm': 22.498828887939453, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.052469756454229355, 'loss_2': 0.00662994384765625, 'loss_3': -15.84087085723877, 'loss_4': 2.2678439617156982, 'epoch': 5.83}
{'loss': 0.0225, 'grad_norm': 9.033994674682617, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.021444423124194145, 'loss_2': 0.0010967254638671875, 'loss_3': -16.152297973632812, 'loss_4': 2.6124019622802734, 'epoch': 5.84}
{'loss': 0.0128, 'grad_norm': 5.817409038543701, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.009837552905082703, 'loss_2': 0.0029964447021484375, 'loss_3': -15.951895713806152, 'loss_4': 2.8024139404296875, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 09:49:22,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:22,339 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:11<1:11:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:29,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01945670321583748, 'eval_runtime': 3.8186, 'eval_samples_per_second': 268.159, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.015892524272203445, 'eval_loss_2': 0.003564178943634033, 'eval_loss_3': -18.06705665588379, 'eval_loss_4': 2.99110746383667, 'epoch': 5.84}
{'loss': 0.0939, 'grad_norm': 13.415407180786133, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.08729320019483566, 'loss_2': 0.006622314453125, 'loss_3': -15.83696174621582, 'loss_4': 2.6904029846191406, 'epoch': 5.85}
{'loss': 0.0757, 'grad_norm': 23.235782623291016, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.07517533004283905, 'loss_2': 0.0005249977111816406, 'loss_3': -15.655635833740234, 'loss_4': 3.3597776889801025, 'epoch': 5.85}
{'loss': 0.0513, 'grad_norm': 15.750592231750488, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.04720397666096687, 'loss_2': 0.00412750244140625, 'loss_3': -15.794824600219727, 'loss_4': 3.3989527225494385, 'epoch': 5.86}
{'loss': 0.0602, 'grad_norm': 17.151857376098633, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.049406349658966064, 'loss_2': 0.01076507568359375, 'loss_3': -15.813560485839844, 'loss_4': 3.1262717247009277, 'epoch': 5.87}
{'loss': 0.0515, 'grad_norm': 16.518911361694336, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.04187954217195511, 'loss_2': 0.00963592529296875, 'loss_3': -15.921050071716309, 'loss_4': 3.044222593307495, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 09:49:29,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:29,698 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:19<1:11:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:37,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015218939632177353, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009851839393377304, 'eval_loss_2': 0.005367100238800049, 'eval_loss_3': -18.16947364807129, 'eval_loss_4': 3.2177252769470215, 'epoch': 5.87}
{'loss': 0.0513, 'grad_norm': 10.634054183959961, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.043459054082632065, 'loss_2': 0.0077972412109375, 'loss_3': -16.080055236816406, 'loss_4': 3.5997555255889893, 'epoch': 5.88}
{'loss': 0.0393, 'grad_norm': 11.910233497619629, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.027560660615563393, 'loss_2': 0.01171112060546875, 'loss_3': -15.88912296295166, 'loss_4': 2.7935903072357178, 'epoch': 5.88}
{'loss': 0.0245, 'grad_norm': 11.681024551391602, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.02058643288910389, 'loss_2': 0.00394439697265625, 'loss_3': -16.05499839782715, 'loss_4': 2.9178409576416016, 'epoch': 5.89}
{'loss': 0.0147, 'grad_norm': 6.112921714782715, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.010615816339850426, 'loss_2': 0.0040740966796875, 'loss_3': -16.232316970825195, 'loss_4': 3.002859592437744, 'epoch': 5.9}
{'loss': 0.0183, 'grad_norm': 7.75735330581665, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.0177584420889616, 'loss_2': 0.0004949569702148438, 'loss_3': -16.024368286132812, 'loss_4': 3.1229329109191895, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 09:49:37,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:37,053 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:26<1:11:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:44,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010095687583088875, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.738, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0070893182419240475, 'eval_loss_2': 0.00300636887550354, 'eval_loss_3': -18.226112365722656, 'eval_loss_4': 3.1422271728515625, 'epoch': 5.9}
{'loss': 0.0142, 'grad_norm': 4.894198417663574, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.011919496580958366, 'loss_2': 0.002277374267578125, 'loss_3': -15.999297142028809, 'loss_4': 2.9922375679016113, 'epoch': 5.91}
{'loss': 0.0469, 'grad_norm': 17.69038200378418, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.0391356386244297, 'loss_2': 0.00775146484375, 'loss_3': -16.015506744384766, 'loss_4': 2.991683006286621, 'epoch': 5.91}
{'loss': 0.0274, 'grad_norm': 7.362847805023193, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.021476613357663155, 'loss_2': 0.005893707275390625, 'loss_3': -15.963565826416016, 'loss_4': 3.550671100616455, 'epoch': 5.92}
{'loss': 0.0257, 'grad_norm': 10.388466835021973, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.021125463768839836, 'loss_2': 0.00458526611328125, 'loss_3': -16.208526611328125, 'loss_4': 2.907329797744751, 'epoch': 5.92}
{'loss': 0.0331, 'grad_norm': 9.329144477844238, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.028201831504702568, 'loss_2': 0.004871368408203125, 'loss_3': -15.907217025756836, 'loss_4': 3.6161231994628906, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 09:49:44,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:44,417 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:33<1:11:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:51,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01220676302909851, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.917, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006604790221899748, 'eval_loss_2': 0.005601972341537476, 'eval_loss_3': -18.255050659179688, 'eval_loss_4': 3.348113536834717, 'epoch': 5.93}
{'loss': 0.0395, 'grad_norm': 15.27292537689209, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.03203146904706955, 'loss_2': 0.00748443603515625, 'loss_3': -16.188880920410156, 'loss_4': 4.384913921356201, 'epoch': 5.94}
{'loss': 0.0228, 'grad_norm': 5.799651622772217, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.013146776705980301, 'loss_2': 0.009613037109375, 'loss_3': -16.2475528717041, 'loss_4': 3.589381694793701, 'epoch': 5.94}
{'loss': 0.0241, 'grad_norm': 10.791553497314453, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.021692898124456406, 'loss_2': 0.0023822784423828125, 'loss_3': -16.053911209106445, 'loss_4': 2.973194122314453, 'epoch': 5.95}
{'loss': 0.0471, 'grad_norm': 15.16406536102295, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.03167678043246269, 'loss_2': 0.015411376953125, 'loss_3': -16.128183364868164, 'loss_4': 3.724693775177002, 'epoch': 5.95}
{'loss': 0.0222, 'grad_norm': 7.821279048919678, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.017549974843859673, 'loss_2': 0.00467681884765625, 'loss_3': -16.050289154052734, 'loss_4': 2.8444502353668213, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 09:49:51,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:51,782 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:41<1:11:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:59,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011640533804893494, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.753, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0068799713626503944, 'eval_loss_2': 0.004760563373565674, 'eval_loss_3': -18.282848358154297, 'eval_loss_4': 3.3462445735931396, 'epoch': 5.96}
{'loss': 0.0201, 'grad_norm': 7.26418924331665, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.01978767290711403, 'loss_2': 0.000324249267578125, 'loss_3': -16.065532684326172, 'loss_4': 3.8505048751831055, 'epoch': 5.97}
{'loss': 0.0365, 'grad_norm': 9.702479362487793, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.034250132739543915, 'loss_2': 0.0022125244140625, 'loss_3': -16.311134338378906, 'loss_4': 3.470111846923828, 'epoch': 5.97}
{'loss': 0.02, 'grad_norm': 8.38165283203125, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.019066346809267998, 'loss_2': 0.0009403228759765625, 'loss_3': -16.022727966308594, 'loss_4': 3.627364158630371, 'epoch': 5.98}
{'loss': 0.0132, 'grad_norm': 5.436607360839844, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.012825077399611473, 'loss_2': 0.00035262107849121094, 'loss_3': -16.253986358642578, 'loss_4': 3.142481565475464, 'epoch': 5.98}
{'loss': 0.0307, 'grad_norm': 11.960243225097656, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.024674927815794945, 'loss_2': 0.0060272216796875, 'loss_3': -16.003925323486328, 'loss_4': 2.99507474899292, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 09:49:59,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:59,147 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:48<1:09:30,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 09:50:06,204 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01211270596832037, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.361, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007424741983413696, 'eval_loss_2': 0.004687964916229248, 'eval_loss_3': -18.29781723022461, 'eval_loss_4': 3.071568727493286, 'epoch': 5.99}
{'loss': 0.0331, 'grad_norm': 10.395588874816895, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.02580893784761429, 'loss_2': 0.00725555419921875, 'loss_3': -16.141056060791016, 'loss_4': 3.1088051795959473, 'epoch': 5.99}
{'loss': 0.0052, 'grad_norm': 5.912901878356934, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.0033454918302595615, 'loss_2': 0.001865386962890625, 'loss_3': -16.28216552734375, 'loss_4': 2.7005059719085693, 'epoch': 6.0}
{'loss': 0.0253, 'grad_norm': 10.012648582458496, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.02466115728020668, 'loss_2': 0.0006780624389648438, 'loss_3': -16.230417251586914, 'loss_4': 3.1927123069763184, 'epoch': 6.01}
{'loss': 0.0253, 'grad_norm': 9.002378463745117, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.02041972056031227, 'loss_2': 0.004901885986328125, 'loss_3': -16.265583038330078, 'loss_4': 3.1382784843444824, 'epoch': 6.01}
{'loss': 0.0188, 'grad_norm': 6.271845817565918, 'learning_rate': 2.4e-05, 'loss_1': 0.014787075109779835, 'loss_2': 0.0040435791015625, 'loss_3': -16.270383834838867, 'loss_4': 3.080531597137451, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 09:50:06,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:06,204 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [25:55<1:10:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:50:13,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011546526104211807, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.893, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007741544861346483, 'eval_loss_2': 0.0038049817085266113, 'eval_loss_3': -18.282512664794922, 'eval_loss_4': 2.993741273880005, 'epoch': 6.02}
{'loss': 0.02, 'grad_norm': 9.30072021484375, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.01917879655957222, 'loss_2': 0.0008592605590820312, 'loss_3': -15.99792766571045, 'loss_4': 2.984757423400879, 'epoch': 6.02}
{'loss': 0.0245, 'grad_norm': 8.99757194519043, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.02077731490135193, 'loss_2': 0.00376129150390625, 'loss_3': -16.12339973449707, 'loss_4': 3.582610607147217, 'epoch': 6.03}
{'loss': 0.0242, 'grad_norm': 7.176541805267334, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.018543586134910583, 'loss_2': 0.005645751953125, 'loss_3': -16.265605926513672, 'loss_4': 3.1872470378875732, 'epoch': 6.03}
{'loss': 0.0126, 'grad_norm': 5.264662265777588, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.010434029623866081, 'loss_2': 0.00215911865234375, 'loss_3': -16.094690322875977, 'loss_4': 2.932460308074951, 'epoch': 6.04}
{'loss': 0.023, 'grad_norm': 7.627463340759277, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.014926958829164505, 'loss_2': 0.008087158203125, 'loss_3': -16.05330467224121, 'loss_4': 2.9034996032714844, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 09:50:13,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:13,558 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:03<1:11:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:20,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015270753763616085, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.16, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010803564451634884, 'eval_loss_2': 0.004467189311981201, 'eval_loss_3': -18.25585174560547, 'eval_loss_4': 3.130380630493164, 'epoch': 6.05}
{'loss': 0.0186, 'grad_norm': 8.478599548339844, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.01396741159260273, 'loss_2': 0.004608154296875, 'loss_3': -15.816394805908203, 'loss_4': 3.2177724838256836, 'epoch': 6.05}
{'loss': 0.0351, 'grad_norm': 19.257099151611328, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.029580609872937202, 'loss_2': 0.00553131103515625, 'loss_3': -16.066843032836914, 'loss_4': 3.6262876987457275, 'epoch': 6.06}
{'loss': 0.0139, 'grad_norm': 6.520242214202881, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.01317379530519247, 'loss_2': 0.0007166862487792969, 'loss_3': -16.164926528930664, 'loss_4': 2.554159164428711, 'epoch': 6.06}
{'loss': 0.0177, 'grad_norm': 7.117751121520996, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.01767631433904171, 'loss_2': 6.657838821411133e-05, 'loss_3': -16.02753257751465, 'loss_4': 3.060985803604126, 'epoch': 6.07}
{'loss': 0.0316, 'grad_norm': 15.056211471557617, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.03147950395941734, 'loss_2': 8.58306884765625e-05, 'loss_3': -15.948151588439941, 'loss_4': 2.841076374053955, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 09:50:20,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:20,911 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:10<1:11:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:28,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012709777802228928, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.967, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008173746056854725, 'eval_loss_2': 0.004536032676696777, 'eval_loss_3': -18.223892211914062, 'eval_loss_4': 2.9788174629211426, 'epoch': 6.08}
{'loss': 0.0205, 'grad_norm': 6.597410678863525, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.011524193920195103, 'loss_2': 0.00897979736328125, 'loss_3': -16.076213836669922, 'loss_4': 2.5245020389556885, 'epoch': 6.08}
{'loss': 0.0291, 'grad_norm': 8.426897048950195, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.020883411169052124, 'loss_2': 0.00823974609375, 'loss_3': -15.976318359375, 'loss_4': 2.90291690826416, 'epoch': 6.09}
{'loss': 0.0192, 'grad_norm': 5.396483421325684, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.012104988098144531, 'loss_2': 0.00713348388671875, 'loss_3': -16.042213439941406, 'loss_4': 2.979475498199463, 'epoch': 6.09}
{'loss': 0.022, 'grad_norm': 12.21261978149414, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.017653299495577812, 'loss_2': 0.00433349609375, 'loss_3': -16.278522491455078, 'loss_4': 2.7817461490631104, 'epoch': 6.1}
{'loss': 0.0231, 'grad_norm': 10.562230110168457, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.020492956042289734, 'loss_2': 0.00263214111328125, 'loss_3': -16.218704223632812, 'loss_4': 2.4982028007507324, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 09:50:28,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:28,265 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:17<1:11:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:35,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01139825489372015, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.339, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008114693686366081, 'eval_loss_2': 0.003283560276031494, 'eval_loss_3': -18.216854095458984, 'eval_loss_4': 2.806788921356201, 'epoch': 6.1}
{'loss': 0.0131, 'grad_norm': 7.059954643249512, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.011925566010177135, 'loss_2': 0.001201629638671875, 'loss_3': -16.114776611328125, 'loss_4': 2.7969977855682373, 'epoch': 6.11}
{'loss': 0.0177, 'grad_norm': 7.993103981018066, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.015317250974476337, 'loss_2': 0.002361297607421875, 'loss_3': -15.959778785705566, 'loss_4': 2.401362895965576, 'epoch': 6.12}
{'loss': 0.0184, 'grad_norm': 5.98719596862793, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.012572778388857841, 'loss_2': 0.005802154541015625, 'loss_3': -16.02610969543457, 'loss_4': 2.8943066596984863, 'epoch': 6.12}
{'loss': 0.0277, 'grad_norm': 9.93643856048584, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.0225260928273201, 'loss_2': 0.005126953125, 'loss_3': -16.277971267700195, 'loss_4': 3.266993284225464, 'epoch': 6.13}
{'loss': 0.045, 'grad_norm': 13.750606536865234, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.03860427811741829, 'loss_2': 0.00640106201171875, 'loss_3': -16.157333374023438, 'loss_4': 3.216238021850586, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 09:50:35,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:35,617 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:25<1:11:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:42,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01098866667598486, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008401943370699883, 'eval_loss_2': 0.0025867223739624023, 'eval_loss_3': -18.20684814453125, 'eval_loss_4': 3.034759521484375, 'epoch': 6.13}
{'loss': 0.0136, 'grad_norm': 6.621148586273193, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.010402307845652103, 'loss_2': 0.0032196044921875, 'loss_3': -16.18280029296875, 'loss_4': 3.1081748008728027, 'epoch': 6.14}
{'loss': 0.0149, 'grad_norm': 5.933986663818359, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.011667132377624512, 'loss_2': 0.0032253265380859375, 'loss_3': -16.233016967773438, 'loss_4': 3.287496566772461, 'epoch': 6.15}
{'loss': 0.0106, 'grad_norm': 4.72759485244751, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.007477093022316694, 'loss_2': 0.0031585693359375, 'loss_3': -16.18138885498047, 'loss_4': 2.70680570602417, 'epoch': 6.15}
{'loss': 0.0189, 'grad_norm': 6.168187141418457, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.011445513926446438, 'loss_2': 0.0074310302734375, 'loss_3': -16.278182983398438, 'loss_4': 3.2314651012420654, 'epoch': 6.16}
{'loss': 0.0451, 'grad_norm': 16.45831298828125, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.035397887229919434, 'loss_2': 0.0096588134765625, 'loss_3': -15.961298942565918, 'loss_4': 2.99240779876709, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 09:50:42,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:42,986 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:32<1:10:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:50,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017956681549549103, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.311, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.009169645607471466, 'eval_loss_2': 0.008787035942077637, 'eval_loss_3': -18.221324920654297, 'eval_loss_4': 3.1603238582611084, 'epoch': 6.16}
{'loss': 0.0309, 'grad_norm': 10.879254341125488, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.026702307164669037, 'loss_2': 0.00420379638671875, 'loss_3': -16.18402671813965, 'loss_4': 3.439971923828125, 'epoch': 6.17}
{'loss': 0.0367, 'grad_norm': 10.347685813903809, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.024809138849377632, 'loss_2': 0.011932373046875, 'loss_3': -16.075403213500977, 'loss_4': 3.268433094024658, 'epoch': 6.17}
{'loss': 0.0556, 'grad_norm': 18.056669235229492, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.05093203857541084, 'loss_2': 0.00463104248046875, 'loss_3': -15.991235733032227, 'loss_4': 2.8709025382995605, 'epoch': 6.18}
{'loss': 0.0467, 'grad_norm': 15.991142272949219, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.036993805319070816, 'loss_2': 0.00970458984375, 'loss_3': -16.073253631591797, 'loss_4': 3.745993137359619, 'epoch': 6.19}
{'loss': 0.0292, 'grad_norm': 10.193397521972656, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.027437249198555946, 'loss_2': 0.001712799072265625, 'loss_3': -15.999695777893066, 'loss_4': 3.433894634246826, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 09:50:50,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:50,348 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:39<1:10:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:57,705 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016185712069272995, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.088, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009652401320636272, 'eval_loss_2': 0.006533309817314148, 'eval_loss_3': -18.206382751464844, 'eval_loss_4': 3.224644184112549, 'epoch': 6.19}
{'loss': 0.0274, 'grad_norm': 17.3115177154541, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.025652533397078514, 'loss_2': 0.0017681121826171875, 'loss_3': -16.203475952148438, 'loss_4': 3.626052141189575, 'epoch': 6.2}
{'loss': 0.0186, 'grad_norm': 6.271781921386719, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.01724236086010933, 'loss_2': 0.0013427734375, 'loss_3': -16.05411720275879, 'loss_4': 3.2559971809387207, 'epoch': 6.2}
{'loss': 0.0114, 'grad_norm': 5.445425510406494, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.009706326760351658, 'loss_2': 0.0016870498657226562, 'loss_3': -16.149566650390625, 'loss_4': 3.1761958599090576, 'epoch': 6.21}
{'loss': 0.0136, 'grad_norm': 5.7926225662231445, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.010569704696536064, 'loss_2': 0.00298309326171875, 'loss_3': -16.124990463256836, 'loss_4': 3.2141356468200684, 'epoch': 6.22}
{'loss': 0.0162, 'grad_norm': 5.4119133949279785, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.00916315708309412, 'loss_2': 0.006988525390625, 'loss_3': -16.089210510253906, 'loss_4': 3.6796844005584717, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 09:50:57,705 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:57,705 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:47<1:10:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:05,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012382104992866516, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.724, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009281769394874573, 'eval_loss_2': 0.0031003355979919434, 'eval_loss_3': -18.223360061645508, 'eval_loss_4': 3.450197696685791, 'epoch': 6.22}
{'loss': 0.0169, 'grad_norm': 5.405126571655273, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.012189810164272785, 'loss_2': 0.004680633544921875, 'loss_3': -16.098894119262695, 'loss_4': 2.9600839614868164, 'epoch': 6.23}
{'loss': 0.0541, 'grad_norm': 28.241994857788086, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.04778464883565903, 'loss_2': 0.006275177001953125, 'loss_3': -16.062904357910156, 'loss_4': 3.228600025177002, 'epoch': 6.23}
{'loss': 0.0161, 'grad_norm': 5.527000427246094, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.01217159815132618, 'loss_2': 0.00394439697265625, 'loss_3': -16.18166160583496, 'loss_4': 3.3071413040161133, 'epoch': 6.24}
{'loss': 0.0365, 'grad_norm': 10.705076217651367, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.029908768832683563, 'loss_2': 0.00662994384765625, 'loss_3': -16.053876876831055, 'loss_4': 3.4777417182922363, 'epoch': 6.24}
{'loss': 0.0242, 'grad_norm': 7.172598838806152, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.016471048817038536, 'loss_2': 0.0077667236328125, 'loss_3': -16.334880828857422, 'loss_4': 3.6776838302612305, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 09:51:05,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:05,067 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [26:54<1:10:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:12,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0157267265021801, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01179563533514738, 'eval_loss_2': 0.003931090235710144, 'eval_loss_3': -18.291963577270508, 'eval_loss_4': 3.915698528289795, 'epoch': 6.25}
{'loss': 0.0802, 'grad_norm': 27.570735931396484, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.07564758509397507, 'loss_2': 0.004573822021484375, 'loss_3': -16.038326263427734, 'loss_4': 4.447964668273926, 'epoch': 6.26}
{'loss': 0.0443, 'grad_norm': 11.505558013916016, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.03437929227948189, 'loss_2': 0.00992584228515625, 'loss_3': -16.056499481201172, 'loss_4': 3.5606346130371094, 'epoch': 6.26}
{'loss': 0.0553, 'grad_norm': 15.868427276611328, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.05142322927713394, 'loss_2': 0.003925323486328125, 'loss_3': -16.18569564819336, 'loss_4': 4.486513614654541, 'epoch': 6.27}
{'loss': 0.0268, 'grad_norm': 7.305579662322998, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.022969914600253105, 'loss_2': 0.003849029541015625, 'loss_3': -16.159027099609375, 'loss_4': 3.7689056396484375, 'epoch': 6.27}
{'loss': 0.0211, 'grad_norm': 6.232954025268555, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.01888049580156803, 'loss_2': 0.002216339111328125, 'loss_3': -16.213727951049805, 'loss_4': 3.933336019515991, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 09:51:12,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:12,431 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:01<1:10:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:19,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014572663232684135, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009682592935860157, 'eval_loss_2': 0.004890069365501404, 'eval_loss_3': -18.33820343017578, 'eval_loss_4': 3.686835289001465, 'epoch': 6.28}
{'loss': 0.0294, 'grad_norm': 10.25454330444336, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.02822921797633171, 'loss_2': 0.001140594482421875, 'loss_3': -16.353736877441406, 'loss_4': 4.069326400756836, 'epoch': 6.28}
{'loss': 0.0387, 'grad_norm': 10.296056747436523, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.030678164213895798, 'loss_2': 0.00799560546875, 'loss_3': -16.13564682006836, 'loss_4': 3.8795435428619385, 'epoch': 6.29}
{'loss': 0.034, 'grad_norm': 9.694405555725098, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.028387969359755516, 'loss_2': 0.005596160888671875, 'loss_3': -16.1689395904541, 'loss_4': 4.563942909240723, 'epoch': 6.3}
{'loss': 0.0294, 'grad_norm': 8.21630859375, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.027394941076636314, 'loss_2': 0.0019683837890625, 'loss_3': -16.039772033691406, 'loss_4': 4.23103141784668, 'epoch': 6.3}
{'loss': 0.0386, 'grad_norm': 10.388684272766113, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.03253632038831711, 'loss_2': 0.00609588623046875, 'loss_3': -16.15723419189453, 'loss_4': 4.187745571136475, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 09:51:19,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:19,786 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:09<1:10:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:27,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012395741418004036, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.621, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008268089964985847, 'eval_loss_2': 0.0041276514530181885, 'eval_loss_3': -18.315021514892578, 'eval_loss_4': 3.6971282958984375, 'epoch': 6.31}
{'loss': 0.0556, 'grad_norm': 29.682167053222656, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.05221133306622505, 'loss_2': 0.0034160614013671875, 'loss_3': -16.203367233276367, 'loss_4': 4.722504138946533, 'epoch': 6.31}
{'loss': 0.0271, 'grad_norm': 10.865717887878418, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.026543185114860535, 'loss_2': 0.0005950927734375, 'loss_3': -16.251691818237305, 'loss_4': 4.326167106628418, 'epoch': 6.32}
{'loss': 0.0272, 'grad_norm': 7.96475076675415, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.025942794978618622, 'loss_2': 0.0012645721435546875, 'loss_3': -15.99400806427002, 'loss_4': 4.409452438354492, 'epoch': 6.33}
{'loss': 0.0429, 'grad_norm': 19.020538330078125, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.04090720787644386, 'loss_2': 0.0019626617431640625, 'loss_3': -16.134946823120117, 'loss_4': 4.127652168273926, 'epoch': 6.33}
{'loss': 0.021, 'grad_norm': 7.349151134490967, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.01614299975335598, 'loss_2': 0.00484466552734375, 'loss_3': -15.941755294799805, 'loss_4': 3.7950353622436523, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 09:51:27,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:27,149 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:16<1:10:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:34,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010249936953186989, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.85, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007071102503687143, 'eval_loss_2': 0.003178834915161133, 'eval_loss_3': -18.324220657348633, 'eval_loss_4': 3.3270316123962402, 'epoch': 6.34}
{'loss': 0.0219, 'grad_norm': 10.053019523620605, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.019400864839553833, 'loss_2': 0.002490997314453125, 'loss_3': -16.18317413330078, 'loss_4': 3.5501327514648438, 'epoch': 6.34}
{'loss': 0.0096, 'grad_norm': 5.932696342468262, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.00793923158198595, 'loss_2': 0.00164031982421875, 'loss_3': -16.373455047607422, 'loss_4': 3.1788949966430664, 'epoch': 6.35}
{'loss': 0.0221, 'grad_norm': 9.41439437866211, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.020545631647109985, 'loss_2': 0.0015134811401367188, 'loss_3': -15.96927261352539, 'loss_4': 3.4627914428710938, 'epoch': 6.35}
{'loss': 0.0108, 'grad_norm': 5.546114444732666, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.010304809547960758, 'loss_2': 0.0004782676696777344, 'loss_3': -16.058727264404297, 'loss_4': 3.133089542388916, 'epoch': 6.36}
{'loss': 0.0165, 'grad_norm': 9.649752616882324, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.016212061047554016, 'loss_2': 0.00031948089599609375, 'loss_3': -16.079774856567383, 'loss_4': 3.171041488647461, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 09:51:34,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:34,505 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:24<1:10:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:41,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012440420687198639, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.183, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007040776778012514, 'eval_loss_2': 0.005399644374847412, 'eval_loss_3': -18.28338623046875, 'eval_loss_4': 2.746770143508911, 'epoch': 6.37}
{'loss': 0.0318, 'grad_norm': 12.818182945251465, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.025587620213627815, 'loss_2': 0.006198883056640625, 'loss_3': -15.931607246398926, 'loss_4': 2.8889031410217285, 'epoch': 6.37}
{'loss': 0.0127, 'grad_norm': 5.668161869049072, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.009082627482712269, 'loss_2': 0.003631591796875, 'loss_3': -16.212665557861328, 'loss_4': 2.532285451889038, 'epoch': 6.38}
{'loss': 0.0206, 'grad_norm': 8.189543724060059, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.011750356294214725, 'loss_2': 0.00882720947265625, 'loss_3': -15.95740795135498, 'loss_4': 2.522414207458496, 'epoch': 6.38}
{'loss': 0.0289, 'grad_norm': 21.064905166625977, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.027231108397245407, 'loss_2': 0.0016498565673828125, 'loss_3': -15.903098106384277, 'loss_4': 1.3518199920654297, 'epoch': 6.39}
{'loss': 0.0177, 'grad_norm': 6.760381698608398, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.012417460791766644, 'loss_2': 0.00531005859375, 'loss_3': -16.134660720825195, 'loss_4': 2.326577663421631, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 09:51:41,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:41,860 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:31<1:10:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:49,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010183672420680523, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.736, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00772410212084651, 'eval_loss_2': 0.0024595707654953003, 'eval_loss_3': -18.242773056030273, 'eval_loss_4': 2.1791510581970215, 'epoch': 6.4}
{'loss': 0.037, 'grad_norm': 16.993804931640625, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.030399443581700325, 'loss_2': 0.00659942626953125, 'loss_3': -16.032936096191406, 'loss_4': 2.6401686668395996, 'epoch': 6.4}
{'loss': 0.03, 'grad_norm': 11.270398139953613, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.026653733104467392, 'loss_2': 0.0033206939697265625, 'loss_3': -16.028274536132812, 'loss_4': 2.033778429031372, 'epoch': 6.41}
{'loss': 0.0248, 'grad_norm': 8.882254600524902, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.022252310067415237, 'loss_2': 0.002529144287109375, 'loss_3': -16.010114669799805, 'loss_4': 2.839756965637207, 'epoch': 6.41}
{'loss': 0.0184, 'grad_norm': 5.474094867706299, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.012252438813447952, 'loss_2': 0.0061187744140625, 'loss_3': -16.131267547607422, 'loss_4': 2.650022029876709, 'epoch': 6.42}
{'loss': 0.0199, 'grad_norm': 5.857486248016357, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.016463039442896843, 'loss_2': 0.003467559814453125, 'loss_3': -15.825424194335938, 'loss_4': 1.8975865840911865, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 09:51:49,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:49,224 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:38<1:10:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:56,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010785216465592384, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.744, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007817047648131847, 'eval_loss_2': 0.0029681697487831116, 'eval_loss_3': -18.238948822021484, 'eval_loss_4': 1.5769926309585571, 'epoch': 6.42}
{'loss': 0.0407, 'grad_norm': 13.566235542297363, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.03407137095928192, 'loss_2': 0.00666046142578125, 'loss_3': -15.9553861618042, 'loss_4': 2.085949420928955, 'epoch': 6.43}
{'loss': 0.0191, 'grad_norm': 8.65694808959961, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.017239021137356758, 'loss_2': 0.0019102096557617188, 'loss_3': -16.13050079345703, 'loss_4': 1.66767156124115, 'epoch': 6.44}
{'loss': 0.0282, 'grad_norm': 8.702614784240723, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.026423601433634758, 'loss_2': 0.0018177032470703125, 'loss_3': -16.01371192932129, 'loss_4': 2.0224592685699463, 'epoch': 6.44}
{'loss': 0.0301, 'grad_norm': 9.525679588317871, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.022758200764656067, 'loss_2': 0.007293701171875, 'loss_3': -15.95352554321289, 'loss_4': 1.6561815738677979, 'epoch': 6.45}
{'loss': 0.0132, 'grad_norm': 6.00765323638916, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.011884939856827259, 'loss_2': 0.0012712478637695312, 'loss_3': -16.309181213378906, 'loss_4': 1.5659785270690918, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 09:51:56,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:56,586 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:46<1:10:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:03,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010223738849163055, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00783858448266983, 'eval_loss_2': 0.002385154366493225, 'eval_loss_3': -18.238929748535156, 'eval_loss_4': 1.469454288482666, 'epoch': 6.45}
{'loss': 0.024, 'grad_norm': 10.184439659118652, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.02280881628394127, 'loss_2': 0.0011882781982421875, 'loss_3': -16.218935012817383, 'loss_4': 1.8720293045043945, 'epoch': 6.46}
{'loss': 0.028, 'grad_norm': 7.676548480987549, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.019949238747358322, 'loss_2': 0.008087158203125, 'loss_3': -16.127161026000977, 'loss_4': 1.6688767671585083, 'epoch': 6.47}
{'loss': 0.0376, 'grad_norm': 12.375426292419434, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.03423915430903435, 'loss_2': 0.0034027099609375, 'loss_3': -16.069137573242188, 'loss_4': 1.7342824935913086, 'epoch': 6.47}
{'loss': 0.0235, 'grad_norm': 9.445331573486328, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.021517688408493996, 'loss_2': 0.00197601318359375, 'loss_3': -16.101499557495117, 'loss_4': 1.6995692253112793, 'epoch': 6.48}
{'loss': 0.0428, 'grad_norm': 10.849864959716797, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.03481414541602135, 'loss_2': 0.00799560546875, 'loss_3': -16.004446029663086, 'loss_4': 1.9377702474594116, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 09:52:03,943 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:03,943 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [27:53<1:09:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:11,305 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01562264934182167, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.392, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0076601835899055, 'eval_loss_2': 0.007962465286254883, 'eval_loss_3': -18.117399215698242, 'eval_loss_4': 1.6206306219100952, 'epoch': 6.48}
{'loss': 0.0234, 'grad_norm': 6.050711631774902, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.013293903321027756, 'loss_2': 0.01015472412109375, 'loss_3': -16.265207290649414, 'loss_4': 1.621260404586792, 'epoch': 6.49}
{'loss': 0.0321, 'grad_norm': 7.372260570526123, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.018235068768262863, 'loss_2': 0.0138397216796875, 'loss_3': -16.061710357666016, 'loss_4': 2.3174571990966797, 'epoch': 6.49}
{'loss': 0.0442, 'grad_norm': 11.03954029083252, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.029122216627001762, 'loss_2': 0.015106201171875, 'loss_3': -15.689424514770508, 'loss_4': 1.7828741073608398, 'epoch': 6.5}
{'loss': 0.0364, 'grad_norm': 12.627378463745117, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.031175509095191956, 'loss_2': 0.005218505859375, 'loss_3': -16.04240608215332, 'loss_4': 2.231689691543579, 'epoch': 6.51}
{'loss': 0.0202, 'grad_norm': 6.6295037269592285, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.017823416739702225, 'loss_2': 0.0024204254150390625, 'loss_3': -16.186538696289062, 'loss_4': 1.9886976480484009, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 09:52:11,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:11,305 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:00<1:09:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:18,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00952563714236021, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006838405970484018, 'eval_loss_2': 0.002687230706214905, 'eval_loss_3': -18.052696228027344, 'eval_loss_4': 2.053659200668335, 'epoch': 6.51}
{'loss': 0.0182, 'grad_norm': 5.358683109283447, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.011583132669329643, 'loss_2': 0.006626129150390625, 'loss_3': -16.187118530273438, 'loss_4': 2.506204128265381, 'epoch': 6.52}
{'loss': 0.0302, 'grad_norm': 9.306060791015625, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.02500361017882824, 'loss_2': 0.00518035888671875, 'loss_3': -16.155508041381836, 'loss_4': 2.5911061763763428, 'epoch': 6.52}
{'loss': 0.0301, 'grad_norm': 6.927343368530273, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.023207522928714752, 'loss_2': 0.00684356689453125, 'loss_3': -16.170589447021484, 'loss_4': 2.3655343055725098, 'epoch': 6.53}
{'loss': 0.0448, 'grad_norm': 10.145626068115234, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.03526592254638672, 'loss_2': 0.009521484375, 'loss_3': -16.111522674560547, 'loss_4': 2.6896681785583496, 'epoch': 6.53}
{'loss': 0.0296, 'grad_norm': 10.77363395690918, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.022572532296180725, 'loss_2': 0.00701141357421875, 'loss_3': -15.849235534667969, 'loss_4': 1.9376106262207031, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 09:52:18,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:18,666 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:08<1:09:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:26,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018672097474336624, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008553612045943737, 'eval_loss_2': 0.010118484497070312, 'eval_loss_3': -17.992868423461914, 'eval_loss_4': 2.1857573986053467, 'epoch': 6.54}
{'loss': 0.0244, 'grad_norm': 5.882274150848389, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.015458747744560242, 'loss_2': 0.00897979736328125, 'loss_3': -16.097230911254883, 'loss_4': 2.3262393474578857, 'epoch': 6.55}
{'loss': 0.0534, 'grad_norm': 17.594335556030273, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.040270306169986725, 'loss_2': 0.013153076171875, 'loss_3': -16.07993507385254, 'loss_4': 2.623764753341675, 'epoch': 6.55}
{'loss': 0.0366, 'grad_norm': 14.206344604492188, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.029779119417071342, 'loss_2': 0.00685882568359375, 'loss_3': -16.02402114868164, 'loss_4': 2.382997989654541, 'epoch': 6.56}
{'loss': 0.0375, 'grad_norm': 7.562558650970459, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.02010597661137581, 'loss_2': 0.017364501953125, 'loss_3': -16.081079483032227, 'loss_4': 2.620497226715088, 'epoch': 6.56}
{'loss': 0.0444, 'grad_norm': 14.56212043762207, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.037310246378183365, 'loss_2': 0.00713348388671875, 'loss_3': -16.23630142211914, 'loss_4': 2.425570487976074, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 09:52:26,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:26,017 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:15<1:09:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:33,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011641266755759716, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008085670880973339, 'eval_loss_2': 0.003555595874786377, 'eval_loss_3': -18.029090881347656, 'eval_loss_4': 2.198638439178467, 'epoch': 6.57}
{'loss': 0.0345, 'grad_norm': 10.31287670135498, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.0316532626748085, 'loss_2': 0.002826690673828125, 'loss_3': -16.024681091308594, 'loss_4': 2.3590526580810547, 'epoch': 6.58}
{'loss': 0.0379, 'grad_norm': 16.658870697021484, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.036021217703819275, 'loss_2': 0.0019073486328125, 'loss_3': -16.101308822631836, 'loss_4': 2.410346746444702, 'epoch': 6.58}
{'loss': 0.0214, 'grad_norm': 8.394206047058105, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.019568288698792458, 'loss_2': 0.00182342529296875, 'loss_3': -16.21407127380371, 'loss_4': 2.2651803493499756, 'epoch': 6.59}
{'loss': 0.0328, 'grad_norm': 12.693658828735352, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.028280241414904594, 'loss_2': 0.00455474853515625, 'loss_3': -15.993192672729492, 'loss_4': 2.4671807289123535, 'epoch': 6.59}
{'loss': 0.0297, 'grad_norm': 8.52308464050293, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.026275115087628365, 'loss_2': 0.0034465789794921875, 'loss_3': -16.181686401367188, 'loss_4': 2.2617294788360596, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 09:52:33,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:33,371 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:22<1:09:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:40,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014465168118476868, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.143, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009814172983169556, 'eval_loss_2': 0.004650995135307312, 'eval_loss_3': -17.952186584472656, 'eval_loss_4': 2.1404013633728027, 'epoch': 6.6}
{'loss': 0.0207, 'grad_norm': 10.647921562194824, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.01782727800309658, 'loss_2': 0.002887725830078125, 'loss_3': -16.327157974243164, 'loss_4': 2.0565402507781982, 'epoch': 6.6}
{'loss': 0.0271, 'grad_norm': 8.998668670654297, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.022595953196287155, 'loss_2': 0.0045318603515625, 'loss_3': -16.018905639648438, 'loss_4': 2.661207675933838, 'epoch': 6.61}
{'loss': 0.0189, 'grad_norm': 6.015125274658203, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.015315314754843712, 'loss_2': 0.003631591796875, 'loss_3': -16.22602653503418, 'loss_4': 2.4389634132385254, 'epoch': 6.62}
{'loss': 0.0248, 'grad_norm': 6.666965484619141, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.018362104892730713, 'loss_2': 0.0064849853515625, 'loss_3': -16.00153350830078, 'loss_4': 2.3632450103759766, 'epoch': 6.62}
{'loss': 0.0422, 'grad_norm': 12.044605255126953, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.03819109871983528, 'loss_2': 0.0039825439453125, 'loss_3': -16.088943481445312, 'loss_4': 2.244790554046631, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 09:52:40,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:40,722 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:30<1:09:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:48,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013506799936294556, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.861, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009536921977996826, 'eval_loss_2': 0.0039698779582977295, 'eval_loss_3': -18.086071014404297, 'eval_loss_4': 2.132460832595825, 'epoch': 6.63}
{'loss': 0.0517, 'grad_norm': 14.745417594909668, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.04387538880109787, 'loss_2': 0.007785797119140625, 'loss_3': -16.183135986328125, 'loss_4': 2.149256706237793, 'epoch': 6.63}
{'loss': 0.0301, 'grad_norm': 8.875496864318848, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.026016389951109886, 'loss_2': 0.00412750244140625, 'loss_3': -16.166528701782227, 'loss_4': 2.5234742164611816, 'epoch': 6.64}
{'loss': 0.0377, 'grad_norm': 11.154437065124512, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.02923872321844101, 'loss_2': 0.00850677490234375, 'loss_3': -16.407150268554688, 'loss_4': 2.29549241065979, 'epoch': 6.65}
{'loss': 0.0448, 'grad_norm': 23.703081130981445, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.039132121950387955, 'loss_2': 0.005695343017578125, 'loss_3': -15.94827651977539, 'loss_4': 1.7076358795166016, 'epoch': 6.65}
{'loss': 0.0425, 'grad_norm': 16.375303268432617, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.03674590215086937, 'loss_2': 0.005741119384765625, 'loss_3': -16.29154396057129, 'loss_4': 2.460550308227539, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 09:52:48,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:48,081 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:37<1:09:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:55,443 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012178444303572178, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.174, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.008483343757689, 'eval_loss_2': 0.0036951005458831787, 'eval_loss_3': -18.16846466064453, 'eval_loss_4': 1.9428633451461792, 'epoch': 6.66}
{'loss': 0.0293, 'grad_norm': 9.423006057739258, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.0210763830691576, 'loss_2': 0.00824737548828125, 'loss_3': -16.312509536743164, 'loss_4': 1.9597220420837402, 'epoch': 6.66}
{'loss': 0.0164, 'grad_norm': 6.467269420623779, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.016280507668852806, 'loss_2': 0.00012302398681640625, 'loss_3': -16.00418472290039, 'loss_4': 1.8538740873336792, 'epoch': 6.67}
{'loss': 0.0205, 'grad_norm': 8.206786155700684, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.01770213060081005, 'loss_2': 0.0027751922607421875, 'loss_3': -16.32008171081543, 'loss_4': 2.3397154808044434, 'epoch': 6.67}
{'loss': 0.0358, 'grad_norm': 24.011409759521484, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.030031513422727585, 'loss_2': 0.00577545166015625, 'loss_3': -16.168132781982422, 'loss_4': 2.547260046005249, 'epoch': 6.68}
{'loss': 0.029, 'grad_norm': 7.828155517578125, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.019707869738340378, 'loss_2': 0.0093231201171875, 'loss_3': -16.176048278808594, 'loss_4': 2.1874256134033203, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 09:52:55,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:55,443 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:44<1:09:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:02,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009822669439017773, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.167, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006558645516633987, 'eval_loss_2': 0.00326402485370636, 'eval_loss_3': -18.218814849853516, 'eval_loss_4': 1.9027960300445557, 'epoch': 6.69}
{'loss': 0.0279, 'grad_norm': 10.289904594421387, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.026108890771865845, 'loss_2': 0.0018310546875, 'loss_3': -16.209318161010742, 'loss_4': 2.902376174926758, 'epoch': 6.69}
{'loss': 0.0763, 'grad_norm': 27.312450408935547, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.07158558815717697, 'loss_2': 0.004741668701171875, 'loss_3': -16.053756713867188, 'loss_4': 2.4440040588378906, 'epoch': 6.7}
{'loss': 0.0226, 'grad_norm': 7.62280797958374, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.021999048069119453, 'loss_2': 0.0006103515625, 'loss_3': -16.22406578063965, 'loss_4': 1.3602559566497803, 'epoch': 6.7}
{'loss': 0.0165, 'grad_norm': 5.123457908630371, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.011461588554084301, 'loss_2': 0.005046844482421875, 'loss_3': -16.286739349365234, 'loss_4': 1.7554781436920166, 'epoch': 6.71}
{'loss': 0.0113, 'grad_norm': 5.648062229156494, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.010561092756688595, 'loss_2': 0.0007257461547851562, 'loss_3': -16.19671630859375, 'loss_4': 1.9914799928665161, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 09:53:02,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:02,793 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [28:52<1:09:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:10,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013364080339670181, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006589685566723347, 'eval_loss_2': 0.006774395704269409, 'eval_loss_3': -18.255691528320312, 'eval_loss_4': 2.0091748237609863, 'epoch': 6.72}
{'loss': 0.0292, 'grad_norm': 7.504411697387695, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.01777704432606697, 'loss_2': 0.0114593505859375, 'loss_3': -16.20942497253418, 'loss_4': 2.2291343212127686, 'epoch': 6.72}
{'loss': 0.0174, 'grad_norm': 6.2569169998168945, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.009050323627889156, 'loss_2': 0.0083465576171875, 'loss_3': -16.288558959960938, 'loss_4': 2.265864849090576, 'epoch': 6.73}
{'loss': 0.0394, 'grad_norm': 11.604329109191895, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.032996147871017456, 'loss_2': 0.0063629150390625, 'loss_3': -16.232275009155273, 'loss_4': 2.141329288482666, 'epoch': 6.73}
{'loss': 0.0438, 'grad_norm': 11.565211296081543, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.03622906282544136, 'loss_2': 0.00757598876953125, 'loss_3': -16.013046264648438, 'loss_4': 2.7408106327056885, 'epoch': 6.74}
{'loss': 0.0318, 'grad_norm': 10.912665367126465, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.02630067616701126, 'loss_2': 0.00554656982421875, 'loss_3': -16.329965591430664, 'loss_4': 3.0967655181884766, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 09:53:10,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:10,139 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [28:59<1:09:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:17,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01444901991635561, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.122, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007534164935350418, 'eval_loss_2': 0.006914854049682617, 'eval_loss_3': -18.30787467956543, 'eval_loss_4': 2.3074984550476074, 'epoch': 6.74}
{'loss': 0.0193, 'grad_norm': 5.7168965339660645, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.01721077226102352, 'loss_2': 0.00208282470703125, 'loss_3': -16.361724853515625, 'loss_4': 2.769254446029663, 'epoch': 6.75}
{'loss': 0.0202, 'grad_norm': 6.290767192840576, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.017180785536766052, 'loss_2': 0.002986907958984375, 'loss_3': -16.167255401611328, 'loss_4': 2.454524040222168, 'epoch': 6.76}
{'loss': 0.0234, 'grad_norm': 8.678902626037598, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.02149798721075058, 'loss_2': 0.00193023681640625, 'loss_3': -16.098175048828125, 'loss_4': 1.9977169036865234, 'epoch': 6.76}
{'loss': 0.0161, 'grad_norm': 6.333035469055176, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.013531461358070374, 'loss_2': 0.002521514892578125, 'loss_3': -16.158414840698242, 'loss_4': 2.66737699508667, 'epoch': 6.77}
{'loss': 0.0179, 'grad_norm': 6.796722412109375, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.012348138727247715, 'loss_2': 0.005596160888671875, 'loss_3': -16.270631790161133, 'loss_4': 2.1539909839630127, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 09:53:17,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:17,490 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:07<1:09:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:24,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0128675801679492, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.942, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00919292401522398, 'eval_loss_2': 0.0036746561527252197, 'eval_loss_3': -18.347267150878906, 'eval_loss_4': 2.617182731628418, 'epoch': 6.77}
{'loss': 0.032, 'grad_norm': 13.672534942626953, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.03146890178322792, 'loss_2': 0.0005125999450683594, 'loss_3': -16.354541778564453, 'loss_4': 2.4796857833862305, 'epoch': 6.78}
{'loss': 0.014, 'grad_norm': 5.116058349609375, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.009970484301447868, 'loss_2': 0.00402069091796875, 'loss_3': -16.378210067749023, 'loss_4': 2.80196475982666, 'epoch': 6.78}
{'loss': 0.0233, 'grad_norm': 8.274839401245117, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.021433163434267044, 'loss_2': 0.0018434524536132812, 'loss_3': -16.253231048583984, 'loss_4': 3.3713231086730957, 'epoch': 6.79}
{'loss': 0.0228, 'grad_norm': 8.435185432434082, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.01996476761996746, 'loss_2': 0.002788543701171875, 'loss_3': -16.300189971923828, 'loss_4': 2.783452033996582, 'epoch': 6.8}
{'loss': 0.0208, 'grad_norm': 7.5806074142456055, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.016741624101996422, 'loss_2': 0.0041046142578125, 'loss_3': -16.414997100830078, 'loss_4': 3.1616439819335938, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 09:53:24,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:24,858 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:14<1:09:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:32,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013556929305195808, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.409, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.00999185536056757, 'eval_loss_2': 0.003565073013305664, 'eval_loss_3': -18.342437744140625, 'eval_loss_4': 3.0929903984069824, 'epoch': 6.8}
{'loss': 0.0143, 'grad_norm': 5.623409271240234, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.012518376111984253, 'loss_2': 0.0018062591552734375, 'loss_3': -16.3175048828125, 'loss_4': 3.4193458557128906, 'epoch': 6.81}
{'loss': 0.027, 'grad_norm': 6.154306888580322, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.01859491877257824, 'loss_2': 0.0084381103515625, 'loss_3': -16.333654403686523, 'loss_4': 3.0656683444976807, 'epoch': 6.81}
{'loss': 0.0318, 'grad_norm': 7.767582416534424, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.022490033879876137, 'loss_2': 0.00931549072265625, 'loss_3': -16.296634674072266, 'loss_4': 3.5716702938079834, 'epoch': 6.82}
{'loss': 0.0301, 'grad_norm': 10.68925952911377, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.024711135774850845, 'loss_2': 0.0054168701171875, 'loss_3': -16.316696166992188, 'loss_4': 3.276491641998291, 'epoch': 6.83}
{'loss': 0.0212, 'grad_norm': 6.729180812835693, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.01881292462348938, 'loss_2': 0.00240325927734375, 'loss_3': -16.317663192749023, 'loss_4': 3.226228952407837, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 09:53:32,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:32,227 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:21<1:08:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:39,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013629700057208538, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.449, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009831035509705544, 'eval_loss_2': 0.00379866361618042, 'eval_loss_3': -18.362430572509766, 'eval_loss_4': 3.2471556663513184, 'epoch': 6.83}
{'loss': 0.0263, 'grad_norm': 7.212060451507568, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.025335580110549927, 'loss_2': 0.0009889602661132812, 'loss_3': -16.424070358276367, 'loss_4': 3.7890846729278564, 'epoch': 6.84}
{'loss': 0.0215, 'grad_norm': 6.163649559020996, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.016505949199199677, 'loss_2': 0.004970550537109375, 'loss_3': -16.249061584472656, 'loss_4': 3.2491559982299805, 'epoch': 6.84}
{'loss': 0.0364, 'grad_norm': 8.88190746307373, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.032529011368751526, 'loss_2': 0.003849029541015625, 'loss_3': -16.279769897460938, 'loss_4': 4.176816940307617, 'epoch': 6.85}
{'loss': 0.0428, 'grad_norm': 14.491156578063965, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.03756054863333702, 'loss_2': 0.00521087646484375, 'loss_3': -16.287446975708008, 'loss_4': 3.0732827186584473, 'epoch': 6.85}
{'loss': 0.0224, 'grad_norm': 7.021972179412842, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.016165606677532196, 'loss_2': 0.0062408447265625, 'loss_3': -16.475954055786133, 'loss_4': 3.241912841796875, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 09:53:39,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:39,573 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:29<1:08:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:46,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015377553179860115, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011776914820075035, 'eval_loss_2': 0.00360063835978508, 'eval_loss_3': -18.300329208374023, 'eval_loss_4': 3.125537633895874, 'epoch': 6.86}
{'loss': 0.041, 'grad_norm': 15.229778289794922, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.03710153326392174, 'loss_2': 0.003917694091796875, 'loss_3': -16.090740203857422, 'loss_4': 3.1176486015319824, 'epoch': 6.87}
{'loss': 0.0227, 'grad_norm': 6.811811447143555, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.021416442468762398, 'loss_2': 0.0012941360473632812, 'loss_3': -16.234176635742188, 'loss_4': 3.7971088886260986, 'epoch': 6.87}
{'loss': 0.0218, 'grad_norm': 6.890154838562012, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.019296038895845413, 'loss_2': 0.002475738525390625, 'loss_3': -16.254291534423828, 'loss_4': 2.8596134185791016, 'epoch': 6.88}
{'loss': 0.021, 'grad_norm': 5.2496562004089355, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.01464894600212574, 'loss_2': 0.0063323974609375, 'loss_3': -16.346220016479492, 'loss_4': 2.7791876792907715, 'epoch': 6.88}
{'loss': 0.0217, 'grad_norm': 9.499069213867188, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.018236737698316574, 'loss_2': 0.0034923553466796875, 'loss_3': -16.278120040893555, 'loss_4': 2.3877296447753906, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 09:53:46,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:46,930 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:36<1:08:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:54,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014348307624459267, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011440558359026909, 'eval_loss_2': 0.002907749265432358, 'eval_loss_3': -18.280529022216797, 'eval_loss_4': 2.8133544921875, 'epoch': 6.89}
{'loss': 0.0198, 'grad_norm': 7.0183539390563965, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.01778322458267212, 'loss_2': 0.002010345458984375, 'loss_3': -16.295190811157227, 'loss_4': 2.913050889968872, 'epoch': 6.9}
{'loss': 0.0247, 'grad_norm': 7.132941246032715, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.015569737181067467, 'loss_2': 0.0091094970703125, 'loss_3': -16.346023559570312, 'loss_4': 2.7601914405822754, 'epoch': 6.9}
{'loss': 0.04, 'grad_norm': 9.851487159729004, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.03331043943762779, 'loss_2': 0.006694793701171875, 'loss_3': -16.138105392456055, 'loss_4': 2.3828396797180176, 'epoch': 6.91}
{'loss': 0.0257, 'grad_norm': 11.45042610168457, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.024351852014660835, 'loss_2': 0.001312255859375, 'loss_3': -16.21515464782715, 'loss_4': 2.4135093688964844, 'epoch': 6.91}
{'loss': 0.025, 'grad_norm': 6.991323947906494, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.020219551399350166, 'loss_2': 0.00476837158203125, 'loss_3': -16.32583999633789, 'loss_4': 2.955489158630371, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 09:53:54,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:54,278 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:43<1:08:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:01,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013966906815767288, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.047, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010733861476182938, 'eval_loss_2': 0.0032330453395843506, 'eval_loss_3': -18.32533073425293, 'eval_loss_4': 2.4975717067718506, 'epoch': 6.92}
{'loss': 0.0361, 'grad_norm': 20.781219482421875, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.03253830969333649, 'loss_2': 0.00354766845703125, 'loss_3': -16.270965576171875, 'loss_4': 3.0899505615234375, 'epoch': 6.92}
{'loss': 0.0409, 'grad_norm': 14.618096351623535, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.030924811959266663, 'loss_2': 0.010009765625, 'loss_3': -15.99190616607666, 'loss_4': 2.782586097717285, 'epoch': 6.93}
{'loss': 0.0122, 'grad_norm': 5.742099761962891, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.012097042985260487, 'loss_2': 8.285045623779297e-05, 'loss_3': -16.30609130859375, 'loss_4': 2.6802377700805664, 'epoch': 6.94}
{'loss': 0.0327, 'grad_norm': 13.557622909545898, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.029168765991926193, 'loss_2': 0.003536224365234375, 'loss_3': -16.186565399169922, 'loss_4': 2.449331760406494, 'epoch': 6.94}
{'loss': 0.0255, 'grad_norm': 8.610586166381836, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.015766363590955734, 'loss_2': 0.0096893310546875, 'loss_3': -16.355636596679688, 'loss_4': 2.929320812225342, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 09:54:01,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:01,632 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [29:51<1:08:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:08,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01308362651616335, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.222, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009513188153505325, 'eval_loss_2': 0.0035704374313354492, 'eval_loss_3': -18.3348331451416, 'eval_loss_4': 2.282435894012451, 'epoch': 6.95}
{'loss': 0.0209, 'grad_norm': 8.160067558288574, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.020520634949207306, 'loss_2': 0.0004162788391113281, 'loss_3': -16.25384521484375, 'loss_4': 2.9380874633789062, 'epoch': 6.95}
{'loss': 0.016, 'grad_norm': 7.643773555755615, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.014986365102231503, 'loss_2': 0.0010223388671875, 'loss_3': -16.210166931152344, 'loss_4': 1.5968824625015259, 'epoch': 6.96}
{'loss': 0.044, 'grad_norm': 11.19969654083252, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.0382736399769783, 'loss_2': 0.00572967529296875, 'loss_3': -16.269405364990234, 'loss_4': 3.3559136390686035, 'epoch': 6.97}
{'loss': 0.0385, 'grad_norm': 12.792828559875488, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.034408703446388245, 'loss_2': 0.00412750244140625, 'loss_3': -15.992337226867676, 'loss_4': 3.1774227619171143, 'epoch': 6.97}
{'loss': 0.0159, 'grad_norm': 8.526129722595215, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.01587533950805664, 'loss_2': 6.699562072753906e-05, 'loss_3': -16.289100646972656, 'loss_4': 2.485942840576172, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 09:54:08,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:08,979 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [29:58<1:04:35,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 09:54:16,029 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011094781570136547, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.737, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00834143441170454, 'eval_loss_2': 0.002753347158432007, 'eval_loss_3': -18.34349822998047, 'eval_loss_4': 1.8827180862426758, 'epoch': 6.98}
{'loss': 0.0101, 'grad_norm': 5.070937633514404, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.009629376232624054, 'loss_2': 0.00042629241943359375, 'loss_3': -16.430606842041016, 'loss_4': 2.787031650543213, 'epoch': 6.98}
{'loss': 0.027, 'grad_norm': 9.032469749450684, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.025574319064617157, 'loss_2': 0.00142669677734375, 'loss_3': -16.50070571899414, 'loss_4': 2.4540250301361084, 'epoch': 6.99}
{'loss': 0.0412, 'grad_norm': 15.860557556152344, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.034304551780223846, 'loss_2': 0.00687408447265625, 'loss_3': -16.387413024902344, 'loss_4': 2.8924872875213623, 'epoch': 6.99}
{'loss': 0.0158, 'grad_norm': 6.40487003326416, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.006775589659810066, 'loss_2': 0.0089874267578125, 'loss_3': -16.330778121948242, 'loss_4': 3.2340025901794434, 'epoch': 7.0}
{'loss': 0.0434, 'grad_norm': 9.908255577087402, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.030574755743145943, 'loss_2': 0.0128631591796875, 'loss_3': -16.238027572631836, 'loss_4': 2.227381944656372, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 09:54:16,029 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:16,029 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:05<1:07:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:54:23,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014565322548151016, 'eval_runtime': 3.8277, 'eval_samples_per_second': 267.524, 'eval_steps_per_second': 4.18, 'eval_loss_1': 0.008105818182229996, 'eval_loss_2': 0.0064595043659210205, 'eval_loss_3': -18.34698486328125, 'eval_loss_4': 1.6741700172424316, 'epoch': 7.01}
{'loss': 0.0413, 'grad_norm': 11.363615036010742, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.030140912160277367, 'loss_2': 0.0111236572265625, 'loss_3': -16.344512939453125, 'loss_4': 2.0442450046539307, 'epoch': 7.01}
{'loss': 0.0237, 'grad_norm': 6.9245285987854, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.019915660843253136, 'loss_2': 0.003753662109375, 'loss_3': -16.31374740600586, 'loss_4': 2.9595577716827393, 'epoch': 7.02}
{'loss': 0.017, 'grad_norm': 6.130313873291016, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.014948569238185883, 'loss_2': 0.00206756591796875, 'loss_3': -16.06796646118164, 'loss_4': 2.0685181617736816, 'epoch': 7.02}
{'loss': 0.0157, 'grad_norm': 6.05860710144043, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.011924797669053078, 'loss_2': 0.00380706787109375, 'loss_3': -16.200742721557617, 'loss_4': 1.9480538368225098, 'epoch': 7.03}
{'loss': 0.0187, 'grad_norm': 6.375019073486328, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.013299298472702503, 'loss_2': 0.0053558349609375, 'loss_3': -16.194677352905273, 'loss_4': 1.8356938362121582, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 09:54:23,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:23,402 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:12<1:08:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:30,752 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012585895135998726, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008235679939389229, 'eval_loss_2': 0.004350215196609497, 'eval_loss_3': -18.314483642578125, 'eval_loss_4': 1.6448321342468262, 'epoch': 7.03}
{'loss': 0.0149, 'grad_norm': 6.950923442840576, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.014708660542964935, 'loss_2': 0.00019741058349609375, 'loss_3': -16.158390045166016, 'loss_4': 1.9466418027877808, 'epoch': 7.04}
{'loss': 0.0288, 'grad_norm': 8.207587242126465, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.01729981042444706, 'loss_2': 0.011474609375, 'loss_3': -16.276885986328125, 'loss_4': 1.9452457427978516, 'epoch': 7.05}
{'loss': 0.0163, 'grad_norm': 6.2785115242004395, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.015251467935740948, 'loss_2': 0.0010309219360351562, 'loss_3': -16.418527603149414, 'loss_4': 2.283073902130127, 'epoch': 7.05}
{'loss': 0.0286, 'grad_norm': 11.934174537658691, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.027693068608641624, 'loss_2': 0.0009241104125976562, 'loss_3': -16.204822540283203, 'loss_4': 2.1709794998168945, 'epoch': 7.06}
{'loss': 0.0299, 'grad_norm': 11.273958206176758, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.022715015336871147, 'loss_2': 0.00720977783203125, 'loss_3': -16.274682998657227, 'loss_4': 2.600399971008301, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 09:54:30,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:30,753 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:20<1:08:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:38,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008970359340310097, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.228, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005883478559553623, 'eval_loss_2': 0.003086879849433899, 'eval_loss_3': -18.308456420898438, 'eval_loss_4': 1.4681612253189087, 'epoch': 7.06}
{'loss': 0.0159, 'grad_norm': 7.127878665924072, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.01470447052270174, 'loss_2': 0.001186370849609375, 'loss_3': -16.498043060302734, 'loss_4': 1.8336976766586304, 'epoch': 7.07}
{'loss': 0.0297, 'grad_norm': 13.680562019348145, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.028206540271639824, 'loss_2': 0.0015354156494140625, 'loss_3': -16.32423973083496, 'loss_4': 2.92710542678833, 'epoch': 7.08}
{'loss': 0.027, 'grad_norm': 11.179299354553223, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.017832890152931213, 'loss_2': 0.00917816162109375, 'loss_3': -16.17789077758789, 'loss_4': 1.8671274185180664, 'epoch': 7.08}
{'loss': 0.0459, 'grad_norm': 22.90123748779297, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.03959029167890549, 'loss_2': 0.00628662109375, 'loss_3': -16.192340850830078, 'loss_4': 1.6218332052230835, 'epoch': 7.09}
{'loss': 0.0193, 'grad_norm': 8.283991813659668, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.013980591669678688, 'loss_2': 0.005283355712890625, 'loss_3': -16.03534698486328, 'loss_4': 1.9705283641815186, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 09:54:38,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:38,099 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:27<1:08:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:45,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010109681636095047, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006403494160622358, 'eval_loss_2': 0.0037061870098114014, 'eval_loss_3': -18.274499893188477, 'eval_loss_4': 1.4048166275024414, 'epoch': 7.09}
{'loss': 0.0177, 'grad_norm': 6.626245975494385, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.01071983203291893, 'loss_2': 0.006999969482421875, 'loss_3': -16.216854095458984, 'loss_4': 1.4432976245880127, 'epoch': 7.1}
{'loss': 0.0267, 'grad_norm': 12.417529106140137, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.022987090051174164, 'loss_2': 0.00373077392578125, 'loss_3': -16.17313575744629, 'loss_4': 1.9148740768432617, 'epoch': 7.1}
{'loss': 0.0296, 'grad_norm': 11.371932029724121, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.026006966829299927, 'loss_2': 0.003631591796875, 'loss_3': -16.138107299804688, 'loss_4': 1.8484312295913696, 'epoch': 7.11}
{'loss': 0.0159, 'grad_norm': 5.525416374206543, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.009783339686691761, 'loss_2': 0.006160736083984375, 'loss_3': -16.185110092163086, 'loss_4': 1.3925580978393555, 'epoch': 7.12}
{'loss': 0.0156, 'grad_norm': 6.229280948638916, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.009064901620149612, 'loss_2': 0.006500244140625, 'loss_3': -16.25631332397461, 'loss_4': 1.805368185043335, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 09:54:45,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:45,441 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:34<1:07:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:52,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012552418746054173, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006242779549211264, 'eval_loss_2': 0.006309639662504196, 'eval_loss_3': -18.226640701293945, 'eval_loss_4': 1.1576709747314453, 'epoch': 7.12}
{'loss': 0.0239, 'grad_norm': 6.9366960525512695, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.01711759716272354, 'loss_2': 0.006744384765625, 'loss_3': -15.971967697143555, 'loss_4': 1.8712867498397827, 'epoch': 7.13}
{'loss': 0.0385, 'grad_norm': 22.999500274658203, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.03711269050836563, 'loss_2': 0.0013427734375, 'loss_3': -15.96908950805664, 'loss_4': 1.1097137928009033, 'epoch': 7.13}
{'loss': 0.026, 'grad_norm': 8.25307559967041, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.01852135919034481, 'loss_2': 0.007526397705078125, 'loss_3': -15.978671073913574, 'loss_4': 0.29769474267959595, 'epoch': 7.14}
{'loss': 0.0106, 'grad_norm': 5.067033767700195, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.009670061990618706, 'loss_2': 0.0009326934814453125, 'loss_3': -16.28247833251953, 'loss_4': 1.3495919704437256, 'epoch': 7.15}
{'loss': 0.0228, 'grad_norm': 9.169510841369629, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.019027864560484886, 'loss_2': 0.003757476806640625, 'loss_3': -16.10357093811035, 'loss_4': 1.2623107433319092, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 09:54:52,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:52,785 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:42<1:07:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:00,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01465936191380024, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.221, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.006669999565929174, 'eval_loss_2': 0.007989361882209778, 'eval_loss_3': -18.208816528320312, 'eval_loss_4': 1.296529769897461, 'epoch': 7.15}
{'loss': 0.0102, 'grad_norm': 4.569993495941162, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.006631115451455116, 'loss_2': 0.0035190582275390625, 'loss_3': -16.078594207763672, 'loss_4': 1.370685338973999, 'epoch': 7.16}
{'loss': 0.035, 'grad_norm': 12.363924026489258, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.02315528690814972, 'loss_2': 0.01180267333984375, 'loss_3': -15.944389343261719, 'loss_4': 2.0811476707458496, 'epoch': 7.16}
{'loss': 0.0286, 'grad_norm': 7.000669956207275, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.01484138797968626, 'loss_2': 0.01371002197265625, 'loss_3': -16.30004119873047, 'loss_4': 1.6076247692108154, 'epoch': 7.17}
{'loss': 0.0226, 'grad_norm': 4.9233293533325195, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.00794931873679161, 'loss_2': 0.0146636962890625, 'loss_3': -16.02073860168457, 'loss_4': 1.7019007205963135, 'epoch': 7.17}
{'loss': 0.0218, 'grad_norm': 7.25001859664917, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.010839090682566166, 'loss_2': 0.0109710693359375, 'loss_3': -16.134357452392578, 'loss_4': 1.8116041421890259, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 09:55:00,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:00,142 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [30:49<1:07:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:07,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019719228148460388, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007669554557651281, 'eval_loss_2': 0.012049674987792969, 'eval_loss_3': -18.25324058532715, 'eval_loss_4': 1.5398399829864502, 'epoch': 7.18}
{'loss': 0.025, 'grad_norm': 9.376002311706543, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.01454597432166338, 'loss_2': 0.01049041748046875, 'loss_3': -15.93122673034668, 'loss_4': 1.6888153553009033, 'epoch': 7.19}
{'loss': 0.013, 'grad_norm': 8.067910194396973, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.012701921164989471, 'loss_2': 0.0003437995910644531, 'loss_3': -16.056026458740234, 'loss_4': 1.1904819011688232, 'epoch': 7.19}
{'loss': 0.028, 'grad_norm': 12.06390380859375, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.024307169020175934, 'loss_2': 0.00368499755859375, 'loss_3': -16.219249725341797, 'loss_4': 1.4684758186340332, 'epoch': 7.2}
{'loss': 0.0331, 'grad_norm': 15.28436279296875, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.0313529297709465, 'loss_2': 0.0017290115356445312, 'loss_3': -16.348918914794922, 'loss_4': 2.1115949153900146, 'epoch': 7.2}
{'loss': 0.0139, 'grad_norm': 5.834566116333008, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.012253346852958202, 'loss_2': 0.001651763916015625, 'loss_3': -16.167186737060547, 'loss_4': 2.052778959274292, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 09:55:07,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:07,493 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [30:57<1:07:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:14,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01051068864762783, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.618, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007399091497063637, 'eval_loss_2': 0.0031115971505641937, 'eval_loss_3': -18.255815505981445, 'eval_loss_4': 1.6773653030395508, 'epoch': 7.21}
{'loss': 0.0096, 'grad_norm': 5.737770080566406, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.009209436364471912, 'loss_2': 0.0003604888916015625, 'loss_3': -15.932332992553711, 'loss_4': 1.4559223651885986, 'epoch': 7.22}
{'loss': 0.0195, 'grad_norm': 6.425878524780273, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.012950283475220203, 'loss_2': 0.006591796875, 'loss_3': -16.12264633178711, 'loss_4': 1.8966987133026123, 'epoch': 7.22}
{'loss': 0.0207, 'grad_norm': 8.473053932189941, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.01431963685899973, 'loss_2': 0.00640869140625, 'loss_3': -16.070446014404297, 'loss_4': 2.331575393676758, 'epoch': 7.23}
{'loss': 0.0381, 'grad_norm': 11.8352632522583, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.033763471990823746, 'loss_2': 0.004291534423828125, 'loss_3': -16.11105728149414, 'loss_4': 1.5936318635940552, 'epoch': 7.23}
{'loss': 0.0274, 'grad_norm': 8.209393501281738, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.019480640068650246, 'loss_2': 0.00787353515625, 'loss_3': -16.17831802368164, 'loss_4': 2.025753974914551, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 09:55:14,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:14,839 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:04<1:07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:22,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010371096432209015, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006909228395670652, 'eval_loss_2': 0.003461867570877075, 'eval_loss_3': -18.27075958251953, 'eval_loss_4': 1.5440999269485474, 'epoch': 7.24}
{'loss': 0.0354, 'grad_norm': 10.043389320373535, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.027522457763552666, 'loss_2': 0.007843017578125, 'loss_3': -16.051965713500977, 'loss_4': 1.6348570585250854, 'epoch': 7.24}
{'loss': 0.0207, 'grad_norm': 8.003557205200195, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.016822349280118942, 'loss_2': 0.00391387939453125, 'loss_3': -16.254318237304688, 'loss_4': 2.342696189880371, 'epoch': 7.25}
{'loss': 0.0199, 'grad_norm': 7.691655158996582, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.01732654683291912, 'loss_2': 0.002532958984375, 'loss_3': -16.119062423706055, 'loss_4': 1.7629441022872925, 'epoch': 7.26}
{'loss': 0.0115, 'grad_norm': 5.404042720794678, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.007592380046844482, 'loss_2': 0.00386810302734375, 'loss_3': -16.178647994995117, 'loss_4': 1.6481177806854248, 'epoch': 7.26}
{'loss': 0.0266, 'grad_norm': 6.780375003814697, 'learning_rate': 2.275e-05, 'loss_1': 0.02008160948753357, 'loss_2': 0.006561279296875, 'loss_3': -16.09159278869629, 'loss_4': 1.8795270919799805, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 09:55:22,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:22,184 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:11<1:07:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:29,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015355299226939678, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.629, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007603655103594065, 'eval_loss_2': 0.007751643657684326, 'eval_loss_3': -18.24627685546875, 'eval_loss_4': 1.3660292625427246, 'epoch': 7.27}
{'loss': 0.0288, 'grad_norm': 7.2856574058532715, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.01479373499751091, 'loss_2': 0.01397705078125, 'loss_3': -16.0593318939209, 'loss_4': 1.7599565982818604, 'epoch': 7.27}
{'loss': 0.02, 'grad_norm': 6.570310592651367, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.01374735962599516, 'loss_2': 0.006237030029296875, 'loss_3': -16.157794952392578, 'loss_4': 1.692835807800293, 'epoch': 7.28}
{'loss': 0.028, 'grad_norm': 7.278527736663818, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.019499311223626137, 'loss_2': 0.0084991455078125, 'loss_3': -16.091602325439453, 'loss_4': 1.2201507091522217, 'epoch': 7.28}
{'loss': 0.0284, 'grad_norm': 12.030776023864746, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.019791128113865852, 'loss_2': 0.008575439453125, 'loss_3': -16.334415435791016, 'loss_4': 2.0275521278381348, 'epoch': 7.29}
{'loss': 0.0292, 'grad_norm': 7.701700687408447, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.024125047028064728, 'loss_2': 0.00508880615234375, 'loss_3': -16.091535568237305, 'loss_4': 1.8312771320343018, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 09:55:29,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:29,523 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:19<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:36,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010044917464256287, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00691465986892581, 'eval_loss_2': 0.0031302571296691895, 'eval_loss_3': -18.254051208496094, 'eval_loss_4': 1.4804401397705078, 'epoch': 7.3}
{'loss': 0.0203, 'grad_norm': 7.495517730712891, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.016202284023165703, 'loss_2': 0.004131317138671875, 'loss_3': -16.20755958557129, 'loss_4': 2.0448083877563477, 'epoch': 7.3}
{'loss': 0.0332, 'grad_norm': 10.449894905090332, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.029527124017477036, 'loss_2': 0.0037212371826171875, 'loss_3': -16.069847106933594, 'loss_4': 1.325440526008606, 'epoch': 7.31}
{'loss': 0.0352, 'grad_norm': 11.798898696899414, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.029320498928427696, 'loss_2': 0.00592041015625, 'loss_3': -16.18526840209961, 'loss_4': 2.1678638458251953, 'epoch': 7.31}
{'loss': 0.1085, 'grad_norm': 40.16859817504883, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.09827516227960587, 'loss_2': 0.01021575927734375, 'loss_3': -15.998627662658691, 'loss_4': 1.8857825994491577, 'epoch': 7.32}
{'loss': 0.0433, 'grad_norm': 15.258864402770996, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.03638951852917671, 'loss_2': 0.00690460205078125, 'loss_3': -16.160999298095703, 'loss_4': 1.1193504333496094, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 09:55:36,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:36,877 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:26<1:07:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:44,225 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010360457003116608, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0070205992087721825, 'eval_loss_2': 0.0033398568630218506, 'eval_loss_3': -18.255754470825195, 'eval_loss_4': 1.6638232469558716, 'epoch': 7.33}
{'loss': 0.0219, 'grad_norm': 9.423083305358887, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.01852789893746376, 'loss_2': 0.003376007080078125, 'loss_3': -16.224885940551758, 'loss_4': 2.098219871520996, 'epoch': 7.33}
{'loss': 0.0474, 'grad_norm': 24.2904109954834, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.046024519950151443, 'loss_2': 0.0013761520385742188, 'loss_3': -15.992961883544922, 'loss_4': 1.8464564085006714, 'epoch': 7.34}
{'loss': 0.0153, 'grad_norm': 5.893432140350342, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.01145574264228344, 'loss_2': 0.003887176513671875, 'loss_3': -16.246917724609375, 'loss_4': 1.3225799798965454, 'epoch': 7.34}
{'loss': 0.019, 'grad_norm': 8.051040649414062, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.01808525249361992, 'loss_2': 0.0008745193481445312, 'loss_3': -16.37895965576172, 'loss_4': 1.57437264919281, 'epoch': 7.35}
{'loss': 0.0221, 'grad_norm': 7.902203559875488, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.021814409643411636, 'loss_2': 0.00027108192443847656, 'loss_3': -16.160194396972656, 'loss_4': 2.4812140464782715, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 09:55:44,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:44,225 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:33<1:07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:51,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009725001640617847, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007001232355833054, 'eval_loss_2': 0.0027237683534622192, 'eval_loss_3': -18.25131607055664, 'eval_loss_4': 1.746815800666809, 'epoch': 7.35}
{'loss': 0.0766, 'grad_norm': 15.739214897155762, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.06942490488290787, 'loss_2': 0.00714874267578125, 'loss_3': -16.004344940185547, 'loss_4': 1.8581650257110596, 'epoch': 7.36}
{'loss': 0.0174, 'grad_norm': 7.280580520629883, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.014922080561518669, 'loss_2': 0.002460479736328125, 'loss_3': -16.306867599487305, 'loss_4': 2.6918742656707764, 'epoch': 7.37}
{'loss': 0.0221, 'grad_norm': 7.731011390686035, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.018517611548304558, 'loss_2': 0.0035552978515625, 'loss_3': -16.122745513916016, 'loss_4': 1.563696265220642, 'epoch': 7.37}
{'loss': 0.0226, 'grad_norm': 6.834019660949707, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.020591389387845993, 'loss_2': 0.001995086669921875, 'loss_3': -16.206146240234375, 'loss_4': 1.5896644592285156, 'epoch': 7.38}
{'loss': 0.0313, 'grad_norm': 12.03424072265625, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.027486266568303108, 'loss_2': 0.003841400146484375, 'loss_3': -16.327177047729492, 'loss_4': 1.838747262954712, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 09:55:51,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:51,562 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:41<1:07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:58,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010166029445827007, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0060877613723278046, 'eval_loss_2': 0.004078269004821777, 'eval_loss_3': -18.25823211669922, 'eval_loss_4': 1.4950957298278809, 'epoch': 7.38}
{'loss': 0.0213, 'grad_norm': 6.455204963684082, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.015482277609407902, 'loss_2': 0.005832672119140625, 'loss_3': -16.347885131835938, 'loss_4': 1.7673580646514893, 'epoch': 7.39}
{'loss': 0.0147, 'grad_norm': 5.150106430053711, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.010699387639760971, 'loss_2': 0.003997802734375, 'loss_3': -16.29854965209961, 'loss_4': 1.6572051048278809, 'epoch': 7.4}
{'loss': 0.0149, 'grad_norm': 6.203484058380127, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.014685256406664848, 'loss_2': 0.00017452239990234375, 'loss_3': -16.20392608642578, 'loss_4': 1.3129620552062988, 'epoch': 7.4}
{'loss': 0.0115, 'grad_norm': 5.412654399871826, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.010404668748378754, 'loss_2': 0.00112152099609375, 'loss_3': -16.177522659301758, 'loss_4': 2.077188014984131, 'epoch': 7.41}
{'loss': 0.0387, 'grad_norm': 11.940659523010254, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.032875847071409225, 'loss_2': 0.00579833984375, 'loss_3': -16.2364501953125, 'loss_4': 1.730893850326538, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 09:55:58,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:58,904 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [31:48<1:07:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:06,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015114021487534046, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.283, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006164830643683672, 'eval_loss_2': 0.008949190378189087, 'eval_loss_3': -18.25165367126465, 'eval_loss_4': 1.2831971645355225, 'epoch': 7.41}
{'loss': 0.0185, 'grad_norm': 6.772796630859375, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.015171410515904427, 'loss_2': 0.003330230712890625, 'loss_3': -16.128936767578125, 'loss_4': 1.6578038930892944, 'epoch': 7.42}
{'loss': 0.0254, 'grad_norm': 6.330644130706787, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.020672449842095375, 'loss_2': 0.00469207763671875, 'loss_3': -16.1144962310791, 'loss_4': 1.1137328147888184, 'epoch': 7.42}
{'loss': 0.0163, 'grad_norm': 6.560178279876709, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.013075999915599823, 'loss_2': 0.00324249267578125, 'loss_3': -16.133869171142578, 'loss_4': 1.663199782371521, 'epoch': 7.43}
{'loss': 0.0272, 'grad_norm': 6.083712577819824, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.01753668114542961, 'loss_2': 0.00969696044921875, 'loss_3': -16.22527503967285, 'loss_4': 0.999157190322876, 'epoch': 7.44}
{'loss': 0.0148, 'grad_norm': 6.620117664337158, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.013555734418332577, 'loss_2': 0.001270294189453125, 'loss_3': -16.126779556274414, 'loss_4': 1.7783408164978027, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 09:56:06,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:06,248 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [31:55<1:07:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:13,604 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009490055963397026, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.789, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006403317209333181, 'eval_loss_2': 0.0030867382884025574, 'eval_loss_3': -18.256927490234375, 'eval_loss_4': 1.1902985572814941, 'epoch': 7.44}
{'loss': 0.0691, 'grad_norm': 21.88719367980957, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.06554222106933594, 'loss_2': 0.0036067962646484375, 'loss_3': -16.15924072265625, 'loss_4': 1.9032583236694336, 'epoch': 7.45}
{'loss': 0.0263, 'grad_norm': 7.736335754394531, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.023009754717350006, 'loss_2': 0.003276824951171875, 'loss_3': -16.22368812561035, 'loss_4': 1.5929431915283203, 'epoch': 7.45}
{'loss': 0.0197, 'grad_norm': 5.458662509918213, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.009526480920612812, 'loss_2': 0.01020050048828125, 'loss_3': -16.22135353088379, 'loss_4': 1.3457996845245361, 'epoch': 7.46}
{'loss': 0.042, 'grad_norm': 8.621644020080566, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.024312173947691917, 'loss_2': 0.0176544189453125, 'loss_3': -16.181751251220703, 'loss_4': 1.6857054233551025, 'epoch': 7.47}
{'loss': 0.0234, 'grad_norm': 6.210395336151123, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.01600048877298832, 'loss_2': 0.00743865966796875, 'loss_3': -16.235733032226562, 'loss_4': 1.7281997203826904, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 09:56:13,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:13,604 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:03<1:06:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:20,951 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009473603218793869, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005514339078217745, 'eval_loss_2': 0.0039592646062374115, 'eval_loss_3': -18.25411033630371, 'eval_loss_4': 1.023158073425293, 'epoch': 7.47}
{'loss': 0.0346, 'grad_norm': 18.75565528869629, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.028088165447115898, 'loss_2': 0.00646209716796875, 'loss_3': -16.220661163330078, 'loss_4': 1.2832396030426025, 'epoch': 7.48}
{'loss': 0.0132, 'grad_norm': 5.563254356384277, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.01129832025617361, 'loss_2': 0.001857757568359375, 'loss_3': -16.297832489013672, 'loss_4': 1.6883008480072021, 'epoch': 7.48}
{'loss': 0.012, 'grad_norm': 5.403164386749268, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.009794390760362148, 'loss_2': 0.002227783203125, 'loss_3': -16.389196395874023, 'loss_4': 1.074714183807373, 'epoch': 7.49}
{'loss': 0.0213, 'grad_norm': 6.336487293243408, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.014758436009287834, 'loss_2': 0.006519317626953125, 'loss_3': -16.157939910888672, 'loss_4': 1.455223560333252, 'epoch': 7.49}
{'loss': 0.0405, 'grad_norm': 16.61121368408203, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.03180702030658722, 'loss_2': 0.00870513916015625, 'loss_3': -15.989681243896484, 'loss_4': 1.5832933187484741, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 09:56:20,951 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:20,951 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:10<1:06:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:28,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015158860944211483, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006061045452952385, 'eval_loss_2': 0.009097814559936523, 'eval_loss_3': -18.227663040161133, 'eval_loss_4': 1.3152921199798584, 'epoch': 7.5}
{'loss': 0.0328, 'grad_norm': 7.339085102081299, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.022034557536244392, 'loss_2': 0.01076507568359375, 'loss_3': -16.24007797241211, 'loss_4': 1.4809789657592773, 'epoch': 7.51}
{'loss': 0.0283, 'grad_norm': 12.3573637008667, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.027538491412997246, 'loss_2': 0.0007371902465820312, 'loss_3': -16.072763442993164, 'loss_4': 1.8699910640716553, 'epoch': 7.51}
{'loss': 0.0266, 'grad_norm': 8.540726661682129, 'learning_rate': 2.25e-05, 'loss_1': 0.020864471793174744, 'loss_2': 0.0057525634765625, 'loss_3': -16.133113861083984, 'loss_4': 1.5573558807373047, 'epoch': 7.52}
{'loss': 0.0163, 'grad_norm': 6.300721645355225, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.01425991766154766, 'loss_2': 0.0020751953125, 'loss_3': -15.984109878540039, 'loss_4': 1.714494228363037, 'epoch': 7.52}
{'loss': 0.0209, 'grad_norm': 6.654814720153809, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.017383702099323273, 'loss_2': 0.00350189208984375, 'loss_3': -16.078235626220703, 'loss_4': 1.801001787185669, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 09:56:28,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:28,305 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:17<1:06:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:35,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011673659086227417, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.323, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007160693407058716, 'eval_loss_2': 0.004512965679168701, 'eval_loss_3': -18.189376831054688, 'eval_loss_4': 1.563240647315979, 'epoch': 7.53}
{'loss': 0.0201, 'grad_norm': 6.164403438568115, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.0178828202188015, 'loss_2': 0.00222015380859375, 'loss_3': -16.182037353515625, 'loss_4': 1.284194827079773, 'epoch': 7.53}
{'loss': 0.0161, 'grad_norm': 5.8903985023498535, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.01331872958689928, 'loss_2': 0.002777099609375, 'loss_3': -16.179847717285156, 'loss_4': 1.8932104110717773, 'epoch': 7.54}
{'loss': 0.0168, 'grad_norm': 7.45077657699585, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.013583986088633537, 'loss_2': 0.003204345703125, 'loss_3': -16.16064453125, 'loss_4': 2.5559885501861572, 'epoch': 7.55}
{'loss': 0.0368, 'grad_norm': 14.951592445373535, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.03058779053390026, 'loss_2': 0.00616455078125, 'loss_3': -16.048795700073242, 'loss_4': 2.825437068939209, 'epoch': 7.55}
{'loss': 0.0245, 'grad_norm': 6.520730495452881, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.012464594095945358, 'loss_2': 0.0120849609375, 'loss_3': -16.13357162475586, 'loss_4': 2.356236696243286, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 09:56:35,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:35,655 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:25<1:06:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:42,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01923471689224243, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.561, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007872759364545345, 'eval_loss_2': 0.011361956596374512, 'eval_loss_3': -18.224653244018555, 'eval_loss_4': 2.147146224975586, 'epoch': 7.56}
{'loss': 0.0385, 'grad_norm': 13.447230339050293, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.021993989124894142, 'loss_2': 0.0164947509765625, 'loss_3': -16.00204086303711, 'loss_4': 2.256707191467285, 'epoch': 7.56}
{'loss': 0.0311, 'grad_norm': 5.704853534698486, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.012739303521811962, 'loss_2': 0.0183258056640625, 'loss_3': -16.13945960998535, 'loss_4': 2.210765838623047, 'epoch': 7.57}
{'loss': 0.0264, 'grad_norm': 5.612823486328125, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.01043226383626461, 'loss_2': 0.015960693359375, 'loss_3': -16.192737579345703, 'loss_4': 2.215284824371338, 'epoch': 7.58}
{'loss': 0.032, 'grad_norm': 8.287694931030273, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.016627559438347816, 'loss_2': 0.0153961181640625, 'loss_3': -16.11544418334961, 'loss_4': 2.3426947593688965, 'epoch': 7.58}
{'loss': 0.0293, 'grad_norm': 8.38748836517334, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.014830048196017742, 'loss_2': 0.014495849609375, 'loss_3': -16.000255584716797, 'loss_4': 2.708289623260498, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 09:56:42,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:42,993 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:32<1:06:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:50,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016024624928832054, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.199, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008088863454759121, 'eval_loss_2': 0.007935762405395508, 'eval_loss_3': -18.222196578979492, 'eval_loss_4': 2.6020569801330566, 'epoch': 7.59}
{'loss': 0.0355, 'grad_norm': 10.552043914794922, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.02788413129746914, 'loss_2': 0.0076446533203125, 'loss_3': -16.040369033813477, 'loss_4': 3.039813995361328, 'epoch': 7.59}
{'loss': 0.0384, 'grad_norm': 9.012110710144043, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.03461703658103943, 'loss_2': 0.0037689208984375, 'loss_3': -16.007291793823242, 'loss_4': 2.9348340034484863, 'epoch': 7.6}
{'loss': 0.027, 'grad_norm': 12.022883415222168, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.022992312908172607, 'loss_2': 0.00403594970703125, 'loss_3': -16.102935791015625, 'loss_4': 3.6745219230651855, 'epoch': 7.6}
{'loss': 0.0405, 'grad_norm': 20.031091690063477, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.036654453724622726, 'loss_2': 0.003856658935546875, 'loss_3': -16.065967559814453, 'loss_4': 3.710028648376465, 'epoch': 7.61}
{'loss': 0.0199, 'grad_norm': 8.571475982666016, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.019180256873369217, 'loss_2': 0.0007476806640625, 'loss_3': -16.21648406982422, 'loss_4': 2.6810381412506104, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 09:56:50,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:50,345 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:39<1:06:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:57,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01553409080952406, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.514, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006815243046730757, 'eval_loss_2': 0.00871884822845459, 'eval_loss_3': -18.24213981628418, 'eval_loss_4': 2.8132474422454834, 'epoch': 7.62}
{'loss': 0.045, 'grad_norm': 16.2106990814209, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.041725337505340576, 'loss_2': 0.0033092498779296875, 'loss_3': -16.324190139770508, 'loss_4': 2.9490718841552734, 'epoch': 7.62}
{'loss': 0.0284, 'grad_norm': 6.583990573883057, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.015025448054075241, 'loss_2': 0.01342010498046875, 'loss_3': -16.10782814025879, 'loss_4': 2.828339099884033, 'epoch': 7.63}
{'loss': 0.0208, 'grad_norm': 5.600876808166504, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.009625094942748547, 'loss_2': 0.01119232177734375, 'loss_3': -16.102272033691406, 'loss_4': 3.030747890472412, 'epoch': 7.63}
{'loss': 0.0226, 'grad_norm': 7.504548072814941, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.01287937443703413, 'loss_2': 0.009735107421875, 'loss_3': -15.850231170654297, 'loss_4': 2.984251022338867, 'epoch': 7.64}
{'loss': 0.0654, 'grad_norm': 32.48735809326172, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.049073778092861176, 'loss_2': 0.016357421875, 'loss_3': -15.955633163452148, 'loss_4': 3.381964683532715, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 09:56:57,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:57,702 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [32:47<1:06:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:05,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023258090019226074, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006501077674329281, 'eval_loss_2': 0.01675701141357422, 'eval_loss_3': -18.24710464477539, 'eval_loss_4': 2.7565972805023193, 'epoch': 7.65}
{'loss': 0.0292, 'grad_norm': 5.991763591766357, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.014208236709237099, 'loss_2': 0.01494598388671875, 'loss_3': -16.056367874145508, 'loss_4': 3.0955379009246826, 'epoch': 7.65}
{'loss': 0.0278, 'grad_norm': 8.164178848266602, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.01584593951702118, 'loss_2': 0.01194000244140625, 'loss_3': -16.106130599975586, 'loss_4': 2.379232406616211, 'epoch': 7.66}
{'loss': 0.0228, 'grad_norm': 7.360300064086914, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.013374621979892254, 'loss_2': 0.00946807861328125, 'loss_3': -16.06678009033203, 'loss_4': 3.10036039352417, 'epoch': 7.66}
{'loss': 0.0419, 'grad_norm': 9.325730323791504, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.034653834998607635, 'loss_2': 0.00722503662109375, 'loss_3': -16.193662643432617, 'loss_4': 2.535236120223999, 'epoch': 7.67}
{'loss': 0.0322, 'grad_norm': 12.382219314575195, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.027098242193460464, 'loss_2': 0.00507354736328125, 'loss_3': -16.06891632080078, 'loss_4': 2.3472867012023926, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 09:57:05,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:05,057 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [32:54<1:08:09,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 09:57:12,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012019485235214233, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.291, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007307796739041805, 'eval_loss_2': 0.0047116875648498535, 'eval_loss_3': -18.225006103515625, 'eval_loss_4': 2.306326389312744, 'epoch': 7.67}
{'loss': 0.0281, 'grad_norm': 9.496676445007324, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.02610687166452408, 'loss_2': 0.002040863037109375, 'loss_3': -16.143068313598633, 'loss_4': 2.4558982849121094, 'epoch': 7.68}
{'loss': 0.0342, 'grad_norm': 8.567694664001465, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.026073094457387924, 'loss_2': 0.0081329345703125, 'loss_3': -16.13973617553711, 'loss_4': 2.580997943878174, 'epoch': 7.69}
{'loss': 0.0342, 'grad_norm': 9.074898719787598, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.02722281590104103, 'loss_2': 0.0070037841796875, 'loss_3': -16.070037841796875, 'loss_4': 3.1456713676452637, 'epoch': 7.69}
{'loss': 0.0312, 'grad_norm': 8.857397079467773, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.022951586171984673, 'loss_2': 0.00823974609375, 'loss_3': -16.060277938842773, 'loss_4': 2.635594367980957, 'epoch': 7.7}
{'loss': 0.0394, 'grad_norm': 16.742393493652344, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.03523671254515648, 'loss_2': 0.0041961669921875, 'loss_3': -16.250150680541992, 'loss_4': 2.762744665145874, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 09:57:12,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:12,597 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:02<1:06:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:19,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011407624930143356, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006546448916196823, 'eval_loss_2': 0.004861176013946533, 'eval_loss_3': -18.225982666015625, 'eval_loss_4': 2.1545791625976562, 'epoch': 7.7}
{'loss': 0.0247, 'grad_norm': 13.257399559020996, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.02095586061477661, 'loss_2': 0.0037593841552734375, 'loss_3': -16.024398803710938, 'loss_4': 3.177119016647339, 'epoch': 7.71}
{'loss': 0.0492, 'grad_norm': 18.558761596679688, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.03999532386660576, 'loss_2': 0.00925445556640625, 'loss_3': -15.857217788696289, 'loss_4': 2.4757299423217773, 'epoch': 7.72}
{'loss': 0.0361, 'grad_norm': 11.576861381530762, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.02721061185002327, 'loss_2': 0.00885772705078125, 'loss_3': -16.261428833007812, 'loss_4': 3.4131760597229004, 'epoch': 7.72}
{'loss': 0.0178, 'grad_norm': 5.107189655303955, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.009785419330000877, 'loss_2': 0.00801849365234375, 'loss_3': -16.084304809570312, 'loss_4': 2.3666138648986816, 'epoch': 7.73}
{'loss': 0.022, 'grad_norm': 5.405120372772217, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.010282295756042004, 'loss_2': 0.011749267578125, 'loss_3': -16.161388397216797, 'loss_4': 2.2346158027648926, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 09:57:19,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:19,954 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:09<1:06:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:27,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008948272094130516, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.948, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005605390761047602, 'eval_loss_2': 0.0033428817987442017, 'eval_loss_3': -18.236705780029297, 'eval_loss_4': 2.1104817390441895, 'epoch': 7.73}
{'loss': 0.0157, 'grad_norm': 5.704021453857422, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.013034038245677948, 'loss_2': 0.002635955810546875, 'loss_3': -15.950149536132812, 'loss_4': 2.1341934204101562, 'epoch': 7.74}
{'loss': 0.0101, 'grad_norm': 6.003228187561035, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.009046290069818497, 'loss_2': 0.001007080078125, 'loss_3': -16.282316207885742, 'loss_4': 2.372870445251465, 'epoch': 7.74}
{'loss': 0.0135, 'grad_norm': 5.106236457824707, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.008774102665483952, 'loss_2': 0.00470733642578125, 'loss_3': -16.10308837890625, 'loss_4': 1.821832537651062, 'epoch': 7.75}
{'loss': 0.0161, 'grad_norm': 10.273490905761719, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.016086837276816368, 'loss_2': 4.482269287109375e-05, 'loss_3': -16.07692527770996, 'loss_4': 1.9222428798675537, 'epoch': 7.76}
{'loss': 0.0279, 'grad_norm': 6.739315509796143, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.0136492308229208, 'loss_2': 0.0142059326171875, 'loss_3': -16.237598419189453, 'loss_4': 2.798201084136963, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 09:57:27,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:27,307 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:16<1:06:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:34,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012028170749545097, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.744, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006526005920022726, 'eval_loss_2': 0.005502164363861084, 'eval_loss_3': -18.218013763427734, 'eval_loss_4': 2.1831934452056885, 'epoch': 7.76}
{'loss': 0.0601, 'grad_norm': 24.538742065429688, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.054670218378305435, 'loss_2': 0.0054473876953125, 'loss_3': -16.213905334472656, 'loss_4': 2.488217353820801, 'epoch': 7.77}
{'loss': 0.0303, 'grad_norm': 10.99277114868164, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.02499164082109928, 'loss_2': 0.00533294677734375, 'loss_3': -16.02617835998535, 'loss_4': 2.6855435371398926, 'epoch': 7.77}
{'loss': 0.0221, 'grad_norm': 7.474592208862305, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.018921900540590286, 'loss_2': 0.0031986236572265625, 'loss_3': -15.972774505615234, 'loss_4': 2.466886281967163, 'epoch': 7.78}
{'loss': 0.0213, 'grad_norm': 9.150949478149414, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.020140353590250015, 'loss_2': 0.0011653900146484375, 'loss_3': -15.916128158569336, 'loss_4': 2.882455348968506, 'epoch': 7.78}
{'loss': 0.0194, 'grad_norm': 8.17597770690918, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.01545269601047039, 'loss_2': 0.00389862060546875, 'loss_3': -16.127071380615234, 'loss_4': 2.3766531944274902, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 09:57:34,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:34,668 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:24<1:06:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:42,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009462440386414528, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.105, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00611740630120039, 'eval_loss_2': 0.0033450350165367126, 'eval_loss_3': -18.222537994384766, 'eval_loss_4': 2.078352928161621, 'epoch': 7.79}
{'loss': 0.0208, 'grad_norm': 5.847431659698486, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.012014222331345081, 'loss_2': 0.0087890625, 'loss_3': -16.176666259765625, 'loss_4': 2.77978515625, 'epoch': 7.8}
{'loss': 0.0292, 'grad_norm': 11.644637107849121, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.016916880384087563, 'loss_2': 0.0123138427734375, 'loss_3': -16.019060134887695, 'loss_4': 2.1868786811828613, 'epoch': 7.8}
{'loss': 0.02, 'grad_norm': 7.55452823638916, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.013880990445613861, 'loss_2': 0.006069183349609375, 'loss_3': -16.040786743164062, 'loss_4': 2.684396743774414, 'epoch': 7.81}
{'loss': 0.0104, 'grad_norm': 5.766013145446777, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.008851596154272556, 'loss_2': 0.0015935897827148438, 'loss_3': -16.167579650878906, 'loss_4': 2.4346656799316406, 'epoch': 7.81}
{'loss': 0.0178, 'grad_norm': 7.815334320068359, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.013039883226156235, 'loss_2': 0.004791259765625, 'loss_3': -16.272247314453125, 'loss_4': 1.9266726970672607, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 09:57:42,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:42,027 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:31<1:06:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:49,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00940951518714428, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.894, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005700318608433008, 'eval_loss_2': 0.0037091970443725586, 'eval_loss_3': -18.203662872314453, 'eval_loss_4': 1.9421534538269043, 'epoch': 7.82}
{'loss': 0.0315, 'grad_norm': 12.05571460723877, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.030360504984855652, 'loss_2': 0.0011262893676757812, 'loss_3': -16.085208892822266, 'loss_4': 1.8396364450454712, 'epoch': 7.83}
{'loss': 0.0308, 'grad_norm': 11.472640037536621, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.021849500015378, 'loss_2': 0.008941650390625, 'loss_3': -16.00387954711914, 'loss_4': 2.2219836711883545, 'epoch': 7.83}
{'loss': 0.0232, 'grad_norm': 7.86993408203125, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.018262090161442757, 'loss_2': 0.004974365234375, 'loss_3': -15.972637176513672, 'loss_4': 1.5460160970687866, 'epoch': 7.84}
{'loss': 0.0141, 'grad_norm': 7.786222457885742, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.010349386371672153, 'loss_2': 0.0037212371826171875, 'loss_3': -16.022560119628906, 'loss_4': 2.032161235809326, 'epoch': 7.84}
{'loss': 0.0271, 'grad_norm': 10.994166374206543, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.02094694972038269, 'loss_2': 0.00616455078125, 'loss_3': -15.946218490600586, 'loss_4': 2.4473745822906494, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 09:57:49,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:49,389 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:38<1:05:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:56,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010532597079873085, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.103, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0060584936290979385, 'eval_loss_2': 0.0044741034507751465, 'eval_loss_3': -18.201364517211914, 'eval_loss_4': 1.9449799060821533, 'epoch': 7.85}
{'loss': 0.0252, 'grad_norm': 8.674798965454102, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.016227375715970993, 'loss_2': 0.00893402099609375, 'loss_3': -15.975152969360352, 'loss_4': 2.3533477783203125, 'epoch': 7.85}
{'loss': 0.0123, 'grad_norm': 6.33753776550293, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.009246595203876495, 'loss_2': 0.0030670166015625, 'loss_3': -15.985593795776367, 'loss_4': 2.1420464515686035, 'epoch': 7.86}
{'loss': 0.0119, 'grad_norm': 5.110754489898682, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.005595759954303503, 'loss_2': 0.006317138671875, 'loss_3': -16.01345443725586, 'loss_4': 1.8007339239120483, 'epoch': 7.87}
{'loss': 0.0172, 'grad_norm': 6.4869890213012695, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.01084859762340784, 'loss_2': 0.00632476806640625, 'loss_3': -16.114147186279297, 'loss_4': 2.593275547027588, 'epoch': 7.87}
{'loss': 0.0101, 'grad_norm': 6.222278118133545, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.008616345934569836, 'loss_2': 0.0014934539794921875, 'loss_3': -16.054019927978516, 'loss_4': 2.6363134384155273, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 09:57:56,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:56,738 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:46<1:05:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:04,091 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009814506396651268, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006061932072043419, 'eval_loss_2': 0.003752574324607849, 'eval_loss_3': -18.183258056640625, 'eval_loss_4': 2.174569845199585, 'epoch': 7.88}
{'loss': 0.0119, 'grad_norm': 4.568432331085205, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.006539046298712492, 'loss_2': 0.00536346435546875, 'loss_3': -16.146530151367188, 'loss_4': 1.8350632190704346, 'epoch': 7.88}
{'loss': 0.0113, 'grad_norm': 5.250946521759033, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.007208045106381178, 'loss_2': 0.004100799560546875, 'loss_3': -16.06979751586914, 'loss_4': 2.107509136199951, 'epoch': 7.89}
{'loss': 0.0133, 'grad_norm': 6.5931572914123535, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.010493750683963299, 'loss_2': 0.0027618408203125, 'loss_3': -16.094074249267578, 'loss_4': 2.3840322494506836, 'epoch': 7.9}
{'loss': 0.0215, 'grad_norm': 7.319041728973389, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.01469864509999752, 'loss_2': 0.006805419921875, 'loss_3': -16.13071060180664, 'loss_4': 2.5952024459838867, 'epoch': 7.9}
{'loss': 0.0136, 'grad_norm': 7.136273384094238, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.011239683255553246, 'loss_2': 0.00235748291015625, 'loss_3': -16.0358943939209, 'loss_4': 2.7074742317199707, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 09:58:04,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:04,092 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [33:53<1:05:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:11,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010041799396276474, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.906, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006597903091460466, 'eval_loss_2': 0.003443896770477295, 'eval_loss_3': -18.168821334838867, 'eval_loss_4': 2.7594189643859863, 'epoch': 7.91}
{'loss': 0.0133, 'grad_norm': 7.7436323165893555, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.012612903490662575, 'loss_2': 0.0006814002990722656, 'loss_3': -15.842891693115234, 'loss_4': 2.745309591293335, 'epoch': 7.91}
{'loss': 0.02, 'grad_norm': 9.96316909790039, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.018330786377191544, 'loss_2': 0.001636505126953125, 'loss_3': -16.134313583374023, 'loss_4': 3.2738780975341797, 'epoch': 7.92}
{'loss': 0.0183, 'grad_norm': 8.340692520141602, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.014307125471532345, 'loss_2': 0.004001617431640625, 'loss_3': -15.98181438446045, 'loss_4': 3.2138512134552, 'epoch': 7.92}
{'loss': 0.0187, 'grad_norm': 5.874752521514893, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.010933967307209969, 'loss_2': 0.00775909423828125, 'loss_3': -16.08281898498535, 'loss_4': 3.4930949211120605, 'epoch': 7.93}
{'loss': 0.0203, 'grad_norm': 8.256083488464355, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.017670422792434692, 'loss_2': 0.002613067626953125, 'loss_3': -16.047252655029297, 'loss_4': 3.5732803344726562, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 09:58:11,452 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:11,452 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:00<1:05:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:18,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01333637721836567, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.381, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.009870130568742752, 'eval_loss_2': 0.0034662485122680664, 'eval_loss_3': -18.146333694458008, 'eval_loss_4': 3.508730173110962, 'epoch': 7.94}
{'loss': 0.0082, 'grad_norm': 5.540268421173096, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.008107058703899384, 'loss_2': 0.00010007619857788086, 'loss_3': -16.08960723876953, 'loss_4': 3.6316077709198, 'epoch': 7.94}
{'loss': 0.0146, 'grad_norm': 5.78776741027832, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.011409246362745762, 'loss_2': 0.0031585693359375, 'loss_3': -15.964799880981445, 'loss_4': 4.001893520355225, 'epoch': 7.95}
{'loss': 0.0119, 'grad_norm': 5.511037826538086, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.009907357394695282, 'loss_2': 0.0019435882568359375, 'loss_3': -16.2845401763916, 'loss_4': 3.999480962753296, 'epoch': 7.95}
{'loss': 0.0259, 'grad_norm': 9.945975303649902, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.015487206168472767, 'loss_2': 0.01043701171875, 'loss_3': -16.120357513427734, 'loss_4': 3.6996262073516846, 'epoch': 7.96}
{'loss': 0.031, 'grad_norm': 13.17382526397705, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.02914847992360592, 'loss_2': 0.001804351806640625, 'loss_3': -16.19707489013672, 'loss_4': 4.417015075683594, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 09:58:18,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:18,816 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:08<1:05:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:58:26,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02208312787115574, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012297715060412884, 'eval_loss_2': 0.00978541374206543, 'eval_loss_3': -18.149349212646484, 'eval_loss_4': 3.98848557472229, 'epoch': 7.97}
{'loss': 0.0423, 'grad_norm': 10.843300819396973, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.029520049691200256, 'loss_2': 0.01275634765625, 'loss_3': -16.06371307373047, 'loss_4': 4.551420211791992, 'epoch': 7.97}
{'loss': 0.0316, 'grad_norm': 10.32003402709961, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.01215609535574913, 'loss_2': 0.01947021484375, 'loss_3': -16.084196090698242, 'loss_4': 3.8122925758361816, 'epoch': 7.98}
{'loss': 0.0343, 'grad_norm': 8.060676574707031, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.018685119226574898, 'loss_2': 0.0156402587890625, 'loss_3': -16.11164093017578, 'loss_4': 4.569901466369629, 'epoch': 7.98}
{'loss': 0.0467, 'grad_norm': 10.577156066894531, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.02772105298936367, 'loss_2': 0.0189971923828125, 'loss_3': -15.920488357543945, 'loss_4': 3.961027145385742, 'epoch': 7.99}
{'loss': 0.0431, 'grad_norm': 20.332061767578125, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.03513249754905701, 'loss_2': 0.0079803466796875, 'loss_3': -16.021282196044922, 'loss_4': 4.078523635864258, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 09:58:26,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:26,158 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:15<1:04:13,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:58:33,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018384288996458054, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.885, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01203344576060772, 'eval_loss_2': 0.006350845098495483, 'eval_loss_3': -18.16355323791504, 'eval_loss_4': 4.037784099578857, 'epoch': 7.99}
{'loss': 0.0118, 'grad_norm': 7.997132301330566, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.008740627206861973, 'loss_2': 0.003009796142578125, 'loss_3': -15.728384971618652, 'loss_4': 2.9136037826538086, 'epoch': 8.0}
{'loss': 0.0153, 'grad_norm': 7.263960838317871, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.012661297805607319, 'loss_2': 0.0026397705078125, 'loss_3': -16.15151023864746, 'loss_4': 3.825709581375122, 'epoch': 8.01}
{'loss': 0.0158, 'grad_norm': 6.359385967254639, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.012138623744249344, 'loss_2': 0.003635406494140625, 'loss_3': -16.117916107177734, 'loss_4': 3.9881460666656494, 'epoch': 8.01}
{'loss': 0.0242, 'grad_norm': 6.322630405426025, 'learning_rate': 2.2e-05, 'loss_1': 0.014300769194960594, 'loss_2': 0.00994110107421875, 'loss_3': -16.219768524169922, 'loss_4': 3.6273133754730225, 'epoch': 8.02}
{'loss': 0.0284, 'grad_norm': 7.898090839385986, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.027618464082479477, 'loss_2': 0.0007486343383789062, 'loss_3': -16.052032470703125, 'loss_4': 3.951624870300293, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 09:58:33,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:33,228 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:22<1:05:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:40,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011871082708239555, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.27, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008477197960019112, 'eval_loss_2': 0.0033938847482204437, 'eval_loss_3': -18.194318771362305, 'eval_loss_4': 3.895108699798584, 'epoch': 8.02}
{'loss': 0.0252, 'grad_norm': 15.715948104858398, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.021700898185372353, 'loss_2': 0.003482818603515625, 'loss_3': -16.013599395751953, 'loss_4': 3.954317808151245, 'epoch': 8.03}
{'loss': 0.017, 'grad_norm': 6.39801025390625, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.011766241863369942, 'loss_2': 0.00521087646484375, 'loss_3': -15.961260795593262, 'loss_4': 4.015307426452637, 'epoch': 8.03}
{'loss': 0.0315, 'grad_norm': 10.91280460357666, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.02221977710723877, 'loss_2': 0.009246826171875, 'loss_3': -16.07733917236328, 'loss_4': 4.0542144775390625, 'epoch': 8.04}
{'loss': 0.0293, 'grad_norm': 11.923311233520508, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.020148510113358498, 'loss_2': 0.00913238525390625, 'loss_3': -15.873275756835938, 'loss_4': 3.7568225860595703, 'epoch': 8.05}
{'loss': 0.0237, 'grad_norm': 7.712920665740967, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.016134481877088547, 'loss_2': 0.0075225830078125, 'loss_3': -15.964590072631836, 'loss_4': 3.7728652954101562, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 09:58:40,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:40,588 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:30<1:05:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:47,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018534168601036072, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008417472243309021, 'eval_loss_2': 0.01011669635772705, 'eval_loss_3': -18.20595359802246, 'eval_loss_4': 3.4926199913024902, 'epoch': 8.05}
{'loss': 0.0299, 'grad_norm': 9.632719993591309, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.01997140236198902, 'loss_2': 0.00988006591796875, 'loss_3': -16.295581817626953, 'loss_4': 3.898247003555298, 'epoch': 8.06}
{'loss': 0.0142, 'grad_norm': 5.401585102081299, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.007096081506460905, 'loss_2': 0.007106781005859375, 'loss_3': -16.2598876953125, 'loss_4': 3.5073816776275635, 'epoch': 8.06}
{'loss': 0.0182, 'grad_norm': 5.790843963623047, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.00951730739325285, 'loss_2': 0.0087127685546875, 'loss_3': -16.019729614257812, 'loss_4': 3.7025339603424072, 'epoch': 8.07}
{'loss': 0.0192, 'grad_norm': 6.553096294403076, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.007072636857628822, 'loss_2': 0.01214599609375, 'loss_3': -16.316299438476562, 'loss_4': 3.6137466430664062, 'epoch': 8.08}
{'loss': 0.019, 'grad_norm': 9.326988220214844, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.013103952631354332, 'loss_2': 0.00589752197265625, 'loss_3': -15.888246536254883, 'loss_4': 3.009091854095459, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 09:58:47,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:47,938 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:37<1:05:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:55,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013549592345952988, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.915, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008500988595187664, 'eval_loss_2': 0.005048602819442749, 'eval_loss_3': -18.215530395507812, 'eval_loss_4': 3.0689892768859863, 'epoch': 8.08}
{'loss': 0.0174, 'grad_norm': 10.844625473022461, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.015479747205972672, 'loss_2': 0.0019006729125976562, 'loss_3': -16.042728424072266, 'loss_4': 3.4063682556152344, 'epoch': 8.09}
{'loss': 0.0398, 'grad_norm': 16.827835083007812, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.038542989641427994, 'loss_2': 0.001300811767578125, 'loss_3': -16.051660537719727, 'loss_4': 2.8718104362487793, 'epoch': 8.09}
{'loss': 0.0246, 'grad_norm': 10.65190315246582, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.02144290693104267, 'loss_2': 0.00319671630859375, 'loss_3': -16.291582107543945, 'loss_4': 3.102050304412842, 'epoch': 8.1}
{'loss': 0.0149, 'grad_norm': 6.883176803588867, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.010691516101360321, 'loss_2': 0.0041961669921875, 'loss_3': -16.095272064208984, 'loss_4': 3.7253780364990234, 'epoch': 8.1}
{'loss': 0.0075, 'grad_norm': 5.24847936630249, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.006571460049599409, 'loss_2': 0.0009441375732421875, 'loss_3': -15.993358612060547, 'loss_4': 3.6571950912475586, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 09:58:55,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:55,303 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:44<1:05:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:02,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01465100608766079, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.66, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008140034973621368, 'eval_loss_2': 0.00651097297668457, 'eval_loss_3': -18.230356216430664, 'eval_loss_4': 3.3024797439575195, 'epoch': 8.11}
{'loss': 0.0201, 'grad_norm': 7.139942646026611, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.013539854437112808, 'loss_2': 0.00655364990234375, 'loss_3': -16.038055419921875, 'loss_4': 3.810087203979492, 'epoch': 8.12}
{'loss': 0.0207, 'grad_norm': 8.879595756530762, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.01700775697827339, 'loss_2': 0.0036983489990234375, 'loss_3': -16.038206100463867, 'loss_4': 4.182517051696777, 'epoch': 8.12}
{'loss': 0.0217, 'grad_norm': 5.780849456787109, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.012962906621396542, 'loss_2': 0.00873565673828125, 'loss_3': -16.130735397338867, 'loss_4': 4.079622745513916, 'epoch': 8.13}
{'loss': 0.0386, 'grad_norm': 14.845587730407715, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.03397788852453232, 'loss_2': 0.004604339599609375, 'loss_3': -16.013776779174805, 'loss_4': 3.7521958351135254, 'epoch': 8.13}
{'loss': 0.0288, 'grad_norm': 8.540704727172852, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.017404258251190186, 'loss_2': 0.0113677978515625, 'loss_3': -16.286537170410156, 'loss_4': 4.263227462768555, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 09:59:02,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:02,671 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [34:52<1:05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:10,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014886814169585705, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.117, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009467797353863716, 'eval_loss_2': 0.005419015884399414, 'eval_loss_3': -18.214834213256836, 'eval_loss_4': 3.863375663757324, 'epoch': 8.14}
{'loss': 0.0608, 'grad_norm': 29.040170669555664, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.059813641011714935, 'loss_2': 0.0009813308715820312, 'loss_3': -16.037662506103516, 'loss_4': 4.564232349395752, 'epoch': 8.15}
{'loss': 0.0145, 'grad_norm': 5.590799331665039, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.010921880602836609, 'loss_2': 0.0035858154296875, 'loss_3': -16.29265594482422, 'loss_4': 4.153524398803711, 'epoch': 8.15}
{'loss': 0.0173, 'grad_norm': 10.413604736328125, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.015817703679203987, 'loss_2': 0.00144195556640625, 'loss_3': -16.264747619628906, 'loss_4': 4.425690650939941, 'epoch': 8.16}
{'loss': 0.0134, 'grad_norm': 6.294083118438721, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.012178662233054638, 'loss_2': 0.0012035369873046875, 'loss_3': -16.30438232421875, 'loss_4': 4.660866737365723, 'epoch': 8.16}
{'loss': 0.0146, 'grad_norm': 6.935960292816162, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.011682265438139439, 'loss_2': 0.002925872802734375, 'loss_3': -16.151147842407227, 'loss_4': 4.3604536056518555, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 09:59:10,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:10,031 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [34:59<1:05:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:17,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011922070756554604, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008151833899319172, 'eval_loss_2': 0.003770235925912857, 'eval_loss_3': -18.269813537597656, 'eval_loss_4': 4.523283958435059, 'epoch': 8.17}
{'loss': 0.0198, 'grad_norm': 8.5440092086792, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.015825271606445312, 'loss_2': 0.00392913818359375, 'loss_3': -16.107254028320312, 'loss_4': 4.554759502410889, 'epoch': 8.17}
{'loss': 0.0206, 'grad_norm': 6.466080188751221, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.01679340749979019, 'loss_2': 0.0037994384765625, 'loss_3': -16.179473876953125, 'loss_4': 5.443521499633789, 'epoch': 8.18}
{'loss': 0.0145, 'grad_norm': 6.132943630218506, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.013702591881155968, 'loss_2': 0.0007658004760742188, 'loss_3': -16.217605590820312, 'loss_4': 4.791674613952637, 'epoch': 8.19}
{'loss': 0.0236, 'grad_norm': 12.718794822692871, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.022212574258446693, 'loss_2': 0.0013971328735351562, 'loss_3': -16.19956398010254, 'loss_4': 4.593579292297363, 'epoch': 8.19}
{'loss': 0.0133, 'grad_norm': 5.873709201812744, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.01164883654564619, 'loss_2': 0.0016260147094726562, 'loss_3': -16.358154296875, 'loss_4': 5.613090991973877, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 09:59:17,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:17,392 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:06<1:04:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:24,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011441927403211594, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.758, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007977288216352463, 'eval_loss_2': 0.003464639186859131, 'eval_loss_3': -18.27594757080078, 'eval_loss_4': 4.610923767089844, 'epoch': 8.2}
{'loss': 0.0124, 'grad_norm': 5.469475746154785, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.012195279821753502, 'loss_2': 0.00022101402282714844, 'loss_3': -16.194181442260742, 'loss_4': 5.229148864746094, 'epoch': 8.2}
{'loss': 0.0127, 'grad_norm': 6.2693657875061035, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.011279212310910225, 'loss_2': 0.00146484375, 'loss_3': -16.327783584594727, 'loss_4': 4.83304500579834, 'epoch': 8.21}
{'loss': 0.0179, 'grad_norm': 6.3813347816467285, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.00957254134118557, 'loss_2': 0.00835418701171875, 'loss_3': -16.263341903686523, 'loss_4': 5.073711395263672, 'epoch': 8.22}
{'loss': 0.0228, 'grad_norm': 5.782559394836426, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.012633978389203548, 'loss_2': 0.01012420654296875, 'loss_3': -16.151058197021484, 'loss_4': 4.751943111419678, 'epoch': 8.22}
{'loss': 0.0203, 'grad_norm': 8.413896560668945, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.017370913177728653, 'loss_2': 0.0029201507568359375, 'loss_3': -16.21339225769043, 'loss_4': 4.627686500549316, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 09:59:24,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:24,757 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:14<1:04:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:32,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015295684337615967, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008244931697845459, 'eval_loss_2': 0.007050752639770508, 'eval_loss_3': -18.268688201904297, 'eval_loss_4': 4.383510589599609, 'epoch': 8.23}
{'loss': 0.0263, 'grad_norm': 7.934098720550537, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.016447344794869423, 'loss_2': 0.00981903076171875, 'loss_3': -16.369035720825195, 'loss_4': 4.651968955993652, 'epoch': 8.23}
{'loss': 0.0254, 'grad_norm': 9.130009651184082, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.016737112775444984, 'loss_2': 0.0086669921875, 'loss_3': -16.20412826538086, 'loss_4': 4.714583873748779, 'epoch': 8.24}
{'loss': 0.0229, 'grad_norm': 8.621458053588867, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.0220501609146595, 'loss_2': 0.0008597373962402344, 'loss_3': -16.110496520996094, 'loss_4': 4.9478631019592285, 'epoch': 8.24}
{'loss': 0.0166, 'grad_norm': 5.426693916320801, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.009449440985918045, 'loss_2': 0.00710296630859375, 'loss_3': -16.048765182495117, 'loss_4': 4.537792205810547, 'epoch': 8.25}
{'loss': 0.0182, 'grad_norm': 8.160962104797363, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.016178132966160774, 'loss_2': 0.001995086669921875, 'loss_3': -16.210025787353516, 'loss_4': 5.007480621337891, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 09:59:32,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:32,113 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:21<1:04:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:39,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012116290628910065, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.381, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0069940462708473206, 'eval_loss_2': 0.005122244358062744, 'eval_loss_3': -18.290508270263672, 'eval_loss_4': 4.23155403137207, 'epoch': 8.26}
{'loss': 0.0266, 'grad_norm': 9.297078132629395, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.022280223667621613, 'loss_2': 0.00435638427734375, 'loss_3': -16.219440460205078, 'loss_4': 4.516547203063965, 'epoch': 8.26}
{'loss': 0.0346, 'grad_norm': 11.809934616088867, 'learning_rate': 2.175e-05, 'loss_1': 0.034299686551094055, 'loss_2': 0.0003211498260498047, 'loss_3': -15.982624053955078, 'loss_4': 4.230690956115723, 'epoch': 8.27}
{'loss': 0.0385, 'grad_norm': 21.07288932800293, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.03339611738920212, 'loss_2': 0.00506591796875, 'loss_3': -16.220169067382812, 'loss_4': 4.298048973083496, 'epoch': 8.27}
{'loss': 0.0085, 'grad_norm': 6.944972515106201, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.007717243395745754, 'loss_2': 0.000774383544921875, 'loss_3': -16.04400634765625, 'loss_4': 5.271469593048096, 'epoch': 8.28}
{'loss': 0.0207, 'grad_norm': 7.185145378112793, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.012691622599959373, 'loss_2': 0.0080108642578125, 'loss_3': -16.136974334716797, 'loss_4': 4.469954490661621, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 09:59:39,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:39,483 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:29<1:04:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:46,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012304084375500679, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.063, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006488995160907507, 'eval_loss_2': 0.005815088748931885, 'eval_loss_3': -18.289705276489258, 'eval_loss_4': 4.13347053527832, 'epoch': 8.28}
{'loss': 0.0385, 'grad_norm': 8.817748069763184, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.027415044605731964, 'loss_2': 0.01110076904296875, 'loss_3': -16.097412109375, 'loss_4': 4.533326625823975, 'epoch': 8.29}
{'loss': 0.0199, 'grad_norm': 5.918920993804932, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.008397764526307583, 'loss_2': 0.0114593505859375, 'loss_3': -16.240848541259766, 'loss_4': 3.9813952445983887, 'epoch': 8.3}
{'loss': 0.0121, 'grad_norm': 5.505215167999268, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.007317550014704466, 'loss_2': 0.00473785400390625, 'loss_3': -16.115835189819336, 'loss_4': 5.0705108642578125, 'epoch': 8.3}
{'loss': 0.0263, 'grad_norm': 10.32209587097168, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.0183000136166811, 'loss_2': 0.00800323486328125, 'loss_3': -16.15916633605957, 'loss_4': 5.590564250946045, 'epoch': 8.31}
{'loss': 0.0174, 'grad_norm': 6.744412899017334, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.015680480748414993, 'loss_2': 0.0017366409301757812, 'loss_3': -16.00440216064453, 'loss_4': 4.830891132354736, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 09:59:46,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:46,839 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:36<1:04:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:54,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009582540020346642, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005676737986505032, 'eval_loss_2': 0.0039058029651641846, 'eval_loss_3': -18.284133911132812, 'eval_loss_4': 3.7753286361694336, 'epoch': 8.31}
{'loss': 0.018, 'grad_norm': 10.933372497558594, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.016569064930081367, 'loss_2': 0.0013885498046875, 'loss_3': -16.098695755004883, 'loss_4': 4.23708438873291, 'epoch': 8.32}
{'loss': 0.0146, 'grad_norm': 5.433716773986816, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.008497237227857113, 'loss_2': 0.00614166259765625, 'loss_3': -16.005958557128906, 'loss_4': 4.4972124099731445, 'epoch': 8.33}
{'loss': 0.0261, 'grad_norm': 27.1815185546875, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.024775952100753784, 'loss_2': 0.0012969970703125, 'loss_3': -16.04485321044922, 'loss_4': 3.9115259647369385, 'epoch': 8.33}
{'loss': 0.0095, 'grad_norm': 5.268992900848389, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.005335615482181311, 'loss_2': 0.004150390625, 'loss_3': -16.27638053894043, 'loss_4': 3.6259946823120117, 'epoch': 8.34}
{'loss': 0.0183, 'grad_norm': 9.349100112915039, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.015478517860174179, 'loss_2': 0.0027866363525390625, 'loss_3': -16.090282440185547, 'loss_4': 3.847966194152832, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 09:59:54,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:54,194 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:43<1:04:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:01,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011505426838994026, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005379976239055395, 'eval_loss_2': 0.006125450134277344, 'eval_loss_3': -18.27043342590332, 'eval_loss_4': 3.0844922065734863, 'epoch': 8.34}
{'loss': 0.0107, 'grad_norm': 4.3030924797058105, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.004157208371907473, 'loss_2': 0.006587982177734375, 'loss_3': -16.066682815551758, 'loss_4': 3.3387398719787598, 'epoch': 8.35}
{'loss': 0.0087, 'grad_norm': 6.003830432891846, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.007323939818888903, 'loss_2': 0.0013608932495117188, 'loss_3': -16.360437393188477, 'loss_4': 3.32865834236145, 'epoch': 8.35}
{'loss': 0.0283, 'grad_norm': 12.636946678161621, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.023070216178894043, 'loss_2': 0.00521087646484375, 'loss_3': -16.110645294189453, 'loss_4': 3.8647878170013428, 'epoch': 8.36}
{'loss': 0.0233, 'grad_norm': 9.451335906982422, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.014225850813090801, 'loss_2': 0.0090789794921875, 'loss_3': -16.104162216186523, 'loss_4': 3.518693685531616, 'epoch': 8.37}
{'loss': 0.0132, 'grad_norm': 5.60103178024292, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.007772988639771938, 'loss_2': 0.00537872314453125, 'loss_3': -16.125349044799805, 'loss_4': 2.8575873374938965, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 10:00:01,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:01,546 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [35:51<1:04:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:08,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008518524467945099, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.003894099034368992, 'eval_loss_2': 0.004624426364898682, 'eval_loss_3': -18.26665496826172, 'eval_loss_4': 2.7951974868774414, 'epoch': 8.37}
{'loss': 0.0205, 'grad_norm': 6.844001293182373, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.014851628802716732, 'loss_2': 0.00567626953125, 'loss_3': -16.243419647216797, 'loss_4': 2.7773592472076416, 'epoch': 8.38}
{'loss': 0.0112, 'grad_norm': 5.354488372802734, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.008027501404285431, 'loss_2': 0.00321197509765625, 'loss_3': -16.20294189453125, 'loss_4': 2.970249652862549, 'epoch': 8.38}
{'loss': 0.0149, 'grad_norm': 4.817347526550293, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.005392330698668957, 'loss_2': 0.00949859619140625, 'loss_3': -16.121389389038086, 'loss_4': 3.050715446472168, 'epoch': 8.39}
{'loss': 0.0135, 'grad_norm': 7.3714823722839355, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.010720046237111092, 'loss_2': 0.002826690673828125, 'loss_3': -16.284217834472656, 'loss_4': 2.889247417449951, 'epoch': 8.4}
{'loss': 0.0164, 'grad_norm': 14.661776542663574, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.016025640070438385, 'loss_2': 0.0003707408905029297, 'loss_3': -16.320768356323242, 'loss_4': 3.135662317276001, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 10:00:08,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:08,896 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [35:58<1:04:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:16,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008871614001691341, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.673, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0053641339763998985, 'eval_loss_2': 0.003507480025291443, 'eval_loss_3': -18.269290924072266, 'eval_loss_4': 2.8470659255981445, 'epoch': 8.4}
{'loss': 0.0174, 'grad_norm': 5.184231758117676, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.009697765111923218, 'loss_2': 0.00768280029296875, 'loss_3': -16.069684982299805, 'loss_4': 3.1252732276916504, 'epoch': 8.41}
{'loss': 0.012, 'grad_norm': 5.6293816566467285, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.011000417172908783, 'loss_2': 0.0009698867797851562, 'loss_3': -16.246479034423828, 'loss_4': 2.657817840576172, 'epoch': 8.41}
{'loss': 0.0137, 'grad_norm': 5.860535621643066, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.010084090754389763, 'loss_2': 0.003658294677734375, 'loss_3': -16.125314712524414, 'loss_4': 2.812455177307129, 'epoch': 8.42}
{'loss': 0.0187, 'grad_norm': 8.067850112915039, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.017593154683709145, 'loss_2': 0.001117706298828125, 'loss_3': -16.396886825561523, 'loss_4': 2.9083194732666016, 'epoch': 8.42}
{'loss': 0.0254, 'grad_norm': 12.784708023071289, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.01731528900563717, 'loss_2': 0.008087158203125, 'loss_3': -16.304872512817383, 'loss_4': 2.523444890975952, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 10:00:16,255 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:16,256 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:05<1:04:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:23,604 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01378033310174942, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.031, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008950859308242798, 'eval_loss_2': 0.004829473793506622, 'eval_loss_3': -18.254657745361328, 'eval_loss_4': 2.7679555416107178, 'epoch': 8.43}
{'loss': 0.0219, 'grad_norm': 13.295056343078613, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.017628265544772148, 'loss_2': 0.00423431396484375, 'loss_3': -16.28720474243164, 'loss_4': 2.5925588607788086, 'epoch': 8.44}
{'loss': 0.0314, 'grad_norm': 11.478381156921387, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.02941477857530117, 'loss_2': 0.0020160675048828125, 'loss_3': -16.1569766998291, 'loss_4': 2.8540210723876953, 'epoch': 8.44}
{'loss': 0.0251, 'grad_norm': 12.43432903289795, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.02273651212453842, 'loss_2': 0.002315521240234375, 'loss_3': -16.209033966064453, 'loss_4': 3.3232085704803467, 'epoch': 8.45}
{'loss': 0.0187, 'grad_norm': 6.56227445602417, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.013802911154925823, 'loss_2': 0.0048675537109375, 'loss_3': -16.066059112548828, 'loss_4': 2.9086668491363525, 'epoch': 8.45}
{'loss': 0.0106, 'grad_norm': 4.749847888946533, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.008628259412944317, 'loss_2': 0.001987457275390625, 'loss_3': -16.24509620666504, 'loss_4': 2.9785680770874023, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 10:00:23,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:23,604 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:13<1:04:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:30,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020112011581659317, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011893426068127155, 'eval_loss_2': 0.008218586444854736, 'eval_loss_3': -18.268693923950195, 'eval_loss_4': 2.8769147396087646, 'epoch': 8.46}
{'loss': 0.0201, 'grad_norm': 8.914274215698242, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.017789272591471672, 'loss_2': 0.002338409423828125, 'loss_3': -15.981820106506348, 'loss_4': 3.6820425987243652, 'epoch': 8.47}
{'loss': 0.0303, 'grad_norm': 15.573152542114258, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.026264389976859093, 'loss_2': 0.0040435791015625, 'loss_3': -16.151779174804688, 'loss_4': 2.4464688301086426, 'epoch': 8.47}
{'loss': 0.0305, 'grad_norm': 6.965555667877197, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.022100510075688362, 'loss_2': 0.00843048095703125, 'loss_3': -16.379741668701172, 'loss_4': 3.5259199142456055, 'epoch': 8.48}
{'loss': 0.0169, 'grad_norm': 8.560897827148438, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.014282546006143093, 'loss_2': 0.002613067626953125, 'loss_3': -16.206283569335938, 'loss_4': 3.079683780670166, 'epoch': 8.48}
{'loss': 0.0275, 'grad_norm': 10.224213600158691, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.022713065147399902, 'loss_2': 0.00479888916015625, 'loss_3': -16.14689064025879, 'loss_4': 2.9194841384887695, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 10:00:30,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:30,959 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:20<1:03:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:38,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015030097216367722, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01111615914851427, 'eval_loss_2': 0.003913938999176025, 'eval_loss_3': -18.29584312438965, 'eval_loss_4': 2.8063480854034424, 'epoch': 8.49}
{'loss': 0.0137, 'grad_norm': 5.426323413848877, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.010526313446462154, 'loss_2': 0.0031375885009765625, 'loss_3': -16.40526008605957, 'loss_4': 3.2641077041625977, 'epoch': 8.49}
{'loss': 0.0172, 'grad_norm': 6.06040620803833, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.01388333085924387, 'loss_2': 0.003284454345703125, 'loss_3': -16.219493865966797, 'loss_4': 2.834120750427246, 'epoch': 8.5}
{'loss': 0.0219, 'grad_norm': 8.309676170349121, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.014672010205686092, 'loss_2': 0.007198333740234375, 'loss_3': -16.30724334716797, 'loss_4': 2.391165256500244, 'epoch': 8.51}
{'loss': 0.0284, 'grad_norm': 7.8632917404174805, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.02126172184944153, 'loss_2': 0.0071258544921875, 'loss_3': -16.417362213134766, 'loss_4': 2.5516812801361084, 'epoch': 8.51}
{'loss': 0.0256, 'grad_norm': 8.716240882873535, 'learning_rate': 2.15e-05, 'loss_1': 0.019919052720069885, 'loss_2': 0.0056610107421875, 'loss_3': -16.38748550415039, 'loss_4': 2.9036331176757812, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 10:00:38,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:38,310 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:27<1:03:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:45,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013550628907978535, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.198, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008230317384004593, 'eval_loss_2': 0.005320310592651367, 'eval_loss_3': -18.380661010742188, 'eval_loss_4': 2.3364787101745605, 'epoch': 8.52}
{'loss': 0.0243, 'grad_norm': 7.39169454574585, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.021286828443408012, 'loss_2': 0.002986907958984375, 'loss_3': -16.257038116455078, 'loss_4': 2.7701401710510254, 'epoch': 8.52}
{'loss': 0.0174, 'grad_norm': 6.624600410461426, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.01646505296230316, 'loss_2': 0.00092315673828125, 'loss_3': -16.403242111206055, 'loss_4': 2.2736315727233887, 'epoch': 8.53}
{'loss': 0.0139, 'grad_norm': 5.377938270568848, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.012901010923087597, 'loss_2': 0.0009927749633789062, 'loss_3': -16.337186813354492, 'loss_4': 2.3428845405578613, 'epoch': 8.53}
{'loss': 0.0177, 'grad_norm': 7.2571024894714355, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.015974484384059906, 'loss_2': 0.00170135498046875, 'loss_3': -16.384170532226562, 'loss_4': 1.893741250038147, 'epoch': 8.54}
{'loss': 0.0298, 'grad_norm': 10.70422649383545, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.02420532889664173, 'loss_2': 0.005615234375, 'loss_3': -16.408767700195312, 'loss_4': 2.220630168914795, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 10:00:45,656 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:45,656 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:35<1:03:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:52,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01143448706716299, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.405, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0072021097876131535, 'eval_loss_2': 0.00423237681388855, 'eval_loss_3': -18.32916831970215, 'eval_loss_4': 1.9646127223968506, 'epoch': 8.55}
{'loss': 0.0185, 'grad_norm': 6.198202133178711, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.016939712688326836, 'loss_2': 0.00154876708984375, 'loss_3': -16.276470184326172, 'loss_4': 2.109729766845703, 'epoch': 8.55}
{'loss': 0.0371, 'grad_norm': 12.239180564880371, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.03350419923663139, 'loss_2': 0.003627777099609375, 'loss_3': -16.165048599243164, 'loss_4': 2.30067777633667, 'epoch': 8.56}
{'loss': 0.0248, 'grad_norm': 12.943110466003418, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.02354380115866661, 'loss_2': 0.00125885009765625, 'loss_3': -16.158863067626953, 'loss_4': 2.2092490196228027, 'epoch': 8.56}
{'loss': 0.0164, 'grad_norm': 6.173584461212158, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.013557824306190014, 'loss_2': 0.002811431884765625, 'loss_3': -16.383426666259766, 'loss_4': 1.5776259899139404, 'epoch': 8.57}
{'loss': 0.0248, 'grad_norm': 13.326045989990234, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.018141020089387894, 'loss_2': 0.006683349609375, 'loss_3': -16.606529235839844, 'loss_4': 2.8795676231384277, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 10:00:52,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:52,997 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:42<1:03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:00,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008935734629631042, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.229, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.0054680705070495605, 'eval_loss_2': 0.003467664122581482, 'eval_loss_3': -18.33342933654785, 'eval_loss_4': 1.740615725517273, 'epoch': 8.58}
{'loss': 0.0261, 'grad_norm': 7.976675987243652, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.01776396669447422, 'loss_2': 0.00835418701171875, 'loss_3': -16.267288208007812, 'loss_4': 2.6968836784362793, 'epoch': 8.58}
{'loss': 0.0119, 'grad_norm': 6.329828262329102, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.011723274365067482, 'loss_2': 0.00018262863159179688, 'loss_3': -16.47776985168457, 'loss_4': 1.9683233499526978, 'epoch': 8.59}
{'loss': 0.0456, 'grad_norm': 10.756041526794434, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.04301445558667183, 'loss_2': 0.00260162353515625, 'loss_3': -16.329936981201172, 'loss_4': 1.799678087234497, 'epoch': 8.59}
{'loss': 0.0211, 'grad_norm': 8.415730476379395, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.016777558252215385, 'loss_2': 0.0042877197265625, 'loss_3': -16.332473754882812, 'loss_4': 1.8236398696899414, 'epoch': 8.6}
{'loss': 0.0199, 'grad_norm': 10.986457824707031, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.01753385178744793, 'loss_2': 0.002399444580078125, 'loss_3': -16.506065368652344, 'loss_4': 1.7115073204040527, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 10:01:00,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:00,359 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [36:49<1:03:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:07,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008726898580789566, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.783, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005663249175995588, 'eval_loss_2': 0.0030636489391326904, 'eval_loss_3': -18.276508331298828, 'eval_loss_4': 1.322967767715454, 'epoch': 8.6}
{'loss': 0.0136, 'grad_norm': 6.1921796798706055, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.010187443345785141, 'loss_2': 0.003459930419921875, 'loss_3': -16.36408233642578, 'loss_4': 1.5528810024261475, 'epoch': 8.61}
{'loss': 0.0212, 'grad_norm': 7.005995273590088, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.01980041153728962, 'loss_2': 0.0013942718505859375, 'loss_3': -16.287559509277344, 'loss_4': 0.8899632096290588, 'epoch': 8.62}
{'loss': 0.0226, 'grad_norm': 7.2253289222717285, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.015568793751299381, 'loss_2': 0.00699615478515625, 'loss_3': -16.062612533569336, 'loss_4': 1.6782097816467285, 'epoch': 8.62}
{'loss': 0.0126, 'grad_norm': 5.901004314422607, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.012041960842907429, 'loss_2': 0.0005092620849609375, 'loss_3': -16.366455078125, 'loss_4': 1.2450635433197021, 'epoch': 8.63}
{'loss': 0.0244, 'grad_norm': 8.434630393981934, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.01829436793923378, 'loss_2': 0.006114959716796875, 'loss_3': -16.256690979003906, 'loss_4': 1.583303689956665, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 10:01:07,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:07,712 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [36:57<1:03:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:15,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009062502533197403, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.858, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0052323415875434875, 'eval_loss_2': 0.0038301609456539154, 'eval_loss_3': -18.24995231628418, 'eval_loss_4': 1.0619944334030151, 'epoch': 8.63}
{'loss': 0.0176, 'grad_norm': 6.94685173034668, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.014446905814111233, 'loss_2': 0.003139495849609375, 'loss_3': -16.049558639526367, 'loss_4': 1.5422589778900146, 'epoch': 8.64}
{'loss': 0.0195, 'grad_norm': 10.03460693359375, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.01841340959072113, 'loss_2': 0.0011310577392578125, 'loss_3': -16.211875915527344, 'loss_4': 1.3188115358352661, 'epoch': 8.65}
{'loss': 0.0138, 'grad_norm': 5.717053413391113, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.009518866427242756, 'loss_2': 0.004245758056640625, 'loss_3': -16.197906494140625, 'loss_4': 1.0331562757492065, 'epoch': 8.65}
{'loss': 0.0171, 'grad_norm': 6.11293888092041, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.010619607754051685, 'loss_2': 0.00650787353515625, 'loss_3': -16.21693992614746, 'loss_4': 1.3118174076080322, 'epoch': 8.66}
{'loss': 0.0286, 'grad_norm': 12.017772674560547, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.027663983404636383, 'loss_2': 0.0009107589721679688, 'loss_3': -16.167070388793945, 'loss_4': 1.5385701656341553, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 10:01:15,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:15,066 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:04<1:03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:22,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008803053759038448, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004885183647274971, 'eval_loss_2': 0.003917869180440903, 'eval_loss_3': -18.238719940185547, 'eval_loss_4': 0.5875810384750366, 'epoch': 8.66}
{'loss': 0.0139, 'grad_norm': 7.211401462554932, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.012910011224448681, 'loss_2': 0.0009722709655761719, 'loss_3': -16.126893997192383, 'loss_4': 0.6947177648544312, 'epoch': 8.67}
{'loss': 0.0232, 'grad_norm': 8.3125638961792, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.020559310913085938, 'loss_2': 0.00267791748046875, 'loss_3': -16.161386489868164, 'loss_4': 0.7367382049560547, 'epoch': 8.67}
{'loss': 0.0307, 'grad_norm': 16.223817825317383, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.024957504123449326, 'loss_2': 0.00569915771484375, 'loss_3': -16.31403350830078, 'loss_4': 0.8017961978912354, 'epoch': 8.68}
{'loss': 0.0097, 'grad_norm': 5.280763626098633, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.00888755451887846, 'loss_2': 0.0008244514465332031, 'loss_3': -16.39872169494629, 'loss_4': 0.5980785489082336, 'epoch': 8.69}
{'loss': 0.0155, 'grad_norm': 6.726811408996582, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.013638783246278763, 'loss_2': 0.0018596649169921875, 'loss_3': -16.263704299926758, 'loss_4': 0.6348446607589722, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 10:01:22,415 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:22,415 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:11<1:03:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:29,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008620957843959332, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004179324023425579, 'eval_loss_2': 0.0044416338205337524, 'eval_loss_3': -18.25084686279297, 'eval_loss_4': 0.255520761013031, 'epoch': 8.69}
{'loss': 0.0211, 'grad_norm': 9.529929161071777, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.02097442001104355, 'loss_2': 9.167194366455078e-05, 'loss_3': -16.36984634399414, 'loss_4': 0.16748662292957306, 'epoch': 8.7}
{'loss': 0.0285, 'grad_norm': 10.72509479522705, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.02387123368680477, 'loss_2': 0.0045928955078125, 'loss_3': -16.026865005493164, 'loss_4': 0.6255935430526733, 'epoch': 8.7}
{'loss': 0.0091, 'grad_norm': 5.204063892364502, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.006835045758634806, 'loss_2': 0.00231170654296875, 'loss_3': -16.216800689697266, 'loss_4': 1.4804699420928955, 'epoch': 8.71}
{'loss': 0.0141, 'grad_norm': 6.051913261413574, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.01303250901401043, 'loss_2': 0.0011119842529296875, 'loss_3': -16.24441909790039, 'loss_4': 1.1131620407104492, 'epoch': 8.72}
{'loss': 0.0139, 'grad_norm': 7.0156145095825195, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.013025856576859951, 'loss_2': 0.000888824462890625, 'loss_3': -16.204376220703125, 'loss_4': 0.6702042818069458, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 10:01:29,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:29,766 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:19<1:03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:37,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010757414624094963, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.724, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00475790910422802, 'eval_loss_2': 0.005999505519866943, 'eval_loss_3': -18.287109375, 'eval_loss_4': 0.3312298059463501, 'epoch': 8.72}
{'loss': 0.0219, 'grad_norm': 7.783911228179932, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.017432916909456253, 'loss_2': 0.0044403076171875, 'loss_3': -16.317581176757812, 'loss_4': 0.9503331780433655, 'epoch': 8.73}
{'loss': 0.0183, 'grad_norm': 5.761849880218506, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.01040166150778532, 'loss_2': 0.00787353515625, 'loss_3': -16.26992416381836, 'loss_4': 0.9462435245513916, 'epoch': 8.73}
{'loss': 0.0275, 'grad_norm': 7.987896919250488, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.016029035672545433, 'loss_2': 0.011505126953125, 'loss_3': -16.45175552368164, 'loss_4': 0.34774771332740784, 'epoch': 8.74}
{'loss': 0.0162, 'grad_norm': 5.469924449920654, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.010162525810301304, 'loss_2': 0.00600433349609375, 'loss_3': -16.14204978942871, 'loss_4': 1.0208652019500732, 'epoch': 8.74}
{'loss': 0.0232, 'grad_norm': 12.990863800048828, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.022800777107477188, 'loss_2': 0.00035381317138671875, 'loss_3': -16.234416961669922, 'loss_4': 0.4091948866844177, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 10:01:37,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:37,117 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:26<1:03:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:44,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00952520128339529, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.969, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004640898667275906, 'eval_loss_2': 0.004884302616119385, 'eval_loss_3': -18.2996826171875, 'eval_loss_4': 0.3518761396408081, 'epoch': 8.75}
{'loss': 0.0252, 'grad_norm': 12.882057189941406, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.024739300832152367, 'loss_2': 0.0004374980926513672, 'loss_3': -16.0224609375, 'loss_4': 1.181248664855957, 'epoch': 8.76}
{'loss': 0.0205, 'grad_norm': 7.386552333831787, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.01682581566274166, 'loss_2': 0.003662109375, 'loss_3': -16.143449783325195, 'loss_4': 0.3421627879142761, 'epoch': 8.76}
{'loss': 0.0164, 'grad_norm': 8.421537399291992, 'learning_rate': 2.125e-05, 'loss_1': 0.011602072045207024, 'loss_2': 0.00479888916015625, 'loss_3': -16.29709243774414, 'loss_4': 1.401289463043213, 'epoch': 8.77}
{'loss': 0.0304, 'grad_norm': 12.971081733703613, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.027686670422554016, 'loss_2': 0.002685546875, 'loss_3': -15.929486274719238, 'loss_4': 1.3340253829956055, 'epoch': 8.77}
{'loss': 0.0105, 'grad_norm': 5.215261459350586, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.00838085263967514, 'loss_2': 0.002162933349609375, 'loss_3': -16.291698455810547, 'loss_4': 0.6902836561203003, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 10:01:44,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:44,470 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:33<1:03:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:51,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009492699056863785, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004913392011076212, 'eval_loss_2': 0.004579305648803711, 'eval_loss_3': -18.284692764282227, 'eval_loss_4': 0.7496041059494019, 'epoch': 8.78}
{'loss': 0.0135, 'grad_norm': 4.80560302734375, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.008393720723688602, 'loss_2': 0.0051116943359375, 'loss_3': -16.11161994934082, 'loss_4': 0.6539357304573059, 'epoch': 8.78}
{'loss': 0.014, 'grad_norm': 5.030498504638672, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.008286122232675552, 'loss_2': 0.00568389892578125, 'loss_3': -16.163280487060547, 'loss_4': 0.9726089239120483, 'epoch': 8.79}
{'loss': 0.0295, 'grad_norm': 8.515254974365234, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.0177666787058115, 'loss_2': 0.0117645263671875, 'loss_3': -15.983071327209473, 'loss_4': 1.4144117832183838, 'epoch': 8.8}
{'loss': 0.0235, 'grad_norm': 11.689906120300293, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.022341705858707428, 'loss_2': 0.0011425018310546875, 'loss_3': -16.125568389892578, 'loss_4': 1.190434217453003, 'epoch': 8.8}
{'loss': 0.0718, 'grad_norm': 26.53813934326172, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.06777697801589966, 'loss_2': 0.00397491455078125, 'loss_3': -16.09286880493164, 'loss_4': 1.2300820350646973, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 10:01:51,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:51,823 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:41<1:02:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:59,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009062344208359718, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.655, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005286404397338629, 'eval_loss_2': 0.0037759393453598022, 'eval_loss_3': -18.2843074798584, 'eval_loss_4': 1.1316531896591187, 'epoch': 8.81}
{'loss': 0.0442, 'grad_norm': 18.522655487060547, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.04159187152981758, 'loss_2': 0.002655029296875, 'loss_3': -16.344219207763672, 'loss_4': 1.5102834701538086, 'epoch': 8.81}
{'loss': 0.0145, 'grad_norm': 7.582817077636719, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.011200769804418087, 'loss_2': 0.0032501220703125, 'loss_3': -16.051755905151367, 'loss_4': 1.0989537239074707, 'epoch': 8.82}
{'loss': 0.02, 'grad_norm': 11.440290451049805, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.019507355988025665, 'loss_2': 0.0004799365997314453, 'loss_3': -16.192092895507812, 'loss_4': 1.5479652881622314, 'epoch': 8.83}
{'loss': 0.0102, 'grad_norm': 5.3401079177856445, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.0068826824426651, 'loss_2': 0.00328826904296875, 'loss_3': -16.165687561035156, 'loss_4': 1.4061177968978882, 'epoch': 8.83}
{'loss': 0.0143, 'grad_norm': 7.473197937011719, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.012826040387153625, 'loss_2': 0.0014820098876953125, 'loss_3': -15.903385162353516, 'loss_4': 1.3684844970703125, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 10:01:59,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:59,175 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [37:48<1:02:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:06,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009375074878334999, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.532, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.00528893806040287, 'eval_loss_2': 0.004086136817932129, 'eval_loss_3': -18.302274703979492, 'eval_loss_4': 1.3685270547866821, 'epoch': 8.84}
{'loss': 0.0127, 'grad_norm': 5.5635294914245605, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.008928508497774601, 'loss_2': 0.00372314453125, 'loss_3': -16.240524291992188, 'loss_4': 2.0721654891967773, 'epoch': 8.84}
{'loss': 0.0185, 'grad_norm': 6.519171237945557, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.014776576310396194, 'loss_2': 0.003734588623046875, 'loss_3': -16.2623233795166, 'loss_4': 1.5678448677062988, 'epoch': 8.85}
{'loss': 0.035, 'grad_norm': 16.56320571899414, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.03338678181171417, 'loss_2': 0.0015668869018554688, 'loss_3': -16.048891067504883, 'loss_4': 1.6939358711242676, 'epoch': 8.85}
{'loss': 0.0217, 'grad_norm': 8.97045612335205, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.021443836390972137, 'loss_2': 0.00023877620697021484, 'loss_3': -16.265886306762695, 'loss_4': 2.1117944717407227, 'epoch': 8.86}
{'loss': 0.0245, 'grad_norm': 8.950953483581543, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.01784636452794075, 'loss_2': 0.00662994384765625, 'loss_3': -16.180831909179688, 'loss_4': 2.6121182441711426, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 10:02:06,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:06,532 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [37:56<1:02:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:13,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01209348626434803, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.924, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006956056226044893, 'eval_loss_2': 0.005137428641319275, 'eval_loss_3': -18.30773162841797, 'eval_loss_4': 1.990281343460083, 'epoch': 8.87}
{'loss': 0.0054, 'grad_norm': 5.041200637817383, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.0051780762150883675, 'loss_2': 0.0002276897430419922, 'loss_3': -16.35289192199707, 'loss_4': 1.9663217067718506, 'epoch': 8.87}
{'loss': 0.0144, 'grad_norm': 6.500545501708984, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.01131688803434372, 'loss_2': 0.0030651092529296875, 'loss_3': -16.303661346435547, 'loss_4': 2.6865737438201904, 'epoch': 8.88}
{'loss': 0.0205, 'grad_norm': 7.5263824462890625, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.01625112071633339, 'loss_2': 0.0042572021484375, 'loss_3': -16.295015335083008, 'loss_4': 2.385540008544922, 'epoch': 8.88}
{'loss': 0.016, 'grad_norm': 7.0426788330078125, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.013856123201549053, 'loss_2': 0.0021457672119140625, 'loss_3': -16.105060577392578, 'loss_4': 2.755079984664917, 'epoch': 8.89}
{'loss': 0.0189, 'grad_norm': 5.743470191955566, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.012513035908341408, 'loss_2': 0.006381988525390625, 'loss_3': -16.185396194458008, 'loss_4': 2.4063119888305664, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 10:02:13,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:13,896 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:03<1:02:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:21,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013218197971582413, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.335, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.008797083981335163, 'eval_loss_2': 0.004421114921569824, 'eval_loss_3': -18.322193145751953, 'eval_loss_4': 2.10654878616333, 'epoch': 8.9}
{'loss': 0.0447, 'grad_norm': 14.517230987548828, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.044105660170316696, 'loss_2': 0.0005555152893066406, 'loss_3': -16.408794403076172, 'loss_4': 2.1470470428466797, 'epoch': 8.9}
{'loss': 0.0183, 'grad_norm': 8.930448532104492, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.016233166679739952, 'loss_2': 0.0020904541015625, 'loss_3': -16.396610260009766, 'loss_4': 2.5636353492736816, 'epoch': 8.91}
{'loss': 0.0217, 'grad_norm': 10.22692584991455, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.02095302753150463, 'loss_2': 0.0007443428039550781, 'loss_3': -16.354427337646484, 'loss_4': 2.4030160903930664, 'epoch': 8.91}
{'loss': 0.0833, 'grad_norm': 19.719451904296875, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.07258648425340652, 'loss_2': 0.0107421875, 'loss_3': -16.393407821655273, 'loss_4': 3.140249729156494, 'epoch': 8.92}
{'loss': 0.0173, 'grad_norm': 8.043931007385254, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.01546453032642603, 'loss_2': 0.0018072128295898438, 'loss_3': -16.260574340820312, 'loss_4': 2.8198604583740234, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 10:02:21,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:21,254 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:10<1:02:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:28,611 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013948176056146622, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.828, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009742949157953262, 'eval_loss_2': 0.004205226898193359, 'eval_loss_3': -18.338342666625977, 'eval_loss_4': 2.248769521713257, 'epoch': 8.92}
{'loss': 0.0152, 'grad_norm': 6.065475940704346, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.015029674395918846, 'loss_2': 0.0002027750015258789, 'loss_3': -16.270864486694336, 'loss_4': 2.325713872909546, 'epoch': 8.93}
{'loss': 0.0263, 'grad_norm': 10.831387519836426, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.020352261140942574, 'loss_2': 0.005985260009765625, 'loss_3': -16.35245704650879, 'loss_4': 3.177168130874634, 'epoch': 8.94}
{'loss': 0.0218, 'grad_norm': 8.166572570800781, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.020470350980758667, 'loss_2': 0.0012845993041992188, 'loss_3': -16.28986358642578, 'loss_4': 2.3850953578948975, 'epoch': 8.94}
{'loss': 0.019, 'grad_norm': 7.451767444610596, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.014392551966011524, 'loss_2': 0.004650115966796875, 'loss_3': -16.263717651367188, 'loss_4': 2.81789493560791, 'epoch': 8.95}
{'loss': 0.0236, 'grad_norm': 5.191705703735352, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.008980175480246544, 'loss_2': 0.0146026611328125, 'loss_3': -16.169536590576172, 'loss_4': 2.6051883697509766, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 10:02:28,611 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:28,611 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:18<1:02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:35,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014154171571135521, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00959760695695877, 'eval_loss_2': 0.004556566476821899, 'eval_loss_3': -18.32011604309082, 'eval_loss_4': 2.3680074214935303, 'epoch': 8.95}
{'loss': 0.0295, 'grad_norm': 14.630562782287598, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.0280846506357193, 'loss_2': 0.0014133453369140625, 'loss_3': -16.34956169128418, 'loss_4': 3.111217498779297, 'epoch': 8.96}
{'loss': 0.0175, 'grad_norm': 6.895264148712158, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.01598198711872101, 'loss_2': 0.0015048980712890625, 'loss_3': -16.17937469482422, 'loss_4': 2.8018438816070557, 'epoch': 8.97}
{'loss': 0.0073, 'grad_norm': 5.018397808074951, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.007311014458537102, 'loss_2': 1.2516975402832031e-05, 'loss_3': -16.29708480834961, 'loss_4': 3.0782885551452637, 'epoch': 8.97}
{'loss': 0.0097, 'grad_norm': 5.473801612854004, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.008397235535085201, 'loss_2': 0.001331329345703125, 'loss_3': -16.151836395263672, 'loss_4': 2.2343711853027344, 'epoch': 8.98}
{'loss': 0.0178, 'grad_norm': 6.590815544128418, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.013157774694263935, 'loss_2': 0.0046539306640625, 'loss_3': -15.958427429199219, 'loss_4': 2.5428309440612793, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 10:02:35,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:35,964 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:25<59:52,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 10:02:42,998 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013579271733760834, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009840048849582672, 'eval_loss_2': 0.0037392228841781616, 'eval_loss_3': -18.296932220458984, 'eval_loss_4': 2.1962549686431885, 'epoch': 8.98}
{'loss': 0.0167, 'grad_norm': 5.776731491088867, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.009916823357343674, 'loss_2': 0.00677490234375, 'loss_3': -16.30642318725586, 'loss_4': 2.1938681602478027, 'epoch': 8.99}
{'loss': 0.0313, 'grad_norm': 9.66894817352295, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.029726918786764145, 'loss_2': 0.001529693603515625, 'loss_3': -16.03484344482422, 'loss_4': 2.934192419052124, 'epoch': 8.99}
{'loss': 0.0097, 'grad_norm': 6.90274715423584, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.006303240079432726, 'loss_2': 0.00334930419921875, 'loss_3': -16.38353729248047, 'loss_4': 1.9423141479492188, 'epoch': 9.0}
{'loss': 0.0205, 'grad_norm': 6.366549015045166, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.016111936420202255, 'loss_2': 0.004428863525390625, 'loss_3': -16.065649032592773, 'loss_4': 2.043593406677246, 'epoch': 9.01}
{'loss': 0.0202, 'grad_norm': 7.695653915405273, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.015321820974349976, 'loss_2': 0.0048675537109375, 'loss_3': -16.015928268432617, 'loss_4': 2.0989747047424316, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 10:02:42,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:42,998 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:32<1:01:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:02:50,354 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014625223353505135, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.958, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010680937208235264, 'eval_loss_2': 0.003944285213947296, 'eval_loss_3': -18.28171157836914, 'eval_loss_4': 1.9284158945083618, 'epoch': 9.01}
{'loss': 0.0168, 'grad_norm': 6.601505279541016, 'learning_rate': 2.1e-05, 'loss_1': 0.014262062497437, 'loss_2': 0.0025768280029296875, 'loss_3': -16.309040069580078, 'loss_4': 2.262234687805176, 'epoch': 9.02}
{'loss': 0.012, 'grad_norm': 7.431161403656006, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.011341058649122715, 'loss_2': 0.0006990432739257812, 'loss_3': -16.27627182006836, 'loss_4': 1.3855714797973633, 'epoch': 9.02}
{'loss': 0.0195, 'grad_norm': 7.823647975921631, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.016717446967959404, 'loss_2': 0.0027675628662109375, 'loss_3': -16.302001953125, 'loss_4': 2.282731533050537, 'epoch': 9.03}
{'loss': 0.0189, 'grad_norm': 7.395843029022217, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.014163168147206306, 'loss_2': 0.004726409912109375, 'loss_3': -16.299808502197266, 'loss_4': 2.38565993309021, 'epoch': 9.03}
{'loss': 0.0237, 'grad_norm': 10.651529312133789, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.02115115337073803, 'loss_2': 0.002552032470703125, 'loss_3': -15.845712661743164, 'loss_4': 2.8830504417419434, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 10:02:50,354 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:50,354 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:39<1:02:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:57,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013407940044999123, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.127, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.00902714766561985, 'eval_loss_2': 0.0043807923793792725, 'eval_loss_3': -18.2655086517334, 'eval_loss_4': 1.983306884765625, 'epoch': 9.04}
{'loss': 0.0175, 'grad_norm': 8.128630638122559, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.017404574900865555, 'loss_2': 9.119510650634766e-05, 'loss_3': -16.096790313720703, 'loss_4': 2.2151224613189697, 'epoch': 9.05}
{'loss': 0.0168, 'grad_norm': 7.538667678833008, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.014635497704148293, 'loss_2': 0.002155303955078125, 'loss_3': -16.101146697998047, 'loss_4': 2.6560966968536377, 'epoch': 9.05}
{'loss': 0.0231, 'grad_norm': 7.623437881469727, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.014777797274291515, 'loss_2': 0.00836181640625, 'loss_3': -16.346675872802734, 'loss_4': 2.530996084213257, 'epoch': 9.06}
{'loss': 0.0287, 'grad_norm': 9.43446159362793, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.02748742513358593, 'loss_2': 0.0012607574462890625, 'loss_3': -16.166282653808594, 'loss_4': 2.7163901329040527, 'epoch': 9.06}
{'loss': 0.0197, 'grad_norm': 7.173231601715088, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.01557356771081686, 'loss_2': 0.00415802001953125, 'loss_3': -16.170230865478516, 'loss_4': 1.9825764894485474, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 10:02:57,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:57,725 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [38:47<1:02:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:05,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012254628352820873, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.861, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0085088349878788, 'eval_loss_2': 0.0037457942962646484, 'eval_loss_3': -18.273977279663086, 'eval_loss_4': 1.936263084411621, 'epoch': 9.07}
{'loss': 0.0241, 'grad_norm': 7.40134859085083, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.02132805623114109, 'loss_2': 0.0028076171875, 'loss_3': -16.282207489013672, 'loss_4': 2.3842062950134277, 'epoch': 9.08}
{'loss': 0.0112, 'grad_norm': 6.08818244934082, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.010054727084934711, 'loss_2': 0.0011615753173828125, 'loss_3': -16.091880798339844, 'loss_4': 2.259916305541992, 'epoch': 9.08}
{'loss': 0.021, 'grad_norm': 5.744623184204102, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.015585130080580711, 'loss_2': 0.005458831787109375, 'loss_3': -16.339920043945312, 'loss_4': 2.121816635131836, 'epoch': 9.09}
{'loss': 0.0214, 'grad_norm': 6.7593793869018555, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.015369041822850704, 'loss_2': 0.006008148193359375, 'loss_3': -16.06647491455078, 'loss_4': 2.4534895420074463, 'epoch': 9.09}
{'loss': 0.0301, 'grad_norm': 10.426088333129883, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.02921278588473797, 'loss_2': 0.0008869171142578125, 'loss_3': -15.963995933532715, 'loss_4': 2.5965676307678223, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 10:03:05,085 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:05,085 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [38:54<1:02:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:12,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013484037481248379, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.143, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009208633564412594, 'eval_loss_2': 0.004275403916835785, 'eval_loss_3': -18.270856857299805, 'eval_loss_4': 1.4994953870773315, 'epoch': 9.1}
{'loss': 0.0191, 'grad_norm': 9.792402267456055, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.017100859433412552, 'loss_2': 0.0020389556884765625, 'loss_3': -16.19495964050293, 'loss_4': 1.9675941467285156, 'epoch': 9.1}
{'loss': 0.0232, 'grad_norm': 8.058207511901855, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.02062225341796875, 'loss_2': 0.0026092529296875, 'loss_3': -16.446849822998047, 'loss_4': 2.4737095832824707, 'epoch': 9.11}
{'loss': 0.0213, 'grad_norm': 9.572072982788086, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.020460082218050957, 'loss_2': 0.0008592605590820312, 'loss_3': -16.288753509521484, 'loss_4': 1.9505295753479004, 'epoch': 9.12}
{'loss': 0.0153, 'grad_norm': 5.051669597625732, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.009261430241167545, 'loss_2': 0.00606536865234375, 'loss_3': -16.44058609008789, 'loss_4': 2.0198192596435547, 'epoch': 9.12}
{'loss': 0.032, 'grad_norm': 7.175889492034912, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.01677560620009899, 'loss_2': 0.01525115966796875, 'loss_3': -16.04569435119629, 'loss_4': 2.1636476516723633, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 10:03:12,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:12,440 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:01<1:02:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:19,787 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017036903649568558, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010236966423690319, 'eval_loss_2': 0.006799936294555664, 'eval_loss_3': -18.337217330932617, 'eval_loss_4': 1.2375980615615845, 'epoch': 9.13}
{'loss': 0.0378, 'grad_norm': 9.221585273742676, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.030516181141138077, 'loss_2': 0.00724029541015625, 'loss_3': -16.21834945678711, 'loss_4': 0.9484519958496094, 'epoch': 9.13}
{'loss': 0.0255, 'grad_norm': 7.882541179656982, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.019004493951797485, 'loss_2': 0.00652313232421875, 'loss_3': -16.187061309814453, 'loss_4': 2.0387167930603027, 'epoch': 9.14}
{'loss': 0.0322, 'grad_norm': 12.989178657531738, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.027636507526040077, 'loss_2': 0.00457763671875, 'loss_3': -16.285322189331055, 'loss_4': 1.8700807094573975, 'epoch': 9.15}
{'loss': 0.0289, 'grad_norm': 9.818410873413086, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.024321364238858223, 'loss_2': 0.00453948974609375, 'loss_3': -16.219266891479492, 'loss_4': 2.0776278972625732, 'epoch': 9.15}
{'loss': 0.0409, 'grad_norm': 18.139894485473633, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.03649997338652611, 'loss_2': 0.0043792724609375, 'loss_3': -16.089740753173828, 'loss_4': 1.7820123434066772, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 10:03:19,787 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:19,787 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:09<1:01:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:27,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01270163431763649, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.125, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009327460080385208, 'eval_loss_2': 0.0033741742372512817, 'eval_loss_3': -18.312902450561523, 'eval_loss_4': 1.332777976989746, 'epoch': 9.16}
{'loss': 0.0147, 'grad_norm': 4.790197372436523, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.009514421224594116, 'loss_2': 0.00521087646484375, 'loss_3': -16.37125015258789, 'loss_4': 1.532421350479126, 'epoch': 9.16}
{'loss': 0.0603, 'grad_norm': 15.75973129272461, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.056716468185186386, 'loss_2': 0.0035858154296875, 'loss_3': -16.08713722229004, 'loss_4': 1.977778673171997, 'epoch': 9.17}
{'loss': 0.0227, 'grad_norm': 7.084163188934326, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.017075933516025543, 'loss_2': 0.005615234375, 'loss_3': -16.150775909423828, 'loss_4': 2.441915512084961, 'epoch': 9.17}
{'loss': 0.0194, 'grad_norm': 7.993929386138916, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.014540057629346848, 'loss_2': 0.0048980712890625, 'loss_3': -16.22807502746582, 'loss_4': 2.2560105323791504, 'epoch': 9.18}
{'loss': 0.0407, 'grad_norm': 11.960105895996094, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.033456992357969284, 'loss_2': 0.007282257080078125, 'loss_3': -16.37333106994629, 'loss_4': 1.9829473495483398, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 10:03:27,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:27,136 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:16<1:01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:34,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011338437907397747, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.823, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008698340505361557, 'eval_loss_2': 0.0026400983333587646, 'eval_loss_3': -18.31189727783203, 'eval_loss_4': 1.4629358053207397, 'epoch': 9.19}
{'loss': 0.0397, 'grad_norm': 21.480653762817383, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.03781035542488098, 'loss_2': 0.0018520355224609375, 'loss_3': -16.309188842773438, 'loss_4': 1.9381475448608398, 'epoch': 9.19}
{'loss': 0.0227, 'grad_norm': 8.491827011108398, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.020620819181203842, 'loss_2': 0.0020427703857421875, 'loss_3': -16.253482818603516, 'loss_4': 2.021535873413086, 'epoch': 9.2}
{'loss': 0.0173, 'grad_norm': 6.112881660461426, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.011698519811034203, 'loss_2': 0.00559234619140625, 'loss_3': -15.946537017822266, 'loss_4': 2.7963879108428955, 'epoch': 9.2}
{'loss': 0.0206, 'grad_norm': 6.253362655639648, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.013540410436689854, 'loss_2': 0.007083892822265625, 'loss_3': -16.287769317626953, 'loss_4': 1.8204346895217896, 'epoch': 9.21}
{'loss': 0.0279, 'grad_norm': 8.723794937133789, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.018773553892970085, 'loss_2': 0.009124755859375, 'loss_3': -16.221546173095703, 'loss_4': 1.2634161710739136, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 10:03:34,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:34,490 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:24<1:01:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:41,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016380250453948975, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.507, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.007355392910540104, 'eval_loss_2': 0.009024858474731445, 'eval_loss_3': -18.292268753051758, 'eval_loss_4': 1.480851650238037, 'epoch': 9.22}
{'loss': 0.037, 'grad_norm': 13.286383628845215, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.03229796513915062, 'loss_2': 0.004657745361328125, 'loss_3': -16.331279754638672, 'loss_4': 1.983205795288086, 'epoch': 9.22}
{'loss': 0.021, 'grad_norm': 6.861209392547607, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.016016045585274696, 'loss_2': 0.00502777099609375, 'loss_3': -16.20339012145996, 'loss_4': 1.8877315521240234, 'epoch': 9.23}
{'loss': 0.0194, 'grad_norm': 6.733060836791992, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.015397601760923862, 'loss_2': 0.00399017333984375, 'loss_3': -16.312620162963867, 'loss_4': 1.6892399787902832, 'epoch': 9.23}
{'loss': 0.0483, 'grad_norm': 35.39948272705078, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.041941720992326736, 'loss_2': 0.00638580322265625, 'loss_3': -16.183996200561523, 'loss_4': 2.3249075412750244, 'epoch': 9.24}
{'loss': 0.017, 'grad_norm': 6.205714225769043, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.011451005935668945, 'loss_2': 0.00554656982421875, 'loss_3': -16.19253921508789, 'loss_4': 2.334975242614746, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 10:03:41,847 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:41,847 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:31<1:01:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:49,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01405059453099966, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.309, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0066782147623598576, 'eval_loss_2': 0.007372379302978516, 'eval_loss_3': -18.25663185119629, 'eval_loss_4': 1.6914466619491577, 'epoch': 9.24}
{'loss': 0.0211, 'grad_norm': 5.966088771820068, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.013902106322348118, 'loss_2': 0.007232666015625, 'loss_3': -16.231224060058594, 'loss_4': 2.0292506217956543, 'epoch': 9.25}
{'loss': 0.0174, 'grad_norm': 6.495611667633057, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.010991081595420837, 'loss_2': 0.00644683837890625, 'loss_3': -16.371671676635742, 'loss_4': 2.3999838829040527, 'epoch': 9.26}
{'loss': 0.0079, 'grad_norm': 5.45355749130249, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.0070403157733380795, 'loss_2': 0.0008206367492675781, 'loss_3': -16.298858642578125, 'loss_4': 2.4661359786987305, 'epoch': 9.26}
{'loss': 0.0104, 'grad_norm': 6.4999518394470215, 'learning_rate': 2.075e-05, 'loss_1': 0.010390538722276688, 'loss_2': 2.0265579223632812e-05, 'loss_3': -16.041296005249023, 'loss_4': 2.555022716522217, 'epoch': 9.27}
{'loss': 0.0157, 'grad_norm': 6.253565311431885, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.0130232572555542, 'loss_2': 0.002635955810546875, 'loss_3': -16.34726905822754, 'loss_4': 2.3994641304016113, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 10:03:49,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:49,195 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:38<1:01:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:56,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010363991372287273, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.153, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007178882602602243, 'eval_loss_2': 0.0031851083040237427, 'eval_loss_3': -18.23162841796875, 'eval_loss_4': 1.9079713821411133, 'epoch': 9.27}
{'loss': 0.019, 'grad_norm': 6.356376647949219, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.013753269799053669, 'loss_2': 0.00525665283203125, 'loss_3': -16.257936477661133, 'loss_4': 1.852722406387329, 'epoch': 9.28}
{'loss': 0.0206, 'grad_norm': 8.876873016357422, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.018955985084176064, 'loss_2': 0.0016202926635742188, 'loss_3': -16.25101661682129, 'loss_4': 2.327620267868042, 'epoch': 9.28}
{'loss': 0.0775, 'grad_norm': 19.232118606567383, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.07694133371114731, 'loss_2': 0.0005340576171875, 'loss_3': -16.134679794311523, 'loss_4': 2.4612069129943848, 'epoch': 9.29}
{'loss': 0.0131, 'grad_norm': 5.8443379402160645, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.009656145237386227, 'loss_2': 0.0034236907958984375, 'loss_3': -16.257530212402344, 'loss_4': 1.9715986251831055, 'epoch': 9.3}
{'loss': 0.0095, 'grad_norm': 5.364469051361084, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.004575866274535656, 'loss_2': 0.0049591064453125, 'loss_3': -16.130552291870117, 'loss_4': 2.039879560470581, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 10:03:56,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:56,546 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [39:46<1:01:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:03,900 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015223067253828049, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009843099862337112, 'eval_loss_2': 0.005379967391490936, 'eval_loss_3': -18.25019073486328, 'eval_loss_4': 2.1839804649353027, 'epoch': 9.3}
{'loss': 0.0206, 'grad_norm': 8.362785339355469, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.015931515023112297, 'loss_2': 0.0046234130859375, 'loss_3': -16.194686889648438, 'loss_4': 2.6557745933532715, 'epoch': 9.31}
{'loss': 0.0319, 'grad_norm': 19.596372604370117, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.02835162915289402, 'loss_2': 0.0035037994384765625, 'loss_3': -16.20769500732422, 'loss_4': 2.093247890472412, 'epoch': 9.31}
{'loss': 0.0209, 'grad_norm': 10.307305335998535, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.012237784452736378, 'loss_2': 0.0086669921875, 'loss_3': -16.31714630126953, 'loss_4': 2.333209753036499, 'epoch': 9.32}
{'loss': 0.0134, 'grad_norm': 4.922579288482666, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.008208755403757095, 'loss_2': 0.005229949951171875, 'loss_3': -16.125553131103516, 'loss_4': 2.551608085632324, 'epoch': 9.33}
{'loss': 0.0083, 'grad_norm': 5.164524078369141, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.005542177241295576, 'loss_2': 0.0027866363525390625, 'loss_3': -16.09013557434082, 'loss_4': 2.1098175048828125, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 10:04:03,900 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:03,900 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [39:53<1:01:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:11,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01611177995800972, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010382834821939468, 'eval_loss_2': 0.0057289451360702515, 'eval_loss_3': -18.247570037841797, 'eval_loss_4': 2.115436315536499, 'epoch': 9.33}
{'loss': 0.0124, 'grad_norm': 5.641219615936279, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.004947591107338667, 'loss_2': 0.00745391845703125, 'loss_3': -16.346782684326172, 'loss_4': 2.43087100982666, 'epoch': 9.34}
{'loss': 0.0111, 'grad_norm': 6.405032634735107, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.006819256581366062, 'loss_2': 0.00423431396484375, 'loss_3': -16.17778778076172, 'loss_4': 2.5847673416137695, 'epoch': 9.34}
{'loss': 0.0339, 'grad_norm': 16.072032928466797, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.02775115706026554, 'loss_2': 0.00611114501953125, 'loss_3': -16.18183708190918, 'loss_4': 2.0610098838806152, 'epoch': 9.35}
{'loss': 0.0102, 'grad_norm': 5.578620910644531, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.007190338335931301, 'loss_2': 0.00301361083984375, 'loss_3': -15.950798034667969, 'loss_4': 2.106398820877075, 'epoch': 9.35}
{'loss': 0.007, 'grad_norm': 5.444887638092041, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.005995411891490221, 'loss_2': 0.0009775161743164062, 'loss_3': -16.44390869140625, 'loss_4': 2.4020886421203613, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 10:04:11,252 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:11,252 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:00<1:01:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:18,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0123938312754035, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.537, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009711443446576595, 'eval_loss_2': 0.0026823878288269043, 'eval_loss_3': -18.237985610961914, 'eval_loss_4': 1.9514471292495728, 'epoch': 9.36}
{'loss': 0.0235, 'grad_norm': 11.678110122680664, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.022759361192584038, 'loss_2': 0.0007038116455078125, 'loss_3': -16.222509384155273, 'loss_4': 2.2006843090057373, 'epoch': 9.37}
{'loss': 0.012, 'grad_norm': 8.225157737731934, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.011739663779735565, 'loss_2': 0.0002589225769042969, 'loss_3': -16.12479019165039, 'loss_4': 1.657233476638794, 'epoch': 9.37}
{'loss': 0.0134, 'grad_norm': 5.504685878753662, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.008500599302351475, 'loss_2': 0.00492095947265625, 'loss_3': -16.208118438720703, 'loss_4': 1.6505446434020996, 'epoch': 9.38}
{'loss': 0.0168, 'grad_norm': 10.888412475585938, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.0144300302490592, 'loss_2': 0.00237274169921875, 'loss_3': -16.234851837158203, 'loss_4': 1.9090886116027832, 'epoch': 9.38}
{'loss': 0.0362, 'grad_norm': 27.27964973449707, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.03472253307700157, 'loss_2': 0.001514434814453125, 'loss_3': -16.057764053344727, 'loss_4': 2.7358598709106445, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 10:04:18,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:18,615 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:08<1:01:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:25,961 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012435756623744965, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.235, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008751609362661839, 'eval_loss_2': 0.0036841481924057007, 'eval_loss_3': -18.231693267822266, 'eval_loss_4': 1.6814364194869995, 'epoch': 9.39}
{'loss': 0.0271, 'grad_norm': 10.364217758178711, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.016165418550372124, 'loss_2': 0.01092529296875, 'loss_3': -16.151151657104492, 'loss_4': 2.542526960372925, 'epoch': 9.4}
{'loss': 0.0103, 'grad_norm': 5.056866645812988, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.004770806524902582, 'loss_2': 0.00554656982421875, 'loss_3': -16.203975677490234, 'loss_4': 1.2215790748596191, 'epoch': 9.4}
{'loss': 0.0125, 'grad_norm': 6.687302112579346, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.008821605704724789, 'loss_2': 0.003726959228515625, 'loss_3': -16.220661163330078, 'loss_4': 2.222977876663208, 'epoch': 9.41}
{'loss': 0.011, 'grad_norm': 5.745695114135742, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.009320101700723171, 'loss_2': 0.0016765594482421875, 'loss_3': -16.30694007873535, 'loss_4': 1.6838746070861816, 'epoch': 9.41}
{'loss': 0.0148, 'grad_norm': 5.179490566253662, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.007831078954041004, 'loss_2': 0.00699615478515625, 'loss_3': -16.176441192626953, 'loss_4': 2.2721445560455322, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 10:04:25,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:25,962 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:15<1:01:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:33,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0124350031837821, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006598039995878935, 'eval_loss_2': 0.005836963653564453, 'eval_loss_3': -18.25145149230957, 'eval_loss_4': 1.6638036966323853, 'epoch': 9.42}
{'loss': 0.0207, 'grad_norm': 10.371261596679688, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.012929515913128853, 'loss_2': 0.007785797119140625, 'loss_3': -15.994964599609375, 'loss_4': 1.9191067218780518, 'epoch': 9.42}
{'loss': 0.0172, 'grad_norm': 9.83170223236084, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.014281023293733597, 'loss_2': 0.002899169921875, 'loss_3': -16.18148422241211, 'loss_4': 1.5003798007965088, 'epoch': 9.43}
{'loss': 0.0175, 'grad_norm': 5.5646562576293945, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.006247900892049074, 'loss_2': 0.0112152099609375, 'loss_3': -16.24433708190918, 'loss_4': 2.0419812202453613, 'epoch': 9.44}
{'loss': 0.0201, 'grad_norm': 6.7965497970581055, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.010439376346766949, 'loss_2': 0.009613037109375, 'loss_3': -16.355480194091797, 'loss_4': 2.240063190460205, 'epoch': 9.44}
{'loss': 0.0126, 'grad_norm': 6.845885753631592, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.010490217246115208, 'loss_2': 0.0020771026611328125, 'loss_3': -16.359949111938477, 'loss_4': 1.9030944108963013, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 10:04:33,316 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:33,316 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:22<1:00:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:40,657 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015600466169416904, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007981502451002598, 'eval_loss_2': 0.007618963718414307, 'eval_loss_3': -18.268308639526367, 'eval_loss_4': 1.775323510169983, 'epoch': 9.45}
{'loss': 0.0162, 'grad_norm': 6.756103038787842, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.00881284847855568, 'loss_2': 0.00737762451171875, 'loss_3': -16.158489227294922, 'loss_4': 1.9802942276000977, 'epoch': 9.45}
{'loss': 0.0187, 'grad_norm': 6.457333564758301, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.01314551942050457, 'loss_2': 0.00559234619140625, 'loss_3': -16.047101974487305, 'loss_4': 2.143462657928467, 'epoch': 9.46}
{'loss': 0.0187, 'grad_norm': 8.238187789916992, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.017343655228614807, 'loss_2': 0.00133514404296875, 'loss_3': -16.228261947631836, 'loss_4': 1.5133709907531738, 'epoch': 9.47}
{'loss': 0.0065, 'grad_norm': 5.406276226043701, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.005446288734674454, 'loss_2': 0.0010061264038085938, 'loss_3': -16.155698776245117, 'loss_4': 1.767885684967041, 'epoch': 9.47}
{'loss': 0.0102, 'grad_norm': 5.925014972686768, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.008667650632560253, 'loss_2': 0.00150299072265625, 'loss_3': -16.418270111083984, 'loss_4': 1.4567334651947021, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 10:04:40,657 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:40,657 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:30<1:00:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:48,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011608753353357315, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007487851195037365, 'eval_loss_2': 0.0041209012269973755, 'eval_loss_3': -18.343395233154297, 'eval_loss_4': 1.5464861392974854, 'epoch': 9.48}
{'loss': 0.0328, 'grad_norm': 16.990158081054688, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.029767876490950584, 'loss_2': 0.003009796142578125, 'loss_3': -16.40741729736328, 'loss_4': 2.1053993701934814, 'epoch': 9.48}
{'loss': 0.0236, 'grad_norm': 5.499834060668945, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.01114906556904316, 'loss_2': 0.012451171875, 'loss_3': -16.474166870117188, 'loss_4': 2.5344338417053223, 'epoch': 9.49}
{'loss': 0.0153, 'grad_norm': 5.704679012298584, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.007581278681755066, 'loss_2': 0.007720947265625, 'loss_3': -16.520877838134766, 'loss_4': 2.1353402137756348, 'epoch': 9.49}
{'loss': 0.0297, 'grad_norm': 5.992974758148193, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.011238208040595055, 'loss_2': 0.018463134765625, 'loss_3': -16.219873428344727, 'loss_4': 1.9551243782043457, 'epoch': 9.5}
{'loss': 0.0356, 'grad_norm': 19.236780166625977, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.024165358394384384, 'loss_2': 0.01142120361328125, 'loss_3': -16.445615768432617, 'loss_4': 2.3563032150268555, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 10:04:48,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:48,009 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:37<1:00:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:55,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013642888516187668, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.812, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006312217563390732, 'eval_loss_2': 0.007330670952796936, 'eval_loss_3': -18.38138198852539, 'eval_loss_4': 1.728341817855835, 'epoch': 9.51}
{'loss': 0.0181, 'grad_norm': 5.1847405433654785, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.007161904126405716, 'loss_2': 0.010955810546875, 'loss_3': -16.238311767578125, 'loss_4': 2.2994532585144043, 'epoch': 9.51}
{'loss': 0.0207, 'grad_norm': 6.223523139953613, 'learning_rate': 2.05e-05, 'loss_1': 0.007567989639937878, 'loss_2': 0.01308441162109375, 'loss_3': -16.42865753173828, 'loss_4': 3.003183603286743, 'epoch': 9.52}
{'loss': 0.0188, 'grad_norm': 7.101069927215576, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.011975456029176712, 'loss_2': 0.006847381591796875, 'loss_3': -16.232860565185547, 'loss_4': 2.9513509273529053, 'epoch': 9.52}
{'loss': 0.0156, 'grad_norm': 5.95791482925415, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.011856833472847939, 'loss_2': 0.003757476806640625, 'loss_3': -16.44615364074707, 'loss_4': 2.3580336570739746, 'epoch': 9.53}
{'loss': 0.0186, 'grad_norm': 6.861858367919922, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.010522464290261269, 'loss_2': 0.00811767578125, 'loss_3': -16.319364547729492, 'loss_4': 3.2031912803649902, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 10:04:55,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:55,366 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [40:44<1:00:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:02,735 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01094394363462925, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.233, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.00604994036257267, 'eval_loss_2': 0.00489400327205658, 'eval_loss_3': -18.3991641998291, 'eval_loss_4': 2.079061269760132, 'epoch': 9.53}
{'loss': 0.0115, 'grad_norm': 5.0464677810668945, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.007197722792625427, 'loss_2': 0.0043487548828125, 'loss_3': -16.226478576660156, 'loss_4': 2.77695631980896, 'epoch': 9.54}
{'loss': 0.0274, 'grad_norm': 13.816892623901367, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.025569884106516838, 'loss_2': 0.001811981201171875, 'loss_3': -16.316781997680664, 'loss_4': 3.0353784561157227, 'epoch': 9.55}
{'loss': 0.0126, 'grad_norm': 6.561089992523193, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.00891305785626173, 'loss_2': 0.003734588623046875, 'loss_3': -16.304542541503906, 'loss_4': 2.525968074798584, 'epoch': 9.55}
{'loss': 0.021, 'grad_norm': 7.220086574554443, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.01296379417181015, 'loss_2': 0.0080108642578125, 'loss_3': -16.326068878173828, 'loss_4': 2.777675151824951, 'epoch': 9.56}
{'loss': 0.0129, 'grad_norm': 5.181142330169678, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.0063780141063034534, 'loss_2': 0.006534576416015625, 'loss_3': -16.438793182373047, 'loss_4': 3.206299066543579, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 10:05:02,735 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:02,735 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [40:52<1:00:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:10,091 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012913930229842663, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00536416657269001, 'eval_loss_2': 0.007549762725830078, 'eval_loss_3': -18.387771606445312, 'eval_loss_4': 2.064175844192505, 'epoch': 9.56}
{'loss': 0.0332, 'grad_norm': 14.053122520446777, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.026741880923509598, 'loss_2': 0.006439208984375, 'loss_3': -16.50665855407715, 'loss_4': 3.1809520721435547, 'epoch': 9.57}
{'loss': 0.0168, 'grad_norm': 10.140300750732422, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.011805443093180656, 'loss_2': 0.004962921142578125, 'loss_3': -16.251379013061523, 'loss_4': 2.530064105987549, 'epoch': 9.58}
{'loss': 0.0214, 'grad_norm': 9.282783508300781, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.015910174697637558, 'loss_2': 0.00547027587890625, 'loss_3': -16.251689910888672, 'loss_4': 3.031193256378174, 'epoch': 9.58}
{'loss': 0.0279, 'grad_norm': 9.724745750427246, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.019567742943763733, 'loss_2': 0.0083465576171875, 'loss_3': -16.295269012451172, 'loss_4': 3.6209444999694824, 'epoch': 9.59}
{'loss': 0.0134, 'grad_norm': 7.064505577087402, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.009021816775202751, 'loss_2': 0.004364013671875, 'loss_3': -16.445045471191406, 'loss_4': 2.299740791320801, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 10:05:10,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:10,092 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [40:59<1:00:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:17,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008355304598808289, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.94, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005837544798851013, 'eval_loss_2': 0.0025177597999572754, 'eval_loss_3': -18.402456283569336, 'eval_loss_4': 1.4166903495788574, 'epoch': 9.59}
{'loss': 0.0315, 'grad_norm': 10.683165550231934, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.027286024764180183, 'loss_2': 0.00417327880859375, 'loss_3': -16.305580139160156, 'loss_4': 2.1539814472198486, 'epoch': 9.6}
{'loss': 0.0167, 'grad_norm': 6.509730815887451, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.012059696950018406, 'loss_2': 0.004604339599609375, 'loss_3': -16.443918228149414, 'loss_4': 2.325751781463623, 'epoch': 9.6}
{'loss': 0.0161, 'grad_norm': 7.208805561065674, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.01477985829114914, 'loss_2': 0.0012798309326171875, 'loss_3': -16.398788452148438, 'loss_4': 2.2765588760375977, 'epoch': 9.61}
{'loss': 0.0131, 'grad_norm': 5.921145439147949, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.01115462090820074, 'loss_2': 0.00199127197265625, 'loss_3': -16.227767944335938, 'loss_4': 1.3178071975708008, 'epoch': 9.62}
{'loss': 0.0169, 'grad_norm': 5.894682884216309, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.012053745798766613, 'loss_2': 0.0048828125, 'loss_3': -16.438514709472656, 'loss_4': 2.13321590423584, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 10:05:17,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:17,449 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:06<1:00:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:24,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010983932763338089, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00845955777913332, 'eval_loss_2': 0.0025243759155273438, 'eval_loss_3': -18.434167861938477, 'eval_loss_4': 1.1749441623687744, 'epoch': 9.62}
{'loss': 0.0329, 'grad_norm': 9.96720027923584, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.030232347548007965, 'loss_2': 0.002620697021484375, 'loss_3': -16.416976928710938, 'loss_4': 1.8946630954742432, 'epoch': 9.63}
{'loss': 0.0325, 'grad_norm': 11.912269592285156, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.030384035781025887, 'loss_2': 0.0021209716796875, 'loss_3': -16.349027633666992, 'loss_4': 1.3822283744812012, 'epoch': 9.63}
{'loss': 0.0273, 'grad_norm': 7.807408332824707, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.023761814460158348, 'loss_2': 0.003536224365234375, 'loss_3': -16.520397186279297, 'loss_4': 1.7648762464523315, 'epoch': 9.64}
{'loss': 0.0341, 'grad_norm': 7.939484596252441, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.03146929666399956, 'loss_2': 0.002590179443359375, 'loss_3': -16.32721710205078, 'loss_4': 1.5237457752227783, 'epoch': 9.65}
{'loss': 0.0436, 'grad_norm': 11.10100269317627, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.03962089866399765, 'loss_2': 0.004001617431640625, 'loss_3': -16.489910125732422, 'loss_4': 1.4926857948303223, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 10:05:24,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:24,804 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:14<1:00:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:32,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017041604965925217, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010894106701016426, 'eval_loss_2': 0.006147496402263641, 'eval_loss_3': -18.44206428527832, 'eval_loss_4': 1.2419151067733765, 'epoch': 9.65}
{'loss': 0.0366, 'grad_norm': 8.858278274536133, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.030248373746871948, 'loss_2': 0.006378173828125, 'loss_3': -16.29970932006836, 'loss_4': 1.3722143173217773, 'epoch': 9.66}
{'loss': 0.0484, 'grad_norm': 16.02034568786621, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.042402733117341995, 'loss_2': 0.005950927734375, 'loss_3': -16.51824188232422, 'loss_4': 2.118913173675537, 'epoch': 9.66}
{'loss': 0.0179, 'grad_norm': 5.929488182067871, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.016661250963807106, 'loss_2': 0.0012388229370117188, 'loss_3': -16.341360092163086, 'loss_4': 2.8283135890960693, 'epoch': 9.67}
{'loss': 0.0243, 'grad_norm': 7.626431465148926, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.023119276389479637, 'loss_2': 0.001224517822265625, 'loss_3': -16.3187255859375, 'loss_4': 2.464503765106201, 'epoch': 9.67}
{'loss': 0.0453, 'grad_norm': 11.784937858581543, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.04181808978319168, 'loss_2': 0.0035247802734375, 'loss_3': -16.361473083496094, 'loss_4': 1.827242374420166, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 10:05:32,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:32,160 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:21<1:00:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:39,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012502371333539486, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.629, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008948626928031445, 'eval_loss_2': 0.0035537444055080414, 'eval_loss_3': -18.39647102355957, 'eval_loss_4': 1.6193630695343018, 'epoch': 9.68}
{'loss': 0.0256, 'grad_norm': 7.674014091491699, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.024929501116275787, 'loss_2': 0.0006966590881347656, 'loss_3': -16.443801879882812, 'loss_4': 2.151002883911133, 'epoch': 9.69}
{'loss': 0.0222, 'grad_norm': 8.4883394241333, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.021189361810684204, 'loss_2': 0.00104522705078125, 'loss_3': -16.391855239868164, 'loss_4': 2.8187031745910645, 'epoch': 9.69}
{'loss': 0.0264, 'grad_norm': 8.642377853393555, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.02139957994222641, 'loss_2': 0.0050201416015625, 'loss_3': -16.353450775146484, 'loss_4': 2.904139995574951, 'epoch': 9.7}
{'loss': 0.0342, 'grad_norm': 11.597188949584961, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.02769448608160019, 'loss_2': 0.0065460205078125, 'loss_3': -16.196346282958984, 'loss_4': 2.7822513580322266, 'epoch': 9.7}
{'loss': 0.0591, 'grad_norm': 19.51297378540039, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.0515114888548851, 'loss_2': 0.00757598876953125, 'loss_3': -16.392192840576172, 'loss_4': 2.011643409729004, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 10:05:39,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:39,524 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:29<1:01:06,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:05:47,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010119175538420677, 'eval_runtime': 4.0037, 'eval_samples_per_second': 255.766, 'eval_steps_per_second': 3.996, 'eval_loss_1': 0.007439886219799519, 'eval_loss_2': 0.002679288387298584, 'eval_loss_3': -18.35434913635254, 'eval_loss_4': 1.950231909751892, 'epoch': 9.71}
{'loss': 0.0199, 'grad_norm': 7.356010913848877, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.01764693669974804, 'loss_2': 0.002231597900390625, 'loss_3': -16.328556060791016, 'loss_4': 2.3258614540100098, 'epoch': 9.72}
{'loss': 0.026, 'grad_norm': 7.064732551574707, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.02242058701813221, 'loss_2': 0.003574371337890625, 'loss_3': -16.26228141784668, 'loss_4': 3.1041932106018066, 'epoch': 9.72}
{'loss': 0.0275, 'grad_norm': 8.043059349060059, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.019396094605326653, 'loss_2': 0.008056640625, 'loss_3': -16.400856018066406, 'loss_4': 3.020612955093384, 'epoch': 9.73}
{'loss': 0.0252, 'grad_norm': 12.498720169067383, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.02487308718264103, 'loss_2': 0.00036334991455078125, 'loss_3': -16.355955123901367, 'loss_4': 2.6548266410827637, 'epoch': 9.73}
{'loss': 0.0206, 'grad_norm': 5.573790550231934, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.01223766803741455, 'loss_2': 0.0083465576171875, 'loss_3': -16.318944931030273, 'loss_4': 2.6021642684936523, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 10:05:47,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:47,069 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:36<1:00:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:54,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010020882822573185, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007067838218063116, 'eval_loss_2': 0.002953045070171356, 'eval_loss_3': -18.342206954956055, 'eval_loss_4': 1.9883038997650146, 'epoch': 9.74}
{'loss': 0.0192, 'grad_norm': 8.195466041564941, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.014820817857980728, 'loss_2': 0.00434112548828125, 'loss_3': -16.141496658325195, 'loss_4': 2.323504686355591, 'epoch': 9.74}
{'loss': 0.0144, 'grad_norm': 7.027896404266357, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.013297982513904572, 'loss_2': 0.0011444091796875, 'loss_3': -16.27408790588379, 'loss_4': 2.927258014678955, 'epoch': 9.75}
{'loss': 0.044, 'grad_norm': 11.89509391784668, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.04006334766745567, 'loss_2': 0.003902435302734375, 'loss_3': -16.34164047241211, 'loss_4': 1.8355973958969116, 'epoch': 9.76}
{'loss': 0.0281, 'grad_norm': 12.943453788757324, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.027653053402900696, 'loss_2': 0.0004661083221435547, 'loss_3': -16.184432983398438, 'loss_4': 3.1038646697998047, 'epoch': 9.76}
{'loss': 0.0151, 'grad_norm': 8.927865982055664, 'learning_rate': 2.025e-05, 'loss_1': 0.014846278354525566, 'loss_2': 0.0002841949462890625, 'loss_3': -16.431163787841797, 'loss_4': 2.4232676029205322, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 10:05:54,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:54,416 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [41:43<1:00:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:01,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011777877807617188, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008317079395055771, 'eval_loss_2': 0.0034607984125614166, 'eval_loss_3': -18.341386795043945, 'eval_loss_4': 1.8766522407531738, 'epoch': 9.77}
{'loss': 0.019, 'grad_norm': 6.8539652824401855, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.016465501859784126, 'loss_2': 0.0025196075439453125, 'loss_3': -16.422555923461914, 'loss_4': 2.7131547927856445, 'epoch': 9.77}
{'loss': 0.0153, 'grad_norm': 6.068204879760742, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.014088488183915615, 'loss_2': 0.0012149810791015625, 'loss_3': -16.394556045532227, 'loss_4': 2.199849843978882, 'epoch': 9.78}
{'loss': 0.0251, 'grad_norm': 8.420744895935059, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.024968836456537247, 'loss_2': 0.0001163482666015625, 'loss_3': -16.30455780029297, 'loss_4': 2.505129814147949, 'epoch': 9.78}
{'loss': 0.02, 'grad_norm': 8.99782657623291, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.019784780219197273, 'loss_2': 0.00017213821411132812, 'loss_3': -16.26131820678711, 'loss_4': 1.6908117532730103, 'epoch': 9.79}
{'loss': 0.0132, 'grad_norm': 5.436249256134033, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.009227641858160496, 'loss_2': 0.004009246826171875, 'loss_3': -16.349563598632812, 'loss_4': 1.8561105728149414, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 10:06:01,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:01,771 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1690/5160 [41:51<1:00:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:09,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012122933752834797, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00676835048943758, 'eval_loss_2': 0.005354583263397217, 'eval_loss_3': -18.340614318847656, 'eval_loss_4': 1.4446965456008911, 'epoch': 9.8}
{'loss': 0.0153, 'grad_norm': 5.550479412078857, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.012720993719995022, 'loss_2': 0.00257110595703125, 'loss_3': -16.39406394958496, 'loss_4': 1.4508748054504395, 'epoch': 9.8}
{'loss': 0.0279, 'grad_norm': 11.224050521850586, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.025235909968614578, 'loss_2': 0.002674102783203125, 'loss_3': -16.408733367919922, 'loss_4': 1.8282991647720337, 'epoch': 9.81}
{'loss': 0.0225, 'grad_norm': 7.579812049865723, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.013943004421889782, 'loss_2': 0.00859832763671875, 'loss_3': -16.479248046875, 'loss_4': 1.5285042524337769, 'epoch': 9.81}
{'loss': 0.0291, 'grad_norm': 13.626089096069336, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.02228008583188057, 'loss_2': 0.0067901611328125, 'loss_3': -16.421024322509766, 'loss_4': 1.3286423683166504, 'epoch': 9.82}
{'loss': 0.0268, 'grad_norm': 12.183279037475586, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.017746107652783394, 'loss_2': 0.00909423828125, 'loss_3': -16.100053787231445, 'loss_4': 1.6592048406600952, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 10:06:09,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:09,122 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [41:58<59:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:16,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009365025907754898, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.053, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005325544625520706, 'eval_loss_2': 0.004039481282234192, 'eval_loss_3': -18.345657348632812, 'eval_loss_4': 1.0263639688491821, 'epoch': 9.83}
{'loss': 0.0177, 'grad_norm': 7.128289699554443, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.011831129901111126, 'loss_2': 0.005908966064453125, 'loss_3': -16.191024780273438, 'loss_4': 1.4054768085479736, 'epoch': 9.83}
{'loss': 0.0137, 'grad_norm': 6.370087623596191, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.011008278466761112, 'loss_2': 0.002643585205078125, 'loss_3': -16.516178131103516, 'loss_4': 1.4614251852035522, 'epoch': 9.84}
{'loss': 0.0178, 'grad_norm': 7.462107181549072, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.01641605608165264, 'loss_2': 0.0013704299926757812, 'loss_3': -16.1582088470459, 'loss_4': 1.9641971588134766, 'epoch': 9.84}
{'loss': 0.0274, 'grad_norm': 9.276754379272461, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.021575763821601868, 'loss_2': 0.005840301513671875, 'loss_3': -16.15906524658203, 'loss_4': 1.1520905494689941, 'epoch': 9.85}
{'loss': 0.0169, 'grad_norm': 5.218776702880859, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.007237828802317381, 'loss_2': 0.00969696044921875, 'loss_3': -16.337345123291016, 'loss_4': 1.7223522663116455, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 10:06:16,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:16,470 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:06<59:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:23,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01088671199977398, 'eval_runtime': 3.8192, 'eval_samples_per_second': 268.12, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.005221589934080839, 'eval_loss_2': 0.005665123462677002, 'eval_loss_3': -18.308704376220703, 'eval_loss_4': 1.0878591537475586, 'epoch': 9.85}
{'loss': 0.0086, 'grad_norm': 5.083751201629639, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.0060434709303081036, 'loss_2': 0.0025730133056640625, 'loss_3': -16.2450008392334, 'loss_4': 1.1246578693389893, 'epoch': 9.86}
{'loss': 0.0117, 'grad_norm': 7.0590410232543945, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.010943233966827393, 'loss_2': 0.0007905960083007812, 'loss_3': -16.508691787719727, 'loss_4': 1.5455822944641113, 'epoch': 9.87}
{'loss': 0.0076, 'grad_norm': 5.159877777099609, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.007510206662118435, 'loss_2': 9.632110595703125e-05, 'loss_3': -16.376609802246094, 'loss_4': 1.6970643997192383, 'epoch': 9.87}
{'loss': 0.0199, 'grad_norm': 11.92107105255127, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.0108210239559412, 'loss_2': 0.0090789794921875, 'loss_3': -15.931137084960938, 'loss_4': 1.8237621784210205, 'epoch': 9.88}
{'loss': 0.0135, 'grad_norm': 5.368600845336914, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.00871801096946001, 'loss_2': 0.0047760009765625, 'loss_3': -16.153045654296875, 'loss_4': 1.9518767595291138, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 10:06:23,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:23,838 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:13<59:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:31,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007643592078238726, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.911, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004246351309120655, 'eval_loss_2': 0.003397241234779358, 'eval_loss_3': -18.311458587646484, 'eval_loss_4': 1.1420936584472656, 'epoch': 9.88}
{'loss': 0.0624, 'grad_norm': 24.499574661254883, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.05837984010577202, 'loss_2': 0.00399017333984375, 'loss_3': -16.033695220947266, 'loss_4': 2.1135623455047607, 'epoch': 9.89}
{'loss': 0.0234, 'grad_norm': 10.12699031829834, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.018699122592806816, 'loss_2': 0.00473785400390625, 'loss_3': -16.175270080566406, 'loss_4': 2.5278851985931396, 'epoch': 9.9}
{'loss': 0.0147, 'grad_norm': 6.212984561920166, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.010076342150568962, 'loss_2': 0.004581451416015625, 'loss_3': -16.206985473632812, 'loss_4': 2.0258595943450928, 'epoch': 9.9}
{'loss': 0.0094, 'grad_norm': 5.1899847984313965, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.0069796377792954445, 'loss_2': 0.0024280548095703125, 'loss_3': -16.186260223388672, 'loss_4': 2.365967035293579, 'epoch': 9.91}
{'loss': 0.0199, 'grad_norm': 13.248383522033691, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.019074799492955208, 'loss_2': 0.0008730888366699219, 'loss_3': -16.126129150390625, 'loss_4': 1.9713871479034424, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 10:06:31,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:31,191 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:20<59:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:38,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010960111394524574, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005451778415590525, 'eval_loss_2': 0.005508333444595337, 'eval_loss_3': -18.316204071044922, 'eval_loss_4': 1.1551486253738403, 'epoch': 9.91}
{'loss': 0.0105, 'grad_norm': 5.34837532043457, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.004442823585122824, 'loss_2': 0.00604248046875, 'loss_3': -16.191936492919922, 'loss_4': 2.014425277709961, 'epoch': 9.92}
{'loss': 0.0396, 'grad_norm': 25.984777450561523, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.038284797221422195, 'loss_2': 0.0013103485107421875, 'loss_3': -16.279129028320312, 'loss_4': 1.4546271562576294, 'epoch': 9.92}
{'loss': 0.0222, 'grad_norm': 12.876041412353516, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.020566929131746292, 'loss_2': 0.0016660690307617188, 'loss_3': -16.218608856201172, 'loss_4': 1.8633402585983276, 'epoch': 9.93}
{'loss': 0.0161, 'grad_norm': 8.902936935424805, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.015830203890800476, 'loss_2': 0.0003094673156738281, 'loss_3': -16.132823944091797, 'loss_4': 2.29587459564209, 'epoch': 9.94}
{'loss': 0.0168, 'grad_norm': 6.9668707847595215, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.013345764018595219, 'loss_2': 0.00341033935546875, 'loss_3': -16.121198654174805, 'loss_4': 1.7484915256500244, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 10:06:38,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:38,541 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:28<59:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:45,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00967215932905674, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005349271930754185, 'eval_loss_2': 0.0043228864669799805, 'eval_loss_3': -18.317996978759766, 'eval_loss_4': 1.314801812171936, 'epoch': 9.94}
{'loss': 0.0164, 'grad_norm': 5.10053014755249, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.005434791091829538, 'loss_2': 0.01094818115234375, 'loss_3': -16.174617767333984, 'loss_4': 2.2388246059417725, 'epoch': 9.95}
{'loss': 0.011, 'grad_norm': 5.960053443908691, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.008025353774428368, 'loss_2': 0.0029697418212890625, 'loss_3': -16.24765396118164, 'loss_4': 1.706754207611084, 'epoch': 9.95}
{'loss': 0.0139, 'grad_norm': 4.958008289337158, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.008294793777167797, 'loss_2': 0.005565643310546875, 'loss_3': -16.36569595336914, 'loss_4': 1.9643431901931763, 'epoch': 9.96}
{'loss': 0.0141, 'grad_norm': 5.317544460296631, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.009008897468447685, 'loss_2': 0.005046844482421875, 'loss_3': -16.37201499938965, 'loss_4': 1.5282673835754395, 'epoch': 9.97}
{'loss': 0.0118, 'grad_norm': 5.628239631652832, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.009561974555253983, 'loss_2': 0.002277374267578125, 'loss_3': -16.358217239379883, 'loss_4': 1.7014269828796387, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 10:06:45,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:45,892 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:35<53:33,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:06:52,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010166110470890999, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0048116762191057205, 'eval_loss_2': 0.005354434251785278, 'eval_loss_3': -18.323495864868164, 'eval_loss_4': 1.2626242637634277, 'epoch': 9.97}
{'loss': 0.0258, 'grad_norm': 13.00896167755127, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.020391372963786125, 'loss_2': 0.005405426025390625, 'loss_3': -16.462926864624023, 'loss_4': 1.731704592704773, 'epoch': 9.98}
{'loss': 0.0178, 'grad_norm': 6.105149269104004, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.010523919016122818, 'loss_2': 0.00724029541015625, 'loss_3': -16.212886810302734, 'loss_4': 1.910024642944336, 'epoch': 9.98}
{'loss': 0.0188, 'grad_norm': 9.850970268249512, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.010003432631492615, 'loss_2': 0.008819580078125, 'loss_3': -16.501567840576172, 'loss_4': 2.0839803218841553, 'epoch': 9.99}
{'loss': 0.0216, 'grad_norm': 5.3969197273254395, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.010456768795847893, 'loss_2': 0.01111602783203125, 'loss_3': -16.382465362548828, 'loss_4': 1.5888983011245728, 'epoch': 9.99}
{'loss': 0.0107, 'grad_norm': 6.96514368057251, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.0018435241654515266, 'loss_2': 0.008880615234375, 'loss_3': -16.382118225097656, 'loss_4': 1.819122076034546, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 10:06:52,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:52,893 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:42<58:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:07:00,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012581628747284412, 'eval_runtime': 3.8558, 'eval_samples_per_second': 265.577, 'eval_steps_per_second': 4.15, 'eval_loss_1': 0.004745972342789173, 'eval_loss_2': 0.00783565640449524, 'eval_loss_3': -18.343957901000977, 'eval_loss_4': 1.0309886932373047, 'epoch': 10.0}
{'loss': 0.0211, 'grad_norm': 5.328928470611572, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.010160939767956734, 'loss_2': 0.0109100341796875, 'loss_3': -16.23733901977539, 'loss_4': 1.4577807188034058, 'epoch': 10.01}
{'loss': 0.0204, 'grad_norm': 7.7731404304504395, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.013709516264498234, 'loss_2': 0.0067291259765625, 'loss_3': -16.277469635009766, 'loss_4': 0.9698911905288696, 'epoch': 10.01}
{'loss': 0.025, 'grad_norm': 6.899264812469482, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.016406593844294548, 'loss_2': 0.00861358642578125, 'loss_3': -16.302396774291992, 'loss_4': 1.5199744701385498, 'epoch': 10.02}
{'loss': 0.0196, 'grad_norm': 10.548251152038574, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.01729615218937397, 'loss_2': 0.00225830078125, 'loss_3': -16.296131134033203, 'loss_4': 1.243679404258728, 'epoch': 10.02}
{'loss': 0.0107, 'grad_norm': 5.160561561584473, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.010592063888907433, 'loss_2': 7.873773574829102e-05, 'loss_3': -16.234615325927734, 'loss_4': 1.683716893196106, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 10:07:00,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:00,340 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [42:49<59:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:07,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009205954149365425, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.691, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005378181580454111, 'eval_loss_2': 0.0038277730345726013, 'eval_loss_3': -18.337215423583984, 'eval_loss_4': 1.0098519325256348, 'epoch': 10.03}
{'loss': 0.0187, 'grad_norm': 8.610543251037598, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.015313495881855488, 'loss_2': 0.00337982177734375, 'loss_3': -16.40774917602539, 'loss_4': 1.1535362005233765, 'epoch': 10.03}
{'loss': 0.0119, 'grad_norm': 4.8131489753723145, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.008226299658417702, 'loss_2': 0.0037097930908203125, 'loss_3': -16.444210052490234, 'loss_4': 1.3947136402130127, 'epoch': 10.04}
{'loss': 0.014, 'grad_norm': 5.323953151702881, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.005801120772957802, 'loss_2': 0.0082244873046875, 'loss_3': -16.280681610107422, 'loss_4': 1.2786859273910522, 'epoch': 10.05}
{'loss': 0.0157, 'grad_norm': 6.399471759796143, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.010235495865345001, 'loss_2': 0.00548553466796875, 'loss_3': -16.285400390625, 'loss_4': 1.459304928779602, 'epoch': 10.05}
{'loss': 0.0209, 'grad_norm': 6.686196804046631, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.016561543568968773, 'loss_2': 0.0043487548828125, 'loss_3': -16.05490493774414, 'loss_4': 1.7402732372283936, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 10:07:07,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:07,697 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [42:57<59:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:15,047 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010276645421981812, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00579902483150363, 'eval_loss_2': 0.0044776201248168945, 'eval_loss_3': -18.32439422607422, 'eval_loss_4': 0.983770489692688, 'epoch': 10.06}
{'loss': 0.0079, 'grad_norm': 5.610995769500732, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.007817455567419529, 'loss_2': 8.213520050048828e-05, 'loss_3': -16.466888427734375, 'loss_4': 1.3852105140686035, 'epoch': 10.06}
{'loss': 0.0114, 'grad_norm': 4.896456241607666, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.009599355049431324, 'loss_2': 0.0017833709716796875, 'loss_3': -16.385986328125, 'loss_4': 1.1503877639770508, 'epoch': 10.07}
{'loss': 0.0362, 'grad_norm': 21.760879516601562, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.03489144518971443, 'loss_2': 0.0013141632080078125, 'loss_3': -16.128925323486328, 'loss_4': 1.4919930696487427, 'epoch': 10.08}
{'loss': 0.0319, 'grad_norm': 14.706381797790527, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.021169738844037056, 'loss_2': 0.010772705078125, 'loss_3': -16.3094482421875, 'loss_4': 1.6622846126556396, 'epoch': 10.08}
{'loss': 0.0227, 'grad_norm': 8.641314506530762, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.021520251408219337, 'loss_2': 0.001178741455078125, 'loss_3': -16.242788314819336, 'loss_4': 1.1960651874542236, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 10:07:15,047 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:15,047 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:04<59:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:22,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011166326701641083, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.323, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006506317760795355, 'eval_loss_2': 0.00466001033782959, 'eval_loss_3': -18.302013397216797, 'eval_loss_4': 1.1361366510391235, 'epoch': 10.09}
{'loss': 0.0113, 'grad_norm': 4.907705307006836, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.005498610902577639, 'loss_2': 0.0057525634765625, 'loss_3': -16.2969913482666, 'loss_4': 1.5344310998916626, 'epoch': 10.09}
{'loss': 0.0248, 'grad_norm': 9.463122367858887, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.01719394326210022, 'loss_2': 0.00762176513671875, 'loss_3': -16.401479721069336, 'loss_4': 2.4811758995056152, 'epoch': 10.1}
{'loss': 0.0127, 'grad_norm': 5.5031304359436035, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.0072235772386193275, 'loss_2': 0.0055084228515625, 'loss_3': -16.141372680664062, 'loss_4': 1.7596495151519775, 'epoch': 10.1}
{'loss': 0.0153, 'grad_norm': 5.552422523498535, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.010388398543000221, 'loss_2': 0.0049285888671875, 'loss_3': -16.278257369995117, 'loss_4': 1.6234233379364014, 'epoch': 10.11}
{'loss': 0.0333, 'grad_norm': 25.369401931762695, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.030346518382430077, 'loss_2': 0.002910614013671875, 'loss_3': -16.246204376220703, 'loss_4': 1.57191801071167, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 10:07:22,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:22,399 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:11<59:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:29,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011792493984103203, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006931495387107134, 'eval_loss_2': 0.004860997200012207, 'eval_loss_3': -18.34202003479004, 'eval_loss_4': 1.1572823524475098, 'epoch': 10.12}
{'loss': 0.0072, 'grad_norm': 5.277878284454346, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.005843219347298145, 'loss_2': 0.0013637542724609375, 'loss_3': -16.229307174682617, 'loss_4': 1.6776862144470215, 'epoch': 10.12}
{'loss': 0.0166, 'grad_norm': 5.343664646148682, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.008805527351796627, 'loss_2': 0.0078277587890625, 'loss_3': -16.15087127685547, 'loss_4': 2.198348045349121, 'epoch': 10.13}
{'loss': 0.0297, 'grad_norm': 10.776021003723145, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.024076880887150764, 'loss_2': 0.00557708740234375, 'loss_3': -16.386539459228516, 'loss_4': 2.0948548316955566, 'epoch': 10.13}
{'loss': 0.0131, 'grad_norm': 5.459190845489502, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.009376469999551773, 'loss_2': 0.0037078857421875, 'loss_3': -16.192195892333984, 'loss_4': 1.6141421794891357, 'epoch': 10.14}
{'loss': 0.0157, 'grad_norm': 6.144636631011963, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.013928158208727837, 'loss_2': 0.0017566680908203125, 'loss_3': -15.992206573486328, 'loss_4': 2.353278636932373, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 10:07:29,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:29,745 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:19<59:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:37,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012490149587392807, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007355805020779371, 'eval_loss_2': 0.0051343441009521484, 'eval_loss_3': -18.323787689208984, 'eval_loss_4': 1.5559310913085938, 'epoch': 10.15}
{'loss': 0.0125, 'grad_norm': 5.548216819763184, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.009595236741006374, 'loss_2': 0.00292205810546875, 'loss_3': -16.112089157104492, 'loss_4': 2.0559167861938477, 'epoch': 10.15}
{'loss': 0.0145, 'grad_norm': 5.148235321044922, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.008811713196337223, 'loss_2': 0.0056610107421875, 'loss_3': -16.36958885192871, 'loss_4': 1.8335931301116943, 'epoch': 10.16}
{'loss': 0.016, 'grad_norm': 7.786696910858154, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.007946162484586239, 'loss_2': 0.0080413818359375, 'loss_3': -16.077465057373047, 'loss_4': 1.7107422351837158, 'epoch': 10.16}
{'loss': 0.0245, 'grad_norm': 7.091188907623291, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.01270104106515646, 'loss_2': 0.0118408203125, 'loss_3': -16.13540267944336, 'loss_4': 2.2148423194885254, 'epoch': 10.17}
{'loss': 0.0185, 'grad_norm': 8.263412475585938, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.013050111010670662, 'loss_2': 0.0054779052734375, 'loss_3': -16.28598976135254, 'loss_4': 2.642493486404419, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 10:07:37,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:37,101 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:26<58:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:44,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009277092292904854, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.098, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.005725713446736336, 'eval_loss_2': 0.003551378846168518, 'eval_loss_3': -18.34713363647461, 'eval_loss_4': 2.1633822917938232, 'epoch': 10.17}
{'loss': 0.0165, 'grad_norm': 5.295385837554932, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.009073300287127495, 'loss_2': 0.00746917724609375, 'loss_3': -16.183813095092773, 'loss_4': 2.2587900161743164, 'epoch': 10.18}
{'loss': 0.019, 'grad_norm': 9.514430046081543, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.01708466187119484, 'loss_2': 0.0019502639770507812, 'loss_3': -16.168079376220703, 'loss_4': 2.9550600051879883, 'epoch': 10.19}
{'loss': 0.0164, 'grad_norm': 6.257897853851318, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.01099865697324276, 'loss_2': 0.00539398193359375, 'loss_3': -16.30803680419922, 'loss_4': 3.2541556358337402, 'epoch': 10.19}
{'loss': 0.0253, 'grad_norm': 7.144552707672119, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.018733711913228035, 'loss_2': 0.00659942626953125, 'loss_3': -16.149982452392578, 'loss_4': 2.391242742538452, 'epoch': 10.2}
{'loss': 0.0264, 'grad_norm': 15.951506614685059, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.023871565237641335, 'loss_2': 0.00247955322265625, 'loss_3': -16.17224884033203, 'loss_4': 2.8828978538513184, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 10:07:44,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:44,463 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:33<58:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:51,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008668177761137486, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005396146792918444, 'eval_loss_2': 0.0032720305025577545, 'eval_loss_3': -18.346939086914062, 'eval_loss_4': 2.3674399852752686, 'epoch': 10.2}
{'loss': 0.0335, 'grad_norm': 11.601164817810059, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.028178080916404724, 'loss_2': 0.005329132080078125, 'loss_3': -16.093618392944336, 'loss_4': 3.2514078617095947, 'epoch': 10.21}
{'loss': 0.0227, 'grad_norm': 9.08242130279541, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.018303997814655304, 'loss_2': 0.004360198974609375, 'loss_3': -16.208864212036133, 'loss_4': 2.4049856662750244, 'epoch': 10.22}
{'loss': 0.0136, 'grad_norm': 6.67703104019165, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.01197163388133049, 'loss_2': 0.001659393310546875, 'loss_3': -16.03022003173828, 'loss_4': 3.1504065990448, 'epoch': 10.22}
{'loss': 0.027, 'grad_norm': 9.746295928955078, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.02451736107468605, 'loss_2': 0.00246429443359375, 'loss_3': -16.255708694458008, 'loss_4': 2.892024040222168, 'epoch': 10.23}
{'loss': 0.0401, 'grad_norm': 16.585285186767578, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.036688435822725296, 'loss_2': 0.003448486328125, 'loss_3': -16.057186126708984, 'loss_4': 2.9764819145202637, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 10:07:51,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:51,820 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:41<58:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:59,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011979501694440842, 'eval_runtime': 3.8205, 'eval_samples_per_second': 268.031, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.005721133667975664, 'eval_loss_2': 0.006258368492126465, 'eval_loss_3': -18.374656677246094, 'eval_loss_4': 2.36350417137146, 'epoch': 10.23}
{'loss': 0.0338, 'grad_norm': 12.823155403137207, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.030759623274207115, 'loss_2': 0.0030040740966796875, 'loss_3': -16.02956199645996, 'loss_4': 3.0785417556762695, 'epoch': 10.24}
{'loss': 0.0218, 'grad_norm': 6.4047112464904785, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.014681323431432247, 'loss_2': 0.00714874267578125, 'loss_3': -16.305030822753906, 'loss_4': 2.567079544067383, 'epoch': 10.24}
{'loss': 0.0189, 'grad_norm': 9.128466606140137, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.01732781156897545, 'loss_2': 0.0015430450439453125, 'loss_3': -16.192502975463867, 'loss_4': 2.429007053375244, 'epoch': 10.25}
{'loss': 0.0201, 'grad_norm': 5.051036834716797, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.008847182616591454, 'loss_2': 0.01126861572265625, 'loss_3': -16.413698196411133, 'loss_4': 3.12764835357666, 'epoch': 10.26}
{'loss': 0.0358, 'grad_norm': 12.761242866516113, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.028424300253391266, 'loss_2': 0.0073699951171875, 'loss_3': -16.362239837646484, 'loss_4': 2.844249963760376, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 10:07:59,193 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:59,193 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [43:48<58:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:06,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011940818279981613, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.979, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00579784344881773, 'eval_loss_2': 0.006142973899841309, 'eval_loss_3': -18.363893508911133, 'eval_loss_4': 2.365391492843628, 'epoch': 10.26}
{'loss': 0.0278, 'grad_norm': 7.792075157165527, 'learning_rate': 1.975e-05, 'loss_1': 0.014312773942947388, 'loss_2': 0.01349639892578125, 'loss_3': -16.486846923828125, 'loss_4': 2.713888645172119, 'epoch': 10.27}
{'loss': 0.0266, 'grad_norm': 7.5833892822265625, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.0185540821403265, 'loss_2': 0.00804901123046875, 'loss_3': -16.301780700683594, 'loss_4': 2.8350002765655518, 'epoch': 10.27}
{'loss': 0.0205, 'grad_norm': 5.903077125549316, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.011133596301078796, 'loss_2': 0.0093536376953125, 'loss_3': -16.374130249023438, 'loss_4': 2.8827261924743652, 'epoch': 10.28}
{'loss': 0.0201, 'grad_norm': 9.715847969055176, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.017602866515517235, 'loss_2': 0.0024871826171875, 'loss_3': -16.413835525512695, 'loss_4': 2.8479466438293457, 'epoch': 10.28}
{'loss': 0.0297, 'grad_norm': 14.779464721679688, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.0245621707290411, 'loss_2': 0.0051116943359375, 'loss_3': -16.452512741088867, 'loss_4': 3.749049186706543, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 10:08:06,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:06,558 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [43:56<58:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:13,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011330210603773594, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008092128671705723, 'eval_loss_2': 0.003238081932067871, 'eval_loss_3': -18.361833572387695, 'eval_loss_4': 2.5157601833343506, 'epoch': 10.29}
{'loss': 0.0259, 'grad_norm': 13.07657241821289, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.022744715213775635, 'loss_2': 0.00312042236328125, 'loss_3': -16.393190383911133, 'loss_4': 2.7159624099731445, 'epoch': 10.3}
{'loss': 0.0123, 'grad_norm': 4.822627544403076, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.006553397048264742, 'loss_2': 0.00569915771484375, 'loss_3': -16.177963256835938, 'loss_4': 3.069969892501831, 'epoch': 10.3}
{'loss': 0.0319, 'grad_norm': 8.586052894592285, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.021954583004117012, 'loss_2': 0.0099029541015625, 'loss_3': -16.432451248168945, 'loss_4': 2.8008170127868652, 'epoch': 10.31}
{'loss': 0.0265, 'grad_norm': 9.200606346130371, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.01647845096886158, 'loss_2': 0.00998687744140625, 'loss_3': -16.095090866088867, 'loss_4': 2.3038547039031982, 'epoch': 10.31}
{'loss': 0.0332, 'grad_norm': 10.845245361328125, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.023287449032068253, 'loss_2': 0.0098876953125, 'loss_3': -16.19390106201172, 'loss_4': 2.3406081199645996, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 10:08:13,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:13,914 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:03<58:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:21,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011045228689908981, 'eval_runtime': 3.8159, 'eval_samples_per_second': 268.35, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007210652809590101, 'eval_loss_2': 0.0038345754146575928, 'eval_loss_3': -18.352548599243164, 'eval_loss_4': 2.26859188079834, 'epoch': 10.32}
{'loss': 0.0084, 'grad_norm': 4.81409215927124, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.008197573013603687, 'loss_2': 0.0002307891845703125, 'loss_3': -16.25736427307129, 'loss_4': 2.3143978118896484, 'epoch': 10.33}
{'loss': 0.0191, 'grad_norm': 6.2684245109558105, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.012526661157608032, 'loss_2': 0.006622314453125, 'loss_3': -16.302194595336914, 'loss_4': 2.214824914932251, 'epoch': 10.33}
{'loss': 0.0122, 'grad_norm': 5.70840311050415, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.008863706141710281, 'loss_2': 0.00336456298828125, 'loss_3': -16.366477966308594, 'loss_4': 2.816422462463379, 'epoch': 10.34}
{'loss': 0.0123, 'grad_norm': 5.929704666137695, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.007677082903683186, 'loss_2': 0.004642486572265625, 'loss_3': -16.384042739868164, 'loss_4': 2.836604595184326, 'epoch': 10.34}
{'loss': 0.0296, 'grad_norm': 14.025508880615234, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.020526770502328873, 'loss_2': 0.00911712646484375, 'loss_3': -16.09331512451172, 'loss_4': 2.006136894226074, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 10:08:21,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:21,277 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:10<58:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:28,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01219860091805458, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005740942433476448, 'eval_loss_2': 0.006457656621932983, 'eval_loss_3': -18.369356155395508, 'eval_loss_4': 2.04805064201355, 'epoch': 10.35}
{'loss': 0.0218, 'grad_norm': 6.668557643890381, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.013707142323255539, 'loss_2': 0.0080718994140625, 'loss_3': -16.417938232421875, 'loss_4': 2.4007492065429688, 'epoch': 10.35}
{'loss': 0.0297, 'grad_norm': 11.05269718170166, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.023891324177384377, 'loss_2': 0.00576019287109375, 'loss_3': -16.30060386657715, 'loss_4': 3.024393081665039, 'epoch': 10.36}
{'loss': 0.0087, 'grad_norm': 5.0847625732421875, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.008655115030705929, 'loss_2': 3.039836883544922e-05, 'loss_3': -16.396827697753906, 'loss_4': 2.240694284439087, 'epoch': 10.37}
{'loss': 0.0212, 'grad_norm': 5.656993865966797, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.011943381279706955, 'loss_2': 0.00920867919921875, 'loss_3': -16.356306076049805, 'loss_4': 2.1112120151519775, 'epoch': 10.37}
{'loss': 0.0184, 'grad_norm': 13.537369728088379, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.01718718558549881, 'loss_2': 0.001232147216796875, 'loss_3': -16.356311798095703, 'loss_4': 2.6262612342834473, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 10:08:28,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:28,630 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:18<58:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:35,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009364347904920578, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.184, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006443243473768234, 'eval_loss_2': 0.0029211044311523438, 'eval_loss_3': -18.375730514526367, 'eval_loss_4': 1.939267873764038, 'epoch': 10.38}
{'loss': 0.0266, 'grad_norm': 11.385863304138184, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.022804265841841698, 'loss_2': 0.003814697265625, 'loss_3': -16.365333557128906, 'loss_4': 1.9436275959014893, 'epoch': 10.38}
{'loss': 0.008, 'grad_norm': 5.292592525482178, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.007074336986988783, 'loss_2': 0.0009417533874511719, 'loss_3': -16.616741180419922, 'loss_4': 2.284829616546631, 'epoch': 10.39}
{'loss': 0.0082, 'grad_norm': 4.645442485809326, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.0051259188912808895, 'loss_2': 0.0030670166015625, 'loss_3': -16.256755828857422, 'loss_4': 2.2209322452545166, 'epoch': 10.4}
{'loss': 0.0129, 'grad_norm': 5.311171054840088, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.009973874315619469, 'loss_2': 0.00289154052734375, 'loss_3': -16.571186065673828, 'loss_4': 2.284313440322876, 'epoch': 10.4}
{'loss': 0.0218, 'grad_norm': 12.1209077835083, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.018488043919205666, 'loss_2': 0.0033473968505859375, 'loss_3': -16.457509994506836, 'loss_4': 2.545248508453369, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 10:08:35,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:35,987 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:25<58:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:43,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009183761663734913, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006247547455132008, 'eval_loss_2': 0.0029362142086029053, 'eval_loss_3': -18.38626480102539, 'eval_loss_4': 1.9551630020141602, 'epoch': 10.41}
{'loss': 0.0103, 'grad_norm': 6.310774326324463, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.009052444249391556, 'loss_2': 0.001201629638671875, 'loss_3': -16.625503540039062, 'loss_4': 2.2484519481658936, 'epoch': 10.41}
{'loss': 0.0096, 'grad_norm': 5.697127342224121, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.008473193272948265, 'loss_2': 0.0011644363403320312, 'loss_3': -16.21788787841797, 'loss_4': 2.073188066482544, 'epoch': 10.42}
{'loss': 0.0182, 'grad_norm': 6.122900009155273, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.01354149915277958, 'loss_2': 0.00469207763671875, 'loss_3': -16.400684356689453, 'loss_4': 2.2803173065185547, 'epoch': 10.42}
{'loss': 0.0229, 'grad_norm': 8.513111114501953, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.020944051444530487, 'loss_2': 0.001987457275390625, 'loss_3': -16.477821350097656, 'loss_4': 2.0892226696014404, 'epoch': 10.43}
{'loss': 0.0133, 'grad_norm': 5.659876346588135, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.011570936068892479, 'loss_2': 0.0017499923706054688, 'loss_3': -16.646883010864258, 'loss_4': 2.5899300575256348, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 10:08:43,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:43,334 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:32<58:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:50,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010711334645748138, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008029073476791382, 'eval_loss_2': 0.0026822611689567566, 'eval_loss_3': -18.402679443359375, 'eval_loss_4': 2.0778307914733887, 'epoch': 10.44}
{'loss': 0.0129, 'grad_norm': 5.431886672973633, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.012804681435227394, 'loss_2': 0.00013256072998046875, 'loss_3': -16.343460083007812, 'loss_4': 2.6118831634521484, 'epoch': 10.44}
{'loss': 0.0172, 'grad_norm': 5.842641353607178, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.01430460438132286, 'loss_2': 0.0029087066650390625, 'loss_3': -16.507930755615234, 'loss_4': 2.702908992767334, 'epoch': 10.45}
{'loss': 0.0215, 'grad_norm': 6.579628944396973, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.0168636292219162, 'loss_2': 0.004669189453125, 'loss_3': -16.541393280029297, 'loss_4': 2.1510980129241943, 'epoch': 10.45}
{'loss': 0.0218, 'grad_norm': 7.541625499725342, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.019443649798631668, 'loss_2': 0.002349853515625, 'loss_3': -16.382061004638672, 'loss_4': 2.752115249633789, 'epoch': 10.46}
{'loss': 0.0151, 'grad_norm': 5.031744003295898, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.008113606832921505, 'loss_2': 0.00695037841796875, 'loss_3': -16.530820846557617, 'loss_4': 3.0076448917388916, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 10:08:50,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:50,680 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:40<58:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:58,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010894624516367912, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.194, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007443918380886316, 'eval_loss_2': 0.0034507066011428833, 'eval_loss_3': -18.403676986694336, 'eval_loss_4': 2.1801300048828125, 'epoch': 10.47}
{'loss': 0.0132, 'grad_norm': 6.07790994644165, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.010527506470680237, 'loss_2': 0.002712249755859375, 'loss_3': -16.364280700683594, 'loss_4': 2.7565698623657227, 'epoch': 10.47}
{'loss': 0.0191, 'grad_norm': 6.89772891998291, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.013327966444194317, 'loss_2': 0.00580596923828125, 'loss_3': -16.404773712158203, 'loss_4': 2.2115509510040283, 'epoch': 10.48}
{'loss': 0.0201, 'grad_norm': 5.763931751251221, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.009947441518306732, 'loss_2': 0.01015472412109375, 'loss_3': -16.465578079223633, 'loss_4': 2.36234712600708, 'epoch': 10.48}
{'loss': 0.0145, 'grad_norm': 8.074070930480957, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.014326811768114567, 'loss_2': 0.0001933574676513672, 'loss_3': -16.500686645507812, 'loss_4': 2.1376023292541504, 'epoch': 10.49}
{'loss': 0.0263, 'grad_norm': 13.753231048583984, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.02121790312230587, 'loss_2': 0.005115509033203125, 'loss_3': -16.45334815979004, 'loss_4': 2.926384449005127, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 10:08:58,030 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:58,030 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [44:47<58:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:05,390 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010111255571246147, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.646, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006696892902255058, 'eval_loss_2': 0.003414362668991089, 'eval_loss_3': -18.427589416503906, 'eval_loss_4': 2.048971176147461, 'epoch': 10.49}
{'loss': 0.0562, 'grad_norm': 19.414220809936523, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.05590606853365898, 'loss_2': 0.00032901763916015625, 'loss_3': -16.134124755859375, 'loss_4': 2.132047653198242, 'epoch': 10.5}
{'loss': 0.033, 'grad_norm': 11.483101844787598, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.025786910206079483, 'loss_2': 0.00725555419921875, 'loss_3': -16.2889461517334, 'loss_4': 2.3142971992492676, 'epoch': 10.51}
{'loss': 0.0405, 'grad_norm': 18.109786987304688, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.03782142698764801, 'loss_2': 0.0027008056640625, 'loss_3': -16.24811553955078, 'loss_4': 2.49466872215271, 'epoch': 10.51}
{'loss': 0.0113, 'grad_norm': 5.581995010375977, 'learning_rate': 1.95e-05, 'loss_1': 0.009766134433448315, 'loss_2': 0.0015392303466796875, 'loss_3': -16.56014633178711, 'loss_4': 2.7267847061157227, 'epoch': 10.52}
{'loss': 0.0129, 'grad_norm': 6.580163478851318, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.010696452111005783, 'loss_2': 0.0022373199462890625, 'loss_3': -16.533891677856445, 'loss_4': 2.9301209449768066, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 10:09:05,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:05,390 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [44:54<57:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:12,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009372837841510773, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.197, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006240095943212509, 'eval_loss_2': 0.0031327418982982635, 'eval_loss_3': -18.438289642333984, 'eval_loss_4': 1.8133823871612549, 'epoch': 10.52}
{'loss': 0.0177, 'grad_norm': 6.423830986022949, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.01143647637218237, 'loss_2': 0.0063018798828125, 'loss_3': -16.397985458374023, 'loss_4': 2.173379421234131, 'epoch': 10.53}
{'loss': 0.0144, 'grad_norm': 6.860175609588623, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.008884001523256302, 'loss_2': 0.00553131103515625, 'loss_3': -16.372411727905273, 'loss_4': 2.1891753673553467, 'epoch': 10.53}
{'loss': 0.0241, 'grad_norm': 9.053322792053223, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.021870730444788933, 'loss_2': 0.002246856689453125, 'loss_3': -16.530574798583984, 'loss_4': 1.9663554430007935, 'epoch': 10.54}
{'loss': 0.0343, 'grad_norm': 14.932205200195312, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.02970774658024311, 'loss_2': 0.0045928955078125, 'loss_3': -16.346914291381836, 'loss_4': 1.6555774211883545, 'epoch': 10.55}
{'loss': 0.0093, 'grad_norm': 5.422645092010498, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.009142828173935413, 'loss_2': 0.0001971721649169922, 'loss_3': -16.235219955444336, 'loss_4': 1.6910600662231445, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 10:09:12,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:12,734 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:02<57:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:20,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010152170434594154, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007032292429357767, 'eval_loss_2': 0.0031198784708976746, 'eval_loss_3': -18.4357967376709, 'eval_loss_4': 1.4001020193099976, 'epoch': 10.55}
{'loss': 0.0327, 'grad_norm': 14.79201602935791, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.03201465681195259, 'loss_2': 0.0006580352783203125, 'loss_3': -16.537303924560547, 'loss_4': 2.9730770587921143, 'epoch': 10.56}
{'loss': 0.0128, 'grad_norm': 5.195436000823975, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.012500418350100517, 'loss_2': 0.00026988983154296875, 'loss_3': -16.434349060058594, 'loss_4': 1.6700351238250732, 'epoch': 10.56}
{'loss': 0.0224, 'grad_norm': 5.595207214355469, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.014736024662852287, 'loss_2': 0.0077056884765625, 'loss_3': -16.420307159423828, 'loss_4': 2.2883520126342773, 'epoch': 10.57}
{'loss': 0.0301, 'grad_norm': 13.917731285095215, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.023292243480682373, 'loss_2': 0.00676727294921875, 'loss_3': -16.594928741455078, 'loss_4': 2.102646827697754, 'epoch': 10.58}
{'loss': 0.0347, 'grad_norm': 18.04507064819336, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.03096797503530979, 'loss_2': 0.003749847412109375, 'loss_3': -16.39785385131836, 'loss_4': 1.2509925365447998, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 10:09:20,078 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:20,078 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:09<57:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:27,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011234642937779427, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007873552851378918, 'eval_loss_2': 0.0033610910177230835, 'eval_loss_3': -18.432458877563477, 'eval_loss_4': 1.1134763956069946, 'epoch': 10.58}
{'loss': 0.0301, 'grad_norm': 8.357938766479492, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.024845847859978676, 'loss_2': 0.00521087646484375, 'loss_3': -16.58144760131836, 'loss_4': 1.402803659439087, 'epoch': 10.59}
{'loss': 0.0135, 'grad_norm': 4.770049095153809, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.009963223710656166, 'loss_2': 0.0035648345947265625, 'loss_3': -16.550853729248047, 'loss_4': 1.2358579635620117, 'epoch': 10.59}
{'loss': 0.0336, 'grad_norm': 11.154276847839355, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.032585691660642624, 'loss_2': 0.001010894775390625, 'loss_3': -16.436830520629883, 'loss_4': 2.1030163764953613, 'epoch': 10.6}
{'loss': 0.0324, 'grad_norm': 7.715529441833496, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.020576603710651398, 'loss_2': 0.01184844970703125, 'loss_3': -16.340545654296875, 'loss_4': 1.897423505783081, 'epoch': 10.6}
{'loss': 0.0475, 'grad_norm': 11.04480266571045, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.03972788155078888, 'loss_2': 0.007801055908203125, 'loss_3': -16.42081069946289, 'loss_4': 1.6222156286239624, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 10:09:27,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:27,423 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:16<57:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:34,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01709909737110138, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009222284890711308, 'eval_loss_2': 0.007876813411712646, 'eval_loss_3': -18.44115447998047, 'eval_loss_4': 1.1458487510681152, 'epoch': 10.61}
{'loss': 0.0331, 'grad_norm': 10.817808151245117, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.026941724121570587, 'loss_2': 0.0061187744140625, 'loss_3': -16.56189727783203, 'loss_4': 1.755627155303955, 'epoch': 10.62}
{'loss': 0.033, 'grad_norm': 7.429114818572998, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.022206364199519157, 'loss_2': 0.010772705078125, 'loss_3': -16.38197135925293, 'loss_4': 1.9248343706130981, 'epoch': 10.62}
{'loss': 0.0344, 'grad_norm': 7.256070137023926, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.02198886312544346, 'loss_2': 0.012420654296875, 'loss_3': -16.401874542236328, 'loss_4': 0.9393584728240967, 'epoch': 10.63}
{'loss': 0.0208, 'grad_norm': 6.165929794311523, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.014671643264591694, 'loss_2': 0.00609588623046875, 'loss_3': -16.362213134765625, 'loss_4': 1.8806488513946533, 'epoch': 10.63}
{'loss': 0.0289, 'grad_norm': 10.039911270141602, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.02744397707283497, 'loss_2': 0.0014362335205078125, 'loss_3': -16.520294189453125, 'loss_4': 1.6057074069976807, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 10:09:34,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:34,768 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:24<57:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:42,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013007352128624916, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.978, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008318194188177586, 'eval_loss_2': 0.004689157009124756, 'eval_loss_3': -18.387313842773438, 'eval_loss_4': 1.3308874368667603, 'epoch': 10.64}
{'loss': 0.0249, 'grad_norm': 7.635453224182129, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.024253718554973602, 'loss_2': 0.0006875991821289062, 'loss_3': -16.334070205688477, 'loss_4': 1.4526218175888062, 'epoch': 10.65}
{'loss': 0.0237, 'grad_norm': 8.652119636535645, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.01785307563841343, 'loss_2': 0.00585174560546875, 'loss_3': -16.2471866607666, 'loss_4': 1.4322235584259033, 'epoch': 10.65}
{'loss': 0.0269, 'grad_norm': 10.481426239013672, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.018886400386691093, 'loss_2': 0.008056640625, 'loss_3': -16.508190155029297, 'loss_4': 1.9337973594665527, 'epoch': 10.66}
{'loss': 0.0181, 'grad_norm': 6.494779586791992, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.016317976638674736, 'loss_2': 0.0017795562744140625, 'loss_3': -16.257177352905273, 'loss_4': 1.6421058177947998, 'epoch': 10.66}
{'loss': 0.0134, 'grad_norm': 4.926765441894531, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.009677779860794544, 'loss_2': 0.0036945343017578125, 'loss_3': -16.386411666870117, 'loss_4': 2.1910481452941895, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 10:09:42,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:42,120 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:31<57:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:49,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011551328003406525, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.369, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007435745559632778, 'eval_loss_2': 0.004115581512451172, 'eval_loss_3': -18.357358932495117, 'eval_loss_4': 1.450697898864746, 'epoch': 10.67}
{'loss': 0.0117, 'grad_norm': 7.172424793243408, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.010583377443253994, 'loss_2': 0.0011587142944335938, 'loss_3': -16.342071533203125, 'loss_4': 1.712928056716919, 'epoch': 10.67}
{'loss': 0.0317, 'grad_norm': 17.350250244140625, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.028386415913701057, 'loss_2': 0.003269195556640625, 'loss_3': -16.205425262451172, 'loss_4': 2.162458896636963, 'epoch': 10.68}
{'loss': 0.0123, 'grad_norm': 6.977689266204834, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.010904121212661266, 'loss_2': 0.0014162063598632812, 'loss_3': -16.454133987426758, 'loss_4': 1.8083653450012207, 'epoch': 10.69}
{'loss': 0.0141, 'grad_norm': 5.131101608276367, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.012991894036531448, 'loss_2': 0.0010786056518554688, 'loss_3': -16.339160919189453, 'loss_4': 2.0281434059143066, 'epoch': 10.69}
{'loss': 0.0182, 'grad_norm': 10.058062553405762, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.017168862745165825, 'loss_2': 0.0010528564453125, 'loss_3': -16.21382713317871, 'loss_4': 2.554446220397949, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 10:09:49,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:49,470 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:38<57:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:56,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01290757767856121, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009657448157668114, 'eval_loss_2': 0.003250129520893097, 'eval_loss_3': -18.315067291259766, 'eval_loss_4': 1.6116199493408203, 'epoch': 10.7}
{'loss': 0.0163, 'grad_norm': 7.134422302246094, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.015320251695811749, 'loss_2': 0.0009860992431640625, 'loss_3': -16.333480834960938, 'loss_4': 1.4684796333312988, 'epoch': 10.7}
{'loss': 0.045, 'grad_norm': 13.980331420898438, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.04084096476435661, 'loss_2': 0.004169464111328125, 'loss_3': -16.415603637695312, 'loss_4': 2.131948709487915, 'epoch': 10.71}
{'loss': 0.0182, 'grad_norm': 6.3175435066223145, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.018084248527884483, 'loss_2': 0.00012862682342529297, 'loss_3': -16.035682678222656, 'loss_4': 1.6122825145721436, 'epoch': 10.72}
{'loss': 0.0116, 'grad_norm': 6.718250751495361, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.011276454664766788, 'loss_2': 0.0003209114074707031, 'loss_3': -16.12738037109375, 'loss_4': 1.9491636753082275, 'epoch': 10.72}
{'loss': 0.0293, 'grad_norm': 8.453569412231445, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.025625895708799362, 'loss_2': 0.0036296844482421875, 'loss_3': -16.43593978881836, 'loss_4': 2.2539477348327637, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 10:09:56,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:56,817 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [45:46<57:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:04,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016024798154830933, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.152, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011782556772232056, 'eval_loss_2': 0.004242241382598877, 'eval_loss_3': -18.259536743164062, 'eval_loss_4': 1.8714858293533325, 'epoch': 10.73}
{'loss': 0.0358, 'grad_norm': 13.257987022399902, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.027993423864245415, 'loss_2': 0.0078125, 'loss_3': -16.30240249633789, 'loss_4': 2.3585927486419678, 'epoch': 10.73}
{'loss': 0.0213, 'grad_norm': 7.7653985023498535, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.017386332154273987, 'loss_2': 0.00395965576171875, 'loss_3': -16.21417999267578, 'loss_4': 2.461826801300049, 'epoch': 10.74}
{'loss': 0.0296, 'grad_norm': 8.854886054992676, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.02141421101987362, 'loss_2': 0.00818634033203125, 'loss_3': -16.376407623291016, 'loss_4': 1.9266061782836914, 'epoch': 10.74}
{'loss': 0.0177, 'grad_norm': 5.679058074951172, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.010644863359630108, 'loss_2': 0.007083892822265625, 'loss_3': -16.268198013305664, 'loss_4': 2.0325894355773926, 'epoch': 10.75}
{'loss': 0.0251, 'grad_norm': 10.850564956665039, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.01814788207411766, 'loss_2': 0.006992340087890625, 'loss_3': -16.35065460205078, 'loss_4': 2.22560977935791, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 10:10:04,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:04,162 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [45:53<57:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:11,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013466430827975273, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.376, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009714161977171898, 'eval_loss_2': 0.0037522688508033752, 'eval_loss_3': -18.226295471191406, 'eval_loss_4': 1.7691876888275146, 'epoch': 10.76}
{'loss': 0.0105, 'grad_norm': 6.134487152099609, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.009845892898738384, 'loss_2': 0.0007023811340332031, 'loss_3': -16.249980926513672, 'loss_4': 1.8277218341827393, 'epoch': 10.76}
{'loss': 0.0147, 'grad_norm': 5.5344557762146, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.008736785501241684, 'loss_2': 0.005970001220703125, 'loss_3': -16.279754638671875, 'loss_4': 1.5436811447143555, 'epoch': 10.77}
{'loss': 0.0994, 'grad_norm': 17.657318115234375, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.09724147617816925, 'loss_2': 0.0021839141845703125, 'loss_3': -16.119260787963867, 'loss_4': 1.8110148906707764, 'epoch': 10.77}
{'loss': 0.0188, 'grad_norm': 5.4209113121032715, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.010308689437806606, 'loss_2': 0.00846099853515625, 'loss_3': -16.29631996154785, 'loss_4': 1.4768754243850708, 'epoch': 10.78}
{'loss': 0.0095, 'grad_norm': 5.43546724319458, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.00926265213638544, 'loss_2': 0.0001996755599975586, 'loss_3': -16.438566207885742, 'loss_4': 0.9994478225708008, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 10:10:11,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:11,501 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:01<57:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:18,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01245548389852047, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00859079323709011, 'eval_loss_2': 0.003864690661430359, 'eval_loss_3': -18.2286319732666, 'eval_loss_4': 1.339909315109253, 'epoch': 10.78}
{'loss': 0.0135, 'grad_norm': 7.526785373687744, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.01341437827795744, 'loss_2': 7.462501525878906e-05, 'loss_3': -16.117767333984375, 'loss_4': 0.9729600548744202, 'epoch': 10.79}
{'loss': 0.0167, 'grad_norm': 5.596779823303223, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.01237025298178196, 'loss_2': 0.00435638427734375, 'loss_3': -16.178085327148438, 'loss_4': 1.744412899017334, 'epoch': 10.8}
{'loss': 0.015, 'grad_norm': 5.415069103240967, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.006460126489400864, 'loss_2': 0.0085296630859375, 'loss_3': -16.15953254699707, 'loss_4': 1.7106192111968994, 'epoch': 10.8}
{'loss': 0.0335, 'grad_norm': 12.284318923950195, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.032944634556770325, 'loss_2': 0.0005784034729003906, 'loss_3': -16.059402465820312, 'loss_4': 1.7603163719177246, 'epoch': 10.81}
{'loss': 0.0141, 'grad_norm': 5.063702583312988, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.007865943014621735, 'loss_2': 0.006195068359375, 'loss_3': -16.11858367919922, 'loss_4': 1.4798619747161865, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 10:10:18,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:18,848 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:08<57:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:26,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013465086929500103, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.694, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009049038402736187, 'eval_loss_2': 0.004416048526763916, 'eval_loss_3': -18.211626052856445, 'eval_loss_4': 1.3161870241165161, 'epoch': 10.81}
{'loss': 0.0134, 'grad_norm': 6.067177772521973, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.009724622592329979, 'loss_2': 0.003681182861328125, 'loss_3': -16.157997131347656, 'loss_4': 1.435023546218872, 'epoch': 10.82}
{'loss': 0.0124, 'grad_norm': 5.283899784088135, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.0075720734894275665, 'loss_2': 0.004791259765625, 'loss_3': -16.46249008178711, 'loss_4': 1.3732699155807495, 'epoch': 10.83}
{'loss': 0.0237, 'grad_norm': 14.746070861816406, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.021275529637932777, 'loss_2': 0.002468109130859375, 'loss_3': -16.050060272216797, 'loss_4': 0.914528489112854, 'epoch': 10.83}
{'loss': 0.018, 'grad_norm': 4.8508524894714355, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.007289532572031021, 'loss_2': 0.01068115234375, 'loss_3': -16.24115753173828, 'loss_4': 1.3779547214508057, 'epoch': 10.84}
{'loss': 0.0088, 'grad_norm': 5.442427158355713, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.005307599436491728, 'loss_2': 0.003509521484375, 'loss_3': -16.36199951171875, 'loss_4': 0.9485270380973816, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 10:10:26,212 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:26,212 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:15<56:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:33,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012591145001351833, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009202560409903526, 'eval_loss_2': 0.0033885836601257324, 'eval_loss_3': -18.206405639648438, 'eval_loss_4': 1.2149879932403564, 'epoch': 10.84}
{'loss': 0.0158, 'grad_norm': 5.53226375579834, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.011473740451037884, 'loss_2': 0.004283905029296875, 'loss_3': -16.342689514160156, 'loss_4': 1.2958223819732666, 'epoch': 10.85}
{'loss': 0.0076, 'grad_norm': 4.689853668212891, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.007443381939083338, 'loss_2': 0.00017547607421875, 'loss_3': -16.45154571533203, 'loss_4': 1.2300723791122437, 'epoch': 10.85}
{'loss': 0.0153, 'grad_norm': 4.982728481292725, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.0063773756846785545, 'loss_2': 0.00893402099609375, 'loss_3': -16.225502014160156, 'loss_4': 1.2699875831604004, 'epoch': 10.86}
{'loss': 0.0121, 'grad_norm': 7.886439323425293, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.00875261053442955, 'loss_2': 0.00333404541015625, 'loss_3': -16.394216537475586, 'loss_4': 1.2778842449188232, 'epoch': 10.87}
{'loss': 0.0126, 'grad_norm': 5.87494421005249, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.008862951770424843, 'loss_2': 0.003780364990234375, 'loss_3': -16.36871337890625, 'loss_4': 1.6968305110931396, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 10:10:33,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:33,557 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:23<56:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:40,900 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012188244611024857, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.481, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007514227647334337, 'eval_loss_2': 0.004674017429351807, 'eval_loss_3': -18.210256576538086, 'eval_loss_4': 1.3348701000213623, 'epoch': 10.87}
{'loss': 0.0125, 'grad_norm': 6.59675407409668, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.011387716978788376, 'loss_2': 0.0010700225830078125, 'loss_3': -16.30866241455078, 'loss_4': 1.1298251152038574, 'epoch': 10.88}
{'loss': 0.017, 'grad_norm': 9.13443374633789, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.016744360327720642, 'loss_2': 0.0002887248992919922, 'loss_3': -16.195659637451172, 'loss_4': 1.674820899963379, 'epoch': 10.88}
{'loss': 0.0476, 'grad_norm': 12.360834121704102, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.0466785691678524, 'loss_2': 0.0009164810180664062, 'loss_3': -16.269330978393555, 'loss_4': 1.7237733602523804, 'epoch': 10.89}
{'loss': 0.0274, 'grad_norm': 12.118294715881348, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.017756391316652298, 'loss_2': 0.0096588134765625, 'loss_3': -16.232072830200195, 'loss_4': 1.0934287309646606, 'epoch': 10.9}
{'loss': 0.0225, 'grad_norm': 7.270438194274902, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.014139984734356403, 'loss_2': 0.008392333984375, 'loss_3': -16.212142944335938, 'loss_4': 1.6835981607437134, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 10:10:40,900 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:40,900 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:30<56:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:48,237 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010774625465273857, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.585, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005265218671411276, 'eval_loss_2': 0.005509406328201294, 'eval_loss_3': -18.200429916381836, 'eval_loss_4': 1.3788338899612427, 'epoch': 10.9}
{'loss': 0.0196, 'grad_norm': 7.957242488861084, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.016683369874954224, 'loss_2': 0.002872467041015625, 'loss_3': -15.883113861083984, 'loss_4': 1.4063456058502197, 'epoch': 10.91}
{'loss': 0.0096, 'grad_norm': 5.649317264556885, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.0065962341614067554, 'loss_2': 0.00302886962890625, 'loss_3': -16.061887741088867, 'loss_4': 1.4754366874694824, 'epoch': 10.91}
{'loss': 0.0191, 'grad_norm': 10.934056282043457, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.018283402547240257, 'loss_2': 0.0008578300476074219, 'loss_3': -16.083946228027344, 'loss_4': 1.328223466873169, 'epoch': 10.92}
{'loss': 0.015, 'grad_norm': 6.1552348136901855, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.013228941708803177, 'loss_2': 0.0017490386962890625, 'loss_3': -16.170551300048828, 'loss_4': 1.5768771171569824, 'epoch': 10.92}
{'loss': 0.0209, 'grad_norm': 8.744800567626953, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.01572539657354355, 'loss_2': 0.005218505859375, 'loss_3': -16.256500244140625, 'loss_4': 1.6342523097991943, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 10:10:48,237 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:48,237 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:37<56:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:55,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008243797346949577, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.242, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004511116072535515, 'eval_loss_2': 0.0037326812744140625, 'eval_loss_3': -18.25079345703125, 'eval_loss_4': 1.7150578498840332, 'epoch': 10.93}
{'loss': 0.0204, 'grad_norm': 6.287589073181152, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.014214033260941505, 'loss_2': 0.00623321533203125, 'loss_3': -16.300661087036133, 'loss_4': 2.1113321781158447, 'epoch': 10.94}
{'loss': 0.0369, 'grad_norm': 16.564525604248047, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.03220212087035179, 'loss_2': 0.004657745361328125, 'loss_3': -16.14619255065918, 'loss_4': 2.134791612625122, 'epoch': 10.94}
{'loss': 0.0276, 'grad_norm': 9.616415977478027, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.02197604440152645, 'loss_2': 0.00563812255859375, 'loss_3': -16.152982711791992, 'loss_4': 2.4160513877868652, 'epoch': 10.95}
{'loss': 0.0082, 'grad_norm': 4.767183303833008, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.00671290373429656, 'loss_2': 0.0014781951904296875, 'loss_3': -16.210296630859375, 'loss_4': 1.9787119626998901, 'epoch': 10.95}
{'loss': 0.0221, 'grad_norm': 7.753875732421875, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.01460206601768732, 'loss_2': 0.00749969482421875, 'loss_3': -16.230487823486328, 'loss_4': 2.428645610809326, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 10:10:55,586 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:55,586 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [46:45<56:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:02,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008936293423175812, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00550357298925519, 'eval_loss_2': 0.003432720899581909, 'eval_loss_3': -18.264556884765625, 'eval_loss_4': 2.147526264190674, 'epoch': 10.96}
{'loss': 0.0145, 'grad_norm': 5.553946018218994, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.012739828787744045, 'loss_2': 0.0017576217651367188, 'loss_3': -16.326953887939453, 'loss_4': 2.5629401206970215, 'epoch': 10.97}
{'loss': 0.0195, 'grad_norm': 6.89891242980957, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.015479891560971737, 'loss_2': 0.004032135009765625, 'loss_3': -16.24437713623047, 'loss_4': 3.1248717308044434, 'epoch': 10.97}
{'loss': 0.0216, 'grad_norm': 11.025580406188965, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.019611790776252747, 'loss_2': 0.0019435882568359375, 'loss_3': -16.29318618774414, 'loss_4': 2.402829647064209, 'epoch': 10.98}
{'loss': 0.0256, 'grad_norm': 10.510224342346191, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.019170470535755157, 'loss_2': 0.0064239501953125, 'loss_3': -16.070781707763672, 'loss_4': 2.2326111793518066, 'epoch': 10.98}
{'loss': 0.0258, 'grad_norm': 9.43692684173584, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.023471815511584282, 'loss_2': 0.00228118896484375, 'loss_3': -16.289716720581055, 'loss_4': 2.661283016204834, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 10:11:02,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:02,935 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [46:52<54:52,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:11:09,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009302714839577675, 'eval_runtime': 3.8197, 'eval_samples_per_second': 268.083, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.0060865189880132675, 'eval_loss_2': 0.0032161958515644073, 'eval_loss_3': -18.305856704711914, 'eval_loss_4': 2.5073635578155518, 'epoch': 10.99}
{'loss': 0.0202, 'grad_norm': 7.123744964599609, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.018255434930324554, 'loss_2': 0.00191497802734375, 'loss_3': -16.390878677368164, 'loss_4': 2.5940258502960205, 'epoch': 10.99}
{'loss': 0.0047, 'grad_norm': 6.283402442932129, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.002464311197400093, 'loss_2': 0.002239227294921875, 'loss_3': -16.53546714782715, 'loss_4': 2.766984701156616, 'epoch': 11.0}
{'loss': 0.0353, 'grad_norm': 11.380000114440918, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.02315814606845379, 'loss_2': 0.01212310791015625, 'loss_3': -16.39863395690918, 'loss_4': 2.6829888820648193, 'epoch': 11.01}
{'loss': 0.0205, 'grad_norm': 8.500677108764648, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.017394494265317917, 'loss_2': 0.0030670166015625, 'loss_3': -16.3487548828125, 'loss_4': 2.763974905014038, 'epoch': 11.01}
{'loss': 0.0192, 'grad_norm': 9.807708740234375, 'learning_rate': 1.9e-05, 'loss_1': 0.013831544667482376, 'loss_2': 0.00534820556640625, 'loss_3': -16.284461975097656, 'loss_4': 2.7946548461914062, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 10:11:09,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:09,984 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [46:59<56:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:11:17,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01089494675397873, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.835, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00632247980684042, 'eval_loss_2': 0.004572466015815735, 'eval_loss_3': -18.358169555664062, 'eval_loss_4': 2.5985822677612305, 'epoch': 11.02}
{'loss': 0.023, 'grad_norm': 6.866177082061768, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.012523467652499676, 'loss_2': 0.010498046875, 'loss_3': -16.155031204223633, 'loss_4': 2.7903051376342773, 'epoch': 11.02}
{'loss': 0.0549, 'grad_norm': 20.816171646118164, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.053839653730392456, 'loss_2': 0.0010461807250976562, 'loss_3': -16.354799270629883, 'loss_4': 2.9924542903900146, 'epoch': 11.03}
{'loss': 0.0137, 'grad_norm': 6.08995246887207, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.01161362323909998, 'loss_2': 0.0021209716796875, 'loss_3': -16.15379524230957, 'loss_4': 3.4055304527282715, 'epoch': 11.03}
{'loss': 0.0146, 'grad_norm': 5.109006881713867, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.0069035813212394714, 'loss_2': 0.007659912109375, 'loss_3': -16.317363739013672, 'loss_4': 3.1016671657562256, 'epoch': 11.04}
{'loss': 0.0104, 'grad_norm': 9.361916542053223, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.010182015597820282, 'loss_2': 0.00024080276489257812, 'loss_3': -16.485488891601562, 'loss_4': 3.411484718322754, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 10:11:17,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:17,337 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:06<56:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:24,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00849698856472969, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0059693120419979095, 'eval_loss_2': 0.002527676522731781, 'eval_loss_3': -18.363452911376953, 'eval_loss_4': 2.674436330795288, 'epoch': 11.05}
{'loss': 0.0109, 'grad_norm': 7.481865406036377, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.010610856115818024, 'loss_2': 0.00031757354736328125, 'loss_3': -16.449668884277344, 'loss_4': 3.2921507358551025, 'epoch': 11.05}
{'loss': 0.0159, 'grad_norm': 7.5573930740356445, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.012437451630830765, 'loss_2': 0.003421783447265625, 'loss_3': -16.27374267578125, 'loss_4': 3.4201807975769043, 'epoch': 11.06}
{'loss': 0.0166, 'grad_norm': 9.013659477233887, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.013554868288338184, 'loss_2': 0.0030364990234375, 'loss_3': -16.563610076904297, 'loss_4': 3.001967191696167, 'epoch': 11.06}
{'loss': 0.0215, 'grad_norm': 6.081477642059326, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.013498907908797264, 'loss_2': 0.007965087890625, 'loss_3': -16.138187408447266, 'loss_4': 3.1873867511749268, 'epoch': 11.07}
{'loss': 0.0318, 'grad_norm': 11.189446449279785, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.028438758105039597, 'loss_2': 0.0033283233642578125, 'loss_3': -16.460050582885742, 'loss_4': 3.153118848800659, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 10:11:24,685 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:24,685 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:14<56:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:32,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014391445554792881, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.224, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.006413840223103762, 'eval_loss_2': 0.007977604866027832, 'eval_loss_3': -18.384435653686523, 'eval_loss_4': 3.000000476837158, 'epoch': 11.08}
{'loss': 0.0172, 'grad_norm': 5.681288242340088, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.013651199638843536, 'loss_2': 0.003589630126953125, 'loss_3': -16.303386688232422, 'loss_4': 3.6357359886169434, 'epoch': 11.08}
{'loss': 0.0232, 'grad_norm': 5.736293315887451, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.015909641981124878, 'loss_2': 0.0072784423828125, 'loss_3': -16.450260162353516, 'loss_4': 3.1545333862304688, 'epoch': 11.09}
{'loss': 0.0301, 'grad_norm': 11.160085678100586, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.02477341517806053, 'loss_2': 0.0053558349609375, 'loss_3': -16.375444412231445, 'loss_4': 3.8130993843078613, 'epoch': 11.09}
{'loss': 0.0301, 'grad_norm': 8.102559089660645, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.0226464681327343, 'loss_2': 0.00745391845703125, 'loss_3': -16.209959030151367, 'loss_4': 3.451359272003174, 'epoch': 11.1}
{'loss': 0.037, 'grad_norm': 17.439952850341797, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.036409277468919754, 'loss_2': 0.0006237030029296875, 'loss_3': -16.326053619384766, 'loss_4': 2.851799249649048, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 10:11:32,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:32,050 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:21<56:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:39,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009654323570430279, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006719420664012432, 'eval_loss_2': 0.0029349029064178467, 'eval_loss_3': -18.369386672973633, 'eval_loss_4': 3.3628125190734863, 'epoch': 11.1}
{'loss': 0.0214, 'grad_norm': 7.170012474060059, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.01708388701081276, 'loss_2': 0.00432586669921875, 'loss_3': -16.157360076904297, 'loss_4': 3.1466317176818848, 'epoch': 11.11}
{'loss': 0.0284, 'grad_norm': 12.71155834197998, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.027174904942512512, 'loss_2': 0.0012216567993164062, 'loss_3': -16.40597152709961, 'loss_4': 3.7089409828186035, 'epoch': 11.12}
{'loss': 0.0175, 'grad_norm': 5.280279636383057, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.01322836335748434, 'loss_2': 0.004276275634765625, 'loss_3': -16.34984588623047, 'loss_4': 3.9390928745269775, 'epoch': 11.12}
{'loss': 0.0272, 'grad_norm': 8.06997013092041, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.02377002313733101, 'loss_2': 0.0034275054931640625, 'loss_3': -16.576730728149414, 'loss_4': 4.485983848571777, 'epoch': 11.13}
{'loss': 0.0303, 'grad_norm': 9.97596263885498, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.026798034086823463, 'loss_2': 0.003459930419921875, 'loss_3': -16.421363830566406, 'loss_4': 4.652059555053711, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 10:11:39,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:39,405 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:28<56:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:46,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01316901296377182, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.783, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007791722193360329, 'eval_loss_2': 0.005377292633056641, 'eval_loss_3': -18.397680282592773, 'eval_loss_4': 3.841794967651367, 'epoch': 11.13}
{'loss': 0.0156, 'grad_norm': 8.056354522705078, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.014086781069636345, 'loss_2': 0.001468658447265625, 'loss_3': -16.296016693115234, 'loss_4': 4.419525146484375, 'epoch': 11.14}
{'loss': 0.0406, 'grad_norm': 12.282235145568848, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.0340578630566597, 'loss_2': 0.0065765380859375, 'loss_3': -16.4345645904541, 'loss_4': 4.3064470291137695, 'epoch': 11.15}
{'loss': 0.0132, 'grad_norm': 5.603588104248047, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.010824440978467464, 'loss_2': 0.0023822784423828125, 'loss_3': -16.391437530517578, 'loss_4': 4.39238977432251, 'epoch': 11.15}
{'loss': 0.0163, 'grad_norm': 5.748342037200928, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.012707646004855633, 'loss_2': 0.0035858154296875, 'loss_3': -16.57684326171875, 'loss_4': 4.036567687988281, 'epoch': 11.16}
{'loss': 0.0107, 'grad_norm': 4.996766567230225, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.00990251637995243, 'loss_2': 0.0007715225219726562, 'loss_3': -16.412063598632812, 'loss_4': 4.193697452545166, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 10:11:46,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:46,763 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:36<56:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:54,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013119731098413467, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008306754752993584, 'eval_loss_2': 0.0048129744827747345, 'eval_loss_3': -18.395843505859375, 'eval_loss_4': 4.082910060882568, 'epoch': 11.16}
{'loss': 0.0198, 'grad_norm': 7.491366863250732, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.015202022157609463, 'loss_2': 0.004589080810546875, 'loss_3': -16.588207244873047, 'loss_4': 4.80869197845459, 'epoch': 11.17}
{'loss': 0.0228, 'grad_norm': 12.020730018615723, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.020231982693076134, 'loss_2': 0.00258636474609375, 'loss_3': -16.388168334960938, 'loss_4': 4.5199995040893555, 'epoch': 11.17}
{'loss': 0.0139, 'grad_norm': 5.5787129402160645, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.01127625722438097, 'loss_2': 0.0026645660400390625, 'loss_3': -16.61084747314453, 'loss_4': 4.457047462463379, 'epoch': 11.18}
{'loss': 0.0194, 'grad_norm': 8.761726379394531, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.015924248844385147, 'loss_2': 0.00347137451171875, 'loss_3': -16.45986557006836, 'loss_4': 3.8627817630767822, 'epoch': 11.19}
{'loss': 0.032, 'grad_norm': 11.358525276184082, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.028169333934783936, 'loss_2': 0.003856658935546875, 'loss_3': -16.461898803710938, 'loss_4': 4.875633239746094, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 10:11:54,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:54,121 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [47:43<55:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:01,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011843569576740265, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00850636512041092, 'eval_loss_2': 0.0033372044563293457, 'eval_loss_3': -18.378150939941406, 'eval_loss_4': 4.133583068847656, 'epoch': 11.19}
{'loss': 0.0421, 'grad_norm': 13.38520336151123, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.03837236389517784, 'loss_2': 0.0037746429443359375, 'loss_3': -16.539081573486328, 'loss_4': 4.78865385055542, 'epoch': 11.2}
{'loss': 0.0111, 'grad_norm': 6.072115898132324, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.00981888733804226, 'loss_2': 0.0013132095336914062, 'loss_3': -16.531543731689453, 'loss_4': 4.067756175994873, 'epoch': 11.2}
{'loss': 0.025, 'grad_norm': 9.567992210388184, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.021616904065012932, 'loss_2': 0.00337982177734375, 'loss_3': -16.308692932128906, 'loss_4': 4.389320373535156, 'epoch': 11.21}
{'loss': 0.0146, 'grad_norm': 6.760207653045654, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.01201152428984642, 'loss_2': 0.0025539398193359375, 'loss_3': -16.780881881713867, 'loss_4': 4.258603572845459, 'epoch': 11.22}
{'loss': 0.0094, 'grad_norm': 6.705132007598877, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.008636224083602428, 'loss_2': 0.0007829666137695312, 'loss_3': -16.273805618286133, 'loss_4': 3.514620065689087, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 10:12:01,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:01,471 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [47:50<55:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:08,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013567371293902397, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.203, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009492411278188229, 'eval_loss_2': 0.004074960947036743, 'eval_loss_3': -18.3732852935791, 'eval_loss_4': 4.034885406494141, 'epoch': 11.22}
{'loss': 0.0166, 'grad_norm': 6.359152317047119, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.012403233908116817, 'loss_2': 0.004222869873046875, 'loss_3': -16.43898582458496, 'loss_4': 4.620826721191406, 'epoch': 11.23}
{'loss': 0.0346, 'grad_norm': 10.064457893371582, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.02370516210794449, 'loss_2': 0.01092529296875, 'loss_3': -16.67099380493164, 'loss_4': 4.31890344619751, 'epoch': 11.23}
{'loss': 0.0124, 'grad_norm': 5.3207855224609375, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.010750077664852142, 'loss_2': 0.0016918182373046875, 'loss_3': -16.5997257232666, 'loss_4': 4.717256546020508, 'epoch': 11.24}
{'loss': 0.0145, 'grad_norm': 6.419717311859131, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.00902567245066166, 'loss_2': 0.00543212890625, 'loss_3': -16.408586502075195, 'loss_4': 4.200021743774414, 'epoch': 11.24}
{'loss': 0.013, 'grad_norm': 5.143386363983154, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.011769270524382591, 'loss_2': 0.00122833251953125, 'loss_3': -16.462596893310547, 'loss_4': 4.11970853805542, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 10:12:08,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:08,825 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [47:58<55:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:16,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01601495034992695, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009928570128977299, 'eval_loss_2': 0.006086379289627075, 'eval_loss_3': -18.344701766967773, 'eval_loss_4': 3.890672206878662, 'epoch': 11.25}
{'loss': 0.0142, 'grad_norm': 5.351944446563721, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.011743925511837006, 'loss_2': 0.002475738525390625, 'loss_3': -16.58934783935547, 'loss_4': 3.905428647994995, 'epoch': 11.26}
{'loss': 0.0125, 'grad_norm': 5.666323184967041, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.010391781106591225, 'loss_2': 0.0020847320556640625, 'loss_3': -16.4500732421875, 'loss_4': 4.083889484405518, 'epoch': 11.26}
{'loss': 0.0192, 'grad_norm': 5.796247959136963, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.01193269807845354, 'loss_2': 0.0072784423828125, 'loss_3': -16.237384796142578, 'loss_4': 3.5954339504241943, 'epoch': 11.27}
{'loss': 0.0123, 'grad_norm': 5.181131839752197, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.008983612060546875, 'loss_2': 0.00333404541015625, 'loss_3': -16.410099029541016, 'loss_4': 3.5540194511413574, 'epoch': 11.27}
{'loss': 0.0192, 'grad_norm': 7.32131290435791, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.012847000733017921, 'loss_2': 0.00634765625, 'loss_3': -16.642745971679688, 'loss_4': 4.372272491455078, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 10:12:16,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:16,171 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:05<55:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:23,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016059041023254395, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009208560921251774, 'eval_loss_2': 0.006850481033325195, 'eval_loss_3': -18.34259033203125, 'eval_loss_4': 3.6706717014312744, 'epoch': 11.28}
{'loss': 0.0099, 'grad_norm': 4.918720245361328, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.006351444870233536, 'loss_2': 0.003505706787109375, 'loss_3': -16.47136688232422, 'loss_4': 4.064881801605225, 'epoch': 11.28}
{'loss': 0.02, 'grad_norm': 7.6964287757873535, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.013654927723109722, 'loss_2': 0.0063629150390625, 'loss_3': -16.299285888671875, 'loss_4': 3.7244768142700195, 'epoch': 11.29}
{'loss': 0.0084, 'grad_norm': 5.170435428619385, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.00784041453152895, 'loss_2': 0.0005369186401367188, 'loss_3': -16.402650833129883, 'loss_4': 4.161960601806641, 'epoch': 11.3}
{'loss': 0.0106, 'grad_norm': 8.39665699005127, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.010526014491915703, 'loss_2': 9.071826934814453e-05, 'loss_3': -16.544450759887695, 'loss_4': 3.5857598781585693, 'epoch': 11.3}
{'loss': 0.0091, 'grad_norm': 5.138009548187256, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.007111808285117149, 'loss_2': 0.0019893646240234375, 'loss_3': -16.61984634399414, 'loss_4': 3.7451393604278564, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 10:12:23,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:23,521 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:13<55:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:30,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012506561353802681, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.537, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008418486453592777, 'eval_loss_2': 0.004088073968887329, 'eval_loss_3': -18.351850509643555, 'eval_loss_4': 3.5866599082946777, 'epoch': 11.31}
{'loss': 0.0316, 'grad_norm': 12.375773429870605, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.02452394925057888, 'loss_2': 0.007099151611328125, 'loss_3': -16.380550384521484, 'loss_4': 4.182082176208496, 'epoch': 11.31}
{'loss': 0.0234, 'grad_norm': 6.47934103012085, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.011501617729663849, 'loss_2': 0.01192474365234375, 'loss_3': -16.516029357910156, 'loss_4': 3.592707872390747, 'epoch': 11.32}
{'loss': 0.0147, 'grad_norm': 5.299304962158203, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.009035528637468815, 'loss_2': 0.00562286376953125, 'loss_3': -16.67919158935547, 'loss_4': 3.7342872619628906, 'epoch': 11.33}
{'loss': 0.0176, 'grad_norm': 8.495577812194824, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.0109041603282094, 'loss_2': 0.006725311279296875, 'loss_3': -16.36111068725586, 'loss_4': 3.6095921993255615, 'epoch': 11.33}
{'loss': 0.0089, 'grad_norm': 5.5701823234558105, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.007787687238305807, 'loss_2': 0.0011272430419921875, 'loss_3': -16.623687744140625, 'loss_4': 3.3465309143066406, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 10:12:30,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:30,883 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:20<55:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:38,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010362685658037663, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0068913116119802, 'eval_loss_2': 0.00347137451171875, 'eval_loss_3': -18.375619888305664, 'eval_loss_4': 3.2098395824432373, 'epoch': 11.34}
{'loss': 0.0311, 'grad_norm': 13.302204132080078, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.024451959878206253, 'loss_2': 0.0066375732421875, 'loss_3': -16.409252166748047, 'loss_4': 3.123040199279785, 'epoch': 11.34}
{'loss': 0.0553, 'grad_norm': 21.829078674316406, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.05204051733016968, 'loss_2': 0.0032520294189453125, 'loss_3': -16.33824348449707, 'loss_4': 3.5616135597229004, 'epoch': 11.35}
{'loss': 0.0118, 'grad_norm': 4.8541693687438965, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.005289929918944836, 'loss_2': 0.0065155029296875, 'loss_3': -16.2232723236084, 'loss_4': 3.150024175643921, 'epoch': 11.35}
{'loss': 0.0114, 'grad_norm': 5.485113620758057, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.009175803512334824, 'loss_2': 0.0022144317626953125, 'loss_3': -16.48567771911621, 'loss_4': 2.9467720985412598, 'epoch': 11.36}
{'loss': 0.0091, 'grad_norm': 5.750570297241211, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.008270489051938057, 'loss_2': 0.0008602142333984375, 'loss_3': -16.488847732543945, 'loss_4': 2.792637348175049, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 10:12:38,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:38,232 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:27<55:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:45,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013559654355049133, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006479576230049133, 'eval_loss_2': 0.007080078125, 'eval_loss_3': -18.363292694091797, 'eval_loss_4': 2.8681492805480957, 'epoch': 11.37}
{'loss': 0.0277, 'grad_norm': 5.304430961608887, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.013157973997294903, 'loss_2': 0.0145721435546875, 'loss_3': -16.487506866455078, 'loss_4': 2.8935599327087402, 'epoch': 11.37}
{'loss': 0.0206, 'grad_norm': 7.72934103012085, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.01285239215940237, 'loss_2': 0.007732391357421875, 'loss_3': -16.429962158203125, 'loss_4': 2.7087502479553223, 'epoch': 11.38}
{'loss': 0.0308, 'grad_norm': 8.490154266357422, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.018934395164251328, 'loss_2': 0.01181793212890625, 'loss_3': -16.565011978149414, 'loss_4': 3.503875494003296, 'epoch': 11.38}
{'loss': 0.0186, 'grad_norm': 5.575275421142578, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.0074110450223088264, 'loss_2': 0.01122283935546875, 'loss_3': -16.445945739746094, 'loss_4': 2.6148486137390137, 'epoch': 11.39}
{'loss': 0.0162, 'grad_norm': 5.612987041473389, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.007181419059634209, 'loss_2': 0.00905609130859375, 'loss_3': -16.44947624206543, 'loss_4': 3.0631613731384277, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 10:12:45,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:45,573 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:35<55:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:52,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013411389663815498, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.141, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006747290957719088, 'eval_loss_2': 0.006664097309112549, 'eval_loss_3': -18.336719512939453, 'eval_loss_4': 2.6457223892211914, 'epoch': 11.4}
{'loss': 0.0035, 'grad_norm': 4.460626125335693, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.0028957973700016737, 'loss_2': 0.0005750656127929688, 'loss_3': -16.514469146728516, 'loss_4': 2.9059293270111084, 'epoch': 11.4}
{'loss': 0.0157, 'grad_norm': 5.0170698165893555, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.0074264551512897015, 'loss_2': 0.0083160400390625, 'loss_3': -16.484817504882812, 'loss_4': 3.261399745941162, 'epoch': 11.41}
{'loss': 0.0205, 'grad_norm': 6.51241397857666, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.013675731606781483, 'loss_2': 0.00681304931640625, 'loss_3': -16.502811431884766, 'loss_4': 2.49611234664917, 'epoch': 11.41}
{'loss': 0.021, 'grad_norm': 8.392695426940918, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.01117467787116766, 'loss_2': 0.00983428955078125, 'loss_3': -16.509849548339844, 'loss_4': 2.892688751220703, 'epoch': 11.42}
{'loss': 0.0183, 'grad_norm': 7.241189956665039, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.016306329518556595, 'loss_2': 0.00194549560546875, 'loss_3': -16.377544403076172, 'loss_4': 2.800886869430542, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 10:12:52,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:52,929 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:42<55:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:00,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010143592953681946, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.134, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006606288719922304, 'eval_loss_2': 0.003537304699420929, 'eval_loss_3': -18.34996223449707, 'eval_loss_4': 2.2763967514038086, 'epoch': 11.42}
{'loss': 0.0136, 'grad_norm': 4.523705005645752, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.005878208205103874, 'loss_2': 0.00769805908203125, 'loss_3': -16.41952133178711, 'loss_4': 2.6661009788513184, 'epoch': 11.43}
{'loss': 0.0099, 'grad_norm': 5.219094753265381, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.003920433111488819, 'loss_2': 0.0059356689453125, 'loss_3': -16.447175979614258, 'loss_4': 2.429288387298584, 'epoch': 11.44}
{'loss': 0.0079, 'grad_norm': 5.248570442199707, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.005755390506237745, 'loss_2': 0.002105712890625, 'loss_3': -16.499710083007812, 'loss_4': 2.4932470321655273, 'epoch': 11.44}
{'loss': 0.0095, 'grad_norm': 6.225266456604004, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.008651793003082275, 'loss_2': 0.000827789306640625, 'loss_3': -16.546016693115234, 'loss_4': 1.816738486289978, 'epoch': 11.45}
{'loss': 0.0217, 'grad_norm': 7.980752944946289, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.0204982478171587, 'loss_2': 0.0011920928955078125, 'loss_3': -16.36783218383789, 'loss_4': 2.385104179382324, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 10:13:00,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:00,279 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [48:49<55:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:07,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011401545256376266, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.779, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006240468472242355, 'eval_loss_2': 0.005161076784133911, 'eval_loss_3': -18.357769012451172, 'eval_loss_4': 1.9885978698730469, 'epoch': 11.45}
{'loss': 0.0155, 'grad_norm': 5.776824951171875, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.010192761197686195, 'loss_2': 0.00528717041015625, 'loss_3': -16.453691482543945, 'loss_4': 2.69655179977417, 'epoch': 11.46}
{'loss': 0.0145, 'grad_norm': 5.440338134765625, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.008137497119605541, 'loss_2': 0.006381988525390625, 'loss_3': -16.455425262451172, 'loss_4': 2.0387654304504395, 'epoch': 11.47}
{'loss': 0.0127, 'grad_norm': 5.364783763885498, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.007668440695852041, 'loss_2': 0.0050048828125, 'loss_3': -16.293001174926758, 'loss_4': 1.5566189289093018, 'epoch': 11.47}
{'loss': 0.035, 'grad_norm': 10.96229076385498, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.02952166460454464, 'loss_2': 0.0055084228515625, 'loss_3': -16.367198944091797, 'loss_4': 1.909389853477478, 'epoch': 11.48}
{'loss': 0.0115, 'grad_norm': 6.491473197937012, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.009118447080254555, 'loss_2': 0.002384185791015625, 'loss_3': -16.694499969482422, 'loss_4': 2.1400279998779297, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 10:13:07,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:07,642 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [48:57<55:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:15,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010822167620062828, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.317, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007308771833777428, 'eval_loss_2': 0.0035133957862854004, 'eval_loss_3': -18.353639602661133, 'eval_loss_4': 1.726362705230713, 'epoch': 11.48}
{'loss': 0.0104, 'grad_norm': 4.941941261291504, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.006161908153444529, 'loss_2': 0.00421905517578125, 'loss_3': -16.31033706665039, 'loss_4': 2.07009220123291, 'epoch': 11.49}
{'loss': 0.0123, 'grad_norm': 8.15592098236084, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.010999114252626896, 'loss_2': 0.0013132095336914062, 'loss_3': -16.393409729003906, 'loss_4': 2.4641354084014893, 'epoch': 11.49}
{'loss': 0.0078, 'grad_norm': 5.0606584548950195, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.005871103145182133, 'loss_2': 0.001972198486328125, 'loss_3': -16.367164611816406, 'loss_4': 1.613097906112671, 'epoch': 11.5}
{'loss': 0.0119, 'grad_norm': 4.500737190246582, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.0038605856243520975, 'loss_2': 0.008087158203125, 'loss_3': -16.368141174316406, 'loss_4': 1.7455815076828003, 'epoch': 11.51}
{'loss': 0.0082, 'grad_norm': 4.956323623657227, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.0063591632060706615, 'loss_2': 0.001865386962890625, 'loss_3': -16.427040100097656, 'loss_4': 1.6476993560791016, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 10:13:15,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:15,005 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:04<54:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:22,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01095191203057766, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.546, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006603008136153221, 'eval_loss_2': 0.0043489038944244385, 'eval_loss_3': -18.355207443237305, 'eval_loss_4': 1.488999843597412, 'epoch': 11.51}
{'loss': 0.0196, 'grad_norm': 10.479581832885742, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.0186652522534132, 'loss_2': 0.0009832382202148438, 'loss_3': -16.321552276611328, 'loss_4': 1.8216159343719482, 'epoch': 11.52}
{'loss': 0.0388, 'grad_norm': 20.45929527282715, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.02816886454820633, 'loss_2': 0.010589599609375, 'loss_3': -16.120126724243164, 'loss_4': 1.1085584163665771, 'epoch': 11.52}
{'loss': 0.024, 'grad_norm': 7.838522911071777, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.016484249383211136, 'loss_2': 0.00751495361328125, 'loss_3': -16.356800079345703, 'loss_4': 1.1069672107696533, 'epoch': 11.53}
{'loss': 0.0231, 'grad_norm': 4.5199127197265625, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.005282903090119362, 'loss_2': 0.0178375244140625, 'loss_3': -16.38328742980957, 'loss_4': 1.8569071292877197, 'epoch': 11.53}
{'loss': 0.0212, 'grad_norm': 7.924572944641113, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.01579643413424492, 'loss_2': 0.005435943603515625, 'loss_3': -16.431184768676758, 'loss_4': 0.9952639937400818, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 10:13:22,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:22,339 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:11<54:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:29,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01213186327368021, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.422, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006308027543127537, 'eval_loss_2': 0.005823835730552673, 'eval_loss_3': -18.355022430419922, 'eval_loss_4': 1.2081549167633057, 'epoch': 11.54}
{'loss': 0.0154, 'grad_norm': 6.459291934967041, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.01261597778648138, 'loss_2': 0.0027618408203125, 'loss_3': -16.24155044555664, 'loss_4': 1.7849295139312744, 'epoch': 11.55}
{'loss': 0.0081, 'grad_norm': 5.7961907386779785, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.007780729793012142, 'loss_2': 0.0003275871276855469, 'loss_3': -16.39162826538086, 'loss_4': 1.512317419052124, 'epoch': 11.55}
{'loss': 0.0112, 'grad_norm': 6.859447479248047, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.0074588521383702755, 'loss_2': 0.003726959228515625, 'loss_3': -16.445676803588867, 'loss_4': 1.7361469268798828, 'epoch': 11.56}
{'loss': 0.0149, 'grad_norm': 5.107412815093994, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.009965010918676853, 'loss_2': 0.004947662353515625, 'loss_3': -16.511611938476562, 'loss_4': 1.3716617822647095, 'epoch': 11.56}
{'loss': 0.0115, 'grad_norm': 8.564242362976074, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.009720776230096817, 'loss_2': 0.0017566680908203125, 'loss_3': -16.364423751831055, 'loss_4': 0.9002261161804199, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 10:13:29,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:29,684 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:19<54:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:37,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01111186295747757, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006913668941706419, 'eval_loss_2': 0.004198193550109863, 'eval_loss_3': -18.34139633178711, 'eval_loss_4': 1.0098588466644287, 'epoch': 11.57}
{'loss': 0.0217, 'grad_norm': 7.986884117126465, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.018342118710279465, 'loss_2': 0.003387451171875, 'loss_3': -16.40728759765625, 'loss_4': 1.2512378692626953, 'epoch': 11.58}
{'loss': 0.0118, 'grad_norm': 5.452012538909912, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.009518628939986229, 'loss_2': 0.0023136138916015625, 'loss_3': -16.306316375732422, 'loss_4': 1.8072433471679688, 'epoch': 11.58}
{'loss': 0.0171, 'grad_norm': 6.171563625335693, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.016205741092562675, 'loss_2': 0.0009360313415527344, 'loss_3': -16.476253509521484, 'loss_4': 0.8755829334259033, 'epoch': 11.59}
{'loss': 0.0455, 'grad_norm': 14.04870319366455, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.04182552173733711, 'loss_2': 0.003711700439453125, 'loss_3': -16.474409103393555, 'loss_4': 1.5371862649917603, 'epoch': 11.59}
{'loss': 0.0106, 'grad_norm': 5.527090072631836, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.0054509942419826984, 'loss_2': 0.00511932373046875, 'loss_3': -16.374319076538086, 'loss_4': 0.7738071084022522, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 10:13:37,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:37,018 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:26<54:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:44,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011702216230332851, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.565, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007481521926820278, 'eval_loss_2': 0.004220694303512573, 'eval_loss_3': -18.348548889160156, 'eval_loss_4': 0.9887953400611877, 'epoch': 11.6}
{'loss': 0.0105, 'grad_norm': 7.505220413208008, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.00820719450712204, 'loss_2': 0.00225067138671875, 'loss_3': -16.30849838256836, 'loss_4': 0.8671063780784607, 'epoch': 11.6}
{'loss': 0.0122, 'grad_norm': 5.9186835289001465, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.009723402559757233, 'loss_2': 0.00244140625, 'loss_3': -16.390460968017578, 'loss_4': 1.3650718927383423, 'epoch': 11.61}
{'loss': 0.0199, 'grad_norm': 11.240752220153809, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.017029818147420883, 'loss_2': 0.002899169921875, 'loss_3': -16.591552734375, 'loss_4': 0.8954545259475708, 'epoch': 11.62}
{'loss': 0.0145, 'grad_norm': 5.396687984466553, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.00744825042784214, 'loss_2': 0.00701141357421875, 'loss_3': -16.189245223999023, 'loss_4': 1.6010093688964844, 'epoch': 11.62}
{'loss': 0.0062, 'grad_norm': 4.979144096374512, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.006180209573358297, 'loss_2': 5.793571472167969e-05, 'loss_3': -16.35909652709961, 'loss_4': 1.6684520244598389, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 10:13:44,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:44,361 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:33<54:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:51,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011227622628211975, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.632, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007300964090973139, 'eval_loss_2': 0.003926657140254974, 'eval_loss_3': -18.33416748046875, 'eval_loss_4': 1.038788080215454, 'epoch': 11.63}
{'loss': 0.0087, 'grad_norm': 6.3979692459106445, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.006569873541593552, 'loss_2': 0.0021457672119140625, 'loss_3': -16.491336822509766, 'loss_4': 0.66658616065979, 'epoch': 11.63}
{'loss': 0.0342, 'grad_norm': 11.194682121276855, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.027482587844133377, 'loss_2': 0.00667572021484375, 'loss_3': -16.329158782958984, 'loss_4': 1.4716837406158447, 'epoch': 11.64}
{'loss': 0.0125, 'grad_norm': 5.825286388397217, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.0064827268943190575, 'loss_2': 0.006000518798828125, 'loss_3': -16.44743537902832, 'loss_4': 0.7892294526100159, 'epoch': 11.65}
{'loss': 0.0179, 'grad_norm': 9.057267189025879, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.013321354053914547, 'loss_2': 0.004543304443359375, 'loss_3': -16.29363250732422, 'loss_4': 1.0976017713546753, 'epoch': 11.65}
{'loss': 0.0177, 'grad_norm': 6.224270820617676, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.011420313268899918, 'loss_2': 0.0062408447265625, 'loss_3': -16.182044982910156, 'loss_4': 0.8435729742050171, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 10:13:51,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:51,719 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:41<54:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:59,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012820646166801453, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.499, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008580580353736877, 'eval_loss_2': 0.004240065813064575, 'eval_loss_3': -18.342567443847656, 'eval_loss_4': 0.9779400825500488, 'epoch': 11.66}
{'loss': 0.0195, 'grad_norm': 7.952462196350098, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.016973579302430153, 'loss_2': 0.002559661865234375, 'loss_3': -16.216209411621094, 'loss_4': 0.9941888451576233, 'epoch': 11.66}
{'loss': 0.0128, 'grad_norm': 5.414997577667236, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.0069227879866957664, 'loss_2': 0.005886077880859375, 'loss_3': -16.38526153564453, 'loss_4': 1.1546595096588135, 'epoch': 11.67}
{'loss': 0.0096, 'grad_norm': 4.5638275146484375, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.005010250024497509, 'loss_2': 0.004573822021484375, 'loss_3': -16.36867332458496, 'loss_4': 1.007261037826538, 'epoch': 11.67}
{'loss': 0.0355, 'grad_norm': 16.70470428466797, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.029968220740556717, 'loss_2': 0.0054931640625, 'loss_3': -16.456268310546875, 'loss_4': 1.108243465423584, 'epoch': 11.68}
{'loss': 0.0082, 'grad_norm': 5.0365986824035645, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.004911683965474367, 'loss_2': 0.0032806396484375, 'loss_3': -16.22233009338379, 'loss_4': 1.09354829788208, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 10:13:59,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:59,062 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [49:48<54:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:06,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012201137840747833, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008592805825173855, 'eval_loss_2': 0.003608331084251404, 'eval_loss_3': -18.355918884277344, 'eval_loss_4': 1.0457264184951782, 'epoch': 11.69}
{'loss': 0.0658, 'grad_norm': 13.877408981323242, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.06562484055757523, 'loss_2': 0.00017547607421875, 'loss_3': -16.073551177978516, 'loss_4': 0.9070625901222229, 'epoch': 11.69}
{'loss': 0.0129, 'grad_norm': 6.173722267150879, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.01052983570843935, 'loss_2': 0.00232696533203125, 'loss_3': -16.25116539001465, 'loss_4': 1.014333724975586, 'epoch': 11.7}
{'loss': 0.0079, 'grad_norm': 4.842139720916748, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.00731069827452302, 'loss_2': 0.0005893707275390625, 'loss_3': -16.1480655670166, 'loss_4': 1.125361442565918, 'epoch': 11.7}
{'loss': 0.011, 'grad_norm': 5.706575870513916, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.006279756780713797, 'loss_2': 0.00473785400390625, 'loss_3': -16.386104583740234, 'loss_4': 1.2961655855178833, 'epoch': 11.71}
{'loss': 0.0262, 'grad_norm': 9.899920463562012, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.017708061262965202, 'loss_2': 0.00848388671875, 'loss_3': -16.592613220214844, 'loss_4': 1.400907278060913, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 10:14:06,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:06,417 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [49:55<54:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:13,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011679111048579216, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0077921729534864426, 'eval_loss_2': 0.0038869380950927734, 'eval_loss_3': -18.36395263671875, 'eval_loss_4': 1.1357269287109375, 'epoch': 11.72}
{'loss': 0.0095, 'grad_norm': 5.2590460777282715, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.005723034031689167, 'loss_2': 0.003753662109375, 'loss_3': -16.293392181396484, 'loss_4': 1.5183498859405518, 'epoch': 11.72}
{'loss': 0.0108, 'grad_norm': 5.363845348358154, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.006490540225058794, 'loss_2': 0.0042877197265625, 'loss_3': -16.419654846191406, 'loss_4': 1.3547701835632324, 'epoch': 11.73}
{'loss': 0.016, 'grad_norm': 8.249282836914062, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.008583787828683853, 'loss_2': 0.00738525390625, 'loss_3': -16.358917236328125, 'loss_4': 1.428467035293579, 'epoch': 11.73}
{'loss': 0.0167, 'grad_norm': 4.647356986999512, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.008400892838835716, 'loss_2': 0.00830078125, 'loss_3': -16.321365356445312, 'loss_4': 1.3285834789276123, 'epoch': 11.74}
{'loss': 0.0062, 'grad_norm': 4.777494430541992, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.0057439738884568214, 'loss_2': 0.0004887580871582031, 'loss_3': -16.158832550048828, 'loss_4': 1.1724098920822144, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 10:14:13,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:13,765 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:03<54:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:21,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011205362156033516, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.487, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007514858152717352, 'eval_loss_2': 0.0036905035376548767, 'eval_loss_3': -18.374380111694336, 'eval_loss_4': 1.2983646392822266, 'epoch': 11.74}
{'loss': 0.008, 'grad_norm': 4.867397308349609, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.005815896671265364, 'loss_2': 0.00222015380859375, 'loss_3': -16.487577438354492, 'loss_4': 1.8180228471755981, 'epoch': 11.75}
{'loss': 0.0085, 'grad_norm': 5.258802890777588, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.006451473105698824, 'loss_2': 0.00200653076171875, 'loss_3': -16.186473846435547, 'loss_4': 1.5206823348999023, 'epoch': 11.76}
{'loss': 0.0096, 'grad_norm': 4.940223217010498, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.008131610229611397, 'loss_2': 0.0014371871948242188, 'loss_3': -16.464143753051758, 'loss_4': 1.4006168842315674, 'epoch': 11.76}
{'loss': 0.0102, 'grad_norm': 5.240411758422852, 'learning_rate': 1.825e-05, 'loss_1': 0.007162884343415499, 'loss_2': 0.0029888153076171875, 'loss_3': -16.416614532470703, 'loss_4': 1.5309475660324097, 'epoch': 11.77}
{'loss': 0.0069, 'grad_norm': 4.348656177520752, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.006605097092688084, 'loss_2': 0.00034332275390625, 'loss_3': -16.339153289794922, 'loss_4': 1.7877998352050781, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 10:14:21,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:21,110 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:10<54:58,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:14:28,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011992878280580044, 'eval_runtime': 3.9924, 'eval_samples_per_second': 256.488, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.008024429902434349, 'eval_loss_2': 0.00396844744682312, 'eval_loss_3': -18.322843551635742, 'eval_loss_4': 1.5083781480789185, 'epoch': 11.77}
{'loss': 0.0153, 'grad_norm': 5.948403358459473, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.009801017120480537, 'loss_2': 0.00548553466796875, 'loss_3': -16.292861938476562, 'loss_4': 1.372270941734314, 'epoch': 11.78}
{'loss': 0.0225, 'grad_norm': 7.316376209259033, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.00843652430921793, 'loss_2': 0.01409149169921875, 'loss_3': -16.33086395263672, 'loss_4': 2.188462018966675, 'epoch': 11.78}
{'loss': 0.0112, 'grad_norm': 5.520700454711914, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.005975583102554083, 'loss_2': 0.00519561767578125, 'loss_3': -16.53152084350586, 'loss_4': 1.9083466529846191, 'epoch': 11.79}
{'loss': 0.0149, 'grad_norm': 6.511726379394531, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.014444171451032162, 'loss_2': 0.0004496574401855469, 'loss_3': -16.27159309387207, 'loss_4': 1.948709487915039, 'epoch': 11.8}
{'loss': 0.0078, 'grad_norm': 5.553463459014893, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.007643008138984442, 'loss_2': 0.00015401840209960938, 'loss_3': -16.14893341064453, 'loss_4': 1.8555676937103271, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 10:14:28,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:28,658 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:18<54:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:36,028 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012239293195307255, 'eval_runtime': 3.8211, 'eval_samples_per_second': 267.985, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.008641095831990242, 'eval_loss_2': 0.0035981982946395874, 'eval_loss_3': -18.29498291015625, 'eval_loss_4': 1.8482799530029297, 'epoch': 11.8}
{'loss': 0.0115, 'grad_norm': 6.718760967254639, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.010909377597272396, 'loss_2': 0.0006008148193359375, 'loss_3': -16.341047286987305, 'loss_4': 2.3495593070983887, 'epoch': 11.81}
{'loss': 0.0139, 'grad_norm': 5.851065635681152, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.007556632626801729, 'loss_2': 0.00634765625, 'loss_3': -16.31702423095703, 'loss_4': 1.6637178659439087, 'epoch': 11.81}
{'loss': 0.0204, 'grad_norm': 9.860626220703125, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.018031660467386246, 'loss_2': 0.00232696533203125, 'loss_3': -16.162429809570312, 'loss_4': 2.6231260299682617, 'epoch': 11.82}
{'loss': 0.014, 'grad_norm': 6.376411437988281, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.011162965558469296, 'loss_2': 0.002838134765625, 'loss_3': -16.38405990600586, 'loss_4': 2.099008083343506, 'epoch': 11.83}
{'loss': 0.0109, 'grad_norm': 4.887138366699219, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.0073575121350586414, 'loss_2': 0.0035858154296875, 'loss_3': -16.377126693725586, 'loss_4': 1.7230474948883057, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 10:14:36,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:36,028 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:25<54:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:43,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012187632732093334, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008077595382928848, 'eval_loss_2': 0.0041100382804870605, 'eval_loss_3': -18.289554595947266, 'eval_loss_4': 2.1361773014068604, 'epoch': 11.83}
{'loss': 0.024, 'grad_norm': 10.701269149780273, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.022298721596598625, 'loss_2': 0.0017480850219726562, 'loss_3': -16.360355377197266, 'loss_4': 2.1535465717315674, 'epoch': 11.84}
{'loss': 0.0176, 'grad_norm': 7.645451545715332, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.0168226920068264, 'loss_2': 0.0007429122924804688, 'loss_3': -16.16229820251465, 'loss_4': 2.857388973236084, 'epoch': 11.84}
{'loss': 0.0095, 'grad_norm': 5.000027179718018, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.005733049940317869, 'loss_2': 0.003749847412109375, 'loss_3': -16.511962890625, 'loss_4': 2.1238903999328613, 'epoch': 11.85}
{'loss': 0.0582, 'grad_norm': 19.41890525817871, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.05443353205919266, 'loss_2': 0.003726959228515625, 'loss_3': -16.257431030273438, 'loss_4': 2.544351816177368, 'epoch': 11.85}
{'loss': 0.0113, 'grad_norm': 6.328039169311523, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.0093151293694973, 'loss_2': 0.001956939697265625, 'loss_3': -16.243595123291016, 'loss_4': 2.1974215507507324, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 10:14:43,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:43,376 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:32<53:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:50,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012630827724933624, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.411, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008655644953250885, 'eval_loss_2': 0.003975182771682739, 'eval_loss_3': -18.275413513183594, 'eval_loss_4': 2.2548892498016357, 'epoch': 11.86}
{'loss': 0.0224, 'grad_norm': 8.954933166503906, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.0139955198392272, 'loss_2': 0.008453369140625, 'loss_3': -16.27610206604004, 'loss_4': 2.343844413757324, 'epoch': 11.87}
{'loss': 0.0111, 'grad_norm': 5.417567253112793, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.007862677797675133, 'loss_2': 0.0032596588134765625, 'loss_3': -16.368366241455078, 'loss_4': 2.292604923248291, 'epoch': 11.87}
{'loss': 0.0049, 'grad_norm': 5.050080299377441, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.0048864614218473434, 'loss_2': 3.796815872192383e-05, 'loss_3': -16.171125411987305, 'loss_4': 1.6011301279067993, 'epoch': 11.88}
{'loss': 0.0145, 'grad_norm': 7.407031536102295, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.012902792543172836, 'loss_2': 0.0016222000122070312, 'loss_3': -16.311962127685547, 'loss_4': 2.2222089767456055, 'epoch': 11.88}
{'loss': 0.0186, 'grad_norm': 10.084362030029297, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.0172871183604002, 'loss_2': 0.0013065338134765625, 'loss_3': -16.218734741210938, 'loss_4': 2.063446044921875, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 10:14:50,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:50,724 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:40<53:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:58,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014283623546361923, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.068, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009332280606031418, 'eval_loss_2': 0.004951342940330505, 'eval_loss_3': -18.24958038330078, 'eval_loss_4': 2.215738296508789, 'epoch': 11.89}
{'loss': 0.0211, 'grad_norm': 9.959610939025879, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.015563949942588806, 'loss_2': 0.00554656982421875, 'loss_3': -16.260406494140625, 'loss_4': 2.563570737838745, 'epoch': 11.9}
{'loss': 0.0249, 'grad_norm': 8.434761047363281, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.020946864038705826, 'loss_2': 0.00394439697265625, 'loss_3': -16.272443771362305, 'loss_4': 2.5758402347564697, 'epoch': 11.9}
{'loss': 0.0174, 'grad_norm': 13.297375679016113, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.01577209308743477, 'loss_2': 0.0016546249389648438, 'loss_3': -16.2504825592041, 'loss_4': 2.590252637863159, 'epoch': 11.91}
{'loss': 0.0358, 'grad_norm': 18.097488403320312, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.035026732832193375, 'loss_2': 0.0007505416870117188, 'loss_3': -16.25658416748047, 'loss_4': 2.0234315395355225, 'epoch': 11.91}
{'loss': 0.0383, 'grad_norm': 13.902499198913574, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.03602438420057297, 'loss_2': 0.00229644775390625, 'loss_3': -16.24270248413086, 'loss_4': 2.445617914199829, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 10:14:58,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:58,079 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [50:47<53:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:05,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014076600782573223, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.058, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00996969174593687, 'eval_loss_2': 0.0041069090366363525, 'eval_loss_3': -18.212600708007812, 'eval_loss_4': 2.3181443214416504, 'epoch': 11.92}
{'loss': 0.0092, 'grad_norm': 4.918745040893555, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.005865425802767277, 'loss_2': 0.0033397674560546875, 'loss_3': -16.362741470336914, 'loss_4': 2.404538154602051, 'epoch': 11.92}
{'loss': 0.0135, 'grad_norm': 6.722517967224121, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.012844356708228588, 'loss_2': 0.0006513595581054688, 'loss_3': -16.3000545501709, 'loss_4': 2.5773732662200928, 'epoch': 11.93}
{'loss': 0.0207, 'grad_norm': 7.292881011962891, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.018753020092844963, 'loss_2': 0.001903533935546875, 'loss_3': -16.253677368164062, 'loss_4': 2.8396880626678467, 'epoch': 11.94}
{'loss': 0.0091, 'grad_norm': 5.871078968048096, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.008368142880499363, 'loss_2': 0.000705718994140625, 'loss_3': -16.198429107666016, 'loss_4': 2.352552652359009, 'epoch': 11.94}
{'loss': 0.0097, 'grad_norm': 5.137021541595459, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.006682444363832474, 'loss_2': 0.0030574798583984375, 'loss_3': -16.343320846557617, 'loss_4': 3.1232824325561523, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 10:15:05,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:05,442 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [50:54<53:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:12,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016310466453433037, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.533, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01170573104172945, 'eval_loss_2': 0.004604734480381012, 'eval_loss_3': -18.189115524291992, 'eval_loss_4': 2.4303994178771973, 'epoch': 11.95}
{'loss': 0.0157, 'grad_norm': 6.376443862915039, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.01102764718234539, 'loss_2': 0.0046539306640625, 'loss_3': -16.366458892822266, 'loss_4': 2.662344455718994, 'epoch': 11.95}
{'loss': 0.0167, 'grad_norm': 7.252069473266602, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.01653069630265236, 'loss_2': 0.00021016597747802734, 'loss_3': -16.285293579101562, 'loss_4': 2.3822526931762695, 'epoch': 11.96}
{'loss': 0.0129, 'grad_norm': 6.7131195068359375, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.01268511451780796, 'loss_2': 0.00018858909606933594, 'loss_3': -16.371845245361328, 'loss_4': 2.9908785820007324, 'epoch': 11.97}
{'loss': 0.0192, 'grad_norm': 5.956936359405518, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.009228692390024662, 'loss_2': 0.0099639892578125, 'loss_3': -16.37388038635254, 'loss_4': 2.021038055419922, 'epoch': 11.97}
{'loss': 0.0147, 'grad_norm': 8.01756763458252, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.010028442367911339, 'loss_2': 0.004669189453125, 'loss_3': -16.415138244628906, 'loss_4': 2.5757367610931396, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 10:15:12,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:12,811 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:02<50:28,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:15:19,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015358169563114643, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.403, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010972592979669571, 'eval_loss_2': 0.0043855756521224976, 'eval_loss_3': -18.194490432739258, 'eval_loss_4': 2.3845467567443848, 'epoch': 11.98}
{'loss': 0.0891, 'grad_norm': 27.448183059692383, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.08261624723672867, 'loss_2': 0.00652313232421875, 'loss_3': -16.171297073364258, 'loss_4': 3.122227191925049, 'epoch': 11.98}
{'loss': 0.0272, 'grad_norm': 9.832672119140625, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.018175452947616577, 'loss_2': 0.00897979736328125, 'loss_3': -16.344533920288086, 'loss_4': 3.062304973602295, 'epoch': 11.99}
{'loss': 0.0208, 'grad_norm': 6.785112380981445, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.014753124676644802, 'loss_2': 0.0060577392578125, 'loss_3': -16.29962921142578, 'loss_4': 2.252732515335083, 'epoch': 11.99}
{'loss': 0.0051, 'grad_norm': 6.67940092086792, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.003499467857182026, 'loss_2': 0.0016269683837890625, 'loss_3': -16.44483184814453, 'loss_4': 2.2476892471313477, 'epoch': 12.0}
{'loss': 0.0495, 'grad_norm': 18.520246505737305, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.04618989676237106, 'loss_2': 0.00333404541015625, 'loss_3': -16.335596084594727, 'loss_4': 2.828441619873047, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 10:15:19,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:19,849 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:09<52:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:15:27,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01025459449738264, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00708794966340065, 'eval_loss_2': 0.0031666457653045654, 'eval_loss_3': -18.292869567871094, 'eval_loss_4': 2.176455020904541, 'epoch': 12.01}
{'loss': 0.0142, 'grad_norm': 7.320374965667725, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.011525668203830719, 'loss_2': 0.0026702880859375, 'loss_3': -16.212200164794922, 'loss_4': 2.2878830432891846, 'epoch': 12.01}
{'loss': 0.005, 'grad_norm': 5.002924919128418, 'learning_rate': 1.8e-05, 'loss_1': 0.004159972537308931, 'loss_2': 0.0008039474487304688, 'loss_3': -16.45868682861328, 'loss_4': 2.7660932540893555, 'epoch': 12.02}
{'loss': 0.0193, 'grad_norm': 9.743645668029785, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.017192823812365532, 'loss_2': 0.0020809173583984375, 'loss_3': -16.23831558227539, 'loss_4': 3.052567481994629, 'epoch': 12.02}
{'loss': 0.0244, 'grad_norm': 6.653732776641846, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.01519392803311348, 'loss_2': 0.0092010498046875, 'loss_3': -16.29952621459961, 'loss_4': 2.264228343963623, 'epoch': 12.03}
{'loss': 0.015, 'grad_norm': 4.746155738830566, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.005316282156854868, 'loss_2': 0.00968170166015625, 'loss_3': -16.24081802368164, 'loss_4': 2.9249231815338135, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 10:15:27,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:27,192 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:16<53:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:34,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009438972920179367, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.769, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005947481840848923, 'eval_loss_2': 0.0034914910793304443, 'eval_loss_3': -18.308059692382812, 'eval_loss_4': 2.4698235988616943, 'epoch': 12.03}
{'loss': 0.0264, 'grad_norm': 19.52619743347168, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.026009690016508102, 'loss_2': 0.0003561973571777344, 'loss_3': -16.295696258544922, 'loss_4': 2.9426965713500977, 'epoch': 12.04}
{'loss': 0.0106, 'grad_norm': 5.2114152908325195, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.00834764912724495, 'loss_2': 0.0022411346435546875, 'loss_3': -16.385589599609375, 'loss_4': 2.924180507659912, 'epoch': 12.05}
{'loss': 0.0102, 'grad_norm': 5.346032619476318, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.007686982396990061, 'loss_2': 0.00254058837890625, 'loss_3': -16.35982322692871, 'loss_4': 3.557997226715088, 'epoch': 12.05}
{'loss': 0.0176, 'grad_norm': 6.397887706756592, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.012519667856395245, 'loss_2': 0.00510406494140625, 'loss_3': -16.334880828857422, 'loss_4': 3.0973246097564697, 'epoch': 12.06}
{'loss': 0.0097, 'grad_norm': 5.662959575653076, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.009250215254724026, 'loss_2': 0.00046825408935546875, 'loss_3': -16.41255760192871, 'loss_4': 3.179091453552246, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 10:15:34,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:34,556 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:24<53:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:41,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011548761278390884, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006539884023368359, 'eval_loss_2': 0.005008876323699951, 'eval_loss_3': -18.3325252532959, 'eval_loss_4': 2.7767293453216553, 'epoch': 12.06}
{'loss': 0.0204, 'grad_norm': 6.113522529602051, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.009283619932830334, 'loss_2': 0.0111541748046875, 'loss_3': -16.111263275146484, 'loss_4': 2.935042381286621, 'epoch': 12.07}
{'loss': 0.0208, 'grad_norm': 8.412873268127441, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.015283196233212948, 'loss_2': 0.00547027587890625, 'loss_3': -16.382606506347656, 'loss_4': 3.248796224594116, 'epoch': 12.08}
{'loss': 0.0157, 'grad_norm': 5.5869855880737305, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.012112143449485302, 'loss_2': 0.003627777099609375, 'loss_3': -16.32457160949707, 'loss_4': 3.3040952682495117, 'epoch': 12.08}
{'loss': 0.0309, 'grad_norm': 7.959950923919678, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.019652703776955605, 'loss_2': 0.0112762451171875, 'loss_3': -16.301551818847656, 'loss_4': 3.948451519012451, 'epoch': 12.09}
{'loss': 0.0185, 'grad_norm': 6.544930934906006, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.01199214905500412, 'loss_2': 0.00646209716796875, 'loss_3': -16.474769592285156, 'loss_4': 2.7215349674224854, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 10:15:41,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:41,905 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:31<53:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:49,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012155934236943722, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.056, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00799168273806572, 'eval_loss_2': 0.004164252430200577, 'eval_loss_3': -18.36722183227539, 'eval_loss_4': 2.925851583480835, 'epoch': 12.09}
{'loss': 0.0128, 'grad_norm': 5.433957576751709, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.010937873274087906, 'loss_2': 0.0018768310546875, 'loss_3': -16.384037017822266, 'loss_4': 2.925948143005371, 'epoch': 12.1}
{'loss': 0.0094, 'grad_norm': 4.7474164962768555, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.006341337226331234, 'loss_2': 0.0030269622802734375, 'loss_3': -16.42319679260254, 'loss_4': 3.0778136253356934, 'epoch': 12.1}
{'loss': 0.035, 'grad_norm': 19.107650756835938, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.031405385583639145, 'loss_2': 0.003620147705078125, 'loss_3': -16.512393951416016, 'loss_4': 3.303377866744995, 'epoch': 12.11}
{'loss': 0.0079, 'grad_norm': 4.350856304168701, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.006321502849459648, 'loss_2': 0.0015764236450195312, 'loss_3': -16.38623046875, 'loss_4': 3.332275867462158, 'epoch': 12.12}
{'loss': 0.0098, 'grad_norm': 5.441005229949951, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.006762118078768253, 'loss_2': 0.003032684326171875, 'loss_3': -16.522186279296875, 'loss_4': 2.673004388809204, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 10:15:49,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:49,260 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:38<53:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:56,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012739654630422592, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.522, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008049366064369678, 'eval_loss_2': 0.004690289497375488, 'eval_loss_3': -18.361797332763672, 'eval_loss_4': 2.7493839263916016, 'epoch': 12.12}
{'loss': 0.0166, 'grad_norm': 5.3333563804626465, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.010816794820129871, 'loss_2': 0.00577545166015625, 'loss_3': -16.483516693115234, 'loss_4': 2.80232572555542, 'epoch': 12.13}
{'loss': 0.0104, 'grad_norm': 6.052799224853516, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.007926219142973423, 'loss_2': 0.002468109130859375, 'loss_3': -16.333385467529297, 'loss_4': 2.371750831604004, 'epoch': 12.13}
{'loss': 0.0086, 'grad_norm': 4.953794002532959, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.008386691100895405, 'loss_2': 0.00018477439880371094, 'loss_3': -16.354732513427734, 'loss_4': 2.8958280086517334, 'epoch': 12.14}
{'loss': 0.0097, 'grad_norm': 5.71471643447876, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.008763451129198074, 'loss_2': 0.000942230224609375, 'loss_3': -16.45467185974121, 'loss_4': 3.3704147338867188, 'epoch': 12.15}
{'loss': 0.0158, 'grad_norm': 4.833176612854004, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.010188567452132702, 'loss_2': 0.005649566650390625, 'loss_3': -16.491886138916016, 'loss_4': 3.453169345855713, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 10:15:56,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:56,623 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [51:46<53:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:03,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010027596727013588, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006635271944105625, 'eval_loss_2': 0.003392323851585388, 'eval_loss_3': -18.35390281677246, 'eval_loss_4': 2.5874719619750977, 'epoch': 12.15}
{'loss': 0.0281, 'grad_norm': 10.509425163269043, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.022881507873535156, 'loss_2': 0.00525665283203125, 'loss_3': -16.302698135375977, 'loss_4': 2.812167167663574, 'epoch': 12.16}
{'loss': 0.0146, 'grad_norm': 5.130969047546387, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.009828613139688969, 'loss_2': 0.004730224609375, 'loss_3': -16.370214462280273, 'loss_4': 3.433213710784912, 'epoch': 12.16}
{'loss': 0.0216, 'grad_norm': 6.985097408294678, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.01679239608347416, 'loss_2': 0.004810333251953125, 'loss_3': -16.441692352294922, 'loss_4': 2.7215042114257812, 'epoch': 12.17}
{'loss': 0.0329, 'grad_norm': 13.234872817993164, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.03128547593951225, 'loss_2': 0.0015859603881835938, 'loss_3': -16.643672943115234, 'loss_4': 2.5158121585845947, 'epoch': 12.17}
{'loss': 0.0277, 'grad_norm': 9.114426612854004, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.02047353982925415, 'loss_2': 0.00717926025390625, 'loss_3': -16.49620819091797, 'loss_4': 3.39823055267334, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 10:16:03,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:03,993 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [51:53<52:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:11,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01004679873585701, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.994, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0073698037303984165, 'eval_loss_2': 0.0026769936084747314, 'eval_loss_3': -18.34942626953125, 'eval_loss_4': 2.4918766021728516, 'epoch': 12.18}
{'loss': 0.0157, 'grad_norm': 7.1872758865356445, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.010105498135089874, 'loss_2': 0.0055694580078125, 'loss_3': -16.440452575683594, 'loss_4': 2.6169545650482178, 'epoch': 12.19}
{'loss': 0.0146, 'grad_norm': 5.246078014373779, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.013238943181931973, 'loss_2': 0.0013628005981445312, 'loss_3': -16.328838348388672, 'loss_4': 2.7081947326660156, 'epoch': 12.19}
{'loss': 0.0084, 'grad_norm': 4.741052627563477, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.008445745334029198, 'loss_2': 4.0531158447265625e-06, 'loss_3': -16.381803512573242, 'loss_4': 2.4438281059265137, 'epoch': 12.2}
{'loss': 0.0302, 'grad_norm': 10.539885520935059, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.02895819954574108, 'loss_2': 0.0012578964233398438, 'loss_3': -16.518756866455078, 'loss_4': 3.060112476348877, 'epoch': 12.2}
{'loss': 0.0124, 'grad_norm': 7.188355922698975, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.012293136678636074, 'loss_2': 0.0001367330551147461, 'loss_3': -16.105701446533203, 'loss_4': 2.065371513366699, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 10:16:11,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:11,344 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:00<52:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:18,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011137530207633972, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00807181652635336, 'eval_loss_2': 0.0030657127499580383, 'eval_loss_3': -18.342565536499023, 'eval_loss_4': 2.3576338291168213, 'epoch': 12.21}
{'loss': 0.0133, 'grad_norm': 6.2780585289001465, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.010529455728828907, 'loss_2': 0.00272369384765625, 'loss_3': -16.346534729003906, 'loss_4': 2.1837987899780273, 'epoch': 12.22}
{'loss': 0.0202, 'grad_norm': 6.58958625793457, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.01414965558797121, 'loss_2': 0.0060577392578125, 'loss_3': -16.577003479003906, 'loss_4': 1.9698418378829956, 'epoch': 12.22}
{'loss': 0.0176, 'grad_norm': 5.823888778686523, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.011465620249509811, 'loss_2': 0.00616455078125, 'loss_3': -16.344646453857422, 'loss_4': 2.3360514640808105, 'epoch': 12.23}
{'loss': 0.0152, 'grad_norm': 7.4910736083984375, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.013808011077344418, 'loss_2': 0.0013427734375, 'loss_3': -16.395469665527344, 'loss_4': 2.664381504058838, 'epoch': 12.23}
{'loss': 0.0292, 'grad_norm': 12.588679313659668, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.023509902879595757, 'loss_2': 0.00566864013671875, 'loss_3': -16.43647575378418, 'loss_4': 2.8334364891052246, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 10:16:18,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:18,696 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:08<52:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:26,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012911392375826836, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009416957385838032, 'eval_loss_2': 0.0034944340586662292, 'eval_loss_3': -18.30963897705078, 'eval_loss_4': 2.5109808444976807, 'epoch': 12.24}
{'loss': 0.016, 'grad_norm': 4.816804885864258, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.008769244886934757, 'loss_2': 0.00722503662109375, 'loss_3': -16.4180965423584, 'loss_4': 2.5761098861694336, 'epoch': 12.24}
{'loss': 0.0257, 'grad_norm': 9.569221496582031, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.02433086186647415, 'loss_2': 0.001415252685546875, 'loss_3': -16.2393741607666, 'loss_4': 2.973308801651001, 'epoch': 12.25}
{'loss': 0.0275, 'grad_norm': 11.651534080505371, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.024374864995479584, 'loss_2': 0.0030803680419921875, 'loss_3': -16.468486785888672, 'loss_4': 2.8153038024902344, 'epoch': 12.26}
{'loss': 0.0282, 'grad_norm': 9.881278038024902, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.026299692690372467, 'loss_2': 0.0018939971923828125, 'loss_3': -16.38080596923828, 'loss_4': 3.3515381813049316, 'epoch': 12.26}
{'loss': 0.0304, 'grad_norm': 9.51518726348877, 'learning_rate': 1.775e-05, 'loss_1': 0.026923788711428642, 'loss_2': 0.003513336181640625, 'loss_3': -16.42809295654297, 'loss_4': 3.522059440612793, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 10:16:26,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:26,049 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:15<52:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:33,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01693039759993553, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.823, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011857744306325912, 'eval_loss_2': 0.005072653293609619, 'eval_loss_3': -18.304431915283203, 'eval_loss_4': 2.8343708515167236, 'epoch': 12.27}
{'loss': 0.02, 'grad_norm': 7.449515342712402, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.015665443614125252, 'loss_2': 0.004302978515625, 'loss_3': -16.45301055908203, 'loss_4': 2.987797737121582, 'epoch': 12.27}
{'loss': 0.0223, 'grad_norm': 9.605011940002441, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.016433579847216606, 'loss_2': 0.00591278076171875, 'loss_3': -16.51951789855957, 'loss_4': 3.2760214805603027, 'epoch': 12.28}
{'loss': 0.0197, 'grad_norm': 5.149067401885986, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.008739225566387177, 'loss_2': 0.01094818115234375, 'loss_3': -16.425567626953125, 'loss_4': 3.491027355194092, 'epoch': 12.28}
{'loss': 0.0184, 'grad_norm': 5.387638092041016, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.01039968989789486, 'loss_2': 0.00799560546875, 'loss_3': -16.55109977722168, 'loss_4': 2.8192641735076904, 'epoch': 12.29}
{'loss': 0.0099, 'grad_norm': 5.369465351104736, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.009388517588376999, 'loss_2': 0.0005054473876953125, 'loss_3': -16.430713653564453, 'loss_4': 2.905066728591919, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 10:16:33,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:33,408 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:22<52:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:40,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014516856521368027, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010922785848379135, 'eval_loss_2': 0.0035940706729888916, 'eval_loss_3': -18.321006774902344, 'eval_loss_4': 2.7717669010162354, 'epoch': 12.3}
{'loss': 0.0088, 'grad_norm': 5.946019649505615, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.008123851381242275, 'loss_2': 0.0006933212280273438, 'loss_3': -16.569110870361328, 'loss_4': 3.1247620582580566, 'epoch': 12.3}
{'loss': 0.0424, 'grad_norm': 19.914047241210938, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.03936855494976044, 'loss_2': 0.00307464599609375, 'loss_3': -16.532609939575195, 'loss_4': 2.9100894927978516, 'epoch': 12.31}
{'loss': 0.0339, 'grad_norm': 21.843647003173828, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.029815619811415672, 'loss_2': 0.00403594970703125, 'loss_3': -16.397010803222656, 'loss_4': 2.9392142295837402, 'epoch': 12.31}
{'loss': 0.0156, 'grad_norm': 5.602222919464111, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.00995380338281393, 'loss_2': 0.00560760498046875, 'loss_3': -16.50894546508789, 'loss_4': 2.8028695583343506, 'epoch': 12.32}
{'loss': 0.0161, 'grad_norm': 7.435415744781494, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.012975108809769154, 'loss_2': 0.003082275390625, 'loss_3': -16.424537658691406, 'loss_4': 3.3971657752990723, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 10:16:40,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:40,765 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:30<52:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:48,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01128171943128109, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007705328986048698, 'eval_loss_2': 0.0035763904452323914, 'eval_loss_3': -18.368072509765625, 'eval_loss_4': 2.64131236076355, 'epoch': 12.33}
{'loss': 0.0184, 'grad_norm': 6.777609348297119, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.014517148025333881, 'loss_2': 0.0038661956787109375, 'loss_3': -16.416122436523438, 'loss_4': 3.3605740070343018, 'epoch': 12.33}
{'loss': 0.0176, 'grad_norm': 5.856040954589844, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.011164050549268723, 'loss_2': 0.0064239501953125, 'loss_3': -16.367948532104492, 'loss_4': 3.2921767234802246, 'epoch': 12.34}
{'loss': 0.0144, 'grad_norm': 5.214471817016602, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.01288523618131876, 'loss_2': 0.0014972686767578125, 'loss_3': -16.554073333740234, 'loss_4': 3.3050756454467773, 'epoch': 12.34}
{'loss': 0.0336, 'grad_norm': 15.501832008361816, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.03173961117863655, 'loss_2': 0.0019073486328125, 'loss_3': -16.378963470458984, 'loss_4': 4.266628742218018, 'epoch': 12.35}
{'loss': 0.0201, 'grad_norm': 6.708370685577393, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.011086119338870049, 'loss_2': 0.00896453857421875, 'loss_3': -16.40106773376465, 'loss_4': 3.867213249206543, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 10:16:48,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:48,120 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:37<52:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:55,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015606340020895004, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007118668872863054, 'eval_loss_2': 0.008487671613693237, 'eval_loss_3': -18.391691207885742, 'eval_loss_4': 3.1749000549316406, 'epoch': 12.35}
{'loss': 0.0398, 'grad_norm': 15.461880683898926, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.03398453816771507, 'loss_2': 0.005840301513671875, 'loss_3': -16.48630142211914, 'loss_4': 4.589235305786133, 'epoch': 12.36}
{'loss': 0.0155, 'grad_norm': 6.369389057159424, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.012356976978480816, 'loss_2': 0.003101348876953125, 'loss_3': -16.304622650146484, 'loss_4': 3.741910696029663, 'epoch': 12.37}
{'loss': 0.0234, 'grad_norm': 6.73098087310791, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.014786769635975361, 'loss_2': 0.00856781005859375, 'loss_3': -16.647613525390625, 'loss_4': 3.870004892349243, 'epoch': 12.37}
{'loss': 0.0112, 'grad_norm': 5.6073899269104, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.009003921411931515, 'loss_2': 0.002239227294921875, 'loss_3': -16.44757843017578, 'loss_4': 3.992888927459717, 'epoch': 12.38}
{'loss': 0.0083, 'grad_norm': 5.322132110595703, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.006376122124493122, 'loss_2': 0.001972198486328125, 'loss_3': -16.431913375854492, 'loss_4': 4.021174430847168, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 10:16:55,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:55,485 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [52:45<52:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:02,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01219218596816063, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.965, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0076729897409677505, 'eval_loss_2': 0.0045191943645477295, 'eval_loss_3': -18.410158157348633, 'eval_loss_4': 3.671207904815674, 'epoch': 12.38}
{'loss': 0.0159, 'grad_norm': 4.947509288787842, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.009891645051538944, 'loss_2': 0.00601959228515625, 'loss_3': -16.304513931274414, 'loss_4': 4.063701152801514, 'epoch': 12.39}
{'loss': 0.0126, 'grad_norm': 6.839182376861572, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.009804724715650082, 'loss_2': 0.0028095245361328125, 'loss_3': -16.648487091064453, 'loss_4': 3.8977694511413574, 'epoch': 12.4}
{'loss': 0.0188, 'grad_norm': 9.401915550231934, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.017811710014939308, 'loss_2': 0.0009622573852539062, 'loss_3': -16.528650283813477, 'loss_4': 4.947347640991211, 'epoch': 12.4}
{'loss': 0.0307, 'grad_norm': 11.387551307678223, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.02788897231221199, 'loss_2': 0.002780914306640625, 'loss_3': -16.509502410888672, 'loss_4': 4.550352573394775, 'epoch': 12.41}
{'loss': 0.0195, 'grad_norm': 7.608705043792725, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.016708387061953545, 'loss_2': 0.002788543701171875, 'loss_3': -16.647729873657227, 'loss_4': 4.854264259338379, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 10:17:02,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:02,848 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [52:52<52:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:10,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011340047232806683, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.482, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007412339095026255, 'eval_loss_2': 0.003927707672119141, 'eval_loss_3': -18.450395584106445, 'eval_loss_4': 3.798524856567383, 'epoch': 12.41}
{'loss': 0.0152, 'grad_norm': 5.2403364181518555, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.011006291955709457, 'loss_2': 0.00423431396484375, 'loss_3': -16.485136032104492, 'loss_4': 4.197092533111572, 'epoch': 12.42}
{'loss': 0.0174, 'grad_norm': 7.0438432693481445, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.017342664301395416, 'loss_2': 1.233816146850586e-05, 'loss_3': -16.54677963256836, 'loss_4': 4.0944600105285645, 'epoch': 12.42}
{'loss': 0.0285, 'grad_norm': 16.835010528564453, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.026955053210258484, 'loss_2': 0.0015316009521484375, 'loss_3': -16.47576141357422, 'loss_4': 4.633514881134033, 'epoch': 12.43}
{'loss': 0.0247, 'grad_norm': 13.051745414733887, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.023357076570391655, 'loss_2': 0.001331329345703125, 'loss_3': -16.61349868774414, 'loss_4': 4.557147026062012, 'epoch': 12.44}
{'loss': 0.0265, 'grad_norm': 11.456889152526855, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.022875361144542694, 'loss_2': 0.00357818603515625, 'loss_3': -16.509960174560547, 'loss_4': 5.178083419799805, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 10:17:10,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:10,198 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [52:59<52:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:17,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011697906069457531, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.807, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007043321616947651, 'eval_loss_2': 0.004654586315155029, 'eval_loss_3': -18.472219467163086, 'eval_loss_4': 4.0028910636901855, 'epoch': 12.44}
{'loss': 0.0203, 'grad_norm': 12.075603485107422, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.01857735589146614, 'loss_2': 0.001750946044921875, 'loss_3': -16.439964294433594, 'loss_4': 4.149053573608398, 'epoch': 12.45}
{'loss': 0.017, 'grad_norm': 6.332594394683838, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.012317266315221786, 'loss_2': 0.004634857177734375, 'loss_3': -16.661815643310547, 'loss_4': 4.542977333068848, 'epoch': 12.45}
{'loss': 0.0596, 'grad_norm': 14.903144836425781, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.0476875938475132, 'loss_2': 0.01190185546875, 'loss_3': -16.55261993408203, 'loss_4': 5.362815856933594, 'epoch': 12.46}
{'loss': 0.0182, 'grad_norm': 8.175660133361816, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.01680053025484085, 'loss_2': 0.0014247894287109375, 'loss_3': -16.615577697753906, 'loss_4': 4.563843250274658, 'epoch': 12.47}
{'loss': 0.0175, 'grad_norm': 5.177377223968506, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.012029546312987804, 'loss_2': 0.00550079345703125, 'loss_3': -16.62291717529297, 'loss_4': 4.185465335845947, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 10:17:17,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:17,559 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:07<52:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:24,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015260818414390087, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.357, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008309725672006607, 'eval_loss_2': 0.006951093673706055, 'eval_loss_3': -18.51088523864746, 'eval_loss_4': 4.176849842071533, 'epoch': 12.47}
{'loss': 0.0223, 'grad_norm': 6.27473783493042, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.016025109216570854, 'loss_2': 0.006256103515625, 'loss_3': -16.497488021850586, 'loss_4': 4.683349609375, 'epoch': 12.48}
{'loss': 0.0246, 'grad_norm': 7.580124378204346, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.02148277871310711, 'loss_2': 0.003139495849609375, 'loss_3': -16.674041748046875, 'loss_4': 5.1455607414245605, 'epoch': 12.48}
{'loss': 0.0132, 'grad_norm': 6.173403739929199, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.01212389301508665, 'loss_2': 0.00102996826171875, 'loss_3': -16.538822174072266, 'loss_4': 4.358070373535156, 'epoch': 12.49}
{'loss': 0.0171, 'grad_norm': 5.686623573303223, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.014026169665157795, 'loss_2': 0.003116607666015625, 'loss_3': -16.553157806396484, 'loss_4': 4.541430473327637, 'epoch': 12.49}
{'loss': 0.0174, 'grad_norm': 6.358355522155762, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.01736241579055786, 'loss_2': 4.38690185546875e-05, 'loss_3': -16.746604919433594, 'loss_4': 4.936563968658447, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 10:17:24,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:24,914 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:14<52:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:32,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013767080381512642, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.338, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00794212706387043, 'eval_loss_2': 0.005824953317642212, 'eval_loss_3': -18.48676109313965, 'eval_loss_4': 3.9549014568328857, 'epoch': 12.5}
{'loss': 0.0343, 'grad_norm': 8.007773399353027, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.025159284472465515, 'loss_2': 0.00909423828125, 'loss_3': -16.607563018798828, 'loss_4': 5.006563663482666, 'epoch': 12.51}
{'loss': 0.0291, 'grad_norm': 9.06773853302002, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.024427633732557297, 'loss_2': 0.004657745361328125, 'loss_3': -16.848739624023438, 'loss_4': 4.016146659851074, 'epoch': 12.51}
{'loss': 0.0179, 'grad_norm': 5.602883815765381, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.008573031052947044, 'loss_2': 0.0093536376953125, 'loss_3': -16.72627830505371, 'loss_4': 4.623884201049805, 'epoch': 12.52}
{'loss': 0.0214, 'grad_norm': 6.129875659942627, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.011812735348939896, 'loss_2': 0.009552001953125, 'loss_3': -16.61554527282715, 'loss_4': 4.141992092132568, 'epoch': 12.52}
{'loss': 0.019, 'grad_norm': 5.5746564865112305, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.012134850956499577, 'loss_2': 0.0068511962890625, 'loss_3': -16.44381332397461, 'loss_4': 4.206830978393555, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 10:17:32,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:32,267 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:21<51:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:39,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014301949180662632, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.297, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008078150451183319, 'eval_loss_2': 0.006223797798156738, 'eval_loss_3': -18.433685302734375, 'eval_loss_4': 3.5942842960357666, 'epoch': 12.53}
{'loss': 0.0201, 'grad_norm': 5.836063861846924, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.012933753430843353, 'loss_2': 0.00720977783203125, 'loss_3': -16.542448043823242, 'loss_4': 4.57413387298584, 'epoch': 12.53}
{'loss': 0.013, 'grad_norm': 7.5431365966796875, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.012665034271776676, 'loss_2': 0.000293731689453125, 'loss_3': -16.826141357421875, 'loss_4': 4.330316543579102, 'epoch': 12.54}
{'loss': 0.013, 'grad_norm': 5.574626445770264, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.012292244471609592, 'loss_2': 0.0007181167602539062, 'loss_3': -16.622146606445312, 'loss_4': 3.900721788406372, 'epoch': 12.55}
{'loss': 0.0166, 'grad_norm': 7.548868656158447, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.012674413621425629, 'loss_2': 0.00396728515625, 'loss_3': -16.58399200439453, 'loss_4': 3.798699140548706, 'epoch': 12.55}
{'loss': 0.0247, 'grad_norm': 13.824458122253418, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.02422116883099079, 'loss_2': 0.000453948974609375, 'loss_3': -16.66844367980957, 'loss_4': 3.5387635231018066, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 10:17:39,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:39,623 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:29<51:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:46,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010559326969087124, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.202, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006198308430612087, 'eval_loss_2': 0.004361018538475037, 'eval_loss_3': -18.39572525024414, 'eval_loss_4': 2.99497127532959, 'epoch': 12.56}
{'loss': 0.0166, 'grad_norm': 9.124213218688965, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.012573862448334694, 'loss_2': 0.004070281982421875, 'loss_3': -16.534791946411133, 'loss_4': 3.5865964889526367, 'epoch': 12.56}
{'loss': 0.0162, 'grad_norm': 8.383766174316406, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.015383917838335037, 'loss_2': 0.00079345703125, 'loss_3': -16.622583389282227, 'loss_4': 3.211967945098877, 'epoch': 12.57}
{'loss': 0.0156, 'grad_norm': 6.151679515838623, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.01219894364476204, 'loss_2': 0.0033779144287109375, 'loss_3': -16.589448928833008, 'loss_4': 3.3040595054626465, 'epoch': 12.58}
{'loss': 0.0294, 'grad_norm': 10.175204277038574, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.020132215693593025, 'loss_2': 0.00927734375, 'loss_3': -16.674049377441406, 'loss_4': 3.2851243019104004, 'epoch': 12.58}
{'loss': 0.0134, 'grad_norm': 5.021002292633057, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.005944525822997093, 'loss_2': 0.007457733154296875, 'loss_3': -16.46782684326172, 'loss_4': 3.4636549949645996, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 10:17:46,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:46,980 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:36<51:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:54,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009308334439992905, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.544, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005295713432133198, 'eval_loss_2': 0.0040126219391822815, 'eval_loss_3': -18.3764591217041, 'eval_loss_4': 2.447679281234741, 'epoch': 12.59}
{'loss': 0.0251, 'grad_norm': 8.59691333770752, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.0224344152957201, 'loss_2': 0.0026702880859375, 'loss_3': -16.330991744995117, 'loss_4': 2.56303334236145, 'epoch': 12.59}
{'loss': 0.0097, 'grad_norm': 5.72999906539917, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.007618919480592012, 'loss_2': 0.002109527587890625, 'loss_3': -16.426027297973633, 'loss_4': 2.570978879928589, 'epoch': 12.6}
{'loss': 0.0075, 'grad_norm': 5.247552394866943, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.0069110700860619545, 'loss_2': 0.00055694580078125, 'loss_3': -16.43052864074707, 'loss_4': 2.7238056659698486, 'epoch': 12.6}
{'loss': 0.0072, 'grad_norm': 4.852345943450928, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.006006164941936731, 'loss_2': 0.001239776611328125, 'loss_3': -16.289886474609375, 'loss_4': 2.612855911254883, 'epoch': 12.61}
{'loss': 0.011, 'grad_norm': 4.635679721832275, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.010518714785575867, 'loss_2': 0.0004763603210449219, 'loss_3': -16.532072067260742, 'loss_4': 2.33608341217041, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 10:17:54,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:54,342 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [53:43<51:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:01,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009908821433782578, 'eval_runtime': 3.8186, 'eval_samples_per_second': 268.159, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.00586899695917964, 'eval_loss_2': 0.00403982400894165, 'eval_loss_3': -18.392709732055664, 'eval_loss_4': 2.1727006435394287, 'epoch': 12.62}
{'loss': 0.0137, 'grad_norm': 9.816885948181152, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.011802783235907555, 'loss_2': 0.0018672943115234375, 'loss_3': -16.63347053527832, 'loss_4': 2.9385733604431152, 'epoch': 12.62}
{'loss': 0.0143, 'grad_norm': 6.92306661605835, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.01160755380988121, 'loss_2': 0.002696990966796875, 'loss_3': -16.52075958251953, 'loss_4': 2.399895429611206, 'epoch': 12.63}
{'loss': 0.0279, 'grad_norm': 10.842628479003906, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.022908248007297516, 'loss_2': 0.005035400390625, 'loss_3': -16.442537307739258, 'loss_4': 2.1436376571655273, 'epoch': 12.63}
{'loss': 0.0175, 'grad_norm': 9.327559471130371, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.014190719462931156, 'loss_2': 0.0032825469970703125, 'loss_3': -16.475099563598633, 'loss_4': 2.869778871536255, 'epoch': 12.64}
{'loss': 0.0094, 'grad_norm': 5.426858425140381, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.008107914589345455, 'loss_2': 0.001255035400390625, 'loss_3': -16.528671264648438, 'loss_4': 3.180210590362549, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 10:18:01,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:01,709 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [53:51<51:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:09,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010028483346104622, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006200054660439491, 'eval_loss_2': 0.0038284286856651306, 'eval_loss_3': -18.404354095458984, 'eval_loss_4': 1.9766185283660889, 'epoch': 12.65}
{'loss': 0.0242, 'grad_norm': 7.786351680755615, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.023473156616091728, 'loss_2': 0.0006895065307617188, 'loss_3': -16.491165161132812, 'loss_4': 3.2428078651428223, 'epoch': 12.65}
{'loss': 0.0198, 'grad_norm': 8.69798469543457, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.01767316833138466, 'loss_2': 0.002162933349609375, 'loss_3': -16.59844207763672, 'loss_4': 2.224196195602417, 'epoch': 12.66}
{'loss': 0.017, 'grad_norm': 6.050169944763184, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.014259763062000275, 'loss_2': 0.00270843505859375, 'loss_3': -16.518564224243164, 'loss_4': 2.3966214656829834, 'epoch': 12.66}
{'loss': 0.0204, 'grad_norm': 10.592499732971191, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.01579427532851696, 'loss_2': 0.00457763671875, 'loss_3': -16.52481460571289, 'loss_4': 2.6723792552948, 'epoch': 12.67}
{'loss': 0.0436, 'grad_norm': 15.172575950622559, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.023832326754927635, 'loss_2': 0.0197296142578125, 'loss_3': -16.581892013549805, 'loss_4': 2.4028284549713135, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 10:18:09,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:09,059 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [53:58<51:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:16,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01394568756222725, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.258, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006064761430025101, 'eval_loss_2': 0.007880926132202148, 'eval_loss_3': -18.406879425048828, 'eval_loss_4': 1.8776891231536865, 'epoch': 12.67}
{'loss': 0.0183, 'grad_norm': 5.852839469909668, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.010928334668278694, 'loss_2': 0.00738525390625, 'loss_3': -16.513839721679688, 'loss_4': 2.3089773654937744, 'epoch': 12.68}
{'loss': 0.0122, 'grad_norm': 5.835965156555176, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.01097299437969923, 'loss_2': 0.001270294189453125, 'loss_3': -16.41973114013672, 'loss_4': 1.62555730342865, 'epoch': 12.69}
{'loss': 0.0457, 'grad_norm': 13.376930236816406, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.042064785957336426, 'loss_2': 0.0036525726318359375, 'loss_3': -16.28936195373535, 'loss_4': 1.8970787525177002, 'epoch': 12.69}
{'loss': 0.0239, 'grad_norm': 8.68464183807373, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.017046384513378143, 'loss_2': 0.006805419921875, 'loss_3': -16.41891860961914, 'loss_4': 2.3085811138153076, 'epoch': 12.7}
{'loss': 0.0195, 'grad_norm': 6.349122524261475, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.011922596022486687, 'loss_2': 0.00753021240234375, 'loss_3': -16.48818016052246, 'loss_4': 2.4182534217834473, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 10:18:16,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:16,404 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:05<51:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:23,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009262423031032085, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005936186295002699, 'eval_loss_2': 0.003326237201690674, 'eval_loss_3': -18.400264739990234, 'eval_loss_4': 1.8411089181900024, 'epoch': 12.7}
{'loss': 0.0231, 'grad_norm': 8.860068321228027, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.019478831440210342, 'loss_2': 0.003658294677734375, 'loss_3': -16.572589874267578, 'loss_4': 1.790257453918457, 'epoch': 12.71}
{'loss': 0.0163, 'grad_norm': 6.148972511291504, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.012140745297074318, 'loss_2': 0.004138946533203125, 'loss_3': -16.43402862548828, 'loss_4': 2.9716126918792725, 'epoch': 12.72}
{'loss': 0.0212, 'grad_norm': 7.715307712554932, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.017916295677423477, 'loss_2': 0.00324249267578125, 'loss_3': -16.438840866088867, 'loss_4': 2.2650346755981445, 'epoch': 12.72}
{'loss': 0.0289, 'grad_norm': 12.056065559387207, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.0221282709389925, 'loss_2': 0.00675201416015625, 'loss_3': -16.65974998474121, 'loss_4': 2.9221086502075195, 'epoch': 12.73}
{'loss': 0.0188, 'grad_norm': 9.230476379394531, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.015972405672073364, 'loss_2': 0.0028076171875, 'loss_3': -16.268203735351562, 'loss_4': 2.3909621238708496, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 10:18:23,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:23,747 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:13<51:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:31,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0110554788261652, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005641634576022625, 'eval_loss_2': 0.005413845181465149, 'eval_loss_3': -18.392614364624023, 'eval_loss_4': 1.897772192955017, 'epoch': 12.73}
{'loss': 0.0491, 'grad_norm': 19.023582458496094, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.04671112075448036, 'loss_2': 0.0024051666259765625, 'loss_3': -16.449832916259766, 'loss_4': 2.601942300796509, 'epoch': 12.74}
{'loss': 0.0429, 'grad_norm': 8.18193244934082, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.0323449932038784, 'loss_2': 0.010589599609375, 'loss_3': -16.441020965576172, 'loss_4': 2.087444543838501, 'epoch': 12.74}
{'loss': 0.0165, 'grad_norm': 6.819800853729248, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.009836443699896336, 'loss_2': 0.006622314453125, 'loss_3': -16.516016006469727, 'loss_4': 2.4170446395874023, 'epoch': 12.75}
{'loss': 0.0154, 'grad_norm': 5.819014549255371, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.009516947902739048, 'loss_2': 0.0059051513671875, 'loss_3': -16.411401748657227, 'loss_4': 2.3781399726867676, 'epoch': 12.76}
{'loss': 0.0122, 'grad_norm': 5.282686233520508, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.00739171402528882, 'loss_2': 0.00481414794921875, 'loss_3': -16.253725051879883, 'loss_4': 1.880622148513794, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 10:18:31,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:31,084 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:20<51:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:38,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010252585634589195, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.462, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006095669232308865, 'eval_loss_2': 0.004156917333602905, 'eval_loss_3': -18.379417419433594, 'eval_loss_4': 1.8229249715805054, 'epoch': 12.76}
{'loss': 0.0148, 'grad_norm': 7.677430152893066, 'learning_rate': 1.725e-05, 'loss_1': 0.014524199068546295, 'loss_2': 0.00031495094299316406, 'loss_3': -16.420475006103516, 'loss_4': 2.025053024291992, 'epoch': 12.77}
{'loss': 0.0151, 'grad_norm': 7.193049907684326, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.013444973155856133, 'loss_2': 0.0016584396362304688, 'loss_3': -16.372833251953125, 'loss_4': 1.8383060693740845, 'epoch': 12.77}
{'loss': 0.0063, 'grad_norm': 4.992921829223633, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.0039636543951928616, 'loss_2': 0.00237274169921875, 'loss_3': -16.63629722595215, 'loss_4': 2.1631417274475098, 'epoch': 12.78}
{'loss': 0.0272, 'grad_norm': 8.606951713562012, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.014098848216235638, 'loss_2': 0.01312255859375, 'loss_3': -16.469104766845703, 'loss_4': 1.8515959978103638, 'epoch': 12.78}
{'loss': 0.0136, 'grad_norm': 4.986487865447998, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.009541209787130356, 'loss_2': 0.00402069091796875, 'loss_3': -16.44742202758789, 'loss_4': 2.2078981399536133, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 10:18:38,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:38,449 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:27<51:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:45,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011303924024105072, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006836853921413422, 'eval_loss_2': 0.00446707010269165, 'eval_loss_3': -18.392963409423828, 'eval_loss_4': 1.5972914695739746, 'epoch': 12.79}
{'loss': 0.0077, 'grad_norm': 4.584948539733887, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.00637059984728694, 'loss_2': 0.001300811767578125, 'loss_3': -16.51541519165039, 'loss_4': 2.0051872730255127, 'epoch': 12.8}
{'loss': 0.0243, 'grad_norm': 6.225898265838623, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.014785710722208023, 'loss_2': 0.009552001953125, 'loss_3': -16.505374908447266, 'loss_4': 1.7609755992889404, 'epoch': 12.8}
{'loss': 0.012, 'grad_norm': 4.518060684204102, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.008138718083500862, 'loss_2': 0.0038127899169921875, 'loss_3': -16.276229858398438, 'loss_4': 2.065237045288086, 'epoch': 12.81}
{'loss': 0.0191, 'grad_norm': 5.668567180633545, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.015974601730704308, 'loss_2': 0.003108978271484375, 'loss_3': -16.330520629882812, 'loss_4': 1.8853037357330322, 'epoch': 12.81}
{'loss': 0.0174, 'grad_norm': 5.352035999298096, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.01130386907607317, 'loss_2': 0.00611114501953125, 'loss_3': -16.25969696044922, 'loss_4': 2.138517379760742, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 10:18:45,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:45,798 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:35<51:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:53,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011040870100259781, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.941, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006549182813614607, 'eval_loss_2': 0.004491686820983887, 'eval_loss_3': -18.40085220336914, 'eval_loss_4': 1.5442614555358887, 'epoch': 12.82}
{'loss': 0.0102, 'grad_norm': 4.84180212020874, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.004739664029330015, 'loss_2': 0.005474090576171875, 'loss_3': -16.361005783081055, 'loss_4': 2.050107479095459, 'epoch': 12.83}
{'loss': 0.0206, 'grad_norm': 5.9549031257629395, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.015315137803554535, 'loss_2': 0.00524139404296875, 'loss_3': -16.446937561035156, 'loss_4': 2.5489420890808105, 'epoch': 12.83}
{'loss': 0.0117, 'grad_norm': 5.019134521484375, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.007995979860424995, 'loss_2': 0.003749847412109375, 'loss_3': -16.724685668945312, 'loss_4': 2.5559730529785156, 'epoch': 12.84}
{'loss': 0.0207, 'grad_norm': 6.740116596221924, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.01165694184601307, 'loss_2': 0.009002685546875, 'loss_3': -16.392757415771484, 'loss_4': 2.076258420944214, 'epoch': 12.84}
{'loss': 0.0232, 'grad_norm': 5.175701141357422, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.009945645928382874, 'loss_2': 0.01323699951171875, 'loss_3': -16.436538696289062, 'loss_4': 1.868086814880371, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 10:18:53,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:53,153 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:42<51:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:00,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011110829189419746, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.65, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0056371260434389114, 'eval_loss_2': 0.005473703145980835, 'eval_loss_3': -18.431232452392578, 'eval_loss_4': 1.6169630289077759, 'epoch': 12.85}
{'loss': 0.0268, 'grad_norm': 6.83035945892334, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.013750966638326645, 'loss_2': 0.0130157470703125, 'loss_3': -16.6785945892334, 'loss_4': 1.8596060276031494, 'epoch': 12.85}
{'loss': 0.0137, 'grad_norm': 5.2314629554748535, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.00715253408998251, 'loss_2': 0.00656890869140625, 'loss_3': -16.44095230102539, 'loss_4': 2.1229608058929443, 'epoch': 12.86}
{'loss': 0.0136, 'grad_norm': 5.898343563079834, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.010931948199868202, 'loss_2': 0.00263214111328125, 'loss_3': -16.44668960571289, 'loss_4': 2.2117791175842285, 'epoch': 12.87}
{'loss': 0.0203, 'grad_norm': 5.9795098304748535, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.01564118079841137, 'loss_2': 0.00467681884765625, 'loss_3': -16.521141052246094, 'loss_4': 2.432380199432373, 'epoch': 12.87}
{'loss': 0.0152, 'grad_norm': 5.920146465301514, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.010461213067173958, 'loss_2': 0.004741668701171875, 'loss_3': -16.512767791748047, 'loss_4': 2.2202138900756836, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 10:19:00,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:00,516 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [54:50<50:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:07,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011145791038870811, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.167, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00737633416429162, 'eval_loss_2': 0.0037694573402404785, 'eval_loss_3': -18.428184509277344, 'eval_loss_4': 1.5534017086029053, 'epoch': 12.88}
{'loss': 0.0291, 'grad_norm': 10.037498474121094, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.02681373804807663, 'loss_2': 0.002323150634765625, 'loss_3': -16.39200210571289, 'loss_4': 1.8030517101287842, 'epoch': 12.88}
{'loss': 0.0144, 'grad_norm': 6.398406982421875, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.012854318134486675, 'loss_2': 0.0015850067138671875, 'loss_3': -16.23724937438965, 'loss_4': 2.01473331451416, 'epoch': 12.89}
{'loss': 0.0172, 'grad_norm': 8.931085586547852, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.016914529725909233, 'loss_2': 0.00028586387634277344, 'loss_3': -16.607723236083984, 'loss_4': 1.9612884521484375, 'epoch': 12.9}
{'loss': 0.0259, 'grad_norm': 7.721787929534912, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.017593786120414734, 'loss_2': 0.00830841064453125, 'loss_3': -16.308094024658203, 'loss_4': 2.8053407669067383, 'epoch': 12.9}
{'loss': 0.0191, 'grad_norm': 7.650623321533203, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.01852465607225895, 'loss_2': 0.0005388259887695312, 'loss_3': -16.3742733001709, 'loss_4': 2.294711112976074, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 10:19:07,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:07,873 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [54:57<50:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:15,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01313949003815651, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0075746215879917145, 'eval_loss_2': 0.005564868450164795, 'eval_loss_3': -18.430740356445312, 'eval_loss_4': 1.4797574281692505, 'epoch': 12.91}
{'loss': 0.0169, 'grad_norm': 7.987045764923096, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.01574425771832466, 'loss_2': 0.0011911392211914062, 'loss_3': -16.55760955810547, 'loss_4': 1.7263952493667603, 'epoch': 12.91}
{'loss': 0.0181, 'grad_norm': 5.074078559875488, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.013420568779110909, 'loss_2': 0.004711151123046875, 'loss_3': -16.409086227416992, 'loss_4': 1.7625082731246948, 'epoch': 12.92}
{'loss': 0.0309, 'grad_norm': 16.569517135620117, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.022617638111114502, 'loss_2': 0.008331298828125, 'loss_3': -16.368886947631836, 'loss_4': 2.004868268966675, 'epoch': 12.92}
{'loss': 0.0209, 'grad_norm': 10.717069625854492, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.018601415678858757, 'loss_2': 0.002300262451171875, 'loss_3': -16.466026306152344, 'loss_4': 1.7490341663360596, 'epoch': 12.93}
{'loss': 0.0179, 'grad_norm': 5.110388278961182, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.008568198420107365, 'loss_2': 0.0093536376953125, 'loss_3': -16.424304962158203, 'loss_4': 1.9158564805984497, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 10:19:15,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:15,229 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:04<50:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:22,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01810111291706562, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.321, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007571354508399963, 'eval_loss_2': 0.010529756546020508, 'eval_loss_3': -18.435546875, 'eval_loss_4': 1.4326192140579224, 'epoch': 12.94}
{'loss': 0.0402, 'grad_norm': 9.3828125, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.022728338837623596, 'loss_2': 0.0174560546875, 'loss_3': -16.430021286010742, 'loss_4': 2.6382956504821777, 'epoch': 12.94}
{'loss': 0.0292, 'grad_norm': 5.870527267456055, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.015367535874247551, 'loss_2': 0.01383209228515625, 'loss_3': -16.228952407836914, 'loss_4': 1.3308706283569336, 'epoch': 12.95}
{'loss': 0.0373, 'grad_norm': 7.67856502532959, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.018245607614517212, 'loss_2': 0.01910400390625, 'loss_3': -16.363784790039062, 'loss_4': 1.4556562900543213, 'epoch': 12.95}
{'loss': 0.0259, 'grad_norm': 5.751083850860596, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.01503322459757328, 'loss_2': 0.0108489990234375, 'loss_3': -16.421245574951172, 'loss_4': 1.4989430904388428, 'epoch': 12.96}
{'loss': 0.0254, 'grad_norm': 6.085896968841553, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.013617784716188908, 'loss_2': 0.01174163818359375, 'loss_3': -16.491199493408203, 'loss_4': 1.8661837577819824, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 10:19:22,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:22,589 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:12<50:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:19:29,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011087480932474136, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.191, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007155919913202524, 'eval_loss_2': 0.00393155962228775, 'eval_loss_3': -18.447935104370117, 'eval_loss_4': 1.2530510425567627, 'epoch': 12.97}
{'loss': 0.0342, 'grad_norm': 11.100709915161133, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.02941504865884781, 'loss_2': 0.004791259765625, 'loss_3': -16.4963321685791, 'loss_4': 1.4414851665496826, 'epoch': 12.97}
{'loss': 0.0279, 'grad_norm': 10.986701965332031, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.024987511336803436, 'loss_2': 0.002899169921875, 'loss_3': -16.278244018554688, 'loss_4': 1.732637882232666, 'epoch': 12.98}
{'loss': 0.0264, 'grad_norm': 8.721089363098145, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.014515611343085766, 'loss_2': 0.0118408203125, 'loss_3': -16.406503677368164, 'loss_4': 2.195251941680908, 'epoch': 12.98}
{'loss': 0.0134, 'grad_norm': 5.262876987457275, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.012375096790492535, 'loss_2': 0.0009984970092773438, 'loss_3': -16.338438034057617, 'loss_4': 1.942859411239624, 'epoch': 12.99}
{'loss': 0.0148, 'grad_norm': 4.718000411987305, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.008063302375376225, 'loss_2': 0.00675201416015625, 'loss_3': -16.318342208862305, 'loss_4': 1.238838791847229, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 10:19:29,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:29,911 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:19<49:29,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:19:36,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013140188530087471, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0070568411611020565, 'eval_loss_2': 0.006083346903324127, 'eval_loss_3': -18.457183837890625, 'eval_loss_4': 1.1236448287963867, 'epoch': 12.99}
{'loss': 0.0114, 'grad_norm': 7.643238067626953, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.005383394192904234, 'loss_2': 0.00597381591796875, 'loss_3': -16.43797492980957, 'loss_4': 1.0629502534866333, 'epoch': 13.0}
{'loss': 0.0283, 'grad_norm': 11.543813705444336, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.02489597722887993, 'loss_2': 0.0034332275390625, 'loss_3': -16.46986961364746, 'loss_4': 1.6394050121307373, 'epoch': 13.01}
{'loss': 0.0179, 'grad_norm': 8.114445686340332, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.017184672877192497, 'loss_2': 0.0006685256958007812, 'loss_3': -16.41419792175293, 'loss_4': 1.7772530317306519, 'epoch': 13.01}
{'loss': 0.015, 'grad_norm': 5.080297946929932, 'learning_rate': 1.7e-05, 'loss_1': 0.0076028453186154366, 'loss_2': 0.007411956787109375, 'loss_3': -16.390893936157227, 'loss_4': 1.6614781618118286, 'epoch': 13.02}
{'loss': 0.0135, 'grad_norm': 6.950169563293457, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.01341417245566845, 'loss_2': 9.679794311523438e-05, 'loss_3': -16.501319885253906, 'loss_4': 1.9829530715942383, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 10:19:36,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:36,964 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:26<50:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:19:44,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009008081629872322, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005992806050926447, 'eval_loss_2': 0.0030152760446071625, 'eval_loss_3': -18.422653198242188, 'eval_loss_4': 1.144360899925232, 'epoch': 13.02}
{'loss': 0.0302, 'grad_norm': 11.663081169128418, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.02542782947421074, 'loss_2': 0.00478363037109375, 'loss_3': -16.708431243896484, 'loss_4': 1.3764067888259888, 'epoch': 13.03}
{'loss': 0.0322, 'grad_norm': 10.922608375549316, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.025205181911587715, 'loss_2': 0.006999969482421875, 'loss_3': -16.410457611083984, 'loss_4': 1.3378822803497314, 'epoch': 13.03}
{'loss': 0.0132, 'grad_norm': 5.737810134887695, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.00993303395807743, 'loss_2': 0.0033016204833984375, 'loss_3': -16.37392234802246, 'loss_4': 1.7399728298187256, 'epoch': 13.04}
{'loss': 0.0196, 'grad_norm': 6.57924747467041, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.012096940539777279, 'loss_2': 0.0075225830078125, 'loss_3': -16.616708755493164, 'loss_4': 0.9530379772186279, 'epoch': 13.05}
{'loss': 0.0271, 'grad_norm': 11.396004676818848, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.02126198261976242, 'loss_2': 0.005859375, 'loss_3': -16.451316833496094, 'loss_4': 1.2355271577835083, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 10:19:44,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:44,306 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:33<50:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:51,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009948121383786201, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005612464621663094, 'eval_loss_2': 0.004335656762123108, 'eval_loss_3': -18.383501052856445, 'eval_loss_4': 1.2033451795578003, 'epoch': 13.05}
{'loss': 0.0135, 'grad_norm': 6.755955696105957, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.00994593184441328, 'loss_2': 0.003559112548828125, 'loss_3': -16.375417709350586, 'loss_4': 2.022456645965576, 'epoch': 13.06}
{'loss': 0.0228, 'grad_norm': 9.647613525390625, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.01960693672299385, 'loss_2': 0.003154754638671875, 'loss_3': -16.37204360961914, 'loss_4': 1.6258331537246704, 'epoch': 13.06}
{'loss': 0.0195, 'grad_norm': 4.433663368225098, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.005270755384117365, 'loss_2': 0.01419830322265625, 'loss_3': -16.52679443359375, 'loss_4': 1.645160436630249, 'epoch': 13.07}
{'loss': 0.0201, 'grad_norm': 6.530491828918457, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.014075386337935925, 'loss_2': 0.00604248046875, 'loss_3': -16.411853790283203, 'loss_4': 1.2414839267730713, 'epoch': 13.08}
{'loss': 0.0198, 'grad_norm': 5.968196392059326, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.0175461508333683, 'loss_2': 0.002288818359375, 'loss_3': -16.54140281677246, 'loss_4': 1.4357720613479614, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 10:19:51,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:51,648 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:41<50:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:58,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009536724537611008, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006068121641874313, 'eval_loss_2': 0.0034686028957366943, 'eval_loss_3': -18.365205764770508, 'eval_loss_4': 0.9500406980514526, 'epoch': 13.08}
{'loss': 0.0169, 'grad_norm': 6.74052619934082, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.014512025751173496, 'loss_2': 0.002391815185546875, 'loss_3': -16.541288375854492, 'loss_4': 1.459288477897644, 'epoch': 13.09}
{'loss': 0.0168, 'grad_norm': 4.658507347106934, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.008921695873141289, 'loss_2': 0.00789642333984375, 'loss_3': -16.550457000732422, 'loss_4': 2.2801568508148193, 'epoch': 13.09}
{'loss': 0.0142, 'grad_norm': 5.44256591796875, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.008947723545134068, 'loss_2': 0.00525665283203125, 'loss_3': -16.53768539428711, 'loss_4': 1.3001772165298462, 'epoch': 13.1}
{'loss': 0.0251, 'grad_norm': 13.264978408813477, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.024293236434459686, 'loss_2': 0.000812530517578125, 'loss_3': -16.322603225708008, 'loss_4': 2.131577253341675, 'epoch': 13.1}
{'loss': 0.0086, 'grad_norm': 5.24994421005249, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.008473330177366734, 'loss_2': 9.179115295410156e-05, 'loss_3': -16.481689453125, 'loss_4': 1.686151385307312, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 10:19:58,999 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:58,999 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [55:48<50:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:06,350 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011899912729859352, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.186, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0057212356477975845, 'eval_loss_2': 0.006178677082061768, 'eval_loss_3': -18.32281494140625, 'eval_loss_4': 0.9902386665344238, 'epoch': 13.11}
{'loss': 0.0186, 'grad_norm': 5.782131671905518, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.010582542978227139, 'loss_2': 0.0080413818359375, 'loss_3': -16.352027893066406, 'loss_4': 1.3518388271331787, 'epoch': 13.12}
{'loss': 0.0163, 'grad_norm': 4.646401882171631, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.008280864916741848, 'loss_2': 0.0079803466796875, 'loss_3': -16.500133514404297, 'loss_4': 0.9515764117240906, 'epoch': 13.12}
{'loss': 0.008, 'grad_norm': 5.08851432800293, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.0071021998301148415, 'loss_2': 0.000934600830078125, 'loss_3': -16.508468627929688, 'loss_4': 0.8767263889312744, 'epoch': 13.13}
{'loss': 0.0128, 'grad_norm': 5.214436054229736, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.007945452816784382, 'loss_2': 0.004840850830078125, 'loss_3': -16.555374145507812, 'loss_4': 0.8149038553237915, 'epoch': 13.13}
{'loss': 0.0124, 'grad_norm': 6.649396896362305, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.009596139192581177, 'loss_2': 0.00275421142578125, 'loss_3': -16.683677673339844, 'loss_4': 0.9197529554367065, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 10:20:06,350 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:06,350 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [55:55<50:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:13,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008142990991473198, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004610360134392977, 'eval_loss_2': 0.0035326294600963593, 'eval_loss_3': -18.30632781982422, 'eval_loss_4': 0.9403513669967651, 'epoch': 13.14}
{'loss': 0.0201, 'grad_norm': 8.688939094543457, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.018405502662062645, 'loss_2': 0.0017423629760742188, 'loss_3': -16.364294052124023, 'loss_4': 1.1895558834075928, 'epoch': 13.15}
{'loss': 0.0121, 'grad_norm': 5.641909122467041, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.010421494022011757, 'loss_2': 0.0016689300537109375, 'loss_3': -16.355192184448242, 'loss_4': 2.0575027465820312, 'epoch': 13.15}
{'loss': 0.0103, 'grad_norm': 5.922967910766602, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.006654495373368263, 'loss_2': 0.0036163330078125, 'loss_3': -16.50052833557129, 'loss_4': 1.585712194442749, 'epoch': 13.16}
{'loss': 0.0039, 'grad_norm': 4.700100898742676, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.0034053835552185774, 'loss_2': 0.0004944801330566406, 'loss_3': -16.419649124145508, 'loss_4': 1.4208542108535767, 'epoch': 13.16}
{'loss': 0.0076, 'grad_norm': 4.988526344299316, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.007210720796138048, 'loss_2': 0.0004069805145263672, 'loss_3': -16.508211135864258, 'loss_4': 1.4916651248931885, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 10:20:13,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:13,700 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:03<49:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:21,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00802516471594572, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004580358974635601, 'eval_loss_2': 0.0034448057413101196, 'eval_loss_3': -18.278600692749023, 'eval_loss_4': 0.9690749645233154, 'epoch': 13.17}
{'loss': 0.0108, 'grad_norm': 7.337461948394775, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.01023468654602766, 'loss_2': 0.0005741119384765625, 'loss_3': -16.469717025756836, 'loss_4': 1.4382168054580688, 'epoch': 13.17}
{'loss': 0.0043, 'grad_norm': 4.341878890991211, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.004307670518755913, 'loss_2': 3.325939178466797e-05, 'loss_3': -16.226943969726562, 'loss_4': 1.1353791952133179, 'epoch': 13.18}
{'loss': 0.0187, 'grad_norm': 9.423242568969727, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.018654324114322662, 'loss_2': 9.059906005859375e-05, 'loss_3': -16.41181182861328, 'loss_4': 0.7319700717926025, 'epoch': 13.19}
{'loss': 0.0119, 'grad_norm': 4.535951614379883, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.0042435345239937305, 'loss_2': 0.00763702392578125, 'loss_3': -16.376296997070312, 'loss_4': 1.185046672821045, 'epoch': 13.19}
{'loss': 0.0186, 'grad_norm': 9.76748275756836, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.01681232638657093, 'loss_2': 0.001739501953125, 'loss_3': -16.410356521606445, 'loss_4': 0.9952399134635925, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 10:20:21,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:21,045 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:10<49:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:28,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01004459336400032, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.125, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005208730697631836, 'eval_loss_2': 0.0048358626663684845, 'eval_loss_3': -18.235830307006836, 'eval_loss_4': 0.8997336030006409, 'epoch': 13.2}
{'loss': 0.0112, 'grad_norm': 6.1887922286987305, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.01065104454755783, 'loss_2': 0.0005388259887695312, 'loss_3': -16.464719772338867, 'loss_4': 1.5871102809906006, 'epoch': 13.2}
{'loss': 0.0236, 'grad_norm': 8.403267860412598, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.01554115116596222, 'loss_2': 0.0081024169921875, 'loss_3': -16.27725601196289, 'loss_4': 1.2644531726837158, 'epoch': 13.21}
{'loss': 0.0132, 'grad_norm': 4.553579330444336, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.0044691176153719425, 'loss_2': 0.0087127685546875, 'loss_3': -16.158100128173828, 'loss_4': 1.448510766029358, 'epoch': 13.22}
{'loss': 0.0118, 'grad_norm': 7.54802131652832, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.008909312076866627, 'loss_2': 0.002933502197265625, 'loss_3': -16.385990142822266, 'loss_4': 1.0432708263397217, 'epoch': 13.22}
{'loss': 0.0121, 'grad_norm': 5.784976959228516, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.009153065271675587, 'loss_2': 0.00290679931640625, 'loss_3': -16.27235221862793, 'loss_4': 1.4326668977737427, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 10:20:28,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:28,396 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:17<49:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:35,752 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011684962548315525, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.448, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005155750550329685, 'eval_loss_2': 0.00652921199798584, 'eval_loss_3': -18.22586441040039, 'eval_loss_4': 0.8703365921974182, 'epoch': 13.23}
{'loss': 0.0049, 'grad_norm': 5.231483459472656, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.00425393832847476, 'loss_2': 0.0006008148193359375, 'loss_3': -16.334617614746094, 'loss_4': 0.8355045914649963, 'epoch': 13.23}
{'loss': 0.0163, 'grad_norm': 4.867380142211914, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.005219554528594017, 'loss_2': 0.0110626220703125, 'loss_3': -16.46004867553711, 'loss_4': 1.6891834735870361, 'epoch': 13.24}
{'loss': 0.0164, 'grad_norm': 7.270180702209473, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.012245726771652699, 'loss_2': 0.00420379638671875, 'loss_3': -16.155319213867188, 'loss_4': 1.0973749160766602, 'epoch': 13.24}
{'loss': 0.0087, 'grad_norm': 4.589967727661133, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.005634963512420654, 'loss_2': 0.00305938720703125, 'loss_3': -16.388530731201172, 'loss_4': 0.6288914084434509, 'epoch': 13.25}
{'loss': 0.0046, 'grad_norm': 5.022172927856445, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.0034160467330366373, 'loss_2': 0.0011949539184570312, 'loss_3': -16.340225219726562, 'loss_4': 1.3563941717147827, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 10:20:35,752 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:35,752 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:25<49:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:43,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008237801492214203, 'eval_runtime': 3.8167, 'eval_samples_per_second': 268.295, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.004551783204078674, 'eval_loss_2': 0.0036860182881355286, 'eval_loss_3': -18.247222900390625, 'eval_loss_4': 0.9366813898086548, 'epoch': 13.26}
{'loss': 0.0345, 'grad_norm': 11.723799705505371, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.021928582340478897, 'loss_2': 0.01256561279296875, 'loss_3': -16.126609802246094, 'loss_4': 1.094636082649231, 'epoch': 13.26}
{'loss': 0.0069, 'grad_norm': 4.889089107513428, 'learning_rate': 1.675e-05, 'loss_1': 0.006253743078559637, 'loss_2': 0.0006799697875976562, 'loss_3': -16.292409896850586, 'loss_4': 1.154313325881958, 'epoch': 13.27}
{'loss': 0.0164, 'grad_norm': 11.456226348876953, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.014187169261276722, 'loss_2': 0.002170562744140625, 'loss_3': -16.204051971435547, 'loss_4': 1.269026756286621, 'epoch': 13.27}
{'loss': 0.009, 'grad_norm': 5.210806846618652, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.006717614829540253, 'loss_2': 0.0023097991943359375, 'loss_3': -16.399242401123047, 'loss_4': 1.0346585512161255, 'epoch': 13.28}
{'loss': 0.0186, 'grad_norm': 7.7163238525390625, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.015521222725510597, 'loss_2': 0.0030803680419921875, 'loss_3': -16.48428726196289, 'loss_4': 2.0537643432617188, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 10:20:43,114 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:43,114 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:32<49:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:50,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009411372244358063, 'eval_runtime': 3.8247, 'eval_samples_per_second': 267.733, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.004775308538228273, 'eval_loss_2': 0.004636064171791077, 'eval_loss_3': -18.21202850341797, 'eval_loss_4': 1.2902926206588745, 'epoch': 13.28}
{'loss': 0.0129, 'grad_norm': 4.914069652557373, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.00469680642709136, 'loss_2': 0.00817108154296875, 'loss_3': -16.412799835205078, 'loss_4': 1.0565483570098877, 'epoch': 13.29}
{'loss': 0.0106, 'grad_norm': 8.646552085876465, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.008339987136423588, 'loss_2': 0.00223541259765625, 'loss_3': -16.418949127197266, 'loss_4': 1.2745976448059082, 'epoch': 13.3}
{'loss': 0.0158, 'grad_norm': 6.4710259437561035, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.013225464150309563, 'loss_2': 0.002613067626953125, 'loss_3': -16.0225887298584, 'loss_4': 1.4191639423370361, 'epoch': 13.3}
{'loss': 0.0047, 'grad_norm': 5.211917400360107, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.004272220656275749, 'loss_2': 0.0004658699035644531, 'loss_3': -16.311561584472656, 'loss_4': 1.5867798328399658, 'epoch': 13.31}
{'loss': 0.0065, 'grad_norm': 5.083802223205566, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.0063392650336027145, 'loss_2': 0.00014412403106689453, 'loss_3': -16.26175308227539, 'loss_4': 2.4035696983337402, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 10:20:50,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:50,488 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:39<49:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:57,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008353970013558865, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.363, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004452964756637812, 'eval_loss_2': 0.0039010047912597656, 'eval_loss_3': -18.24244499206543, 'eval_loss_4': 1.6162352561950684, 'epoch': 13.31}
{'loss': 0.0163, 'grad_norm': 6.109136581420898, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.01173557247966528, 'loss_2': 0.004547119140625, 'loss_3': -16.316116333007812, 'loss_4': 2.0162863731384277, 'epoch': 13.32}
{'loss': 0.0039, 'grad_norm': 4.814707279205322, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.0024317794013768435, 'loss_2': 0.0015048980712890625, 'loss_3': -16.342273712158203, 'loss_4': 2.6233980655670166, 'epoch': 13.33}
{'loss': 0.0096, 'grad_norm': 5.3392181396484375, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.008050437085330486, 'loss_2': 0.0015583038330078125, 'loss_3': -16.413528442382812, 'loss_4': 2.326261043548584, 'epoch': 13.33}
{'loss': 0.0073, 'grad_norm': 5.808687210083008, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.007176544051617384, 'loss_2': 0.00015485286712646484, 'loss_3': -16.239788055419922, 'loss_4': 2.0606141090393066, 'epoch': 13.34}
{'loss': 0.0069, 'grad_norm': 4.533681392669678, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.006116639822721481, 'loss_2': 0.0008196830749511719, 'loss_3': -16.455190658569336, 'loss_4': 1.5948209762573242, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 10:20:57,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:57,836 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [56:47<49:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:05,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008193781599402428, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.004484242293983698, 'eval_loss_2': 0.003709539771080017, 'eval_loss_3': -18.259981155395508, 'eval_loss_4': 1.831418752670288, 'epoch': 13.34}
{'loss': 0.0201, 'grad_norm': 8.756346702575684, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.019172875210642815, 'loss_2': 0.000972747802734375, 'loss_3': -16.13706398010254, 'loss_4': 1.9658119678497314, 'epoch': 13.35}
{'loss': 0.0109, 'grad_norm': 5.790541172027588, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.009223968721926212, 'loss_2': 0.0016937255859375, 'loss_3': -16.155717849731445, 'loss_4': 2.0280256271362305, 'epoch': 13.35}
{'loss': 0.0142, 'grad_norm': 4.835330009460449, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.005788752343505621, 'loss_2': 0.00844573974609375, 'loss_3': -16.377790451049805, 'loss_4': 1.8785535097122192, 'epoch': 13.36}
{'loss': 0.0187, 'grad_norm': 5.881585597991943, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.01469494216144085, 'loss_2': 0.0040130615234375, 'loss_3': -16.355846405029297, 'loss_4': 2.4466817378997803, 'epoch': 13.37}
{'loss': 0.0183, 'grad_norm': 8.145426750183105, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.015453536994755268, 'loss_2': 0.0028324127197265625, 'loss_3': -16.555831909179688, 'loss_4': 2.161653995513916, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 10:21:05,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:05,182 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [56:54<49:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:12,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00902259536087513, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004540982190519571, 'eval_loss_2': 0.004481613636016846, 'eval_loss_3': -18.25617218017578, 'eval_loss_4': 2.145077705383301, 'epoch': 13.37}
{'loss': 0.0092, 'grad_norm': 4.989757061004639, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.005515295080840588, 'loss_2': 0.003681182861328125, 'loss_3': -16.43836212158203, 'loss_4': 2.5746521949768066, 'epoch': 13.38}
{'loss': 0.0182, 'grad_norm': 6.604805946350098, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.012226284481585026, 'loss_2': 0.0059967041015625, 'loss_3': -16.441152572631836, 'loss_4': 2.8872668743133545, 'epoch': 13.38}
{'loss': 0.0055, 'grad_norm': 4.275993347167969, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.004672701004892588, 'loss_2': 0.0008420944213867188, 'loss_3': -16.2718505859375, 'loss_4': 2.298074722290039, 'epoch': 13.39}
{'loss': 0.0112, 'grad_norm': 4.821611404418945, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.007746476214379072, 'loss_2': 0.0034427642822265625, 'loss_3': -16.40837287902832, 'loss_4': 2.6032464504241943, 'epoch': 13.4}
{'loss': 0.0207, 'grad_norm': 5.508772850036621, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.009736915118992329, 'loss_2': 0.01092529296875, 'loss_3': -16.08787727355957, 'loss_4': 2.6655542850494385, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 10:21:12,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:12,533 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [56:58<49:24,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 10:21:16,338 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-2305
[INFO|configuration_utils.py:420] 2025-01-21 10:21:16,340 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-2305/config.json                                                                             
{'eval_loss': 0.006650294177234173, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004040765576064587, 'eval_loss_2': 0.002609528601169586, 'eval_loss_3': -18.275806427001953, 'eval_loss_4': 2.540022373199463, 'epoch': 13.4}
[INFO|modeling_utils.py:2988] 2025-01-21 10:21:16,843 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-2305/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:21:16,844 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-2305/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:21:16,845 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-2305/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:21:17,860 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-970] due to args.save_total_limit
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:03<54:54,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 10:21:21,512 >>
{'loss': 0.0121, 'grad_norm': 6.638843536376953, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.011327830143272877, 'loss_2': 0.0008211135864257812, 'loss_3': -16.454269409179688, 'loss_4': 2.9227428436279297, 'epoch': 13.41}
{'loss': 0.0077, 'grad_norm': 5.177882671356201, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.007305496837943792, 'loss_2': 0.0003829002380371094, 'loss_3': -16.62738609313965, 'loss_4': 3.3348894119262695, 'epoch': 13.41}
{'loss': 0.0307, 'grad_norm': 7.717564582824707, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.03065028414130211, 'loss_2': 5.0067901611328125e-05, 'loss_3': -16.390348434448242, 'loss_4': 3.2748024463653564, 'epoch': 13.42}
{'loss': 0.03, 'grad_norm': 17.605440139770508, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.02790510095655918, 'loss_2': 0.002094268798828125, 'loss_3': -16.512187957763672, 'loss_4': 3.342240810394287, 'epoch': 13.42}
{'loss': 0.0357, 'grad_norm': 9.868361473083496, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.03420845791697502, 'loss_2': 0.0014543533325195312, 'loss_3': -16.57229995727539, 'loss_4': 3.7925562858581543, 'epoch': 13.43}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:21:21,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:21,512 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:11<50:08,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:21:28,854 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007116807624697685, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.541, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.004074228461831808, 'eval_loss_2': 0.00304257869720459, 'eval_loss_3': -18.309255599975586, 'eval_loss_4': 2.8151743412017822, 'epoch': 13.43}
{'loss': 0.0215, 'grad_norm': 15.281575202941895, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.016380801796913147, 'loss_2': 0.00516510009765625, 'loss_3': -16.286361694335938, 'loss_4': 3.4829049110412598, 'epoch': 13.44}
{'loss': 0.0109, 'grad_norm': 5.449234485626221, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.010002333670854568, 'loss_2': 0.000850677490234375, 'loss_3': -16.459259033203125, 'loss_4': 2.983813762664795, 'epoch': 13.44}
{'loss': 0.0084, 'grad_norm': 4.891510486602783, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.00493017490953207, 'loss_2': 0.003459930419921875, 'loss_3': -16.391063690185547, 'loss_4': 2.6611952781677246, 'epoch': 13.45}
{'loss': 0.027, 'grad_norm': 12.23189640045166, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.02555934526026249, 'loss_2': 0.00139617919921875, 'loss_3': -16.446996688842773, 'loss_4': 3.6252663135528564, 'epoch': 13.45}
{'loss': 0.0103, 'grad_norm': 6.58931303024292, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.0083175553008914, 'loss_2': 0.00202178955078125, 'loss_3': -16.409183502197266, 'loss_4': 2.854717254638672, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 10:21:28,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:28,854 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:18<49:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:36,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008978686295449734, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.562, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.004414013586938381, 'eval_loss_2': 0.0045646727085113525, 'eval_loss_3': -18.32680892944336, 'eval_loss_4': 2.878135919570923, 'epoch': 13.46}
{'loss': 0.0365, 'grad_norm': 10.611981391906738, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.031158817932009697, 'loss_2': 0.005298614501953125, 'loss_3': -16.43907928466797, 'loss_4': 2.8370883464813232, 'epoch': 13.47}
{'loss': 0.018, 'grad_norm': 8.232930183410645, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.013199971057474613, 'loss_2': 0.0048370361328125, 'loss_3': -16.600418090820312, 'loss_4': 3.3113529682159424, 'epoch': 13.47}
{'loss': 0.0141, 'grad_norm': 5.807624340057373, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.009093387983739376, 'loss_2': 0.004978179931640625, 'loss_3': -16.4423828125, 'loss_4': 3.142235279083252, 'epoch': 13.48}
{'loss': 0.0145, 'grad_norm': 4.606009006500244, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.0074943131767213345, 'loss_2': 0.00699615478515625, 'loss_3': -16.545852661132812, 'loss_4': 3.3069498538970947, 'epoch': 13.48}
{'loss': 0.025, 'grad_norm': 8.660242080688477, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.02320319414138794, 'loss_2': 0.001827239990234375, 'loss_3': -16.504440307617188, 'loss_4': 3.692058801651001, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 10:21:36,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:36,201 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:25<49:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:43,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008654346689581871, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005496641620993614, 'eval_loss_2': 0.003157705068588257, 'eval_loss_3': -18.327739715576172, 'eval_loss_4': 2.989232301712036, 'epoch': 13.49}
{'loss': 0.0254, 'grad_norm': 9.403450012207031, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.02542790025472641, 'loss_2': 1.919269561767578e-05, 'loss_3': -16.41168975830078, 'loss_4': 3.5982778072357178, 'epoch': 13.49}
{'loss': 0.0153, 'grad_norm': 4.702568531036377, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.008765204809606075, 'loss_2': 0.00658416748046875, 'loss_3': -16.45343017578125, 'loss_4': 3.1010332107543945, 'epoch': 13.5}
{'loss': 0.0191, 'grad_norm': 5.440502166748047, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.009621277451515198, 'loss_2': 0.00943756103515625, 'loss_3': -16.524309158325195, 'loss_4': 3.6886539459228516, 'epoch': 13.51}
{'loss': 0.0135, 'grad_norm': 5.048496723175049, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.012337738648056984, 'loss_2': 0.0011882781982421875, 'loss_3': -16.55065155029297, 'loss_4': 3.465977430343628, 'epoch': 13.51}
{'loss': 0.024, 'grad_norm': 12.912353515625, 'learning_rate': 1.65e-05, 'loss_1': 0.015688717365264893, 'loss_2': 0.00833892822265625, 'loss_3': -16.48116683959961, 'loss_4': 3.051362991333008, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 10:21:43,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:43,551 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:33<48:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:50,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008490312844514847, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004999262280762196, 'eval_loss_2': 0.003491051495075226, 'eval_loss_3': -18.332904815673828, 'eval_loss_4': 3.0455374717712402, 'epoch': 13.52}
{'loss': 0.0162, 'grad_norm': 6.803570747375488, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.014892954379320145, 'loss_2': 0.0013494491577148438, 'loss_3': -16.497920989990234, 'loss_4': 3.755535125732422, 'epoch': 13.52}
{'loss': 0.0141, 'grad_norm': 5.442947864532471, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.012659840285778046, 'loss_2': 0.0014591217041015625, 'loss_3': -16.418697357177734, 'loss_4': 3.8704590797424316, 'epoch': 13.53}
{'loss': 0.0133, 'grad_norm': 5.145544052124023, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.011816148646175861, 'loss_2': 0.0014743804931640625, 'loss_3': -16.609317779541016, 'loss_4': 2.938951015472412, 'epoch': 13.53}
{'loss': 0.0172, 'grad_norm': 8.103976249694824, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.017083927989006042, 'loss_2': 8.308887481689453e-05, 'loss_3': -16.329320907592773, 'loss_4': 3.5608420372009277, 'epoch': 13.54}
{'loss': 0.0146, 'grad_norm': 5.060877323150635, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.005802888888865709, 'loss_2': 0.00881195068359375, 'loss_3': -16.606592178344727, 'loss_4': 3.440263032913208, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 10:21:50,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:50,896 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:40<48:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:58,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008877454325556755, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.732, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0046742502599954605, 'eval_loss_2': 0.0042032040655612946, 'eval_loss_3': -18.305017471313477, 'eval_loss_4': 3.0102667808532715, 'epoch': 13.55}
{'loss': 0.0114, 'grad_norm': 5.591965675354004, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.007633580360561609, 'loss_2': 0.003810882568359375, 'loss_3': -16.28155517578125, 'loss_4': 3.441540241241455, 'epoch': 13.55}
{'loss': 0.015, 'grad_norm': 6.406569004058838, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.012345164082944393, 'loss_2': 0.002666473388671875, 'loss_3': -16.507469177246094, 'loss_4': 3.8143632411956787, 'epoch': 13.56}
{'loss': 0.0141, 'grad_norm': 4.979359149932861, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.009706294164061546, 'loss_2': 0.004390716552734375, 'loss_3': -16.50071144104004, 'loss_4': 3.958153247833252, 'epoch': 13.56}
{'loss': 0.0122, 'grad_norm': 7.67072868347168, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.009088139981031418, 'loss_2': 0.00315093994140625, 'loss_3': -16.435773849487305, 'loss_4': 3.7543277740478516, 'epoch': 13.57}
{'loss': 0.0132, 'grad_norm': 9.148309707641602, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.009802453219890594, 'loss_2': 0.00341033935546875, 'loss_3': -16.5987548828125, 'loss_4': 3.424959659576416, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 10:21:58,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:58,242 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [57:47<48:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:05,605 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008912384510040283, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.42, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0049857497215271, 'eval_loss_2': 0.003926634788513184, 'eval_loss_3': -18.284278869628906, 'eval_loss_4': 2.9897522926330566, 'epoch': 13.58}
{'loss': 0.0085, 'grad_norm': 5.490182399749756, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.00791153497993946, 'loss_2': 0.00063323974609375, 'loss_3': -16.459083557128906, 'loss_4': 2.982017993927002, 'epoch': 13.58}
{'loss': 0.0227, 'grad_norm': 9.216309547424316, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.01724635809659958, 'loss_2': 0.0054473876953125, 'loss_3': -16.46954345703125, 'loss_4': 3.363961696624756, 'epoch': 13.59}
{'loss': 0.0063, 'grad_norm': 4.586463451385498, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.005233731120824814, 'loss_2': 0.0010995864868164062, 'loss_3': -16.32855224609375, 'loss_4': 3.3831675052642822, 'epoch': 13.59}
{'loss': 0.0116, 'grad_norm': 4.958117961883545, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.007484118919819593, 'loss_2': 0.00412750244140625, 'loss_3': -16.331880569458008, 'loss_4': 3.683819532394409, 'epoch': 13.6}
{'loss': 0.0112, 'grad_norm': 5.950770854949951, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.01066580880433321, 'loss_2': 0.0005650520324707031, 'loss_3': -16.18013572692871, 'loss_4': 3.9403133392333984, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 10:22:05,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:05,606 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [57:55<48:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:12,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008451665751636028, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.457, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006172809284180403, 'eval_loss_2': 0.002278856933116913, 'eval_loss_3': -18.259334564208984, 'eval_loss_4': 3.211116313934326, 'epoch': 13.6}
{'loss': 0.0073, 'grad_norm': 4.774788856506348, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.006554132327437401, 'loss_2': 0.0007648468017578125, 'loss_3': -16.44537925720215, 'loss_4': 4.173004150390625, 'epoch': 13.61}
{'loss': 0.013, 'grad_norm': 5.12206506729126, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.007721466012299061, 'loss_2': 0.005290985107421875, 'loss_3': -16.420175552368164, 'loss_4': 3.6615304946899414, 'epoch': 13.62}
{'loss': 0.0292, 'grad_norm': 13.695730209350586, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.025762014091014862, 'loss_2': 0.003391265869140625, 'loss_3': -16.149658203125, 'loss_4': 3.6931824684143066, 'epoch': 13.62}
{'loss': 0.0219, 'grad_norm': 6.019379138946533, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.013621937483549118, 'loss_2': 0.00823974609375, 'loss_3': -16.472261428833008, 'loss_4': 3.490872383117676, 'epoch': 13.63}
{'loss': 0.0263, 'grad_norm': 9.819469451904297, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.019722674041986465, 'loss_2': 0.006565093994140625, 'loss_3': -16.545513153076172, 'loss_4': 4.024949550628662, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 10:22:12,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:12,950 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:02<48:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:20,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012779474258422852, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007383943535387516, 'eval_loss_2': 0.00539553165435791, 'eval_loss_3': -18.22043800354004, 'eval_loss_4': 3.420928716659546, 'epoch': 13.63}
{'loss': 0.017, 'grad_norm': 5.40713357925415, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.008037639781832695, 'loss_2': 0.0089263916015625, 'loss_3': -16.42890167236328, 'loss_4': 4.794004440307617, 'epoch': 13.64}
{'loss': 0.022, 'grad_norm': 7.299903869628906, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.012427976354956627, 'loss_2': 0.00958251953125, 'loss_3': -16.447463989257812, 'loss_4': 4.243535995483398, 'epoch': 13.65}
{'loss': 0.0211, 'grad_norm': 6.493439674377441, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.012120450846850872, 'loss_2': 0.0089874267578125, 'loss_3': -16.5493221282959, 'loss_4': 3.9730091094970703, 'epoch': 13.65}
{'loss': 0.0353, 'grad_norm': 9.787941932678223, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.029089761897921562, 'loss_2': 0.0062255859375, 'loss_3': -16.345657348632812, 'loss_4': 3.8292529582977295, 'epoch': 13.66}
{'loss': 0.034, 'grad_norm': 24.352336883544922, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.02818388305604458, 'loss_2': 0.005794525146484375, 'loss_3': -16.406021118164062, 'loss_4': 3.8070249557495117, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 10:22:20,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:20,295 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:09<48:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:27,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007992012426257133, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.315, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006136557087302208, 'eval_loss_2': 0.0018554553389549255, 'eval_loss_3': -18.216875076293945, 'eval_loss_4': 3.2802507877349854, 'epoch': 13.66}
{'loss': 0.0098, 'grad_norm': 6.211451053619385, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.008557325229048729, 'loss_2': 0.0012912750244140625, 'loss_3': -16.561063766479492, 'loss_4': 3.89170503616333, 'epoch': 13.67}
{'loss': 0.0102, 'grad_norm': 5.723830223083496, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.009311309084296227, 'loss_2': 0.000926971435546875, 'loss_3': -16.390453338623047, 'loss_4': 3.5266623497009277, 'epoch': 13.67}
{'loss': 0.0404, 'grad_norm': 12.941960334777832, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.03845011442899704, 'loss_2': 0.0019083023071289062, 'loss_3': -16.14847183227539, 'loss_4': 3.5473251342773438, 'epoch': 13.68}
{'loss': 0.0285, 'grad_norm': 12.37021541595459, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.01772688515484333, 'loss_2': 0.0107879638671875, 'loss_3': -16.4893798828125, 'loss_4': 3.3283119201660156, 'epoch': 13.69}
{'loss': 0.0181, 'grad_norm': 4.833436489105225, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.010449494235217571, 'loss_2': 0.00760650634765625, 'loss_3': -16.350736618041992, 'loss_4': 3.338042736053467, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 10:22:27,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:27,648 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:17<48:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:34,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013944711536169052, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006632175762206316, 'eval_loss_2': 0.0073125362396240234, 'eval_loss_3': -18.226688385009766, 'eval_loss_4': 2.88862681388855, 'epoch': 13.69}
{'loss': 0.0291, 'grad_norm': 6.409219264984131, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.019883817061781883, 'loss_2': 0.00922393798828125, 'loss_3': -16.267837524414062, 'loss_4': 3.1017212867736816, 'epoch': 13.7}
{'loss': 0.0218, 'grad_norm': 5.347015380859375, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.006766620557755232, 'loss_2': 0.0150146484375, 'loss_3': -16.385665893554688, 'loss_4': 3.2155871391296387, 'epoch': 13.7}
{'loss': 0.0301, 'grad_norm': 7.868114948272705, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.020437799394130707, 'loss_2': 0.009674072265625, 'loss_3': -16.3135986328125, 'loss_4': 2.892634868621826, 'epoch': 13.71}
{'loss': 0.0218, 'grad_norm': 5.221634864807129, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.009632227011024952, 'loss_2': 0.012176513671875, 'loss_3': -16.430192947387695, 'loss_4': 3.2085022926330566, 'epoch': 13.72}
{'loss': 0.015, 'grad_norm': 5.406862258911133, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.0071164751425385475, 'loss_2': 0.0078582763671875, 'loss_3': -16.39174461364746, 'loss_4': 2.850924015045166, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 10:22:34,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:34,996 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:24<48:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:42,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01080401986837387, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.089, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0061158775351941586, 'eval_loss_2': 0.004688143730163574, 'eval_loss_3': -18.245393753051758, 'eval_loss_4': 2.4743173122406006, 'epoch': 13.72}
{'loss': 0.0188, 'grad_norm': 7.100316524505615, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.012085974216461182, 'loss_2': 0.00667572021484375, 'loss_3': -16.419387817382812, 'loss_4': 2.9009881019592285, 'epoch': 13.73}
{'loss': 0.0092, 'grad_norm': 4.70361328125, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.005264435429126024, 'loss_2': 0.00389862060546875, 'loss_3': -16.328521728515625, 'loss_4': 2.942389965057373, 'epoch': 13.73}
{'loss': 0.0254, 'grad_norm': 8.160515785217285, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.019478676840662956, 'loss_2': 0.00595855712890625, 'loss_3': -16.42023468017578, 'loss_4': 2.9544544219970703, 'epoch': 13.74}
{'loss': 0.0129, 'grad_norm': 5.167158603668213, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.008569088764488697, 'loss_2': 0.00433349609375, 'loss_3': -16.53902816772461, 'loss_4': 2.7232728004455566, 'epoch': 13.74}
{'loss': 0.0158, 'grad_norm': 8.056327819824219, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.01113450713455677, 'loss_2': 0.004711151123046875, 'loss_3': -16.529075622558594, 'loss_4': 2.910050630569458, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 10:22:42,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:42,357 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:31<48:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:49,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008386681787669659, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.848, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005180377047508955, 'eval_loss_2': 0.003206305205821991, 'eval_loss_3': -18.287731170654297, 'eval_loss_4': 2.40110445022583, 'epoch': 13.75}
{'loss': 0.0118, 'grad_norm': 4.974539279937744, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.005155380815267563, 'loss_2': 0.0066375732421875, 'loss_3': -16.494773864746094, 'loss_4': 1.9600797891616821, 'epoch': 13.76}
{'loss': 0.0166, 'grad_norm': 5.744261264801025, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.011251343414187431, 'loss_2': 0.00536346435546875, 'loss_3': -16.368175506591797, 'loss_4': 3.085825204849243, 'epoch': 13.76}
{'loss': 0.0114, 'grad_norm': 5.469767093658447, 'learning_rate': 1.625e-05, 'loss_1': 0.010437371209263802, 'loss_2': 0.00099945068359375, 'loss_3': -16.694347381591797, 'loss_4': 3.3492813110351562, 'epoch': 13.77}
{'loss': 0.0193, 'grad_norm': 9.41845703125, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.016249150037765503, 'loss_2': 0.003055572509765625, 'loss_3': -16.52845001220703, 'loss_4': 2.93593692779541, 'epoch': 13.77}
{'loss': 0.0174, 'grad_norm': 8.809361457824707, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.015414269641041756, 'loss_2': 0.0019359588623046875, 'loss_3': -16.50809097290039, 'loss_4': 2.7059686183929443, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 10:22:49,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:49,719 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:39<48:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:57,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00718151219189167, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.173, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004970105364918709, 'eval_loss_2': 0.0022114068269729614, 'eval_loss_3': -18.293521881103516, 'eval_loss_4': 2.4242100715637207, 'epoch': 13.78}
{'loss': 0.0132, 'grad_norm': 7.8184332847595215, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.012217646464705467, 'loss_2': 0.0009360313415527344, 'loss_3': -16.368789672851562, 'loss_4': 2.142882823944092, 'epoch': 13.78}
{'loss': 0.0115, 'grad_norm': 6.131124019622803, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.00983049813657999, 'loss_2': 0.0016508102416992188, 'loss_3': -16.15610694885254, 'loss_4': 3.1826634407043457, 'epoch': 13.79}
{'loss': 0.012, 'grad_norm': 6.049078941345215, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.009139209054410458, 'loss_2': 0.002872467041015625, 'loss_3': -16.39637565612793, 'loss_4': 3.228344202041626, 'epoch': 13.8}
{'loss': 0.0104, 'grad_norm': 5.445465564727783, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.007915482856333256, 'loss_2': 0.00249481201171875, 'loss_3': -16.399656295776367, 'loss_4': 1.681154727935791, 'epoch': 13.8}
{'loss': 0.0163, 'grad_norm': 7.90430212020874, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.010383812710642815, 'loss_2': 0.00586700439453125, 'loss_3': -16.266666412353516, 'loss_4': 2.559965133666992, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 10:22:57,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:57,071 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [58:46<48:48,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:23:04,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010136783123016357, 'eval_runtime': 3.9923, 'eval_samples_per_second': 256.495, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.005537740420550108, 'eval_loss_2': 0.004599042236804962, 'eval_loss_3': -18.291431427001953, 'eval_loss_4': 2.1880593299865723, 'epoch': 13.81}
{'loss': 0.0176, 'grad_norm': 5.032066822052002, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.00853582564741373, 'loss_2': 0.0090179443359375, 'loss_3': -16.462066650390625, 'loss_4': 2.853128433227539, 'epoch': 13.81}
{'loss': 0.0118, 'grad_norm': 5.358146667480469, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.009505673311650753, 'loss_2': 0.0023040771484375, 'loss_3': -16.335060119628906, 'loss_4': 2.872772216796875, 'epoch': 13.82}
{'loss': 0.0244, 'grad_norm': 6.360122203826904, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.014918391592800617, 'loss_2': 0.00949859619140625, 'loss_3': -16.36197853088379, 'loss_4': 2.3888559341430664, 'epoch': 13.83}
{'loss': 0.0233, 'grad_norm': 7.006099700927734, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.020195472985506058, 'loss_2': 0.0030727386474609375, 'loss_3': -16.29225730895996, 'loss_4': 2.669856071472168, 'epoch': 13.83}
{'loss': 0.0172, 'grad_norm': 7.072164058685303, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.01694260537624359, 'loss_2': 0.00026345252990722656, 'loss_3': -16.346750259399414, 'loss_4': 2.821141481399536, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 10:23:04,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:04,617 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [58:54<48:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:11,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008252603933215141, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00488722138106823, 'eval_loss_2': 0.0033653825521469116, 'eval_loss_3': -18.286518096923828, 'eval_loss_4': 1.8641279935836792, 'epoch': 13.84}
{'loss': 0.0064, 'grad_norm': 4.824389457702637, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.0061395661905407906, 'loss_2': 0.0002529621124267578, 'loss_3': -16.524141311645508, 'loss_4': 2.4407107830047607, 'epoch': 13.84}
{'loss': 0.0166, 'grad_norm': 6.28952693939209, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.010930228047072887, 'loss_2': 0.00565338134765625, 'loss_3': -16.338111877441406, 'loss_4': 2.266906499862671, 'epoch': 13.85}
{'loss': 0.0254, 'grad_norm': 11.119983673095703, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.021560434252023697, 'loss_2': 0.003810882568359375, 'loss_3': -16.442474365234375, 'loss_4': 2.836256742477417, 'epoch': 13.85}
{'loss': 0.0163, 'grad_norm': 6.69162130355835, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.0134311243891716, 'loss_2': 0.002902984619140625, 'loss_3': -16.497323989868164, 'loss_4': 2.0487749576568604, 'epoch': 13.86}
{'loss': 0.0127, 'grad_norm': 4.692307472229004, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.004560122266411781, 'loss_2': 0.0081634521484375, 'loss_3': -16.382991790771484, 'loss_4': 1.9832332134246826, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 10:23:11,970 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:11,970 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:01<47:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:19,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008168105967342854, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005153423175215721, 'eval_loss_2': 0.003014683723449707, 'eval_loss_3': -18.298297882080078, 'eval_loss_4': 1.6414203643798828, 'epoch': 13.87}
{'loss': 0.021, 'grad_norm': 9.534649848937988, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.020511850714683533, 'loss_2': 0.00043964385986328125, 'loss_3': -16.267301559448242, 'loss_4': 1.6255738735198975, 'epoch': 13.87}
{'loss': 0.0207, 'grad_norm': 8.039931297302246, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.014300931245088577, 'loss_2': 0.0064239501953125, 'loss_3': -16.35573959350586, 'loss_4': 2.4440832138061523, 'epoch': 13.88}
{'loss': 0.0185, 'grad_norm': 7.235011577606201, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.016133403405547142, 'loss_2': 0.002414703369140625, 'loss_3': -16.490188598632812, 'loss_4': 2.5610289573669434, 'epoch': 13.88}
{'loss': 0.0112, 'grad_norm': 5.178283214569092, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.008000832051038742, 'loss_2': 0.003215789794921875, 'loss_3': -16.5357666015625, 'loss_4': 2.598479986190796, 'epoch': 13.89}
{'loss': 0.024, 'grad_norm': 8.711507797241211, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.019021539017558098, 'loss_2': 0.0049896240234375, 'loss_3': -16.591405868530273, 'loss_4': 1.4083828926086426, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 10:23:19,318 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:19,318 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:08<47:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:26,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008798935450613499, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.362, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005908825434744358, 'eval_loss_2': 0.0028901100158691406, 'eval_loss_3': -18.313318252563477, 'eval_loss_4': 1.4368312358856201, 'epoch': 13.9}
{'loss': 0.0132, 'grad_norm': 6.1967267990112305, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.012090588919818401, 'loss_2': 0.001129150390625, 'loss_3': -16.37889862060547, 'loss_4': 1.4899845123291016, 'epoch': 13.9}
{'loss': 0.0258, 'grad_norm': 10.145845413208008, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.025595329701900482, 'loss_2': 0.00025391578674316406, 'loss_3': -16.57688331604004, 'loss_4': 1.9543874263763428, 'epoch': 13.91}
{'loss': 0.007, 'grad_norm': 4.694637775421143, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.005794133525341749, 'loss_2': 0.001232147216796875, 'loss_3': -16.424482345581055, 'loss_4': 1.7860958576202393, 'epoch': 13.91}
{'loss': 0.0122, 'grad_norm': 4.6506733894348145, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.00817697960883379, 'loss_2': 0.00397491455078125, 'loss_3': -16.467260360717773, 'loss_4': 2.2995243072509766, 'epoch': 13.92}
{'loss': 0.0341, 'grad_norm': 13.573427200317383, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.034060314297676086, 'loss_2': 2.5272369384765625e-05, 'loss_3': -16.38800811767578, 'loss_4': 2.975740909576416, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 10:23:26,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:26,682 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:16<47:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:34,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008644959889352322, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005277663003653288, 'eval_loss_2': 0.003367297351360321, 'eval_loss_3': -18.312604904174805, 'eval_loss_4': 1.5100311040878296, 'epoch': 13.92}
{'loss': 0.0111, 'grad_norm': 5.682044982910156, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.00869577843695879, 'loss_2': 0.002429962158203125, 'loss_3': -16.342151641845703, 'loss_4': 1.7934068441390991, 'epoch': 13.93}
{'loss': 0.0163, 'grad_norm': 7.047484874725342, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.011517218314111233, 'loss_2': 0.0047607421875, 'loss_3': -16.415409088134766, 'loss_4': 1.807502269744873, 'epoch': 13.94}
{'loss': 0.0196, 'grad_norm': 6.1410441398620605, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.017395487055182457, 'loss_2': 0.002185821533203125, 'loss_3': -16.33733558654785, 'loss_4': 2.1578872203826904, 'epoch': 13.94}
{'loss': 0.0227, 'grad_norm': 10.068000793457031, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.019538041204214096, 'loss_2': 0.003139495849609375, 'loss_3': -16.500137329101562, 'loss_4': 2.0051844120025635, 'epoch': 13.95}
{'loss': 0.0168, 'grad_norm': 5.340077877044678, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.008862181566655636, 'loss_2': 0.007965087890625, 'loss_3': -16.232616424560547, 'loss_4': 1.891946792602539, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 10:23:34,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:34,041 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:23<47:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:41,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008715293370187283, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00567250233143568, 'eval_loss_2': 0.003042791038751602, 'eval_loss_3': -18.323997497558594, 'eval_loss_4': 1.6060904264450073, 'epoch': 13.95}
{'loss': 0.0091, 'grad_norm': 5.8780107498168945, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.008606400340795517, 'loss_2': 0.0004978179931640625, 'loss_3': -16.307615280151367, 'loss_4': 2.066744565963745, 'epoch': 13.96}
{'loss': 0.0157, 'grad_norm': 6.455174446105957, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.011470037512481213, 'loss_2': 0.0041961669921875, 'loss_3': -16.43209457397461, 'loss_4': 2.5536069869995117, 'epoch': 13.97}
{'loss': 0.0199, 'grad_norm': 13.786797523498535, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.016505641862750053, 'loss_2': 0.003353118896484375, 'loss_3': -16.27776336669922, 'loss_4': 1.9510107040405273, 'epoch': 13.97}
{'loss': 0.0111, 'grad_norm': 5.159551620483398, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.00806677807122469, 'loss_2': 0.003021240234375, 'loss_3': -16.503528594970703, 'loss_4': 1.9982208013534546, 'epoch': 13.98}
{'loss': 0.0163, 'grad_norm': 4.866577625274658, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.011637883260846138, 'loss_2': 0.00461578369140625, 'loss_3': -16.477184295654297, 'loss_4': 2.1137688159942627, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 10:23:41,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:41,395 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:30<45:42,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 10:23:48,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010707148350775242, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0054827118292450905, 'eval_loss_2': 0.005224436521530151, 'eval_loss_3': -18.320331573486328, 'eval_loss_4': 1.8512333631515503, 'epoch': 13.98}
{'loss': 0.0102, 'grad_norm': 4.851884365081787, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.00727633573114872, 'loss_2': 0.0029621124267578125, 'loss_3': -16.306324005126953, 'loss_4': 1.9505691528320312, 'epoch': 13.99}
{'loss': 0.0287, 'grad_norm': 14.046903610229492, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.028211601078510284, 'loss_2': 0.00049591064453125, 'loss_3': -16.31519317626953, 'loss_4': 2.705904483795166, 'epoch': 13.99}
{'loss': 0.0041, 'grad_norm': 7.116696834564209, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.0036451302003115416, 'loss_2': 0.0004372596740722656, 'loss_3': -16.405241012573242, 'loss_4': 2.4815428256988525, 'epoch': 14.0}
{'loss': 0.02, 'grad_norm': 10.069445610046387, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.016666751354932785, 'loss_2': 0.0033416748046875, 'loss_3': -16.520204544067383, 'loss_4': 2.7629189491271973, 'epoch': 14.01}
{'loss': 0.0505, 'grad_norm': 22.538280487060547, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.046623602509498596, 'loss_2': 0.00385284423828125, 'loss_3': -16.537899017333984, 'loss_4': 2.248354434967041, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 10:23:48,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:48,441 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:37<47:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:23:55,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00945322960615158, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.048, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005358273163437843, 'eval_loss_2': 0.004094958305358887, 'eval_loss_3': -18.342144012451172, 'eval_loss_4': 2.089000701904297, 'epoch': 14.01}
{'loss': 0.0162, 'grad_norm': 5.907306671142578, 'learning_rate': 1.6e-05, 'loss_1': 0.00961818266659975, 'loss_2': 0.00661468505859375, 'loss_3': -16.418718338012695, 'loss_4': 2.8851003646850586, 'epoch': 14.02}
{'loss': 0.0087, 'grad_norm': 5.192531108856201, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.007972436025738716, 'loss_2': 0.0007534027099609375, 'loss_3': -16.488048553466797, 'loss_4': 3.150068759918213, 'epoch': 14.02}
{'loss': 0.0141, 'grad_norm': 5.054283142089844, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.010137688368558884, 'loss_2': 0.003936767578125, 'loss_3': -16.379819869995117, 'loss_4': 2.7110047340393066, 'epoch': 14.03}
{'loss': 0.0171, 'grad_norm': 5.581410884857178, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.01262627076357603, 'loss_2': 0.004425048828125, 'loss_3': -16.37830352783203, 'loss_4': 3.1024444103240967, 'epoch': 14.03}
{'loss': 0.036, 'grad_norm': 13.658256530761719, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.030618097633123398, 'loss_2': 0.005344390869140625, 'loss_3': -16.343841552734375, 'loss_4': 2.755284309387207, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 10:23:55,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:55,793 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 2420/5160 [59:45<47:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:03,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008678480982780457, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004975616931915283, 'eval_loss_2': 0.0037028640508651733, 'eval_loss_3': -18.337364196777344, 'eval_loss_4': 2.205284833908081, 'epoch': 14.04}
{'loss': 0.0131, 'grad_norm': 7.799942493438721, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.009949622675776482, 'loss_2': 0.003154754638671875, 'loss_3': -16.384685516357422, 'loss_4': 2.737797260284424, 'epoch': 14.05}
{'loss': 0.012, 'grad_norm': 5.976032257080078, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.011928615160286427, 'loss_2': 9.566545486450195e-05, 'loss_3': -16.52377700805664, 'loss_4': 2.1857848167419434, 'epoch': 14.05}
{'loss': 0.0194, 'grad_norm': 6.8787336349487305, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.016018208116292953, 'loss_2': 0.00341796875, 'loss_3': -16.35147476196289, 'loss_4': 2.539884567260742, 'epoch': 14.06}
{'loss': 0.0096, 'grad_norm': 5.4316582679748535, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.00858833733946085, 'loss_2': 0.0010309219360351562, 'loss_3': -16.47146987915039, 'loss_4': 2.7992448806762695, 'epoch': 14.06}
{'loss': 0.0112, 'grad_norm': 5.72413444519043, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.009483336471021175, 'loss_2': 0.0017566680908203125, 'loss_3': -16.222959518432617, 'loss_4': 3.2519712448120117, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 10:24:03,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:03,147 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 2425/5160 [59:52<47:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:10,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007963413372635841, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.461, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004609622992575169, 'eval_loss_2': 0.003353789448738098, 'eval_loss_3': -18.35002326965332, 'eval_loss_4': 2.362354040145874, 'epoch': 14.07}
{'loss': 0.0142, 'grad_norm': 6.405065059661865, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.010745668783783913, 'loss_2': 0.00342559814453125, 'loss_3': -16.354583740234375, 'loss_4': 2.6455283164978027, 'epoch': 14.08}
{'loss': 0.0169, 'grad_norm': 5.968170166015625, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.01095171831548214, 'loss_2': 0.005908966064453125, 'loss_3': -16.240694046020508, 'loss_4': 3.1906986236572266, 'epoch': 14.08}
{'loss': 0.0196, 'grad_norm': 8.048028945922852, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.015280241146683693, 'loss_2': 0.004306793212890625, 'loss_3': -16.51578140258789, 'loss_4': 2.6648449897766113, 'epoch': 14.09}
{'loss': 0.0116, 'grad_norm': 6.131897926330566, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.01093462947756052, 'loss_2': 0.0006561279296875, 'loss_3': -16.38770294189453, 'loss_4': 3.31558895111084, 'epoch': 14.09}
{'loss': 0.0116, 'grad_norm': 5.338510513305664, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.009832103736698627, 'loss_2': 0.0017786026000976562, 'loss_3': -16.381807327270508, 'loss_4': 3.0424137115478516, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 10:24:10,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:10,518 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:00<47:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:17,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008878648281097412, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005559951066970825, 'eval_loss_2': 0.003318697214126587, 'eval_loss_3': -18.34623908996582, 'eval_loss_4': 2.4907889366149902, 'epoch': 14.1}
{'loss': 0.0434, 'grad_norm': 14.720171928405762, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.039892248809337616, 'loss_2': 0.003475189208984375, 'loss_3': -16.458343505859375, 'loss_4': 3.7625434398651123, 'epoch': 14.1}
{'loss': 0.021, 'grad_norm': 11.13546085357666, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.01598215103149414, 'loss_2': 0.0050506591796875, 'loss_3': -16.469064712524414, 'loss_4': 3.197300910949707, 'epoch': 14.11}
{'loss': 0.0137, 'grad_norm': 8.385066032409668, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.010268570855259895, 'loss_2': 0.003467559814453125, 'loss_3': -16.548080444335938, 'loss_4': 2.5700607299804688, 'epoch': 14.12}
{'loss': 0.0176, 'grad_norm': 6.506669521331787, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.013048254884779453, 'loss_2': 0.00452423095703125, 'loss_3': -16.356842041015625, 'loss_4': 3.4428634643554688, 'epoch': 14.12}
{'loss': 0.0133, 'grad_norm': 4.6681365966796875, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.008098348043859005, 'loss_2': 0.0051727294921875, 'loss_3': -16.299400329589844, 'loss_4': 3.077446937561035, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 10:24:17,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:17,869 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:07<47:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:25,212 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009123580530285835, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005334931425750256, 'eval_loss_2': 0.0037886500358581543, 'eval_loss_3': -18.355693817138672, 'eval_loss_4': 2.3815553188323975, 'epoch': 14.13}
{'loss': 0.0184, 'grad_norm': 6.203202247619629, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.0147456806153059, 'loss_2': 0.003681182861328125, 'loss_3': -16.544940948486328, 'loss_4': 3.007927656173706, 'epoch': 14.13}
{'loss': 0.0089, 'grad_norm': 6.7824602127075195, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.008730423636734486, 'loss_2': 0.0001537799835205078, 'loss_3': -16.379554748535156, 'loss_4': 3.0369746685028076, 'epoch': 14.14}
{'loss': 0.0114, 'grad_norm': 6.843696594238281, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.010574380867183208, 'loss_2': 0.0007925033569335938, 'loss_3': -16.381376266479492, 'loss_4': 3.4256372451782227, 'epoch': 14.15}
{'loss': 0.0278, 'grad_norm': 9.869696617126465, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.017000995576381683, 'loss_2': 0.010772705078125, 'loss_3': -16.509584426879883, 'loss_4': 3.0723814964294434, 'epoch': 14.15}
{'loss': 0.0108, 'grad_norm': 4.957918643951416, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.004230980295687914, 'loss_2': 0.006549835205078125, 'loss_3': -16.41141128540039, 'loss_4': 2.6865286827087402, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 10:24:25,212 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:25,212 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:14<47:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:32,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011565515771508217, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005176658742129803, 'eval_loss_2': 0.006388857960700989, 'eval_loss_3': -18.347612380981445, 'eval_loss_4': 2.169126033782959, 'epoch': 14.16}
{'loss': 0.008, 'grad_norm': 4.5217390060424805, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.007683589588850737, 'loss_2': 0.0002727508544921875, 'loss_3': -16.648143768310547, 'loss_4': 3.1680283546447754, 'epoch': 14.16}
{'loss': 0.0221, 'grad_norm': 6.520409107208252, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.013178079389035702, 'loss_2': 0.008941650390625, 'loss_3': -16.34592628479004, 'loss_4': 2.640315532684326, 'epoch': 14.17}
{'loss': 0.0104, 'grad_norm': 5.927677154541016, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.007812835276126862, 'loss_2': 0.002590179443359375, 'loss_3': -16.454648971557617, 'loss_4': 2.4541821479797363, 'epoch': 14.17}
{'loss': 0.0058, 'grad_norm': 4.722279071807861, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.004845773801207542, 'loss_2': 0.0009260177612304688, 'loss_3': -16.54991340637207, 'loss_4': 2.478224277496338, 'epoch': 14.18}
{'loss': 0.032, 'grad_norm': 14.370469093322754, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.02180309221148491, 'loss_2': 0.010162353515625, 'loss_3': -16.232955932617188, 'loss_4': 2.7994372844696045, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 10:24:32,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:32,559 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:22<46:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:39,899 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011459851637482643, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00561144296079874, 'eval_loss_2': 0.005848407745361328, 'eval_loss_3': -18.349775314331055, 'eval_loss_4': 1.9456026554107666, 'epoch': 14.19}
{'loss': 0.0115, 'grad_norm': 6.75955057144165, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.011378524824976921, 'loss_2': 0.000118255615234375, 'loss_3': -16.420534133911133, 'loss_4': 2.28582763671875, 'epoch': 14.19}
{'loss': 0.0146, 'grad_norm': 5.867536544799805, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.008131778798997402, 'loss_2': 0.006439208984375, 'loss_3': -16.36061668395996, 'loss_4': 2.4982552528381348, 'epoch': 14.2}
{'loss': 0.0167, 'grad_norm': 5.421478748321533, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.007296132389456034, 'loss_2': 0.00943756103515625, 'loss_3': -16.578712463378906, 'loss_4': 2.186213493347168, 'epoch': 14.2}
{'loss': 0.0111, 'grad_norm': 5.172816276550293, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.0068425945937633514, 'loss_2': 0.0042724609375, 'loss_3': -16.003406524658203, 'loss_4': 3.1976821422576904, 'epoch': 14.21}
{'loss': 0.033, 'grad_norm': 14.093929290771484, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.028020652011036873, 'loss_2': 0.00499725341796875, 'loss_3': -16.21058464050293, 'loss_4': 2.7822699546813965, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 10:24:39,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:39,899 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:29<46:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:47,257 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008343992754817009, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005017025396227837, 'eval_loss_2': 0.0033269673585891724, 'eval_loss_3': -18.34764862060547, 'eval_loss_4': 1.8340204954147339, 'epoch': 14.22}
{'loss': 0.0066, 'grad_norm': 4.279664039611816, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.0036820180248469114, 'loss_2': 0.0029296875, 'loss_3': -16.398073196411133, 'loss_4': 2.1925995349884033, 'epoch': 14.22}
{'loss': 0.0109, 'grad_norm': 8.315849304199219, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.010233907960355282, 'loss_2': 0.0006551742553710938, 'loss_3': -16.59840202331543, 'loss_4': 2.0000500679016113, 'epoch': 14.23}
{'loss': 0.0107, 'grad_norm': 5.068726062774658, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.006252196151763201, 'loss_2': 0.0044097900390625, 'loss_3': -16.25061798095703, 'loss_4': 2.2695579528808594, 'epoch': 14.23}
{'loss': 0.0121, 'grad_norm': 5.4991841316223145, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.006799212656915188, 'loss_2': 0.005260467529296875, 'loss_3': -16.397781372070312, 'loss_4': 2.6822516918182373, 'epoch': 14.24}
{'loss': 0.0202, 'grad_norm': 9.751572608947754, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.01984676532447338, 'loss_2': 0.0003962516784667969, 'loss_3': -16.42274284362793, 'loss_4': 2.3166744709014893, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 10:24:47,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:47,258 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:36<46:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:54,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01056047435849905, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.004784128628671169, 'eval_loss_2': 0.005776345729827881, 'eval_loss_3': -18.366378784179688, 'eval_loss_4': 1.7165101766586304, 'epoch': 14.24}
{'loss': 0.0106, 'grad_norm': 5.54734992980957, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.009821386076509953, 'loss_2': 0.0008153915405273438, 'loss_3': -16.184911727905273, 'loss_4': 2.0690560340881348, 'epoch': 14.25}
{'loss': 0.0154, 'grad_norm': 5.502054691314697, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.007501059211790562, 'loss_2': 0.00794219970703125, 'loss_3': -16.20013427734375, 'loss_4': 2.875704288482666, 'epoch': 14.26}
{'loss': 0.0366, 'grad_norm': 10.391858100891113, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.027651064097881317, 'loss_2': 0.0089874267578125, 'loss_3': -16.379859924316406, 'loss_4': 3.046262264251709, 'epoch': 14.26}
{'loss': 0.0131, 'grad_norm': 5.155460357666016, 'learning_rate': 1.575e-05, 'loss_1': 0.006444516591727734, 'loss_2': 0.006687164306640625, 'loss_3': -16.411983489990234, 'loss_4': 1.7076797485351562, 'epoch': 14.27}
{'loss': 0.0088, 'grad_norm': 4.824296474456787, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.0051632351242005825, 'loss_2': 0.003620147705078125, 'loss_3': -16.464988708496094, 'loss_4': 2.372647762298584, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 10:24:54,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:54,603 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:44<46:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:01,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009946324862539768, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.004764505662024021, 'eval_loss_2': 0.005181819200515747, 'eval_loss_3': -18.3548583984375, 'eval_loss_4': 1.60112726688385, 'epoch': 14.27}
{'loss': 0.0146, 'grad_norm': 6.7563862800598145, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.011612667702138424, 'loss_2': 0.0029754638671875, 'loss_3': -16.379804611206055, 'loss_4': 2.6217877864837646, 'epoch': 14.28}
{'loss': 0.0097, 'grad_norm': 5.730663299560547, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.008546680212020874, 'loss_2': 0.001132965087890625, 'loss_3': -16.440818786621094, 'loss_4': 1.8805270195007324, 'epoch': 14.28}
{'loss': 0.0258, 'grad_norm': 6.278207302093506, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.015102033503353596, 'loss_2': 0.01067352294921875, 'loss_3': -16.330474853515625, 'loss_4': 2.7031726837158203, 'epoch': 14.29}
{'loss': 0.0231, 'grad_norm': 10.821728706359863, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.02080066315829754, 'loss_2': 0.0022640228271484375, 'loss_3': -16.39553451538086, 'loss_4': 1.784355878829956, 'epoch': 14.3}
{'loss': 0.0063, 'grad_norm': 4.577313423156738, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.004805700853466988, 'loss_2': 0.001468658447265625, 'loss_3': -16.51267433166504, 'loss_4': 1.8891462087631226, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 10:25:01,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:01,950 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:00:51<46:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:09,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009411164559423923, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006439367309212685, 'eval_loss_2': 0.0029717981815338135, 'eval_loss_3': -18.37032127380371, 'eval_loss_4': 1.4304604530334473, 'epoch': 14.3}
{'loss': 0.0179, 'grad_norm': 6.203740119934082, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.013755084946751595, 'loss_2': 0.004184722900390625, 'loss_3': -16.225784301757812, 'loss_4': 1.601590871810913, 'epoch': 14.31}
{'loss': 0.0096, 'grad_norm': 4.836989879608154, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.007525231689214706, 'loss_2': 0.0020904541015625, 'loss_3': -16.632198333740234, 'loss_4': 1.8856866359710693, 'epoch': 14.31}
{'loss': 0.0142, 'grad_norm': 5.338867664337158, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.006804434582591057, 'loss_2': 0.007404327392578125, 'loss_3': -16.287630081176758, 'loss_4': 1.7282922267913818, 'epoch': 14.32}
{'loss': 0.0135, 'grad_norm': 6.326818943023682, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.012205303646624088, 'loss_2': 0.001251220703125, 'loss_3': -16.404375076293945, 'loss_4': 1.92633056640625, 'epoch': 14.33}
{'loss': 0.0562, 'grad_norm': 11.183196067810059, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.043946195393800735, 'loss_2': 0.01224517822265625, 'loss_3': -16.337631225585938, 'loss_4': 1.719949722290039, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 10:25:09,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:09,291 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:00:58<46:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:16,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012238780036568642, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.071, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007727690506726503, 'eval_loss_2': 0.004511088132858276, 'eval_loss_3': -18.358774185180664, 'eval_loss_4': 1.2936214208602905, 'epoch': 14.33}
{'loss': 0.011, 'grad_norm': 4.502769470214844, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.004863835871219635, 'loss_2': 0.0061187744140625, 'loss_3': -16.541019439697266, 'loss_4': 1.779099702835083, 'epoch': 14.34}
{'loss': 0.008, 'grad_norm': 5.141516208648682, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.006758682895451784, 'loss_2': 0.0012054443359375, 'loss_3': -16.39495086669922, 'loss_4': 1.9705708026885986, 'epoch': 14.34}
{'loss': 0.0174, 'grad_norm': 6.232812881469727, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.014853596687316895, 'loss_2': 0.0025806427001953125, 'loss_3': -16.537551879882812, 'loss_4': 1.8835335969924927, 'epoch': 14.35}
{'loss': 0.0083, 'grad_norm': 5.647895812988281, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.0070733423344790936, 'loss_2': 0.001178741455078125, 'loss_3': -16.430644989013672, 'loss_4': 1.657854676246643, 'epoch': 14.35}
{'loss': 0.012, 'grad_norm': 4.960311412811279, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.008315203711390495, 'loss_2': 0.00363922119140625, 'loss_3': -16.407743453979492, 'loss_4': 2.12036395072937, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 10:25:16,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:16,645 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:06<46:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:23,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011052518151700497, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.103, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007162599824368954, 'eval_loss_2': 0.003889918327331543, 'eval_loss_3': -18.368032455444336, 'eval_loss_4': 1.3114244937896729, 'epoch': 14.36}
{'loss': 0.0258, 'grad_norm': 9.390615463256836, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.025070490315556526, 'loss_2': 0.0007352828979492188, 'loss_3': -16.39169692993164, 'loss_4': 1.890101671218872, 'epoch': 14.37}
{'loss': 0.0091, 'grad_norm': 5.025625705718994, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.007892891764640808, 'loss_2': 0.0012426376342773438, 'loss_3': -16.39156723022461, 'loss_4': 1.8465214967727661, 'epoch': 14.37}
{'loss': 0.0143, 'grad_norm': 14.327093124389648, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.014046475291252136, 'loss_2': 0.00029087066650390625, 'loss_3': -16.29313087463379, 'loss_4': 1.53978431224823, 'epoch': 14.38}
{'loss': 0.0076, 'grad_norm': 4.983823776245117, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.005377791356295347, 'loss_2': 0.002208709716796875, 'loss_3': -16.4799747467041, 'loss_4': 2.3783011436462402, 'epoch': 14.38}
{'loss': 0.0124, 'grad_norm': 6.007014751434326, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.012071724981069565, 'loss_2': 0.0003216266632080078, 'loss_3': -16.494857788085938, 'loss_4': 1.3131088018417358, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 10:25:23,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:23,995 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:13<46:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:31,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01027529314160347, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.001, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006986711174249649, 'eval_loss_2': 0.003288581967353821, 'eval_loss_3': -18.36672592163086, 'eval_loss_4': 1.2974326610565186, 'epoch': 14.39}
{'loss': 0.0086, 'grad_norm': 4.662909507751465, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.007775991689413786, 'loss_2': 0.0008649826049804688, 'loss_3': -16.280712127685547, 'loss_4': 1.669980525970459, 'epoch': 14.4}
{'loss': 0.0375, 'grad_norm': 13.125895500183105, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.029551804065704346, 'loss_2': 0.00792694091796875, 'loss_3': -16.183794021606445, 'loss_4': 1.3754961490631104, 'epoch': 14.4}
{'loss': 0.0181, 'grad_norm': 6.569441318511963, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.01367570087313652, 'loss_2': 0.00439453125, 'loss_3': -16.637279510498047, 'loss_4': 1.5041415691375732, 'epoch': 14.41}
{'loss': 0.017, 'grad_norm': 6.075314521789551, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.01221170648932457, 'loss_2': 0.0048065185546875, 'loss_3': -16.323108673095703, 'loss_4': 1.8198504447937012, 'epoch': 14.41}
{'loss': 0.0166, 'grad_norm': 5.785133361816406, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.009359429590404034, 'loss_2': 0.00725555419921875, 'loss_3': -16.20043182373047, 'loss_4': 2.3403751850128174, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 10:25:31,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:31,357 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:20<46:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:38,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010852537117898464, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.578, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005968502722680569, 'eval_loss_2': 0.0048840343952178955, 'eval_loss_3': -18.343931198120117, 'eval_loss_4': 1.284028172492981, 'epoch': 14.42}
{'loss': 0.0398, 'grad_norm': 10.971565246582031, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.02699861489236355, 'loss_2': 0.0128021240234375, 'loss_3': -16.4873046875, 'loss_4': 1.5454177856445312, 'epoch': 14.42}
{'loss': 0.0229, 'grad_norm': 9.821590423583984, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.01737253926694393, 'loss_2': 0.0054931640625, 'loss_3': -16.46345329284668, 'loss_4': 2.4311914443969727, 'epoch': 14.43}
{'loss': 0.0119, 'grad_norm': 6.003472805023193, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.0098398607224226, 'loss_2': 0.00209808349609375, 'loss_3': -16.57267189025879, 'loss_4': 1.4104094505310059, 'epoch': 14.44}
{'loss': 0.0187, 'grad_norm': 6.267998218536377, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.012629378587007523, 'loss_2': 0.00608062744140625, 'loss_3': -16.38265609741211, 'loss_4': 1.854818344116211, 'epoch': 14.44}
{'loss': 0.0115, 'grad_norm': 7.921671390533447, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.011246226727962494, 'loss_2': 0.00024628639221191406, 'loss_3': -16.42766761779785, 'loss_4': 1.7894673347473145, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 10:25:38,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:38,713 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:28<46:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:46,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009398473426699638, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006125221960246563, 'eval_loss_2': 0.00327325239777565, 'eval_loss_3': -18.335193634033203, 'eval_loss_4': 1.3346549272537231, 'epoch': 14.45}
{'loss': 0.0111, 'grad_norm': 5.382057189941406, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.009585941210389137, 'loss_2': 0.0014905929565429688, 'loss_3': -16.470020294189453, 'loss_4': 1.8822137117385864, 'epoch': 14.45}
{'loss': 0.0121, 'grad_norm': 6.133822441101074, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.011466855183243752, 'loss_2': 0.0006394386291503906, 'loss_3': -16.31072235107422, 'loss_4': 2.072056293487549, 'epoch': 14.46}
{'loss': 0.0073, 'grad_norm': 4.578419208526611, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.0043243588879704475, 'loss_2': 0.00301361083984375, 'loss_3': -16.482698440551758, 'loss_4': 1.7979481220245361, 'epoch': 14.47}
{'loss': 0.0075, 'grad_norm': 4.996964931488037, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.005259901750832796, 'loss_2': 0.002216339111328125, 'loss_3': -16.418954849243164, 'loss_4': 1.709017276763916, 'epoch': 14.47}
{'loss': 0.0067, 'grad_norm': 4.823306083679199, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.005876902025192976, 'loss_2': 0.0007915496826171875, 'loss_3': -16.302202224731445, 'loss_4': 1.7956079244613647, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 10:25:46,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:46,069 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:35<46:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:53,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009897302836179733, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.932, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006345342379063368, 'eval_loss_2': 0.003551959991455078, 'eval_loss_3': -18.324495315551758, 'eval_loss_4': 1.320594310760498, 'epoch': 14.48}
{'loss': 0.0114, 'grad_norm': 5.193968772888184, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.007902625016868114, 'loss_2': 0.003543853759765625, 'loss_3': -16.110937118530273, 'loss_4': 1.826872706413269, 'epoch': 14.48}
{'loss': 0.016, 'grad_norm': 5.91085958480835, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.011481279507279396, 'loss_2': 0.00452423095703125, 'loss_3': -16.390872955322266, 'loss_4': 1.8884094953536987, 'epoch': 14.49}
{'loss': 0.0175, 'grad_norm': 5.968560695648193, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.010513347573578358, 'loss_2': 0.006984710693359375, 'loss_3': -16.3941593170166, 'loss_4': 1.6060645580291748, 'epoch': 14.49}
{'loss': 0.0114, 'grad_norm': 5.523849964141846, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.00743383914232254, 'loss_2': 0.0040130615234375, 'loss_3': -16.36838150024414, 'loss_4': 1.5426125526428223, 'epoch': 14.5}
{'loss': 0.015, 'grad_norm': 6.3418378829956055, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.012011014856398106, 'loss_2': 0.00299835205078125, 'loss_3': -16.344749450683594, 'loss_4': 1.6959848403930664, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 10:25:53,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:53,431 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:42<46:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:00,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012016406282782555, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.225, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00786894466727972, 'eval_loss_2': 0.004147462546825409, 'eval_loss_3': -18.30897331237793, 'eval_loss_4': 1.387586236000061, 'epoch': 14.51}
{'loss': 0.0193, 'grad_norm': 6.2544403076171875, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.013281865045428276, 'loss_2': 0.00597381591796875, 'loss_3': -16.474124908447266, 'loss_4': 1.4097797870635986, 'epoch': 14.51}
{'loss': 0.0188, 'grad_norm': 8.300482749938965, 'learning_rate': 1.55e-05, 'loss_1': 0.014829332940280437, 'loss_2': 0.003948211669921875, 'loss_3': -16.43243408203125, 'loss_4': 1.9333627223968506, 'epoch': 14.52}
{'loss': 0.018, 'grad_norm': 7.512638568878174, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.01360570639371872, 'loss_2': 0.00439453125, 'loss_3': -16.18474578857422, 'loss_4': 1.7164992094039917, 'epoch': 14.52}
{'loss': 0.0065, 'grad_norm': 4.799777030944824, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.006031532306224108, 'loss_2': 0.0005183219909667969, 'loss_3': -16.432113647460938, 'loss_4': 1.5159063339233398, 'epoch': 14.53}
{'loss': 0.0041, 'grad_norm': 4.884966850280762, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.002961147343739867, 'loss_2': 0.0011301040649414062, 'loss_3': -16.232481002807617, 'loss_4': 1.7971031665802002, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 10:26:00,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:00,779 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:01:50<45:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:08,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01388494111597538, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.42, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009474672377109528, 'eval_loss_2': 0.004410266876220703, 'eval_loss_3': -18.2972469329834, 'eval_loss_4': 1.490490436553955, 'epoch': 14.53}
{'loss': 0.0062, 'grad_norm': 5.456804275512695, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.004515119828283787, 'loss_2': 0.001659393310546875, 'loss_3': -16.41236114501953, 'loss_4': 1.1184468269348145, 'epoch': 14.54}
{'loss': 0.0188, 'grad_norm': 12.09139347076416, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.017713772132992744, 'loss_2': 0.001064300537109375, 'loss_3': -16.087230682373047, 'loss_4': 1.90802001953125, 'epoch': 14.55}
{'loss': 0.0057, 'grad_norm': 5.557557582855225, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.005113735795021057, 'loss_2': 0.000579833984375, 'loss_3': -16.412811279296875, 'loss_4': 2.4076826572418213, 'epoch': 14.55}
{'loss': 0.0159, 'grad_norm': 5.386020183563232, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.008332778699696064, 'loss_2': 0.00757598876953125, 'loss_3': -16.297733306884766, 'loss_4': 1.9752691984176636, 'epoch': 14.56}
{'loss': 0.0053, 'grad_norm': 4.493780612945557, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.004362378269433975, 'loss_2': 0.000896453857421875, 'loss_3': -16.399982452392578, 'loss_4': 2.4139273166656494, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 10:26:08,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:08,140 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:01:57<45:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:15,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012811875902116299, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008992351591587067, 'eval_loss_2': 0.0038195252418518066, 'eval_loss_3': -18.307865142822266, 'eval_loss_4': 1.618809700012207, 'epoch': 14.56}
{'loss': 0.0235, 'grad_norm': 9.466286659240723, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.02121535874903202, 'loss_2': 0.0023059844970703125, 'loss_3': -16.15440559387207, 'loss_4': 1.938462495803833, 'epoch': 14.57}
{'loss': 0.0103, 'grad_norm': 5.3103251457214355, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.00723975570872426, 'loss_2': 0.00310516357421875, 'loss_3': -16.280681610107422, 'loss_4': 2.227781295776367, 'epoch': 14.58}
{'loss': 0.0213, 'grad_norm': 9.884806632995605, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.01880602166056633, 'loss_2': 0.00252532958984375, 'loss_3': -16.454965591430664, 'loss_4': 1.752007007598877, 'epoch': 14.58}
{'loss': 0.0093, 'grad_norm': 5.280306816101074, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.007845021784305573, 'loss_2': 0.0014801025390625, 'loss_3': -16.185382843017578, 'loss_4': 2.0828423500061035, 'epoch': 14.59}
{'loss': 0.0073, 'grad_norm': 4.208909511566162, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.004566591698676348, 'loss_2': 0.0027484893798828125, 'loss_3': -16.18663787841797, 'loss_4': 1.8419756889343262, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 10:26:15,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:15,493 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:05<45:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:22,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013032338581979275, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.323, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009111306630074978, 'eval_loss_2': 0.003921031951904297, 'eval_loss_3': -18.297990798950195, 'eval_loss_4': 1.5938594341278076, 'epoch': 14.59}
{'loss': 0.0189, 'grad_norm': 8.459602355957031, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.016169670969247818, 'loss_2': 0.002758026123046875, 'loss_3': -16.01726531982422, 'loss_4': 1.985849142074585, 'epoch': 14.6}
{'loss': 0.009, 'grad_norm': 5.460146903991699, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.007497584912925959, 'loss_2': 0.0015163421630859375, 'loss_3': -16.30899429321289, 'loss_4': 1.4906164407730103, 'epoch': 14.6}
{'loss': 0.0236, 'grad_norm': 11.247602462768555, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.02119642123579979, 'loss_2': 0.00238037109375, 'loss_3': -16.27772331237793, 'loss_4': 2.469106435775757, 'epoch': 14.61}
{'loss': 0.0078, 'grad_norm': 4.273410320281982, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.003240272868424654, 'loss_2': 0.004528045654296875, 'loss_3': -16.335647583007812, 'loss_4': 1.5182417631149292, 'epoch': 14.62}
{'loss': 0.0136, 'grad_norm': 5.1276421546936035, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.009258165955543518, 'loss_2': 0.00429534912109375, 'loss_3': -16.170379638671875, 'loss_4': 1.8418917655944824, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 10:26:22,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:22,851 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:12<45:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:30,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013069365173578262, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008394020609557629, 'eval_loss_2': 0.004675343632698059, 'eval_loss_3': -18.313722610473633, 'eval_loss_4': 1.532285451889038, 'epoch': 14.62}
{'loss': 0.0114, 'grad_norm': 4.814021110534668, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.00640510581433773, 'loss_2': 0.00501251220703125, 'loss_3': -16.064756393432617, 'loss_4': 1.6720209121704102, 'epoch': 14.63}
{'loss': 0.0116, 'grad_norm': 4.8735175132751465, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.00888137985020876, 'loss_2': 0.0026874542236328125, 'loss_3': -16.338197708129883, 'loss_4': 1.6412196159362793, 'epoch': 14.63}
{'loss': 0.0084, 'grad_norm': 4.6048383712768555, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.005802098661661148, 'loss_2': 0.0025920867919921875, 'loss_3': -16.471324920654297, 'loss_4': 1.457190752029419, 'epoch': 14.64}
{'loss': 0.0136, 'grad_norm': 5.122157573699951, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.00271627027541399, 'loss_2': 0.01084136962890625, 'loss_3': -16.31833839416504, 'loss_4': 1.9605422019958496, 'epoch': 14.65}
{'loss': 0.0126, 'grad_norm': 5.667749881744385, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.00979510135948658, 'loss_2': 0.002838134765625, 'loss_3': -16.18289566040039, 'loss_4': 1.8138236999511719, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 10:26:30,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:30,199 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:19<45:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:37,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011738135479390621, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.472, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007387353107333183, 'eval_loss_2': 0.004350781440734863, 'eval_loss_3': -18.332124710083008, 'eval_loss_4': 1.4710278511047363, 'epoch': 14.65}
{'loss': 0.0082, 'grad_norm': 4.757884502410889, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.006267729215323925, 'loss_2': 0.00197601318359375, 'loss_3': -16.18451690673828, 'loss_4': 1.7973949909210205, 'epoch': 14.66}
{'loss': 0.0108, 'grad_norm': 4.454095363616943, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.004306718707084656, 'loss_2': 0.00644683837890625, 'loss_3': -16.281822204589844, 'loss_4': 1.771203637123108, 'epoch': 14.66}
{'loss': 0.0061, 'grad_norm': 4.904003620147705, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.0038249515928328037, 'loss_2': 0.00228118896484375, 'loss_3': -16.402019500732422, 'loss_4': 1.747615933418274, 'epoch': 14.67}
{'loss': 0.0086, 'grad_norm': 4.823602676391602, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.006317754741758108, 'loss_2': 0.002269744873046875, 'loss_3': -16.26610565185547, 'loss_4': 2.1413354873657227, 'epoch': 14.67}
{'loss': 0.009, 'grad_norm': 4.6501569747924805, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.003141648368909955, 'loss_2': 0.0058746337890625, 'loss_3': -16.235706329345703, 'loss_4': 1.8737554550170898, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 10:26:37,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:37,548 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:27<45:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:44,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01080321054905653, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.094, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0075834947638213634, 'eval_loss_2': 0.003219716250896454, 'eval_loss_3': -18.34456443786621, 'eval_loss_4': 1.5365809202194214, 'epoch': 14.68}
{'loss': 0.0141, 'grad_norm': 8.122986793518066, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.01253257691860199, 'loss_2': 0.0015459060668945312, 'loss_3': -16.25832176208496, 'loss_4': 2.3859000205993652, 'epoch': 14.69}
{'loss': 0.0076, 'grad_norm': 5.091663360595703, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.006899879779666662, 'loss_2': 0.0007319450378417969, 'loss_3': -16.19092559814453, 'loss_4': 1.2385321855545044, 'epoch': 14.69}
{'loss': 0.0099, 'grad_norm': 6.424065589904785, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.008822898380458355, 'loss_2': 0.0011053085327148438, 'loss_3': -16.252521514892578, 'loss_4': 2.2565951347351074, 'epoch': 14.7}
{'loss': 0.0147, 'grad_norm': 7.523776531219482, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.013435501605272293, 'loss_2': 0.0012598037719726562, 'loss_3': -16.326343536376953, 'loss_4': 2.340524196624756, 'epoch': 14.7}
{'loss': 0.0151, 'grad_norm': 8.399928092956543, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.013948861509561539, 'loss_2': 0.00116729736328125, 'loss_3': -16.325599670410156, 'loss_4': 1.777759313583374, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 10:26:44,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:44,905 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:34<45:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:52,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010979948565363884, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.426, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007642028387635946, 'eval_loss_2': 0.0033379197120666504, 'eval_loss_3': -18.362567901611328, 'eval_loss_4': 1.4393136501312256, 'epoch': 14.71}
{'loss': 0.0098, 'grad_norm': 8.238128662109375, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.009637081995606422, 'loss_2': 0.00013589859008789062, 'loss_3': -16.19741439819336, 'loss_4': 2.553388833999634, 'epoch': 14.72}
{'loss': 0.0152, 'grad_norm': 6.408388614654541, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.010469515807926655, 'loss_2': 0.00475311279296875, 'loss_3': -16.180477142333984, 'loss_4': 2.0462732315063477, 'epoch': 14.72}
{'loss': 0.0128, 'grad_norm': 5.762163162231445, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.009122141636908054, 'loss_2': 0.0037078857421875, 'loss_3': -16.152956008911133, 'loss_4': 1.4540002346038818, 'epoch': 14.73}
{'loss': 0.0111, 'grad_norm': 5.922948360443115, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.009099883027374744, 'loss_2': 0.00203704833984375, 'loss_3': -16.572612762451172, 'loss_4': 1.8237004280090332, 'epoch': 14.73}
{'loss': 0.0136, 'grad_norm': 5.775304317474365, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.00871224794536829, 'loss_2': 0.004917144775390625, 'loss_3': -16.256118774414062, 'loss_4': 2.629511833190918, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 10:26:52,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:52,261 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:41<45:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:59,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01068284921348095, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.499, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007076307199895382, 'eval_loss_2': 0.003606542944908142, 'eval_loss_3': -18.366512298583984, 'eval_loss_4': 1.2554523944854736, 'epoch': 14.74}
{'loss': 0.0466, 'grad_norm': 19.459190368652344, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.044867414981126785, 'loss_2': 0.0017757415771484375, 'loss_3': -16.025829315185547, 'loss_4': 0.9467886686325073, 'epoch': 14.74}
{'loss': 0.0296, 'grad_norm': 13.727400779724121, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.028931474313139915, 'loss_2': 0.000621795654296875, 'loss_3': -16.221580505371094, 'loss_4': 1.5411943197250366, 'epoch': 14.75}
{'loss': 0.0077, 'grad_norm': 4.73215913772583, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.002482237294316292, 'loss_2': 0.0051727294921875, 'loss_3': -16.191640853881836, 'loss_4': 2.31007719039917, 'epoch': 14.76}
{'loss': 0.0137, 'grad_norm': 6.084578990936279, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.006407789885997772, 'loss_2': 0.007274627685546875, 'loss_3': -16.315336227416992, 'loss_4': 2.3585686683654785, 'epoch': 14.76}
{'loss': 0.0123, 'grad_norm': 5.270058631896973, 'learning_rate': 1.525e-05, 'loss_1': 0.008429617621004581, 'loss_2': 0.003875732421875, 'loss_3': -16.30994987487793, 'loss_4': 1.3520276546478271, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 10:26:59,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:59,606 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:02:49<45:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:06,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011133969761431217, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.368, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005853116977959871, 'eval_loss_2': 0.005280852317810059, 'eval_loss_3': -18.346935272216797, 'eval_loss_4': 1.2346408367156982, 'epoch': 14.77}
{'loss': 0.0247, 'grad_norm': 13.795486450195312, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.024006437510252, 'loss_2': 0.0006799697875976562, 'loss_3': -16.24773597717285, 'loss_4': 2.7635746002197266, 'epoch': 14.77}
{'loss': 0.0131, 'grad_norm': 6.733871936798096, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.010655495338141918, 'loss_2': 0.002414703369140625, 'loss_3': -16.176219940185547, 'loss_4': 1.469576358795166, 'epoch': 14.78}
{'loss': 0.0301, 'grad_norm': 11.2227783203125, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.016602031886577606, 'loss_2': 0.013519287109375, 'loss_3': -16.02450942993164, 'loss_4': 1.623703956604004, 'epoch': 14.78}
{'loss': 0.0116, 'grad_norm': 5.775625228881836, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.009898717515170574, 'loss_2': 0.001728057861328125, 'loss_3': -16.097423553466797, 'loss_4': 1.1876599788665771, 'epoch': 14.79}
{'loss': 0.0082, 'grad_norm': 5.10895299911499, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.007072945591062307, 'loss_2': 0.0011272430419921875, 'loss_3': -16.268768310546875, 'loss_4': 1.3393882513046265, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 10:27:06,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:06,954 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:02:56<45:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:14,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010678490623831749, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006753615103662014, 'eval_loss_2': 0.00392487645149231, 'eval_loss_3': -18.329954147338867, 'eval_loss_4': 1.1161390542984009, 'epoch': 14.8}
{'loss': 0.0062, 'grad_norm': 4.724152088165283, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.00600824411958456, 'loss_2': 0.0001430511474609375, 'loss_3': -16.034687042236328, 'loss_4': 1.1764243841171265, 'epoch': 14.8}
{'loss': 0.0053, 'grad_norm': 4.451022148132324, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.004713816102594137, 'loss_2': 0.0005397796630859375, 'loss_3': -16.345664978027344, 'loss_4': 1.8550957441329956, 'epoch': 14.81}
{'loss': 0.0071, 'grad_norm': 4.614675045013428, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.006406489294022322, 'loss_2': 0.0006699562072753906, 'loss_3': -16.289127349853516, 'loss_4': 1.3371741771697998, 'epoch': 14.81}
{'loss': 0.0134, 'grad_norm': 5.274171829223633, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.008036205545067787, 'loss_2': 0.0053863525390625, 'loss_3': -16.33530044555664, 'loss_4': 1.4166710376739502, 'epoch': 14.82}
{'loss': 0.0113, 'grad_norm': 8.029718399047852, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.010259255766868591, 'loss_2': 0.0010023117065429688, 'loss_3': -16.27460479736328, 'loss_4': 1.6040247678756714, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 10:27:14,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:14,309 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:03<45:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:21,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011504098773002625, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.803, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007314071524888277, 'eval_loss_2': 0.004190027713775635, 'eval_loss_3': -18.325002670288086, 'eval_loss_4': 0.8726573586463928, 'epoch': 14.83}
{'loss': 0.0108, 'grad_norm': 5.189631938934326, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.010785343125462532, 'loss_2': 5.245208740234375e-05, 'loss_3': -16.35791015625, 'loss_4': 1.4249835014343262, 'epoch': 14.83}
{'loss': 0.0201, 'grad_norm': 7.383389949798584, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.0149787412956357, 'loss_2': 0.00511932373046875, 'loss_3': -16.32189178466797, 'loss_4': 1.5257208347320557, 'epoch': 14.84}
{'loss': 0.0161, 'grad_norm': 9.238481521606445, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.011260062456130981, 'loss_2': 0.004791259765625, 'loss_3': -16.3206844329834, 'loss_4': 1.1727837324142456, 'epoch': 14.84}
{'loss': 0.0128, 'grad_norm': 6.6100568771362305, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.01174682192504406, 'loss_2': 0.001049041748046875, 'loss_3': -16.214229583740234, 'loss_4': 0.9812970757484436, 'epoch': 14.85}
{'loss': 0.0101, 'grad_norm': 5.316294193267822, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.009584272280335426, 'loss_2': 0.0005564689636230469, 'loss_3': -16.274520874023438, 'loss_4': 1.0436575412750244, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 10:27:21,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:21,667 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:11<44:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:29,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011316323652863503, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.827, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007381538860499859, 'eval_loss_2': 0.003934785723686218, 'eval_loss_3': -18.323755264282227, 'eval_loss_4': 0.8718005418777466, 'epoch': 14.85}
{'loss': 0.0087, 'grad_norm': 5.771244525909424, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.007259845733642578, 'loss_2': 0.0014162063598632812, 'loss_3': -16.34134292602539, 'loss_4': 1.247014045715332, 'epoch': 14.86}
{'loss': 0.0191, 'grad_norm': 12.746661186218262, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.016124220564961433, 'loss_2': 0.0029354095458984375, 'loss_3': -16.24489402770996, 'loss_4': 1.0902668237686157, 'epoch': 14.87}
{'loss': 0.017, 'grad_norm': 7.4910407066345215, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.011781999841332436, 'loss_2': 0.0052490234375, 'loss_3': -16.390079498291016, 'loss_4': 0.7526819705963135, 'epoch': 14.87}
{'loss': 0.011, 'grad_norm': 5.4600138664245605, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.008511655032634735, 'loss_2': 0.002452850341796875, 'loss_3': -16.294292449951172, 'loss_4': 1.3124163150787354, 'epoch': 14.88}
{'loss': 0.0103, 'grad_norm': 4.621456146240234, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.004467555787414312, 'loss_2': 0.00583648681640625, 'loss_3': -16.34648323059082, 'loss_4': 0.9182192087173462, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 10:27:29,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:29,019 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:18<44:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:36,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01182203833013773, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.615, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008693225681781769, 'eval_loss_2': 0.0031288117170333862, 'eval_loss_3': -18.28190040588379, 'eval_loss_4': 0.8481112718582153, 'epoch': 14.88}
{'loss': 0.0097, 'grad_norm': 5.5261712074279785, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.008300499990582466, 'loss_2': 0.0014362335205078125, 'loss_3': -16.382999420166016, 'loss_4': 1.2965843677520752, 'epoch': 14.89}
{'loss': 0.0071, 'grad_norm': 5.176101207733154, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.0060474141500890255, 'loss_2': 0.0010118484497070312, 'loss_3': -16.35844612121582, 'loss_4': 1.1971477270126343, 'epoch': 14.9}
{'loss': 0.0087, 'grad_norm': 4.614415168762207, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.006972712464630604, 'loss_2': 0.0016794204711914062, 'loss_3': -16.374757766723633, 'loss_4': 1.5941356420516968, 'epoch': 14.9}
{'loss': 0.0119, 'grad_norm': 6.119424343109131, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.007354226429015398, 'loss_2': 0.00450897216796875, 'loss_3': -16.292835235595703, 'loss_4': 1.4812668561935425, 'epoch': 14.91}
{'loss': 0.0139, 'grad_norm': 5.656224727630615, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.009410642087459564, 'loss_2': 0.004467010498046875, 'loss_3': -16.233905792236328, 'loss_4': 1.1705942153930664, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 10:27:36,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:36,378 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:25<44:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:43,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011905429884791374, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.738, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007343424949795008, 'eval_loss_2': 0.004562005400657654, 'eval_loss_3': -18.27521514892578, 'eval_loss_4': 0.9463724493980408, 'epoch': 14.91}
{'loss': 0.0175, 'grad_norm': 6.430912494659424, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.010494804009795189, 'loss_2': 0.007022857666015625, 'loss_3': -16.287113189697266, 'loss_4': 1.4346380233764648, 'epoch': 14.92}
{'loss': 0.0066, 'grad_norm': 4.6621832847595215, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.006578418891876936, 'loss_2': 3.6776065826416016e-05, 'loss_3': -16.39208984375, 'loss_4': 1.6110371351242065, 'epoch': 14.92}
{'loss': 0.0268, 'grad_norm': 19.15785026550293, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.02281421609222889, 'loss_2': 0.003963470458984375, 'loss_3': -16.20708465576172, 'loss_4': 1.3634299039840698, 'epoch': 14.93}
{'loss': 0.0247, 'grad_norm': 6.901198863983154, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.015038330107927322, 'loss_2': 0.00970458984375, 'loss_3': -16.28919219970703, 'loss_4': 1.1954225301742554, 'epoch': 14.94}
{'loss': 0.0152, 'grad_norm': 5.6823248863220215, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.00859005469828844, 'loss_2': 0.00659942626953125, 'loss_3': -16.465747833251953, 'loss_4': 1.630875825881958, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 10:27:43,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:43,730 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:33<44:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:51,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010545728728175163, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006972250994294882, 'eval_loss_2': 0.003573477268218994, 'eval_loss_3': -18.283933639526367, 'eval_loss_4': 0.9560254812240601, 'epoch': 14.94}
{'loss': 0.0193, 'grad_norm': 12.691826820373535, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.01680430769920349, 'loss_2': 0.002475738525390625, 'loss_3': -16.28418731689453, 'loss_4': 1.9276752471923828, 'epoch': 14.95}
{'loss': 0.0175, 'grad_norm': 6.376659393310547, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.008216563612222672, 'loss_2': 0.00930023193359375, 'loss_3': -16.108612060546875, 'loss_4': 1.288311243057251, 'epoch': 14.95}
{'loss': 0.0256, 'grad_norm': 7.125061988830566, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.01612318493425846, 'loss_2': 0.0094757080078125, 'loss_3': -16.15184211730957, 'loss_4': 2.5524752140045166, 'epoch': 14.96}
{'loss': 0.0072, 'grad_norm': 4.8006744384765625, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.005751855671405792, 'loss_2': 0.0014972686767578125, 'loss_3': -16.388805389404297, 'loss_4': 1.5026962757110596, 'epoch': 14.97}
{'loss': 0.0087, 'grad_norm': 5.00197696685791, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.00837597157806158, 'loss_2': 0.00037288665771484375, 'loss_3': -16.435518264770508, 'loss_4': 1.1948468685150146, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 10:27:51,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:51,078 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:40<40:09,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:27:58,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007486754097044468, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0053010368719697, 'eval_loss_2': 0.002185717225074768, 'eval_loss_3': -18.328632354736328, 'eval_loss_4': 0.8066258430480957, 'epoch': 14.97}
{'loss': 0.0142, 'grad_norm': 6.683135032653809, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.0123740928247571, 'loss_2': 0.001842498779296875, 'loss_3': -16.28482437133789, 'loss_4': 1.5479490756988525, 'epoch': 14.98}
{'loss': 0.0421, 'grad_norm': 23.203258514404297, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.03919433057308197, 'loss_2': 0.0029125213623046875, 'loss_3': -16.281103134155273, 'loss_4': 0.8498985767364502, 'epoch': 14.98}
{'loss': 0.0107, 'grad_norm': 7.358123779296875, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.010051785968244076, 'loss_2': 0.0006837844848632812, 'loss_3': -16.21303939819336, 'loss_4': 0.6902298927307129, 'epoch': 14.99}
{'loss': 0.0114, 'grad_norm': 5.246967792510986, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.007572156377136707, 'loss_2': 0.00380706787109375, 'loss_3': -16.153234481811523, 'loss_4': 1.1863579750061035, 'epoch': 14.99}
{'loss': 0.0025, 'grad_norm': 6.362338066101074, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.0017013971228152514, 'loss_2': 0.0007977485656738281, 'loss_3': -16.162944793701172, 'loss_4': 1.9992218017578125, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 10:27:58,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:58,078 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:03:47<43:58,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:28:05,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00966094620525837, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.752, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006086217705160379, 'eval_loss_2': 0.0035747289657592773, 'eval_loss_3': -18.31816291809082, 'eval_loss_4': 0.810379147529602, 'epoch': 15.0}
{'loss': 0.0163, 'grad_norm': 7.901969909667969, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.015584990382194519, 'loss_2': 0.0006694793701171875, 'loss_3': -16.359479904174805, 'loss_4': 1.5294872522354126, 'epoch': 15.01}
{'loss': 0.0104, 'grad_norm': 4.774701118469238, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.0053292070515453815, 'loss_2': 0.0050811767578125, 'loss_3': -16.32854461669922, 'loss_4': 1.1370923519134521, 'epoch': 15.01}
{'loss': 0.009, 'grad_norm': 4.399806499481201, 'learning_rate': 1.5e-05, 'loss_1': 0.004789239726960659, 'loss_2': 0.00423431396484375, 'loss_3': -16.32777976989746, 'loss_4': 0.6828073263168335, 'epoch': 15.02}
{'loss': 0.0137, 'grad_norm': 6.822668552398682, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.010810621082782745, 'loss_2': 0.0029296875, 'loss_3': -16.12799835205078, 'loss_4': 1.5541911125183105, 'epoch': 15.02}
{'loss': 0.0115, 'grad_norm': 4.756105422973633, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.00963736791163683, 'loss_2': 0.0018358230590820312, 'loss_3': -16.434463500976562, 'loss_4': 1.5125718116760254, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 10:28:05,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:05,478 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:03:54<44:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:12,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010659970343112946, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006357825826853514, 'eval_loss_2': 0.0043021440505981445, 'eval_loss_3': -18.28513526916504, 'eval_loss_4': 0.7286185026168823, 'epoch': 15.03}
{'loss': 0.008, 'grad_norm': 4.493223190307617, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.00519369263201952, 'loss_2': 0.002796173095703125, 'loss_3': -16.441699981689453, 'loss_4': 1.3671832084655762, 'epoch': 15.03}
{'loss': 0.0173, 'grad_norm': 5.055279731750488, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.005644277203828096, 'loss_2': 0.0116729736328125, 'loss_3': -16.33661460876465, 'loss_4': 1.3365561962127686, 'epoch': 15.04}
{'loss': 0.0135, 'grad_norm': 5.777731895446777, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.012329548597335815, 'loss_2': 0.0011816024780273438, 'loss_3': -16.347431182861328, 'loss_4': 0.9161544442176819, 'epoch': 15.05}
{'loss': 0.0139, 'grad_norm': 5.568959712982178, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.008514927700161934, 'loss_2': 0.00542449951171875, 'loss_3': -16.415571212768555, 'loss_4': 1.2759864330291748, 'epoch': 15.05}
{'loss': 0.0233, 'grad_norm': 7.976076126098633, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.016183706000447273, 'loss_2': 0.00708770751953125, 'loss_3': -16.353742599487305, 'loss_4': 0.9988398551940918, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 10:28:12,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:12,831 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:02<44:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:20,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00933837704360485, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0065530226565897465, 'eval_loss_2': 0.0027853548526763916, 'eval_loss_3': -18.249330520629883, 'eval_loss_4': 0.653580904006958, 'epoch': 15.06}
{'loss': 0.0081, 'grad_norm': 5.196188449859619, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.0064856200478971004, 'loss_2': 0.001644134521484375, 'loss_3': -16.29428482055664, 'loss_4': 1.2217113971710205, 'epoch': 15.06}
{'loss': 0.0077, 'grad_norm': 4.467509746551514, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.007185555528849363, 'loss_2': 0.0005617141723632812, 'loss_3': -16.14058494567871, 'loss_4': 1.21903657913208, 'epoch': 15.07}
{'loss': 0.0188, 'grad_norm': 7.7914557456970215, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.015014651231467724, 'loss_2': 0.0037860870361328125, 'loss_3': -16.350173950195312, 'loss_4': 1.3054910898208618, 'epoch': 15.08}
{'loss': 0.0092, 'grad_norm': 5.802608966827393, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.007948786951601505, 'loss_2': 0.0012111663818359375, 'loss_3': -16.452484130859375, 'loss_4': 0.7325441241264343, 'epoch': 15.08}
{'loss': 0.0071, 'grad_norm': 5.633467197418213, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.005241990089416504, 'loss_2': 0.0018749237060546875, 'loss_3': -16.5322265625, 'loss_4': 0.9389389157295227, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 10:28:20,187 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:20,187 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:09<44:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:27,543 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009823503904044628, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.936, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007331314496695995, 'eval_loss_2': 0.002492189407348633, 'eval_loss_3': -18.182836532592773, 'eval_loss_4': 0.7799466848373413, 'epoch': 15.09}
{'loss': 0.0253, 'grad_norm': 11.599234580993652, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.023226886987686157, 'loss_2': 0.002040863037109375, 'loss_3': -16.473472595214844, 'loss_4': 1.3383243083953857, 'epoch': 15.09}
{'loss': 0.0211, 'grad_norm': 5.147705554962158, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.006274924613535404, 'loss_2': 0.0148468017578125, 'loss_3': -16.202430725097656, 'loss_4': 1.4349987506866455, 'epoch': 15.1}
{'loss': 0.0134, 'grad_norm': 7.0833845138549805, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.011670314706861973, 'loss_2': 0.0016994476318359375, 'loss_3': -16.40705108642578, 'loss_4': 1.251821756362915, 'epoch': 15.1}
{'loss': 0.0235, 'grad_norm': 11.613373756408691, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.017551667988300323, 'loss_2': 0.0059814453125, 'loss_3': -16.2520751953125, 'loss_4': 0.8944240212440491, 'epoch': 15.11}
{'loss': 0.0146, 'grad_norm': 6.691873550415039, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.010827518999576569, 'loss_2': 0.00373077392578125, 'loss_3': -16.408432006835938, 'loss_4': 1.8489102125167847, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 10:28:27,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:27,543 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:17<44:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:34,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011584091000258923, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007907675579190254, 'eval_loss_2': 0.0036764144897460938, 'eval_loss_3': -18.150609970092773, 'eval_loss_4': 0.9807406663894653, 'epoch': 15.12}
{'loss': 0.0092, 'grad_norm': 4.923861026763916, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.009167669340968132, 'loss_2': 6.473064422607422e-05, 'loss_3': -16.370718002319336, 'loss_4': 1.161684274673462, 'epoch': 15.12}
{'loss': 0.01, 'grad_norm': 5.165348529815674, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.006142905913293362, 'loss_2': 0.003875732421875, 'loss_3': -16.196813583374023, 'loss_4': 1.255021572113037, 'epoch': 15.13}
{'loss': 0.0119, 'grad_norm': 5.874214172363281, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.009919675998389721, 'loss_2': 0.001972198486328125, 'loss_3': -16.317264556884766, 'loss_4': 1.275192379951477, 'epoch': 15.13}
{'loss': 0.0155, 'grad_norm': 5.675931930541992, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.01247443538159132, 'loss_2': 0.0030078887939453125, 'loss_3': -16.14181900024414, 'loss_4': 1.150654673576355, 'epoch': 15.14}
{'loss': 0.0114, 'grad_norm': 15.90373706817627, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.011158778332173824, 'loss_2': 0.000244140625, 'loss_3': -16.11220932006836, 'loss_4': 1.1861733198165894, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 10:28:34,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:34,893 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:24<44:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:42,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009970953688025475, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.104, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0078070880845189095, 'eval_loss_2': 0.0021638646721839905, 'eval_loss_3': -18.16390609741211, 'eval_loss_4': 0.8813928365707397, 'epoch': 15.15}
{'loss': 0.0083, 'grad_norm': 5.0941996574401855, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.006599740125238895, 'loss_2': 0.0016584396362304688, 'loss_3': -16.267471313476562, 'loss_4': 1.2971196174621582, 'epoch': 15.15}
{'loss': 0.0132, 'grad_norm': 4.859918594360352, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.00873562227934599, 'loss_2': 0.00443267822265625, 'loss_3': -16.423664093017578, 'loss_4': 1.4688758850097656, 'epoch': 15.16}
{'loss': 0.0153, 'grad_norm': 5.426100254058838, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.011306535452604294, 'loss_2': 0.003978729248046875, 'loss_3': -16.313213348388672, 'loss_4': 1.0208321809768677, 'epoch': 15.16}
{'loss': 0.0283, 'grad_norm': 12.620797157287598, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.024198060855269432, 'loss_2': 0.00414276123046875, 'loss_3': -16.371448516845703, 'loss_4': 1.3770346641540527, 'epoch': 15.17}
{'loss': 0.0132, 'grad_norm': 5.638801574707031, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.012483238242566586, 'loss_2': 0.0007104873657226562, 'loss_3': -16.470577239990234, 'loss_4': 1.0928020477294922, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 10:28:42,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:42,245 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:31<44:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:49,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0117923179641366, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.866, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007954039610922337, 'eval_loss_2': 0.003838278353214264, 'eval_loss_3': -18.15039825439453, 'eval_loss_4': 0.82999187707901, 'epoch': 15.17}
{'loss': 0.0191, 'grad_norm': 5.937676429748535, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.008648892864584923, 'loss_2': 0.01047515869140625, 'loss_3': -16.307218551635742, 'loss_4': 1.054746150970459, 'epoch': 15.18}
{'loss': 0.023, 'grad_norm': 13.581844329833984, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.022510332986712456, 'loss_2': 0.00045490264892578125, 'loss_3': -16.3594913482666, 'loss_4': 1.208967685699463, 'epoch': 15.19}
{'loss': 0.0157, 'grad_norm': 8.322887420654297, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.012023531831800938, 'loss_2': 0.003688812255859375, 'loss_3': -16.270845413208008, 'loss_4': 1.4343341588974, 'epoch': 15.19}
{'loss': 0.0159, 'grad_norm': 4.765579700469971, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.006757484283298254, 'loss_2': 0.00909423828125, 'loss_3': -16.39802360534668, 'loss_4': 1.077312707901001, 'epoch': 15.2}
{'loss': 0.0191, 'grad_norm': 7.927213668823242, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.016611510887742043, 'loss_2': 0.002521514892578125, 'loss_3': -16.390405654907227, 'loss_4': 1.3390930891036987, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 10:28:49,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:49,606 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:39<44:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:56,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01138958428055048, 'eval_runtime': 3.8167, 'eval_samples_per_second': 268.298, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008157270029187202, 'eval_loss_2': 0.003232315182685852, 'eval_loss_3': -18.170642852783203, 'eval_loss_4': 0.7543513774871826, 'epoch': 15.2}
{'loss': 0.0099, 'grad_norm': 5.213287353515625, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.009709808975458145, 'loss_2': 0.00019860267639160156, 'loss_3': -16.255695343017578, 'loss_4': 0.9349066615104675, 'epoch': 15.21}
{'loss': 0.0057, 'grad_norm': 4.622476577758789, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.0049872319214046, 'loss_2': 0.000682830810546875, 'loss_3': -16.130615234375, 'loss_4': 1.157202959060669, 'epoch': 15.22}
{'loss': 0.0247, 'grad_norm': 10.07950496673584, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.01887691393494606, 'loss_2': 0.005832672119140625, 'loss_3': -16.309463500976562, 'loss_4': 0.9311832785606384, 'epoch': 15.22}
{'loss': 0.0135, 'grad_norm': 6.077445983886719, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.009556683711707592, 'loss_2': 0.0039043426513671875, 'loss_3': -16.214689254760742, 'loss_4': 0.9681239128112793, 'epoch': 15.23}
{'loss': 0.0072, 'grad_norm': 5.268599987030029, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.005828430410474539, 'loss_2': 0.001338958740234375, 'loss_3': -16.163108825683594, 'loss_4': 1.5227328538894653, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 10:28:56,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:56,972 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:04:46<43:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:04,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012208862230181694, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.611, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007261840160936117, 'eval_loss_2': 0.0049470216035842896, 'eval_loss_3': -18.17947769165039, 'eval_loss_4': 0.7397085428237915, 'epoch': 15.23}
{'loss': 0.0153, 'grad_norm': 8.14393424987793, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.010935609228909016, 'loss_2': 0.00439453125, 'loss_3': -16.180686950683594, 'loss_4': 1.7271969318389893, 'epoch': 15.24}
{'loss': 0.0144, 'grad_norm': 6.816531658172607, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.013727874495089054, 'loss_2': 0.000675201416015625, 'loss_3': -16.318099975585938, 'loss_4': 1.6744368076324463, 'epoch': 15.24}
{'loss': 0.0071, 'grad_norm': 5.094769477844238, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.005876519717276096, 'loss_2': 0.0011882781982421875, 'loss_3': -16.411834716796875, 'loss_4': 0.8988885879516602, 'epoch': 15.25}
{'loss': 0.0187, 'grad_norm': 4.651124000549316, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.0039733401499688625, 'loss_2': 0.0147552490234375, 'loss_3': -16.275272369384766, 'loss_4': 0.945972204208374, 'epoch': 15.26}
{'loss': 0.0199, 'grad_norm': 10.194416046142578, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.011116525158286095, 'loss_2': 0.008819580078125, 'loss_3': -16.25286865234375, 'loss_4': 1.0274734497070312, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 10:29:04,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:04,337 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:04:53<43:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:11,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012734662741422653, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007429276593029499, 'eval_loss_2': 0.005305387079715729, 'eval_loss_3': -18.183385848999023, 'eval_loss_4': 0.7595354318618774, 'epoch': 15.26}
{'loss': 0.0055, 'grad_norm': 5.189844131469727, 'learning_rate': 1.475e-05, 'loss_1': 0.00527082197368145, 'loss_2': 0.0002498626708984375, 'loss_3': -16.333984375, 'loss_4': 0.8660410642623901, 'epoch': 15.27}
{'loss': 0.0073, 'grad_norm': 4.432549953460693, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.003234338713809848, 'loss_2': 0.004070281982421875, 'loss_3': -16.212238311767578, 'loss_4': 0.9928594827651978, 'epoch': 15.27}
{'loss': 0.0081, 'grad_norm': 4.710015773773193, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.0063792383298277855, 'loss_2': 0.0016956329345703125, 'loss_3': -16.497661590576172, 'loss_4': 0.7452110052108765, 'epoch': 15.28}
{'loss': 0.007, 'grad_norm': 4.613444805145264, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.003405932569876313, 'loss_2': 0.00360870361328125, 'loss_3': -16.454442977905273, 'loss_4': 0.9557914137840271, 'epoch': 15.28}
{'loss': 0.0165, 'grad_norm': 4.916084289550781, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.008661198429763317, 'loss_2': 0.00785064697265625, 'loss_3': -16.325302124023438, 'loss_4': 0.5463525056838989, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 10:29:11,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:11,687 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:01<43:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:19,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011681923642754555, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006468184757977724, 'eval_loss_2': 0.005213737487792969, 'eval_loss_3': -18.211000442504883, 'eval_loss_4': 0.7128990292549133, 'epoch': 15.29}
{'loss': 0.0084, 'grad_norm': 4.962427139282227, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.0071609606966376305, 'loss_2': 0.001255035400390625, 'loss_3': -16.34308624267578, 'loss_4': 1.0710831880569458, 'epoch': 15.3}
{'loss': 0.0092, 'grad_norm': 5.474061012268066, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.00906634796410799, 'loss_2': 0.0001125335693359375, 'loss_3': -16.264442443847656, 'loss_4': 1.102726697921753, 'epoch': 15.3}
{'loss': 0.0115, 'grad_norm': 6.199896335601807, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.008522970601916313, 'loss_2': 0.003009796142578125, 'loss_3': -16.26215362548828, 'loss_4': 1.392091155052185, 'epoch': 15.31}
{'loss': 0.0156, 'grad_norm': 6.572023868560791, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.014465834014117718, 'loss_2': 0.0011444091796875, 'loss_3': -16.09958267211914, 'loss_4': 1.3454389572143555, 'epoch': 15.31}
{'loss': 0.0126, 'grad_norm': 4.339684963226318, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.005044562742114067, 'loss_2': 0.00751495361328125, 'loss_3': -16.299713134765625, 'loss_4': 1.637336254119873, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 10:29:19,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:19,033 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:08<43:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:26,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010850667022168636, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.137, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006668324116617441, 'eval_loss_2': 0.004182342439889908, 'eval_loss_3': -18.22163200378418, 'eval_loss_4': 0.7098217606544495, 'epoch': 15.32}
{'loss': 0.0096, 'grad_norm': 4.761572360992432, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.00952158309519291, 'loss_2': 0.00011456012725830078, 'loss_3': -16.263824462890625, 'loss_4': 1.2874115705490112, 'epoch': 15.33}
{'loss': 0.0151, 'grad_norm': 5.751004219055176, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.012230519205331802, 'loss_2': 0.0028324127197265625, 'loss_3': -16.462196350097656, 'loss_4': 0.8564749956130981, 'epoch': 15.33}
{'loss': 0.0117, 'grad_norm': 4.595266819000244, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.00577002577483654, 'loss_2': 0.005916595458984375, 'loss_3': -16.44073486328125, 'loss_4': 1.0013823509216309, 'epoch': 15.34}
{'loss': 0.0133, 'grad_norm': 4.41098165512085, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.003926787059754133, 'loss_2': 0.0093994140625, 'loss_3': -16.448444366455078, 'loss_4': 1.24562668800354, 'epoch': 15.34}
{'loss': 0.0162, 'grad_norm': 7.50415563583374, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.01539898943156004, 'loss_2': 0.0007834434509277344, 'loss_3': -16.066001892089844, 'loss_4': 1.150717854499817, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 10:29:26,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:26,382 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:15<43:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:33,740 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011206007562577724, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.566, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006704307626932859, 'eval_loss_2': 0.004501700401306152, 'eval_loss_3': -18.2301025390625, 'eval_loss_4': 0.8254073858261108, 'epoch': 15.35}
{'loss': 0.0192, 'grad_norm': 14.18065071105957, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.018221160396933556, 'loss_2': 0.0009717941284179688, 'loss_3': -16.36610984802246, 'loss_4': 1.235321283340454, 'epoch': 15.35}
{'loss': 0.0168, 'grad_norm': 5.597777843475342, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.010868548415601254, 'loss_2': 0.0059814453125, 'loss_3': -16.16272735595703, 'loss_4': 1.0152287483215332, 'epoch': 15.36}
{'loss': 0.0092, 'grad_norm': 5.286305904388428, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.007834594696760178, 'loss_2': 0.001384735107421875, 'loss_3': -16.04119110107422, 'loss_4': 1.2496098279953003, 'epoch': 15.37}
{'loss': 0.0196, 'grad_norm': 7.739022254943848, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.015672435984015465, 'loss_2': 0.00394439697265625, 'loss_3': -16.174739837646484, 'loss_4': 1.7827340364456177, 'epoch': 15.37}
{'loss': 0.0078, 'grad_norm': 4.499504566192627, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.002834462095052004, 'loss_2': 0.00496673583984375, 'loss_3': -16.35182762145996, 'loss_4': 1.3846508264541626, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 10:29:33,740 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:33,740 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:23<43:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:41,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010744541883468628, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.234, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0061156670562922955, 'eval_loss_2': 0.004628874361515045, 'eval_loss_3': -18.24277114868164, 'eval_loss_4': 1.0092030763626099, 'epoch': 15.38}
{'loss': 0.0213, 'grad_norm': 9.047743797302246, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.019430693238973618, 'loss_2': 0.0018444061279296875, 'loss_3': -16.362308502197266, 'loss_4': 1.0845789909362793, 'epoch': 15.38}
{'loss': 0.0218, 'grad_norm': 14.443711280822754, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.020502688363194466, 'loss_2': 0.0013217926025390625, 'loss_3': -16.431488037109375, 'loss_4': 1.8402436971664429, 'epoch': 15.39}
{'loss': 0.0217, 'grad_norm': 10.345687866210938, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.01916559971868992, 'loss_2': 0.002532958984375, 'loss_3': -16.247074127197266, 'loss_4': 1.576520562171936, 'epoch': 15.4}
{'loss': 0.0112, 'grad_norm': 6.015819072723389, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.010311090387403965, 'loss_2': 0.0008563995361328125, 'loss_3': -16.14788055419922, 'loss_4': 2.0095226764678955, 'epoch': 15.4}
{'loss': 0.011, 'grad_norm': 5.1052680015563965, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.006935582961887121, 'loss_2': 0.0041046142578125, 'loss_3': -16.302154541015625, 'loss_4': 2.013021945953369, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 10:29:41,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:41,093 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:30<43:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:48,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010168829932808876, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.164, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006086597219109535, 'eval_loss_2': 0.004082232713699341, 'eval_loss_3': -18.243505477905273, 'eval_loss_4': 1.1407283544540405, 'epoch': 15.41}
{'loss': 0.0134, 'grad_norm': 7.200679302215576, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.012212244793772697, 'loss_2': 0.0011501312255859375, 'loss_3': -16.425830841064453, 'loss_4': 1.5982362031936646, 'epoch': 15.41}
{'loss': 0.0162, 'grad_norm': 6.806783676147461, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.010012583807110786, 'loss_2': 0.00621795654296875, 'loss_3': -16.288387298583984, 'loss_4': 1.8798673152923584, 'epoch': 15.42}
{'loss': 0.0096, 'grad_norm': 4.977390289306641, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.0053903511725366116, 'loss_2': 0.004238128662109375, 'loss_3': -16.31463623046875, 'loss_4': 2.200514793395996, 'epoch': 15.42}
{'loss': 0.0155, 'grad_norm': 5.670464992523193, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.011140466667711735, 'loss_2': 0.004398345947265625, 'loss_3': -16.39551544189453, 'loss_4': 1.0581231117248535, 'epoch': 15.43}
{'loss': 0.013, 'grad_norm': 6.564526557922363, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.010785560123622417, 'loss_2': 0.0021953582763671875, 'loss_3': -16.455101013183594, 'loss_4': 2.1791577339172363, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 10:29:48,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:48,445 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:37<43:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:55,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010473408736288548, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006213092710822821, 'eval_loss_2': 0.004260316491127014, 'eval_loss_3': -18.27165985107422, 'eval_loss_4': 1.0592814683914185, 'epoch': 15.44}
{'loss': 0.0177, 'grad_norm': 4.690401077270508, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.005738959647715092, 'loss_2': 0.0119171142578125, 'loss_3': -16.114091873168945, 'loss_4': 1.8624165058135986, 'epoch': 15.44}
{'loss': 0.0105, 'grad_norm': 5.40708589553833, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.0067155188880860806, 'loss_2': 0.003795623779296875, 'loss_3': -16.195663452148438, 'loss_4': 2.212027072906494, 'epoch': 15.45}
{'loss': 0.0064, 'grad_norm': 4.90794038772583, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.005520942155271769, 'loss_2': 0.0008535385131835938, 'loss_3': -16.381229400634766, 'loss_4': 1.3155708312988281, 'epoch': 15.45}
{'loss': 0.0158, 'grad_norm': 8.245040893554688, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.015069924294948578, 'loss_2': 0.0007271766662597656, 'loss_3': -16.318923950195312, 'loss_4': 1.7919844388961792, 'epoch': 15.46}
{'loss': 0.0155, 'grad_norm': 6.099388122558594, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.010199145413935184, 'loss_2': 0.005279541015625, 'loss_3': -16.35840606689453, 'loss_4': 2.1468095779418945, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 10:29:55,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:55,797 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:05:45<43:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:03,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01045171543955803, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.837, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005808859597891569, 'eval_loss_2': 0.004642855376005173, 'eval_loss_3': -18.26359748840332, 'eval_loss_4': 1.0500620603561401, 'epoch': 15.47}
{'loss': 0.0185, 'grad_norm': 5.359538555145264, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.00904887169599533, 'loss_2': 0.009490966796875, 'loss_3': -16.387073516845703, 'loss_4': 1.5149096250534058, 'epoch': 15.47}
{'loss': 0.0092, 'grad_norm': 4.843189239501953, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.008462966419756413, 'loss_2': 0.000762939453125, 'loss_3': -16.01968002319336, 'loss_4': 1.3538140058517456, 'epoch': 15.48}
{'loss': 0.0058, 'grad_norm': 4.58135461807251, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.005453558638691902, 'loss_2': 0.0002999305725097656, 'loss_3': -16.311721801757812, 'loss_4': 1.7465201616287231, 'epoch': 15.48}
{'loss': 0.0154, 'grad_norm': 5.487129211425781, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.01050330139696598, 'loss_2': 0.00489044189453125, 'loss_3': -16.172014236450195, 'loss_4': 1.688158631324768, 'epoch': 15.49}
{'loss': 0.0154, 'grad_norm': 5.688382625579834, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.009672464802861214, 'loss_2': 0.00568389892578125, 'loss_3': -16.24759292602539, 'loss_4': 1.713718056678772, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 10:30:03,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:03,154 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:05:52<43:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:10,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010037440806627274, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.184, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005505104083567858, 'eval_loss_2': 0.004532337188720703, 'eval_loss_3': -18.263368606567383, 'eval_loss_4': 1.0410029888153076, 'epoch': 15.49}
{'loss': 0.0078, 'grad_norm': 4.908269882202148, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.005223358515650034, 'loss_2': 0.0025310516357421875, 'loss_3': -16.226789474487305, 'loss_4': 2.078835964202881, 'epoch': 15.5}
{'loss': 0.0038, 'grad_norm': 5.7505202293396, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.0034222472459077835, 'loss_2': 0.0003421306610107422, 'loss_3': -16.277576446533203, 'loss_4': 1.6383864879608154, 'epoch': 15.51}
{'loss': 0.009, 'grad_norm': 5.184647560119629, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.005247984081506729, 'loss_2': 0.00377655029296875, 'loss_3': -16.179086685180664, 'loss_4': 1.61453115940094, 'epoch': 15.51}
{'loss': 0.0071, 'grad_norm': 5.497893810272217, 'learning_rate': 1.45e-05, 'loss_1': 0.00612245686352253, 'loss_2': 0.0009775161743164062, 'loss_3': -16.41183090209961, 'loss_4': 2.249324083328247, 'epoch': 15.52}
{'loss': 0.0105, 'grad_norm': 4.81142520904541, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.004457441624253988, 'loss_2': 0.006072998046875, 'loss_3': -16.39075469970703, 'loss_4': 1.980354905128479, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 10:30:10,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:10,513 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:00<43:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:17,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009879089891910553, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.376, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005579955875873566, 'eval_loss_2': 0.004299134016036987, 'eval_loss_3': -18.22374725341797, 'eval_loss_4': 1.0322808027267456, 'epoch': 15.52}
{'loss': 0.0084, 'grad_norm': 4.941450119018555, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.005896416958421469, 'loss_2': 0.002544403076171875, 'loss_3': -16.24885368347168, 'loss_4': 1.3485409021377563, 'epoch': 15.53}
{'loss': 0.008, 'grad_norm': 5.131166458129883, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.007707552518695593, 'loss_2': 0.0003323554992675781, 'loss_3': -16.458593368530273, 'loss_4': 1.5379503965377808, 'epoch': 15.53}
{'loss': 0.0173, 'grad_norm': 5.954527378082275, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.00960374902933836, 'loss_2': 0.007656097412109375, 'loss_3': -16.149547576904297, 'loss_4': 2.0601930618286133, 'epoch': 15.54}
{'loss': 0.0172, 'grad_norm': 8.080221176147461, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.014418761245906353, 'loss_2': 0.002773284912109375, 'loss_3': -16.25058937072754, 'loss_4': 1.1964523792266846, 'epoch': 15.55}
{'loss': 0.0377, 'grad_norm': 11.781064987182617, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.02628966048359871, 'loss_2': 0.0113677978515625, 'loss_3': -16.363418579101562, 'loss_4': 1.3347127437591553, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 10:30:17,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:17,882 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:07<42:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:25,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009035278111696243, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.117, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005164656788110733, 'eval_loss_2': 0.0038706213235855103, 'eval_loss_3': -18.25501251220703, 'eval_loss_4': 0.8886911869049072, 'epoch': 15.55}
{'loss': 0.0116, 'grad_norm': 5.531271457672119, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.008403509855270386, 'loss_2': 0.003223419189453125, 'loss_3': -16.1065673828125, 'loss_4': 1.4721766710281372, 'epoch': 15.56}
{'loss': 0.0199, 'grad_norm': 7.010988235473633, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.010618333704769611, 'loss_2': 0.0093231201171875, 'loss_3': -16.071399688720703, 'loss_4': 1.0860400199890137, 'epoch': 15.56}
{'loss': 0.0077, 'grad_norm': 5.072960376739502, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.00725015951320529, 'loss_2': 0.0004572868347167969, 'loss_3': -16.17784309387207, 'loss_4': 1.2068947553634644, 'epoch': 15.57}
{'loss': 0.0093, 'grad_norm': 4.79233455657959, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.0058556171134114265, 'loss_2': 0.003448486328125, 'loss_3': -16.178688049316406, 'loss_4': 0.9934311509132385, 'epoch': 15.58}
{'loss': 0.0121, 'grad_norm': 5.579349517822266, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.005386249162256718, 'loss_2': 0.006755828857421875, 'loss_3': -16.315147399902344, 'loss_4': 1.3127665519714355, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 10:30:25,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:25,239 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:14<42:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:32,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009211286902427673, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005342918913811445, 'eval_loss_2': 0.003868367522954941, 'eval_loss_3': -18.260513305664062, 'eval_loss_4': 0.7484622597694397, 'epoch': 15.58}
{'loss': 0.0061, 'grad_norm': 5.016757011413574, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.0043107895180583, 'loss_2': 0.0018138885498046875, 'loss_3': -16.393110275268555, 'loss_4': 1.141297459602356, 'epoch': 15.59}
{'loss': 0.0155, 'grad_norm': 11.808395385742188, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.011884753592312336, 'loss_2': 0.003574371337890625, 'loss_3': -16.146198272705078, 'loss_4': 1.153830647468567, 'epoch': 15.59}
{'loss': 0.0149, 'grad_norm': 4.325509548187256, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.005615944974124432, 'loss_2': 0.00928497314453125, 'loss_3': -16.248212814331055, 'loss_4': 1.304317831993103, 'epoch': 15.6}
{'loss': 0.011, 'grad_norm': 5.365816116333008, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.010156366974115372, 'loss_2': 0.0007967948913574219, 'loss_3': -15.985065460205078, 'loss_4': 1.431309461593628, 'epoch': 15.6}
{'loss': 0.0114, 'grad_norm': 5.482137203216553, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.008805499412119389, 'loss_2': 0.002628326416015625, 'loss_3': -16.28006362915039, 'loss_4': 1.339522361755371, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 10:30:32,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:32,593 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:22<42:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:39,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009027047082781792, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005559547804296017, 'eval_loss_2': 0.0034675002098083496, 'eval_loss_3': -18.249685287475586, 'eval_loss_4': 0.8237243890762329, 'epoch': 15.61}
{'loss': 0.0159, 'grad_norm': 5.131796360015869, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.008453721180558205, 'loss_2': 0.007442474365234375, 'loss_3': -16.28055763244629, 'loss_4': 0.8953685760498047, 'epoch': 15.62}
{'loss': 0.0116, 'grad_norm': 5.07041597366333, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.008267772383987904, 'loss_2': 0.003307342529296875, 'loss_3': -16.132680892944336, 'loss_4': 0.9301842451095581, 'epoch': 15.62}
{'loss': 0.0137, 'grad_norm': 8.141677856445312, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.008756538853049278, 'loss_2': 0.004974365234375, 'loss_3': -16.394794464111328, 'loss_4': 1.0261298418045044, 'epoch': 15.63}
{'loss': 0.0223, 'grad_norm': 6.620944976806641, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.012896480038762093, 'loss_2': 0.0093536376953125, 'loss_3': -15.92896842956543, 'loss_4': 1.9551780223846436, 'epoch': 15.63}
{'loss': 0.0244, 'grad_norm': 14.242013931274414, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.02009960636496544, 'loss_2': 0.004322052001953125, 'loss_3': -16.209657669067383, 'loss_4': 1.3072710037231445, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 10:30:39,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:39,945 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:29<42:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:47,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010065059177577496, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005376407876610756, 'eval_loss_2': 0.004688650369644165, 'eval_loss_3': -18.227182388305664, 'eval_loss_4': 0.8089425563812256, 'epoch': 15.64}
{'loss': 0.0123, 'grad_norm': 11.51461410522461, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.012234744615852833, 'loss_2': 5.1081180572509766e-05, 'loss_3': -16.18251609802246, 'loss_4': 0.9011470079421997, 'epoch': 15.65}
{'loss': 0.0143, 'grad_norm': 6.014091491699219, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.00827186368405819, 'loss_2': 0.0060272216796875, 'loss_3': -16.2341365814209, 'loss_4': 0.9008439779281616, 'epoch': 15.65}
{'loss': 0.0109, 'grad_norm': 4.338671684265137, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.0038634713273495436, 'loss_2': 0.00705718994140625, 'loss_3': -16.39627456665039, 'loss_4': 1.2035164833068848, 'epoch': 15.66}
{'loss': 0.0123, 'grad_norm': 4.62772798538208, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.003923885058611631, 'loss_2': 0.00836181640625, 'loss_3': -16.216398239135742, 'loss_4': 1.2685339450836182, 'epoch': 15.66}
{'loss': 0.006, 'grad_norm': 4.538964748382568, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.004338317085057497, 'loss_2': 0.0016841888427734375, 'loss_3': -16.401166915893555, 'loss_4': 0.7951948642730713, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 10:30:47,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:47,295 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:36<42:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:54,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009303316473960876, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.395, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005606476683169603, 'eval_loss_2': 0.0036968402564525604, 'eval_loss_3': -18.223947525024414, 'eval_loss_4': 0.5935605764389038, 'epoch': 15.67}
{'loss': 0.0173, 'grad_norm': 6.571147441864014, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.009446410462260246, 'loss_2': 0.00789642333984375, 'loss_3': -16.33430290222168, 'loss_4': 1.2648496627807617, 'epoch': 15.67}
{'loss': 0.0126, 'grad_norm': 6.55647611618042, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.008653745986521244, 'loss_2': 0.0039215087890625, 'loss_3': -16.095327377319336, 'loss_4': 1.7508748769760132, 'epoch': 15.68}
{'loss': 0.0333, 'grad_norm': 18.29660987854004, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.03224679455161095, 'loss_2': 0.0010547637939453125, 'loss_3': -16.21900749206543, 'loss_4': 0.5750601887702942, 'epoch': 15.69}
{'loss': 0.0148, 'grad_norm': 7.631328582763672, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.014430222101509571, 'loss_2': 0.00034117698669433594, 'loss_3': -16.280601501464844, 'loss_4': 1.2306954860687256, 'epoch': 15.69}
{'loss': 0.0225, 'grad_norm': 10.802812576293945, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.021363230422139168, 'loss_2': 0.0010967254638671875, 'loss_3': -16.075382232666016, 'loss_4': 1.2979049682617188, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 10:30:54,663 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:54,663 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:44<42:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:02,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009014209732413292, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.447, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005856839939951897, 'eval_loss_2': 0.0031573697924613953, 'eval_loss_3': -18.23952293395996, 'eval_loss_4': 0.5627244114875793, 'epoch': 15.7}
{'loss': 0.0073, 'grad_norm': 4.631616592407227, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.003665720112621784, 'loss_2': 0.003673553466796875, 'loss_3': -16.431049346923828, 'loss_4': 0.677837610244751, 'epoch': 15.7}
{'loss': 0.0119, 'grad_norm': 5.011354446411133, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.008495060727000237, 'loss_2': 0.0033702850341796875, 'loss_3': -16.082489013671875, 'loss_4': 0.5607645511627197, 'epoch': 15.71}
{'loss': 0.0107, 'grad_norm': 5.253142356872559, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.00877968966960907, 'loss_2': 0.0018815994262695312, 'loss_3': -16.237911224365234, 'loss_4': 1.0241329669952393, 'epoch': 15.72}
{'loss': 0.0158, 'grad_norm': 6.045012474060059, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.009926922619342804, 'loss_2': 0.005855560302734375, 'loss_3': -16.188804626464844, 'loss_4': 0.7823834419250488, 'epoch': 15.72}
{'loss': 0.0206, 'grad_norm': 9.889106750488281, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.010894381441175938, 'loss_2': 0.0097503662109375, 'loss_3': -16.308605194091797, 'loss_4': 1.2514476776123047, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 10:31:02,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:02,009 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:06:51<42:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:09,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008487295359373093, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005966599564999342, 'eval_loss_2': 0.0025206953287124634, 'eval_loss_3': -18.207698822021484, 'eval_loss_4': 0.6785376667976379, 'epoch': 15.73}
{'loss': 0.0144, 'grad_norm': 5.2369303703308105, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.008538519032299519, 'loss_2': 0.005847930908203125, 'loss_3': -16.252700805664062, 'loss_4': 0.793464183807373, 'epoch': 15.73}
{'loss': 0.0101, 'grad_norm': 4.51693868637085, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.005713607184588909, 'loss_2': 0.004367828369140625, 'loss_3': -16.33033561706543, 'loss_4': 1.449833631515503, 'epoch': 15.74}
{'loss': 0.0125, 'grad_norm': 6.28291130065918, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.006226782687008381, 'loss_2': 0.00624847412109375, 'loss_3': -16.249202728271484, 'loss_4': 1.101247787475586, 'epoch': 15.74}
{'loss': 0.0092, 'grad_norm': 5.144198417663574, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.006431640591472387, 'loss_2': 0.0027980804443359375, 'loss_3': -16.171424865722656, 'loss_4': 1.540590524673462, 'epoch': 15.75}
{'loss': 0.0075, 'grad_norm': 5.324770450592041, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.005894744768738747, 'loss_2': 0.0016498565673828125, 'loss_3': -16.25777816772461, 'loss_4': 1.2002418041229248, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 10:31:09,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:09,363 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:06:58<42:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:16,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01047638338059187, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.75, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006164299789816141, 'eval_loss_2': 0.004312083125114441, 'eval_loss_3': -18.214584350585938, 'eval_loss_4': 0.7698075175285339, 'epoch': 15.76}
{'loss': 0.0193, 'grad_norm': 7.516730785369873, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.010701123625040054, 'loss_2': 0.00858306884765625, 'loss_3': -16.100664138793945, 'loss_4': 1.0700902938842773, 'epoch': 15.76}
{'loss': 0.0357, 'grad_norm': 18.8519344329834, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.03314122557640076, 'loss_2': 0.002597808837890625, 'loss_3': -16.008792877197266, 'loss_4': 1.2675912380218506, 'epoch': 15.77}
{'loss': 0.0116, 'grad_norm': 6.204798698425293, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.005317030008882284, 'loss_2': 0.00628662109375, 'loss_3': -16.45151710510254, 'loss_4': 1.4536672830581665, 'epoch': 15.77}
{'loss': 0.0169, 'grad_norm': 6.122115135192871, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.011773944832384586, 'loss_2': 0.0050811767578125, 'loss_3': -16.29888916015625, 'loss_4': 0.955644965171814, 'epoch': 15.78}
{'loss': 0.0081, 'grad_norm': 4.546631336212158, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.006004427094012499, 'loss_2': 0.0020465850830078125, 'loss_3': -16.385169982910156, 'loss_4': 1.011125087738037, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 10:31:16,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:16,724 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:06<42:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:24,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013671898283064365, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006817006506025791, 'eval_loss_2': 0.006854891777038574, 'eval_loss_3': -18.245948791503906, 'eval_loss_4': 0.8657238483428955, 'epoch': 15.78}
{'loss': 0.016, 'grad_norm': 4.410684585571289, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.005216668359935284, 'loss_2': 0.0108184814453125, 'loss_3': -16.3699951171875, 'loss_4': 1.355749487876892, 'epoch': 15.79}
{'loss': 0.0454, 'grad_norm': 14.469550132751465, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.032045189291238785, 'loss_2': 0.013336181640625, 'loss_3': -16.327957153320312, 'loss_4': 2.305985689163208, 'epoch': 15.8}
{'loss': 0.0078, 'grad_norm': 4.490493297576904, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.00396523205563426, 'loss_2': 0.00383758544921875, 'loss_3': -16.17754364013672, 'loss_4': 1.0951602458953857, 'epoch': 15.8}
{'loss': 0.0107, 'grad_norm': 5.90341854095459, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.007953519932925701, 'loss_2': 0.0027828216552734375, 'loss_3': -16.369388580322266, 'loss_4': 1.665649652481079, 'epoch': 15.81}
{'loss': 0.0108, 'grad_norm': 5.4356369972229, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.008767747320234776, 'loss_2': 0.0020618438720703125, 'loss_3': -16.528928756713867, 'loss_4': 0.754127025604248, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 10:31:24,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:24,076 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:13<42:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:31,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010352161712944508, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.872, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007419105619192123, 'eval_loss_2': 0.0029330551624298096, 'eval_loss_3': -18.219818115234375, 'eval_loss_4': 0.838371217250824, 'epoch': 15.81}
{'loss': 0.0089, 'grad_norm': 5.509599208831787, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.007987787015736103, 'loss_2': 0.0008802413940429688, 'loss_3': -16.23613739013672, 'loss_4': 1.03523588180542, 'epoch': 15.82}
{'loss': 0.0157, 'grad_norm': 5.794040679931641, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.009635955095291138, 'loss_2': 0.0060577392578125, 'loss_3': -16.417673110961914, 'loss_4': 1.2016074657440186, 'epoch': 15.83}
{'loss': 0.0057, 'grad_norm': 4.676604270935059, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.005022239405661821, 'loss_2': 0.0006628036499023438, 'loss_3': -16.240421295166016, 'loss_4': 1.2863178253173828, 'epoch': 15.83}
{'loss': 0.013, 'grad_norm': 5.116940975189209, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.0069948118180036545, 'loss_2': 0.006053924560546875, 'loss_3': -16.29641342163086, 'loss_4': 1.3194910287857056, 'epoch': 15.84}
{'loss': 0.0078, 'grad_norm': 5.768846035003662, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.006908423732966185, 'loss_2': 0.0008521080017089844, 'loss_3': -16.128185272216797, 'loss_4': 1.0842442512512207, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 10:31:31,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:31,434 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:20<42:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:38,796 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01093797292560339, 'eval_runtime': 3.8182, 'eval_samples_per_second': 268.186, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.00657550897449255, 'eval_loss_2': 0.00436246395111084, 'eval_loss_3': -18.227218627929688, 'eval_loss_4': 0.5815556645393372, 'epoch': 15.84}
{'loss': 0.0124, 'grad_norm': 5.341164588928223, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.008223088458180428, 'loss_2': 0.004199981689453125, 'loss_3': -16.456039428710938, 'loss_4': 0.9719074368476868, 'epoch': 15.85}
{'loss': 0.0091, 'grad_norm': 4.694582462310791, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.007162001915276051, 'loss_2': 0.001953125, 'loss_3': -16.384498596191406, 'loss_4': 0.5232982635498047, 'epoch': 15.85}
{'loss': 0.0147, 'grad_norm': 5.298522472381592, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.009237579070031643, 'loss_2': 0.00550079345703125, 'loss_3': -16.180753707885742, 'loss_4': 0.5412096381187439, 'epoch': 15.86}
{'loss': 0.0199, 'grad_norm': 5.717545986175537, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.00947269145399332, 'loss_2': 0.01047515869140625, 'loss_3': -16.48247528076172, 'loss_4': 1.5303339958190918, 'epoch': 15.87}
{'loss': 0.0118, 'grad_norm': 4.924998760223389, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.004623054526746273, 'loss_2': 0.00717926025390625, 'loss_3': -16.3278751373291, 'loss_4': 1.1135112047195435, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 10:31:38,796 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:38,796 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:28<42:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:46,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009874138981103897, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.829, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005545231979340315, 'eval_loss_2': 0.004328906536102295, 'eval_loss_3': -18.244029998779297, 'eval_loss_4': 0.5425763130187988, 'epoch': 15.87}
{'loss': 0.0481, 'grad_norm': 21.246047973632812, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.04547847434878349, 'loss_2': 0.00263214111328125, 'loss_3': -16.397924423217773, 'loss_4': 1.199127435684204, 'epoch': 15.88}
{'loss': 0.0077, 'grad_norm': 4.862066745758057, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.005830908194184303, 'loss_2': 0.0018444061279296875, 'loss_3': -16.287940979003906, 'loss_4': 0.9804427027702332, 'epoch': 15.88}
{'loss': 0.0216, 'grad_norm': 11.950784683227539, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.02139313705265522, 'loss_2': 0.00024771690368652344, 'loss_3': -16.225027084350586, 'loss_4': 1.3010478019714355, 'epoch': 15.89}
{'loss': 0.0105, 'grad_norm': 7.4555277824401855, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.00959510263055563, 'loss_2': 0.0008602142333984375, 'loss_3': -16.32611083984375, 'loss_4': 1.4372706413269043, 'epoch': 15.9}
{'loss': 0.0105, 'grad_norm': 5.371437072753906, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.008930088020861149, 'loss_2': 0.0015544891357421875, 'loss_3': -16.396745681762695, 'loss_4': 1.2509948015213013, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 10:31:46,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:46,161 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:35<42:28,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:31:53,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008722507394850254, 'eval_runtime': 4.0016, 'eval_samples_per_second': 255.898, 'eval_steps_per_second': 3.998, 'eval_loss_1': 0.005518072284758091, 'eval_loss_2': 0.003204435110092163, 'eval_loss_3': -18.261287689208984, 'eval_loss_4': 0.5564247369766235, 'epoch': 15.9}
{'loss': 0.0149, 'grad_norm': 5.985923767089844, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.008905751630663872, 'loss_2': 0.006008148193359375, 'loss_3': -16.202877044677734, 'loss_4': 1.0073792934417725, 'epoch': 15.91}
{'loss': 0.0169, 'grad_norm': 6.8339104652404785, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.012504305690526962, 'loss_2': 0.004413604736328125, 'loss_3': -16.39800262451172, 'loss_4': 1.1321736574172974, 'epoch': 15.91}
{'loss': 0.0225, 'grad_norm': 9.839163780212402, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.017983732745051384, 'loss_2': 0.0045623779296875, 'loss_3': -16.272056579589844, 'loss_4': 1.0008254051208496, 'epoch': 15.92}
{'loss': 0.0068, 'grad_norm': 4.857208728790283, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.003546430030837655, 'loss_2': 0.0032291412353515625, 'loss_3': -16.34086036682129, 'loss_4': 0.44545885920524597, 'epoch': 15.92}
{'loss': 0.0299, 'grad_norm': 14.55545711517334, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.02735888585448265, 'loss_2': 0.0025310516357421875, 'loss_3': -16.324913024902344, 'loss_4': 0.5914852023124695, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 10:31:53,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:53,712 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:43<41:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:01,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009327762760221958, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.221, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006440155208110809, 'eval_loss_2': 0.0028876066207885742, 'eval_loss_3': -18.235055923461914, 'eval_loss_4': 0.47733914852142334, 'epoch': 15.93}
{'loss': 0.0055, 'grad_norm': 4.253036975860596, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.0054871151223778725, 'loss_2': 2.968311309814453e-05, 'loss_3': -16.186443328857422, 'loss_4': 0.47733429074287415, 'epoch': 15.94}
{'loss': 0.0206, 'grad_norm': 9.471512794494629, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.014756723307073116, 'loss_2': 0.005855560302734375, 'loss_3': -16.453018188476562, 'loss_4': 1.37282133102417, 'epoch': 15.94}
{'loss': 0.0149, 'grad_norm': 6.577507019042969, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.01061023399233818, 'loss_2': 0.004245758056640625, 'loss_3': -16.329181671142578, 'loss_4': 1.3014432191848755, 'epoch': 15.95}
{'loss': 0.0135, 'grad_norm': 4.562449932098389, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.004196257796138525, 'loss_2': 0.00927734375, 'loss_3': -16.578632354736328, 'loss_4': 1.519516110420227, 'epoch': 15.95}
{'loss': 0.0108, 'grad_norm': 5.329463481903076, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.008891040459275246, 'loss_2': 0.001918792724609375, 'loss_3': -16.591957092285156, 'loss_4': 0.657620906829834, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 10:32:01,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:01,068 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:07:50<41:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:08,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009374002926051617, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.964, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006811911705881357, 'eval_loss_2': 0.002562090754508972, 'eval_loss_3': -18.25645637512207, 'eval_loss_4': 0.5271562337875366, 'epoch': 15.96}
{'loss': 0.0121, 'grad_norm': 5.659769535064697, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.008994734846055508, 'loss_2': 0.003124237060546875, 'loss_3': -16.385587692260742, 'loss_4': 0.7467416524887085, 'epoch': 15.97}
{'loss': 0.0077, 'grad_norm': 5.471949100494385, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.006942464504390955, 'loss_2': 0.0007257461547851562, 'loss_3': -16.222347259521484, 'loss_4': 1.2480568885803223, 'epoch': 15.97}
{'loss': 0.011, 'grad_norm': 4.433896541595459, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.00547244306653738, 'loss_2': 0.0054931640625, 'loss_3': -16.392478942871094, 'loss_4': 1.0490257740020752, 'epoch': 15.98}
{'loss': 0.0167, 'grad_norm': 8.52116584777832, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.012143759056925774, 'loss_2': 0.0045623779296875, 'loss_3': -16.41421127319336, 'loss_4': 1.2260937690734863, 'epoch': 15.98}
{'loss': 0.0121, 'grad_norm': 5.045203685760498, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.006869013421237469, 'loss_2': 0.00518798828125, 'loss_3': -16.381208419799805, 'loss_4': 1.7087156772613525, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 10:32:08,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:08,432 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:07:57<40:29,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:32:15,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010600130073726177, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.866, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007217596285045147, 'eval_loss_2': 0.0033825337886810303, 'eval_loss_3': -18.262922286987305, 'eval_loss_4': 0.7481871247291565, 'epoch': 15.99}
{'loss': 0.0317, 'grad_norm': 9.744407653808594, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.01908344402909279, 'loss_2': 0.0125885009765625, 'loss_3': -16.517820358276367, 'loss_4': 1.1384522914886475, 'epoch': 15.99}
{'loss': 0.0051, 'grad_norm': 6.335499286651611, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.0028110661078244448, 'loss_2': 0.00229644775390625, 'loss_3': -16.258296966552734, 'loss_4': 1.4462207555770874, 'epoch': 16.0}
{'loss': 0.0147, 'grad_norm': 5.189770221710205, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.01207596343010664, 'loss_2': 0.0026569366455078125, 'loss_3': -16.432064056396484, 'loss_4': 0.9980248212814331, 'epoch': 16.01}
{'loss': 0.0167, 'grad_norm': 5.849053859710693, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.016343245282769203, 'loss_2': 0.0003628730773925781, 'loss_3': -16.405513763427734, 'loss_4': 1.4240663051605225, 'epoch': 16.01}
{'loss': 0.0079, 'grad_norm': 4.450953483581543, 'learning_rate': 1.4e-05, 'loss_1': 0.0037454315461218357, 'loss_2': 0.00411224365234375, 'loss_3': -16.44537925720215, 'loss_4': 1.5237183570861816, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 10:32:15,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:15,480 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:05<41:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:22,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012467059306800365, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.516, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007840189151465893, 'eval_loss_2': 0.004626870155334473, 'eval_loss_3': -18.261539459228516, 'eval_loss_4': 0.829059362411499, 'epoch': 16.02}
{'loss': 0.0244, 'grad_norm': 9.354021072387695, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.019617289304733276, 'loss_2': 0.00481414794921875, 'loss_3': -16.289459228515625, 'loss_4': 1.9922680854797363, 'epoch': 16.02}
{'loss': 0.0104, 'grad_norm': 5.71235466003418, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.010189938358962536, 'loss_2': 0.00022733211517333984, 'loss_3': -16.40726661682129, 'loss_4': 1.0776221752166748, 'epoch': 16.03}
{'loss': 0.0087, 'grad_norm': 5.696563720703125, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.006845435127615929, 'loss_2': 0.001819610595703125, 'loss_3': -16.6054744720459, 'loss_4': 1.2586345672607422, 'epoch': 16.03}
{'loss': 0.018, 'grad_norm': 5.108880519866943, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.01277959905564785, 'loss_2': 0.0052642822265625, 'loss_3': -16.315689086914062, 'loss_4': 1.2487351894378662, 'epoch': 16.04}
{'loss': 0.0529, 'grad_norm': 15.760333061218262, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.048620209097862244, 'loss_2': 0.00424957275390625, 'loss_3': -16.27818489074707, 'loss_4': 1.3504197597503662, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 10:32:22,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:22,848 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:12<41:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:30,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014616696164011955, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007996081374585629, 'eval_loss_2': 0.006620615720748901, 'eval_loss_3': -18.27619743347168, 'eval_loss_4': 0.8181662559509277, 'epoch': 16.05}
{'loss': 0.0197, 'grad_norm': 5.95780611038208, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.012100482359528542, 'loss_2': 0.007572174072265625, 'loss_3': -16.377742767333984, 'loss_4': 1.4464954137802124, 'epoch': 16.05}
{'loss': 0.0186, 'grad_norm': 5.474670886993408, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.012708070687949657, 'loss_2': 0.0058746337890625, 'loss_3': -16.634599685668945, 'loss_4': 1.3457859754562378, 'epoch': 16.06}
{'loss': 0.0218, 'grad_norm': 6.4436821937561035, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.02058444544672966, 'loss_2': 0.001239776611328125, 'loss_3': -16.43388557434082, 'loss_4': 1.5236984491348267, 'epoch': 16.06}
{'loss': 0.0212, 'grad_norm': 5.3245015144348145, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.014659964479506016, 'loss_2': 0.0065460205078125, 'loss_3': -16.51415252685547, 'loss_4': 1.209904670715332, 'epoch': 16.07}
{'loss': 0.0144, 'grad_norm': 4.919328689575195, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.010991922579705715, 'loss_2': 0.00344085693359375, 'loss_3': -16.476337432861328, 'loss_4': 1.6412218809127808, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 10:32:30,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:30,211 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:19<41:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:37,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012069659307599068, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.134, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008876281790435314, 'eval_loss_2': 0.003193378448486328, 'eval_loss_3': -18.250825881958008, 'eval_loss_4': 1.095719337463379, 'epoch': 16.08}
{'loss': 0.0204, 'grad_norm': 6.9372334480285645, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.01939522661268711, 'loss_2': 0.0009784698486328125, 'loss_3': -16.564411163330078, 'loss_4': 1.5152251720428467, 'epoch': 16.08}
{'loss': 0.0278, 'grad_norm': 7.788761615753174, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.015700211748480797, 'loss_2': 0.012115478515625, 'loss_3': -16.31589126586914, 'loss_4': 1.6090304851531982, 'epoch': 16.09}
{'loss': 0.0149, 'grad_norm': 5.339356899261475, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.011115701869130135, 'loss_2': 0.003814697265625, 'loss_3': -16.53662872314453, 'loss_4': 1.6915651559829712, 'epoch': 16.09}
{'loss': 0.0116, 'grad_norm': 5.559887886047363, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.010516279377043247, 'loss_2': 0.0010776519775390625, 'loss_3': -16.441993713378906, 'loss_4': 1.4547154903411865, 'epoch': 16.1}
{'loss': 0.0073, 'grad_norm': 4.53705358505249, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.006245333701372147, 'loss_2': 0.00109100341796875, 'loss_3': -16.573144912719727, 'loss_4': 1.4170445203781128, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 10:32:37,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:37,576 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:27<41:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:44,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012277736328542233, 'eval_runtime': 3.8181, 'eval_samples_per_second': 268.193, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.009677177295088768, 'eval_loss_2': 0.00260055810213089, 'eval_loss_3': -18.24380874633789, 'eval_loss_4': 1.20389723777771, 'epoch': 16.1}
{'loss': 0.0127, 'grad_norm': 5.25535774230957, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.012323007918894291, 'loss_2': 0.00040268898010253906, 'loss_3': -16.564273834228516, 'loss_4': 1.5760369300842285, 'epoch': 16.11}
{'loss': 0.0134, 'grad_norm': 6.428464889526367, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.011375435627996922, 'loss_2': 0.002071380615234375, 'loss_3': -16.430566787719727, 'loss_4': 1.4689762592315674, 'epoch': 16.12}
{'loss': 0.0166, 'grad_norm': 6.043385982513428, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.011294905096292496, 'loss_2': 0.0053253173828125, 'loss_3': -16.492599487304688, 'loss_4': 1.5289852619171143, 'epoch': 16.12}
{'loss': 0.0094, 'grad_norm': 5.184015274047852, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.008496478199958801, 'loss_2': 0.000904083251953125, 'loss_3': -16.564821243286133, 'loss_4': 1.1135083436965942, 'epoch': 16.13}
{'loss': 0.0276, 'grad_norm': 15.935600280761719, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.024174315854907036, 'loss_2': 0.0034122467041015625, 'loss_3': -16.344440460205078, 'loss_4': 1.1492009162902832, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 10:32:44,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:44,940 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:34<41:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:52,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013240262866020203, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009691924788057804, 'eval_loss_2': 0.003548339009284973, 'eval_loss_3': -18.228879928588867, 'eval_loss_4': 1.2358161211013794, 'epoch': 16.13}
{'loss': 0.0203, 'grad_norm': 8.63691234588623, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.01652657985687256, 'loss_2': 0.0037841796875, 'loss_3': -16.399646759033203, 'loss_4': 1.490187406539917, 'epoch': 16.14}
{'loss': 0.0139, 'grad_norm': 8.293994903564453, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.013171432539820671, 'loss_2': 0.000766754150390625, 'loss_3': -16.646169662475586, 'loss_4': 1.0646891593933105, 'epoch': 16.15}
{'loss': 0.0167, 'grad_norm': 5.79255485534668, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.015935685485601425, 'loss_2': 0.000812530517578125, 'loss_3': -16.436298370361328, 'loss_4': 1.6407604217529297, 'epoch': 16.15}
{'loss': 0.0087, 'grad_norm': 4.732641220092773, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.0058134798891842365, 'loss_2': 0.00292205810546875, 'loss_3': -16.459468841552734, 'loss_4': 2.0678844451904297, 'epoch': 16.16}
{'loss': 0.0112, 'grad_norm': 6.891499996185303, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.01091728638857603, 'loss_2': 0.00032711029052734375, 'loss_3': -16.452041625976562, 'loss_4': 1.7430267333984375, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 10:32:52,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:52,297 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:41<41:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:59,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012783433310687542, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.791, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008947905153036118, 'eval_loss_2': 0.003835529088973999, 'eval_loss_3': -18.21451187133789, 'eval_loss_4': 1.1258519887924194, 'epoch': 16.16}
{'loss': 0.019, 'grad_norm': 6.430112361907959, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.012163852341473103, 'loss_2': 0.006801605224609375, 'loss_3': -16.46853256225586, 'loss_4': 1.1627297401428223, 'epoch': 16.17}
{'loss': 0.0258, 'grad_norm': 11.032808303833008, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.022110292688012123, 'loss_2': 0.0037384033203125, 'loss_3': -16.48776626586914, 'loss_4': 1.5690228939056396, 'epoch': 16.17}
{'loss': 0.0161, 'grad_norm': 4.727687358856201, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.008316736668348312, 'loss_2': 0.00777435302734375, 'loss_3': -16.481056213378906, 'loss_4': 1.9406195878982544, 'epoch': 16.18}
{'loss': 0.013, 'grad_norm': 5.166380882263184, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.008216287940740585, 'loss_2': 0.004817962646484375, 'loss_3': -16.400394439697266, 'loss_4': 1.354079008102417, 'epoch': 16.19}
{'loss': 0.018, 'grad_norm': 7.37852668762207, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.013782481662929058, 'loss_2': 0.004180908203125, 'loss_3': -16.54285430908203, 'loss_4': 1.9148231744766235, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 10:32:59,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:59,667 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:08:49<41:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:07,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012160534039139748, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.89, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008914210833609104, 'eval_loss_2': 0.003246322274208069, 'eval_loss_3': -18.225313186645508, 'eval_loss_4': 1.3427886962890625, 'epoch': 16.19}
{'loss': 0.0269, 'grad_norm': 10.607354164123535, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.019740477204322815, 'loss_2': 0.0071563720703125, 'loss_3': -16.432764053344727, 'loss_4': 1.5577218532562256, 'epoch': 16.2}
{'loss': 0.0148, 'grad_norm': 5.445413589477539, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.010263817384839058, 'loss_2': 0.0045013427734375, 'loss_3': -16.296340942382812, 'loss_4': 1.986640453338623, 'epoch': 16.2}
{'loss': 0.0188, 'grad_norm': 8.140949249267578, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.015307852998375893, 'loss_2': 0.003513336181640625, 'loss_3': -16.228191375732422, 'loss_4': 1.7431122064590454, 'epoch': 16.21}
{'loss': 0.0152, 'grad_norm': 8.81749439239502, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.012054515071213245, 'loss_2': 0.003192901611328125, 'loss_3': -16.54384422302246, 'loss_4': 1.9552552700042725, 'epoch': 16.22}
{'loss': 0.0311, 'grad_norm': 9.31859016418457, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.025073161348700523, 'loss_2': 0.00604248046875, 'loss_3': -16.456100463867188, 'loss_4': 2.6176838874816895, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 10:33:07,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:07,027 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:08:56<40:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:14,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011445827782154083, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00883201602846384, 'eval_loss_2': 0.0026138126850128174, 'eval_loss_3': -18.232873916625977, 'eval_loss_4': 1.6518454551696777, 'epoch': 16.22}
{'loss': 0.0156, 'grad_norm': 6.639082431793213, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.012246068567037582, 'loss_2': 0.0033130645751953125, 'loss_3': -16.387935638427734, 'loss_4': 2.1612913608551025, 'epoch': 16.23}
{'loss': 0.0202, 'grad_norm': 6.312304973602295, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.011777134612202644, 'loss_2': 0.008392333984375, 'loss_3': -16.52913475036621, 'loss_4': 2.3122739791870117, 'epoch': 16.23}
{'loss': 0.0188, 'grad_norm': 5.338585376739502, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.007124320603907108, 'loss_2': 0.0117034912109375, 'loss_3': -16.303455352783203, 'loss_4': 2.799542188644409, 'epoch': 16.24}
{'loss': 0.016, 'grad_norm': 11.57626724243164, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.015872810035943985, 'loss_2': 0.00011807680130004883, 'loss_3': -16.385549545288086, 'loss_4': 2.6657767295837402, 'epoch': 16.24}
{'loss': 0.0379, 'grad_norm': 15.893898010253906, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.0338822640478611, 'loss_2': 0.00400543212890625, 'loss_3': -16.35652732849121, 'loss_4': 2.8799235820770264, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 10:33:14,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:14,386 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:03<40:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:21,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01292240247130394, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.953, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008806015364825726, 'eval_loss_2': 0.00411638617515564, 'eval_loss_3': -18.24112319946289, 'eval_loss_4': 1.9019131660461426, 'epoch': 16.25}
{'loss': 0.0162, 'grad_norm': 6.2119221687316895, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.01588597521185875, 'loss_2': 0.0003342628479003906, 'loss_3': -16.582767486572266, 'loss_4': 2.027421474456787, 'epoch': 16.26}
{'loss': 0.04, 'grad_norm': 22.528127670288086, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.03759549930691719, 'loss_2': 0.0023899078369140625, 'loss_3': -16.361892700195312, 'loss_4': 2.3737716674804688, 'epoch': 16.26}
{'loss': 0.0175, 'grad_norm': 6.746423244476318, 'learning_rate': 1.375e-05, 'loss_1': 0.010318845510482788, 'loss_2': 0.00716400146484375, 'loss_3': -16.586214065551758, 'loss_4': 2.775162696838379, 'epoch': 16.27}
{'loss': 0.0132, 'grad_norm': 4.97172212600708, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.0082322359085083, 'loss_2': 0.00496673583984375, 'loss_3': -16.374500274658203, 'loss_4': 1.9235291481018066, 'epoch': 16.27}
{'loss': 0.0203, 'grad_norm': 5.232508182525635, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.010992252267897129, 'loss_2': 0.0093536376953125, 'loss_3': -16.421855926513672, 'loss_4': 2.7063722610473633, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 10:33:21,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:21,749 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:11<40:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:29,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012413297779858112, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.002, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007465575821697712, 'eval_loss_2': 0.0049477219581604, 'eval_loss_3': -18.27497673034668, 'eval_loss_4': 2.130727529525757, 'epoch': 16.28}
{'loss': 0.0164, 'grad_norm': 7.270648956298828, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.015335450880229473, 'loss_2': 0.001079559326171875, 'loss_3': -16.413644790649414, 'loss_4': 2.980466604232788, 'epoch': 16.28}
{'loss': 0.0154, 'grad_norm': 5.253252029418945, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.009034255519509315, 'loss_2': 0.00635528564453125, 'loss_3': -16.62052345275879, 'loss_4': 2.684175729751587, 'epoch': 16.29}
{'loss': 0.0214, 'grad_norm': 9.723125457763672, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.01966729573905468, 'loss_2': 0.00177764892578125, 'loss_3': -16.512205123901367, 'loss_4': 2.7092840671539307, 'epoch': 16.3}
{'loss': 0.0117, 'grad_norm': 5.00987434387207, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.011032937094569206, 'loss_2': 0.0006780624389648438, 'loss_3': -16.454025268554688, 'loss_4': 2.879991054534912, 'epoch': 16.3}
{'loss': 0.0138, 'grad_norm': 6.492313385009766, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.013165120966732502, 'loss_2': 0.0006513595581054688, 'loss_3': -16.640886306762695, 'loss_4': 2.789076805114746, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 10:33:29,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:29,118 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:18<40:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:36,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009769240394234657, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.034, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006854342762380838, 'eval_loss_2': 0.002914898097515106, 'eval_loss_3': -18.29851531982422, 'eval_loss_4': 2.32173490524292, 'epoch': 16.31}
{'loss': 0.0182, 'grad_norm': 7.00187873840332, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.01501601841300726, 'loss_2': 0.00318145751953125, 'loss_3': -16.363222122192383, 'loss_4': 2.99383282661438, 'epoch': 16.31}
{'loss': 0.0238, 'grad_norm': 8.674521446228027, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.022903045639395714, 'loss_2': 0.0008702278137207031, 'loss_3': -16.579490661621094, 'loss_4': 2.9090323448181152, 'epoch': 16.32}
{'loss': 0.0244, 'grad_norm': 9.70273494720459, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.019268030300736427, 'loss_2': 0.00511932373046875, 'loss_3': -16.55019760131836, 'loss_4': 3.384974479675293, 'epoch': 16.33}
{'loss': 0.0137, 'grad_norm': 5.535984516143799, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.010269858874380589, 'loss_2': 0.0034465789794921875, 'loss_3': -16.342044830322266, 'loss_4': 2.382753849029541, 'epoch': 16.33}
{'loss': 0.0105, 'grad_norm': 5.5829668045043945, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.007836365140974522, 'loss_2': 0.0026760101318359375, 'loss_3': -16.39349937438965, 'loss_4': 2.9188051223754883, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 10:33:36,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:36,477 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:26<40:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:43,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009479932487010956, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.313, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006746187340468168, 'eval_loss_2': 0.0027337446808815002, 'eval_loss_3': -18.301286697387695, 'eval_loss_4': 2.4139389991760254, 'epoch': 16.34}
{'loss': 0.0148, 'grad_norm': 6.767031192779541, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.01169380359351635, 'loss_2': 0.0031528472900390625, 'loss_3': -16.668262481689453, 'loss_4': 3.198662757873535, 'epoch': 16.34}
{'loss': 0.0096, 'grad_norm': 5.0648980140686035, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.007590780034661293, 'loss_2': 0.002017974853515625, 'loss_3': -16.522733688354492, 'loss_4': 2.7430667877197266, 'epoch': 16.35}
{'loss': 0.0262, 'grad_norm': 13.776145935058594, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.02530866116285324, 'loss_2': 0.0008521080017089844, 'loss_3': -16.41657257080078, 'loss_4': 2.8512520790100098, 'epoch': 16.35}
{'loss': 0.0301, 'grad_norm': 7.852611541748047, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.01751808635890484, 'loss_2': 0.012603759765625, 'loss_3': -16.66297149658203, 'loss_4': 3.738215684890747, 'epoch': 16.36}
{'loss': 0.0101, 'grad_norm': 5.716182708740234, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.008358156308531761, 'loss_2': 0.0017566680908203125, 'loss_3': -16.554080963134766, 'loss_4': 2.9959754943847656, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 10:33:43,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:43,855 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:33<40:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:51,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014762669801712036, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00759700033813715, 'eval_loss_2': 0.007165670394897461, 'eval_loss_3': -18.312725067138672, 'eval_loss_4': 2.4302453994750977, 'epoch': 16.37}
{'loss': 0.0294, 'grad_norm': 7.99623966217041, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.01912061683833599, 'loss_2': 0.010284423828125, 'loss_3': -16.73650360107422, 'loss_4': 3.2058568000793457, 'epoch': 16.37}
{'loss': 0.0134, 'grad_norm': 4.8827314376831055, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.010712687857449055, 'loss_2': 0.0026569366455078125, 'loss_3': -16.500274658203125, 'loss_4': 3.35068941116333, 'epoch': 16.38}
{'loss': 0.0177, 'grad_norm': 6.258258819580078, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.013465261086821556, 'loss_2': 0.00423431396484375, 'loss_3': -16.480525970458984, 'loss_4': 2.7351272106170654, 'epoch': 16.38}
{'loss': 0.0192, 'grad_norm': 6.600559234619141, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.011890926398336887, 'loss_2': 0.007266998291015625, 'loss_3': -16.441064834594727, 'loss_4': 3.34753155708313, 'epoch': 16.39}
{'loss': 0.0281, 'grad_norm': 11.860374450683594, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.017658542841672897, 'loss_2': 0.0104522705078125, 'loss_3': -16.395048141479492, 'loss_4': 3.691725969314575, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 10:33:51,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:51,225 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:40<40:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:58,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016405154019594193, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.942, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00733642652630806, 'eval_loss_2': 0.009068727493286133, 'eval_loss_3': -18.311494827270508, 'eval_loss_4': 2.417111873626709, 'epoch': 16.4}
{'loss': 0.0204, 'grad_norm': 4.861227512359619, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.008549978025257587, 'loss_2': 0.0118255615234375, 'loss_3': -16.179166793823242, 'loss_4': 3.2345058917999268, 'epoch': 16.4}
{'loss': 0.0271, 'grad_norm': 13.284260749816895, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.018675604835152626, 'loss_2': 0.0084228515625, 'loss_3': -16.3703670501709, 'loss_4': 2.7767434120178223, 'epoch': 16.41}
{'loss': 0.0109, 'grad_norm': 5.059893608093262, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.009487919509410858, 'loss_2': 0.0014505386352539062, 'loss_3': -16.491352081298828, 'loss_4': 3.7377984523773193, 'epoch': 16.41}
{'loss': 0.0144, 'grad_norm': 5.938700199127197, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.008638514205813408, 'loss_2': 0.0057830810546875, 'loss_3': -16.520641326904297, 'loss_4': 2.621025562286377, 'epoch': 16.42}
{'loss': 0.0129, 'grad_norm': 5.294544219970703, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.008033732883632183, 'loss_2': 0.00489044189453125, 'loss_3': -16.490018844604492, 'loss_4': 3.0914132595062256, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 10:33:58,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:58,591 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:09:48<40:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:05,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01301911287009716, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.932, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00695875845849514, 'eval_loss_2': 0.00606035441160202, 'eval_loss_3': -18.31137466430664, 'eval_loss_4': 2.3700778484344482, 'epoch': 16.42}
{'loss': 0.0076, 'grad_norm': 5.725010395050049, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.005677220411598682, 'loss_2': 0.0019245147705078125, 'loss_3': -16.325389862060547, 'loss_4': 2.832535743713379, 'epoch': 16.43}
{'loss': 0.0202, 'grad_norm': 5.580219268798828, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.010436329059302807, 'loss_2': 0.009765625, 'loss_3': -16.720048904418945, 'loss_4': 3.4119529724121094, 'epoch': 16.44}
{'loss': 0.0197, 'grad_norm': 5.934015274047852, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.010462148115038872, 'loss_2': 0.00926971435546875, 'loss_3': -16.546871185302734, 'loss_4': 3.263639450073242, 'epoch': 16.44}
{'loss': 0.0229, 'grad_norm': 5.093724250793457, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.01016028132289648, 'loss_2': 0.0127105712890625, 'loss_3': -16.39415168762207, 'loss_4': 2.657702922821045, 'epoch': 16.45}
{'loss': 0.0101, 'grad_norm': 5.399519920349121, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.007684614975005388, 'loss_2': 0.002391815185546875, 'loss_3': -16.69924545288086, 'loss_4': 3.6546783447265625, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 10:34:05,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:05,952 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:09:55<40:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:13,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008543701842427254, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006245494820177555, 'eval_loss_2': 0.002298206090927124, 'eval_loss_3': -18.30060577392578, 'eval_loss_4': 2.3353824615478516, 'epoch': 16.45}
{'loss': 0.0125, 'grad_norm': 5.521839618682861, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.00960308313369751, 'loss_2': 0.002925872802734375, 'loss_3': -16.4445743560791, 'loss_4': 3.2468345165252686, 'epoch': 16.46}
{'loss': 0.0316, 'grad_norm': 9.261728286743164, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.02931889146566391, 'loss_2': 0.002300262451171875, 'loss_3': -16.408517837524414, 'loss_4': 2.7638936042785645, 'epoch': 16.47}
{'loss': 0.0109, 'grad_norm': 5.644011974334717, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.008354389108717442, 'loss_2': 0.002532958984375, 'loss_3': -16.464799880981445, 'loss_4': 2.5309109687805176, 'epoch': 16.47}
{'loss': 0.0232, 'grad_norm': 10.37414836883545, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.02134660631418228, 'loss_2': 0.00186920166015625, 'loss_3': -16.344865798950195, 'loss_4': 3.072385311126709, 'epoch': 16.48}
{'loss': 0.0115, 'grad_norm': 5.302655220031738, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.010575848631560802, 'loss_2': 0.0009551048278808594, 'loss_3': -16.418928146362305, 'loss_4': 3.0654456615448, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 10:34:13,317 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:13,317 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:02<40:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:20,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011527972295880318, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.911, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00672026164829731, 'eval_loss_2': 0.004807710647583008, 'eval_loss_3': -18.307727813720703, 'eval_loss_4': 2.279942512512207, 'epoch': 16.48}
{'loss': 0.0176, 'grad_norm': 6.796523094177246, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.013341354206204414, 'loss_2': 0.00428009033203125, 'loss_3': -16.359760284423828, 'loss_4': 2.7513203620910645, 'epoch': 16.49}
{'loss': 0.0269, 'grad_norm': 7.953386306762695, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.016596244648098946, 'loss_2': 0.01030731201171875, 'loss_3': -16.356178283691406, 'loss_4': 2.8243749141693115, 'epoch': 16.49}
{'loss': 0.0235, 'grad_norm': 8.800214767456055, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.01698211394250393, 'loss_2': 0.006500244140625, 'loss_3': -16.1602840423584, 'loss_4': 2.413517713546753, 'epoch': 16.5}
{'loss': 0.0148, 'grad_norm': 6.918826580047607, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.013241707347333431, 'loss_2': 0.0015659332275390625, 'loss_3': -16.60112190246582, 'loss_4': 2.899881601333618, 'epoch': 16.51}
{'loss': 0.0123, 'grad_norm': 6.090900897979736, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.010807598009705544, 'loss_2': 0.0014553070068359375, 'loss_3': -16.350330352783203, 'loss_4': 2.7829670906066895, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 10:34:20,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:20,680 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:10<40:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:28,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012420721352100372, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.878, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006548233795911074, 'eval_loss_2': 0.005872488021850586, 'eval_loss_3': -18.286964416503906, 'eval_loss_4': 2.0871191024780273, 'epoch': 16.51}
{'loss': 0.0123, 'grad_norm': 5.417778491973877, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.008776828646659851, 'loss_2': 0.003475189208984375, 'loss_3': -16.368831634521484, 'loss_4': 3.045992612838745, 'epoch': 16.52}
{'loss': 0.0148, 'grad_norm': 6.581887722015381, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.013473624363541603, 'loss_2': 0.0013246536254882812, 'loss_3': -16.403614044189453, 'loss_4': 3.312498092651367, 'epoch': 16.52}
{'loss': 0.0153, 'grad_norm': 9.325554847717285, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.012533316388726234, 'loss_2': 0.002788543701171875, 'loss_3': -16.36254119873047, 'loss_4': 2.254096746444702, 'epoch': 16.53}
{'loss': 0.0222, 'grad_norm': 10.403120994567871, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.01779349148273468, 'loss_2': 0.004405975341796875, 'loss_3': -16.40863609313965, 'loss_4': 2.0680665969848633, 'epoch': 16.53}
{'loss': 0.0253, 'grad_norm': 10.166633605957031, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.02300223708152771, 'loss_2': 0.0022754669189453125, 'loss_3': -16.420164108276367, 'loss_4': 2.8680830001831055, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 10:34:28,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:28,046 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:17<40:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:35,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009801761247217655, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006439046002924442, 'eval_loss_2': 0.003362715244293213, 'eval_loss_3': -18.293411254882812, 'eval_loss_4': 2.005511999130249, 'epoch': 16.54}
{'loss': 0.0101, 'grad_norm': 4.745404243469238, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.008256519213318825, 'loss_2': 0.001819610595703125, 'loss_3': -16.487606048583984, 'loss_4': 2.3537440299987793, 'epoch': 16.55}
{'loss': 0.0217, 'grad_norm': 7.307796955108643, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.014133966527879238, 'loss_2': 0.00754547119140625, 'loss_3': -16.443742752075195, 'loss_4': 2.470534563064575, 'epoch': 16.55}
{'loss': 0.0199, 'grad_norm': 8.41801929473877, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.018158787861466408, 'loss_2': 0.0016956329345703125, 'loss_3': -16.565303802490234, 'loss_4': 3.0694127082824707, 'epoch': 16.56}
{'loss': 0.0156, 'grad_norm': 11.83887004852295, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.014092664234340191, 'loss_2': 0.0015478134155273438, 'loss_3': -16.481624603271484, 'loss_4': 2.2322115898132324, 'epoch': 16.56}
{'loss': 0.0134, 'grad_norm': 7.473862648010254, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.009576148353517056, 'loss_2': 0.003849029541015625, 'loss_3': -16.58384895324707, 'loss_4': 3.0519824028015137, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 10:34:35,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:35,406 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:24<39:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:42,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010533595457673073, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0070485565811395645, 'eval_loss_2': 0.0034850388765335083, 'eval_loss_3': -18.285001754760742, 'eval_loss_4': 1.9743542671203613, 'epoch': 16.57}
{'loss': 0.0066, 'grad_norm': 5.306064128875732, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.006510075181722641, 'loss_2': 6.139278411865234e-05, 'loss_3': -16.579404830932617, 'loss_4': 2.2621877193450928, 'epoch': 16.58}
{'loss': 0.0144, 'grad_norm': 6.736695766448975, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.013033362105488777, 'loss_2': 0.0013723373413085938, 'loss_3': -16.226634979248047, 'loss_4': 2.4678244590759277, 'epoch': 16.58}
{'loss': 0.013, 'grad_norm': 6.3203349113464355, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.012933125719428062, 'loss_2': 2.9206275939941406e-05, 'loss_3': -16.415283203125, 'loss_4': 2.758037567138672, 'epoch': 16.59}
{'loss': 0.0118, 'grad_norm': 5.72144079208374, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.008537779562175274, 'loss_2': 0.0032367706298828125, 'loss_3': -16.408199310302734, 'loss_4': 2.384110450744629, 'epoch': 16.59}
{'loss': 0.012, 'grad_norm': 6.114241123199463, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.008767577819526196, 'loss_2': 0.003231048583984375, 'loss_3': -16.690719604492188, 'loss_4': 2.789968729019165, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 10:34:42,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:42,762 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:32<39:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:50,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010016906075179577, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.086, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006780016236007214, 'eval_loss_2': 0.0032368898391723633, 'eval_loss_3': -18.265777587890625, 'eval_loss_4': 1.8097493648529053, 'epoch': 16.6}
{'loss': 0.011, 'grad_norm': 5.098206043243408, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.00892525352537632, 'loss_2': 0.0020771026611328125, 'loss_3': -16.262617111206055, 'loss_4': 2.9493725299835205, 'epoch': 16.6}
{'loss': 0.0146, 'grad_norm': 6.5312628746032715, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.01104010734707117, 'loss_2': 0.0035915374755859375, 'loss_3': -16.3004150390625, 'loss_4': 2.586629867553711, 'epoch': 16.61}
{'loss': 0.0075, 'grad_norm': 5.378815650939941, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.007293482776731253, 'loss_2': 0.00023567676544189453, 'loss_3': -16.405593872070312, 'loss_4': 2.593174934387207, 'epoch': 16.62}
{'loss': 0.0264, 'grad_norm': 13.240114212036133, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.02322850003838539, 'loss_2': 0.0031280517578125, 'loss_3': -16.512107849121094, 'loss_4': 2.4708409309387207, 'epoch': 16.62}
{'loss': 0.0214, 'grad_norm': 6.497046947479248, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.013003437779843807, 'loss_2': 0.0084228515625, 'loss_3': -16.332420349121094, 'loss_4': 2.427643060684204, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 10:34:50,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:50,130 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:39<39:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:57,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014078746549785137, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007704864256083965, 'eval_loss_2': 0.006373882293701172, 'eval_loss_3': -18.237667083740234, 'eval_loss_4': 1.7603726387023926, 'epoch': 16.63}
{'loss': 0.0135, 'grad_norm': 5.045403003692627, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.008314771577715874, 'loss_2': 0.005161285400390625, 'loss_3': -16.529586791992188, 'loss_4': 2.808415412902832, 'epoch': 16.63}
{'loss': 0.0177, 'grad_norm': 6.142289638519287, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.014199674129486084, 'loss_2': 0.0035419464111328125, 'loss_3': -16.481943130493164, 'loss_4': 2.4681501388549805, 'epoch': 16.64}
{'loss': 0.0148, 'grad_norm': 5.4747724533081055, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.0065725925378501415, 'loss_2': 0.00823974609375, 'loss_3': -16.329059600830078, 'loss_4': 1.9893583059310913, 'epoch': 16.65}
{'loss': 0.0139, 'grad_norm': 7.3264594078063965, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.008957559242844582, 'loss_2': 0.004924774169921875, 'loss_3': -16.464599609375, 'loss_4': 2.210603713989258, 'epoch': 16.65}
{'loss': 0.0123, 'grad_norm': 6.748943328857422, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.009831768460571766, 'loss_2': 0.0024738311767578125, 'loss_3': -16.53015899658203, 'loss_4': 2.633942127227783, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 10:34:57,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:57,491 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:10:47<39:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:04,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010325780138373375, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.138, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.008084584958851337, 'eval_loss_2': 0.002241194248199463, 'eval_loss_3': -18.227306365966797, 'eval_loss_4': 1.6668543815612793, 'epoch': 16.66}
{'loss': 0.0082, 'grad_norm': 4.720656871795654, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.0055935499258339405, 'loss_2': 0.002593994140625, 'loss_3': -16.383825302124023, 'loss_4': 2.22865629196167, 'epoch': 16.66}
{'loss': 0.0171, 'grad_norm': 7.563126564025879, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.016591208055615425, 'loss_2': 0.0005383491516113281, 'loss_3': -16.38025665283203, 'loss_4': 1.9555442333221436, 'epoch': 16.67}
{'loss': 0.0129, 'grad_norm': 6.537510395050049, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.008003974333405495, 'loss_2': 0.0048675537109375, 'loss_3': -16.49106216430664, 'loss_4': 2.6051855087280273, 'epoch': 16.67}
{'loss': 0.0196, 'grad_norm': 7.569551467895508, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.01560487225651741, 'loss_2': 0.004016876220703125, 'loss_3': -16.265331268310547, 'loss_4': 2.431044101715088, 'epoch': 16.68}
{'loss': 0.0163, 'grad_norm': 8.530379295349121, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.014093155972659588, 'loss_2': 0.002254486083984375, 'loss_3': -16.55467987060547, 'loss_4': 2.042774200439453, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 10:35:04,876 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:04,876 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:10:54<39:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:12,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01489418838173151, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008419455960392952, 'eval_loss_2': 0.006474733352661133, 'eval_loss_3': -18.239791870117188, 'eval_loss_4': 1.5614702701568604, 'epoch': 16.69}
{'loss': 0.02, 'grad_norm': 6.455252170562744, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.012195156887173653, 'loss_2': 0.00778961181640625, 'loss_3': -16.54759979248047, 'loss_4': 2.3209500312805176, 'epoch': 16.69}
{'loss': 0.0461, 'grad_norm': 23.3444881439209, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.03265242651104927, 'loss_2': 0.013427734375, 'loss_3': -16.386072158813477, 'loss_4': 2.0412447452545166, 'epoch': 16.7}
{'loss': 0.011, 'grad_norm': 5.412103652954102, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.007325594779103994, 'loss_2': 0.00372314453125, 'loss_3': -16.30830955505371, 'loss_4': 2.7026772499084473, 'epoch': 16.7}
{'loss': 0.0131, 'grad_norm': 5.359570503234863, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.009696916677057743, 'loss_2': 0.0033721923828125, 'loss_3': -16.489360809326172, 'loss_4': 2.017827033996582, 'epoch': 16.71}
{'loss': 0.0168, 'grad_norm': 6.591339111328125, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.01215319987386465, 'loss_2': 0.00460052490234375, 'loss_3': -16.253456115722656, 'loss_4': 1.8999269008636475, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 10:35:12,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:12,241 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:01<39:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:19,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014139389619231224, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.048, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008188670501112938, 'eval_loss_2': 0.005950719118118286, 'eval_loss_3': -18.23567771911621, 'eval_loss_4': 1.520286202430725, 'epoch': 16.72}
{'loss': 0.0181, 'grad_norm': 6.144972801208496, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.006055821664631367, 'loss_2': 0.01202392578125, 'loss_3': -16.606908798217773, 'loss_4': 2.184309959411621, 'epoch': 16.72}
{'loss': 0.011, 'grad_norm': 5.3713603019714355, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.010232063010334969, 'loss_2': 0.0008153915405273438, 'loss_3': -16.627443313598633, 'loss_4': 2.3013854026794434, 'epoch': 16.73}
{'loss': 0.0061, 'grad_norm': 4.756468296051025, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.0059344531036913395, 'loss_2': 0.00014925003051757812, 'loss_3': -16.33236312866211, 'loss_4': 1.6608951091766357, 'epoch': 16.73}
{'loss': 0.0118, 'grad_norm': 4.817751884460449, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.007328166160732508, 'loss_2': 0.00450897216796875, 'loss_3': -16.4749755859375, 'loss_4': 2.1820685863494873, 'epoch': 16.74}
{'loss': 0.012, 'grad_norm': 5.939507961273193, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.008794043213129044, 'loss_2': 0.003173828125, 'loss_3': -16.35887336730957, 'loss_4': 1.7170629501342773, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 10:35:19,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:19,606 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:09<39:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:26,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011472507379949093, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0072332099080085754, 'eval_loss_2': 0.004239298403263092, 'eval_loss_3': -18.237808227539062, 'eval_loss_4': 1.3302552700042725, 'epoch': 16.74}
{'loss': 0.0074, 'grad_norm': 4.861635684967041, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.0053863548673689365, 'loss_2': 0.0020465850830078125, 'loss_3': -16.290454864501953, 'loss_4': 2.6709659099578857, 'epoch': 16.75}
{'loss': 0.0126, 'grad_norm': 6.002625942230225, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.008792638778686523, 'loss_2': 0.00379180908203125, 'loss_3': -16.471323013305664, 'loss_4': 1.5293471813201904, 'epoch': 16.76}
{'loss': 0.0278, 'grad_norm': 19.827144622802734, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.02416345477104187, 'loss_2': 0.00362396240234375, 'loss_3': -16.438547134399414, 'loss_4': 2.2036590576171875, 'epoch': 16.76}
{'loss': 0.0101, 'grad_norm': 5.223296642303467, 'learning_rate': 1.325e-05, 'loss_1': 0.006131631322205067, 'loss_2': 0.00399017333984375, 'loss_3': -16.196552276611328, 'loss_4': 1.6538809537887573, 'epoch': 16.77}
{'loss': 0.0186, 'grad_norm': 4.827406406402588, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.009618010371923447, 'loss_2': 0.0090179443359375, 'loss_3': -16.419754028320312, 'loss_4': 2.0701475143432617, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 10:35:26,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:26,963 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:16<39:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:34,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0167425274848938, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0072526345029473305, 'eval_loss_2': 0.009489893913269043, 'eval_loss_3': -18.239734649658203, 'eval_loss_4': 1.0541638135910034, 'epoch': 16.77}
{'loss': 0.0248, 'grad_norm': 5.042524337768555, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.0077677564695477486, 'loss_2': 0.0170135498046875, 'loss_3': -16.41661262512207, 'loss_4': 2.042947769165039, 'epoch': 16.78}
{'loss': 0.0175, 'grad_norm': 5.709660053253174, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.005306738894432783, 'loss_2': 0.012237548828125, 'loss_3': -16.293243408203125, 'loss_4': 1.9118839502334595, 'epoch': 16.78}
{'loss': 0.0117, 'grad_norm': 5.184963703155518, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.005914020352065563, 'loss_2': 0.005748748779296875, 'loss_3': -16.397544860839844, 'loss_4': 1.1833893060684204, 'epoch': 16.79}
{'loss': 0.0232, 'grad_norm': 4.621264457702637, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.005249808542430401, 'loss_2': 0.017974853515625, 'loss_3': -16.40853500366211, 'loss_4': 1.8040552139282227, 'epoch': 16.8}
{'loss': 0.0205, 'grad_norm': 9.970039367675781, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.015944818034768105, 'loss_2': 0.004604339599609375, 'loss_3': -16.570636749267578, 'loss_4': 1.8591618537902832, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 10:35:34,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:34,326 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:23<39:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:41,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01326657272875309, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006887683179229498, 'eval_loss_2': 0.006378889083862305, 'eval_loss_3': -18.25183868408203, 'eval_loss_4': 0.9512116312980652, 'epoch': 16.8}
{'loss': 0.014, 'grad_norm': 5.756407260894775, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.005705337040126324, 'loss_2': 0.0083160400390625, 'loss_3': -16.4512882232666, 'loss_4': 1.1950666904449463, 'epoch': 16.81}
{'loss': 0.0159, 'grad_norm': 8.804956436157227, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.010788673534989357, 'loss_2': 0.005084991455078125, 'loss_3': -16.490829467773438, 'loss_4': 1.6995761394500732, 'epoch': 16.81}
{'loss': 0.0068, 'grad_norm': 4.709667682647705, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.0031187415588647127, 'loss_2': 0.003726959228515625, 'loss_3': -16.362625122070312, 'loss_4': 1.197399377822876, 'epoch': 16.82}
{'loss': 0.0106, 'grad_norm': 6.562191963195801, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.010437358170747757, 'loss_2': 0.00013196468353271484, 'loss_3': -16.365005493164062, 'loss_4': 1.2783658504486084, 'epoch': 16.83}
{'loss': 0.0145, 'grad_norm': 6.95875358581543, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.014462909661233425, 'loss_2': 7.724761962890625e-05, 'loss_3': -16.223169326782227, 'loss_4': 1.270120620727539, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 10:35:41,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:41,684 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:31<39:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:49,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011362997815012932, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007455827668309212, 'eval_loss_2': 0.00390717014670372, 'eval_loss_3': -18.256011962890625, 'eval_loss_4': 0.8708353042602539, 'epoch': 16.83}
{'loss': 0.0127, 'grad_norm': 5.115253448486328, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.007735989987850189, 'loss_2': 0.00493621826171875, 'loss_3': -16.2159423828125, 'loss_4': 1.4610859155654907, 'epoch': 16.84}
{'loss': 0.0093, 'grad_norm': 5.224062442779541, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.005006628111004829, 'loss_2': 0.00434112548828125, 'loss_3': -16.48154067993164, 'loss_4': 0.9265868663787842, 'epoch': 16.84}
{'loss': 0.0227, 'grad_norm': 11.178380966186523, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.014426391571760178, 'loss_2': 0.00824737548828125, 'loss_3': -16.27794647216797, 'loss_4': 1.367431640625, 'epoch': 16.85}
{'loss': 0.0289, 'grad_norm': 6.965576171875, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.022471630945801735, 'loss_2': 0.006435394287109375, 'loss_3': -16.179685592651367, 'loss_4': 0.40587276220321655, 'epoch': 16.85}
{'loss': 0.0198, 'grad_norm': 6.835118770599365, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.011945339851081371, 'loss_2': 0.007843017578125, 'loss_3': -16.573463439941406, 'loss_4': 2.1029958724975586, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 10:35:49,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:49,036 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:38<39:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:56,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012029657140374184, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008089059963822365, 'eval_loss_2': 0.003940597176551819, 'eval_loss_3': -18.25424575805664, 'eval_loss_4': 0.6320423483848572, 'epoch': 16.86}
{'loss': 0.008, 'grad_norm': 5.124787330627441, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.006109720095992088, 'loss_2': 0.00189971923828125, 'loss_3': -16.352191925048828, 'loss_4': 1.9120875597000122, 'epoch': 16.87}
{'loss': 0.0095, 'grad_norm': 5.168614864349365, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.008393367752432823, 'loss_2': 0.001102447509765625, 'loss_3': -16.336410522460938, 'loss_4': 1.1564419269561768, 'epoch': 16.87}
{'loss': 0.0345, 'grad_norm': 17.502094268798828, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.029780304059386253, 'loss_2': 0.004680633544921875, 'loss_3': -16.3612117767334, 'loss_4': 1.5290734767913818, 'epoch': 16.88}
{'loss': 0.0081, 'grad_norm': 4.7086100578308105, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.0032450207509100437, 'loss_2': 0.00487518310546875, 'loss_3': -16.499759674072266, 'loss_4': 1.296311855316162, 'epoch': 16.88}
{'loss': 0.0074, 'grad_norm': 5.090181827545166, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.005015669856220484, 'loss_2': 0.0024261474609375, 'loss_3': -16.3139705657959, 'loss_4': 1.5039443969726562, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 10:35:56,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:56,394 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:11:45<38:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:03,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011504607275128365, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007827835157513618, 'eval_loss_2': 0.003676772117614746, 'eval_loss_3': -18.22808074951172, 'eval_loss_4': 0.5139321684837341, 'epoch': 16.89}
{'loss': 0.0074, 'grad_norm': 4.786987781524658, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.004777674563229084, 'loss_2': 0.002590179443359375, 'loss_3': -16.499448776245117, 'loss_4': 1.0932464599609375, 'epoch': 16.9}
{'loss': 0.0109, 'grad_norm': 6.238668918609619, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.00881699938327074, 'loss_2': 0.0021266937255859375, 'loss_3': -16.447185516357422, 'loss_4': 1.4670639038085938, 'epoch': 16.9}
{'loss': 0.0112, 'grad_norm': 6.01901388168335, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.007358758710324764, 'loss_2': 0.003833770751953125, 'loss_3': -16.399669647216797, 'loss_4': 1.206984043121338, 'epoch': 16.91}
{'loss': 0.0139, 'grad_norm': 6.719335079193115, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.01307060569524765, 'loss_2': 0.0008573532104492188, 'loss_3': -16.413833618164062, 'loss_4': 1.7808386087417603, 'epoch': 16.91}
{'loss': 0.01, 'grad_norm': 5.270437717437744, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.006457468960434198, 'loss_2': 0.0035495758056640625, 'loss_3': -16.18022918701172, 'loss_4': 1.0112202167510986, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 10:36:03,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:03,748 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:11:53<38:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:11,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011588518507778645, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00853736512362957, 'eval_loss_2': 0.003051154315471649, 'eval_loss_3': -18.2499942779541, 'eval_loss_4': 0.49163132905960083, 'epoch': 16.92}
{'loss': 0.0215, 'grad_norm': 6.41738224029541, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.011902892962098122, 'loss_2': 0.00962066650390625, 'loss_3': -16.47229766845703, 'loss_4': 1.3171461820602417, 'epoch': 16.92}
{'loss': 0.0103, 'grad_norm': 5.852755546569824, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.00858023576438427, 'loss_2': 0.0017681121826171875, 'loss_3': -16.313720703125, 'loss_4': 1.036601185798645, 'epoch': 16.93}
{'loss': 0.0143, 'grad_norm': 4.8871750831604, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.005961502902209759, 'loss_2': 0.0083770751953125, 'loss_3': -16.219223022460938, 'loss_4': 1.5598303079605103, 'epoch': 16.94}
{'loss': 0.0132, 'grad_norm': 5.289578437805176, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.004522327333688736, 'loss_2': 0.00868988037109375, 'loss_3': -16.34537124633789, 'loss_4': 0.5001803040504456, 'epoch': 16.94}
{'loss': 0.0091, 'grad_norm': 4.663952350616455, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.006263893563300371, 'loss_2': 0.0028228759765625, 'loss_3': -16.493682861328125, 'loss_4': 0.9394971132278442, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 10:36:11,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:11,110 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:00<38:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:18,464 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012623835355043411, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008926850743591785, 'eval_loss_2': 0.0036969855427742004, 'eval_loss_3': -18.220903396606445, 'eval_loss_4': 0.49583861231803894, 'epoch': 16.95}
{'loss': 0.0149, 'grad_norm': 5.8483781814575195, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.006059913896024227, 'loss_2': 0.00887298583984375, 'loss_3': -16.255935668945312, 'loss_4': 1.196974515914917, 'epoch': 16.95}
{'loss': 0.0069, 'grad_norm': 4.512664318084717, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.004487880039960146, 'loss_2': 0.0024127960205078125, 'loss_3': -16.228137969970703, 'loss_4': 1.0687414407730103, 'epoch': 16.96}
{'loss': 0.0084, 'grad_norm': 5.692339897155762, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.007955487817525864, 'loss_2': 0.00048732757568359375, 'loss_3': -16.166831970214844, 'loss_4': 1.1618801355361938, 'epoch': 16.97}
{'loss': 0.0193, 'grad_norm': 6.549725532531738, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.015838123857975006, 'loss_2': 0.0034332275390625, 'loss_3': -16.313678741455078, 'loss_4': 0.7736859321594238, 'epoch': 16.97}
{'loss': 0.0115, 'grad_norm': 5.678070545196533, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.009339315816760063, 'loss_2': 0.00214385986328125, 'loss_3': -16.304306030273438, 'loss_4': 0.8449164628982544, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 10:36:18,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:18,464 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:07<36:30,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:36:25,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013365136459469795, 'eval_runtime': 3.8222, 'eval_samples_per_second': 267.907, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.009332897141575813, 'eval_loss_2': 0.004032239317893982, 'eval_loss_3': -18.216737747192383, 'eval_loss_4': 0.5017827153205872, 'epoch': 16.98}
{'loss': 0.0217, 'grad_norm': 9.091403007507324, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.01956465281546116, 'loss_2': 0.002166748046875, 'loss_3': -16.256874084472656, 'loss_4': 1.9922692775726318, 'epoch': 16.98}
{'loss': 0.0131, 'grad_norm': 7.573404312133789, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.007865137420594692, 'loss_2': 0.005279541015625, 'loss_3': -16.333885192871094, 'loss_4': 0.9150878190994263, 'epoch': 16.99}
{'loss': 0.0096, 'grad_norm': 5.265524864196777, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.007143613416701555, 'loss_2': 0.0024700164794921875, 'loss_3': -16.32842445373535, 'loss_4': 1.0073037147521973, 'epoch': 16.99}
{'loss': 0.0039, 'grad_norm': 6.057242393493652, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.0019210348837077618, 'loss_2': 0.0020084381103515625, 'loss_3': -16.55803108215332, 'loss_4': 1.498490571975708, 'epoch': 17.0}
{'loss': 0.0172, 'grad_norm': 5.777423858642578, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.014487721025943756, 'loss_2': 0.002716064453125, 'loss_3': -16.348102569580078, 'loss_4': 0.9789597988128662, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 10:36:25,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:25,530 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:15<38:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:36:32,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012750793248414993, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008223195560276508, 'eval_loss_2': 0.00452759861946106, 'eval_loss_3': -18.229290008544922, 'eval_loss_4': 0.6273605227470398, 'epoch': 17.01}
{'loss': 0.0235, 'grad_norm': 14.325695037841797, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.021719269454479218, 'loss_2': 0.0017642974853515625, 'loss_3': -16.412220001220703, 'loss_4': 0.7638612389564514, 'epoch': 17.01}
{'loss': 0.0127, 'grad_norm': 6.526352405548096, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.012226640246808529, 'loss_2': 0.00045680999755859375, 'loss_3': -16.2913761138916, 'loss_4': 0.44039303064346313, 'epoch': 17.02}
{'loss': 0.0227, 'grad_norm': 10.523436546325684, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.017371460795402527, 'loss_2': 0.00536346435546875, 'loss_3': -16.458724975585938, 'loss_4': 0.8251283168792725, 'epoch': 17.02}
{'loss': 0.0057, 'grad_norm': 4.404687404632568, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.005111312959343195, 'loss_2': 0.0005979537963867188, 'loss_3': -16.186309814453125, 'loss_4': 1.4548735618591309, 'epoch': 17.03}
{'loss': 0.0165, 'grad_norm': 6.114035129547119, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.011814631521701813, 'loss_2': 0.004703521728515625, 'loss_3': -16.559314727783203, 'loss_4': 0.6412183046340942, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 10:36:32,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:32,888 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:22<38:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:40,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011352656409144402, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0072646718472242355, 'eval_loss_2': 0.004087984561920166, 'eval_loss_3': -18.232093811035156, 'eval_loss_4': 0.7248376607894897, 'epoch': 17.03}
{'loss': 0.0056, 'grad_norm': 4.3145246505737305, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.004732948262244463, 'loss_2': 0.000827789306640625, 'loss_3': -16.516948699951172, 'loss_4': 1.0579745769500732, 'epoch': 17.04}
{'loss': 0.0077, 'grad_norm': 4.106944561004639, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.005934171378612518, 'loss_2': 0.00171661376953125, 'loss_3': -16.377201080322266, 'loss_4': 1.4940743446350098, 'epoch': 17.05}
{'loss': 0.014, 'grad_norm': 6.962184906005859, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.010437196120619774, 'loss_2': 0.0035400390625, 'loss_3': -16.230022430419922, 'loss_4': 1.9325332641601562, 'epoch': 17.05}
{'loss': 0.006, 'grad_norm': 4.283413887023926, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.0038193832151591778, 'loss_2': 0.0021533966064453125, 'loss_3': -16.468833923339844, 'loss_4': 1.539311170578003, 'epoch': 17.06}
{'loss': 0.0225, 'grad_norm': 13.099190711975098, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.021895209327340126, 'loss_2': 0.0005750656127929688, 'loss_3': -16.336673736572266, 'loss_4': 2.051511287689209, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 10:36:40,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:40,245 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:29<38:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:47,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00940932147204876, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.978, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006406095810234547, 'eval_loss_2': 0.003003224730491638, 'eval_loss_3': -18.258588790893555, 'eval_loss_4': 0.847374439239502, 'epoch': 17.06}
{'loss': 0.0175, 'grad_norm': 6.610804080963135, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.01073588989675045, 'loss_2': 0.006717681884765625, 'loss_3': -16.274383544921875, 'loss_4': 1.4077199697494507, 'epoch': 17.07}
{'loss': 0.0072, 'grad_norm': 4.781617164611816, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.006654955912381411, 'loss_2': 0.0005502700805664062, 'loss_3': -16.321008682250977, 'loss_4': 1.2847709655761719, 'epoch': 17.08}
{'loss': 0.0066, 'grad_norm': 5.400661945343018, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.006307236384600401, 'loss_2': 0.00033926963806152344, 'loss_3': -16.506378173828125, 'loss_4': 1.7371536493301392, 'epoch': 17.08}
{'loss': 0.0122, 'grad_norm': 5.776538848876953, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.009439750574529171, 'loss_2': 0.002758026123046875, 'loss_3': -16.468177795410156, 'loss_4': 1.2428052425384521, 'epoch': 17.09}
{'loss': 0.014, 'grad_norm': 7.429044723510742, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.011590411886572838, 'loss_2': 0.0023784637451171875, 'loss_3': -16.45882797241211, 'loss_4': 1.6680831909179688, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 10:36:47,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:47,591 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:37<38:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:54,947 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012303190305829048, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006842152681201696, 'eval_loss_2': 0.0054610371589660645, 'eval_loss_3': -18.266904830932617, 'eval_loss_4': 1.0356742143630981, 'epoch': 17.09}
{'loss': 0.0292, 'grad_norm': 9.547831535339355, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.01979704201221466, 'loss_2': 0.009368896484375, 'loss_3': -16.409236907958984, 'loss_4': 0.9444947242736816, 'epoch': 17.1}
{'loss': 0.0183, 'grad_norm': 6.340037822723389, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.01557279285043478, 'loss_2': 0.00276947021484375, 'loss_3': -16.363441467285156, 'loss_4': 1.8593833446502686, 'epoch': 17.1}
{'loss': 0.0107, 'grad_norm': 5.425929546356201, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.010556713677942753, 'loss_2': 0.00011390447616577148, 'loss_3': -16.519044876098633, 'loss_4': 1.4481858015060425, 'epoch': 17.11}
{'loss': 0.0087, 'grad_norm': 4.879642009735107, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.008594661019742489, 'loss_2': 0.00015306472778320312, 'loss_3': -16.486373901367188, 'loss_4': 1.425174593925476, 'epoch': 17.12}
{'loss': 0.0099, 'grad_norm': 5.089460372924805, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.006137857213616371, 'loss_2': 0.003734588623046875, 'loss_3': -16.323041915893555, 'loss_4': 1.8674771785736084, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 10:36:54,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:54,947 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:44<38:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:02,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009980805218219757, 'eval_runtime': 3.8205, 'eval_samples_per_second': 268.026, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.006699391175061464, 'eval_loss_2': 0.00328141450881958, 'eval_loss_3': -18.28341293334961, 'eval_loss_4': 1.0903587341308594, 'epoch': 17.12}
{'loss': 0.0147, 'grad_norm': 5.1028056144714355, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.0069961994886398315, 'loss_2': 0.007663726806640625, 'loss_3': -16.239471435546875, 'loss_4': 1.7055072784423828, 'epoch': 17.13}
{'loss': 0.0082, 'grad_norm': 5.049798488616943, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.005333759356290102, 'loss_2': 0.0028533935546875, 'loss_3': -16.538969039916992, 'loss_4': 1.3096401691436768, 'epoch': 17.13}
{'loss': 0.0195, 'grad_norm': 6.411962509155273, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.013482680544257164, 'loss_2': 0.00601959228515625, 'loss_3': -16.41530418395996, 'loss_4': 1.8913482427597046, 'epoch': 17.14}
{'loss': 0.0074, 'grad_norm': 6.3586106300354, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.005555406678467989, 'loss_2': 0.00189208984375, 'loss_3': -16.482532501220703, 'loss_4': 1.9030299186706543, 'epoch': 17.15}
{'loss': 0.0137, 'grad_norm': 5.895148277282715, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.010844485834240913, 'loss_2': 0.0028629302978515625, 'loss_3': -16.480998992919922, 'loss_4': 1.7916704416275024, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 10:37:02,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:02,325 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:12:51<38:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:09,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011144802905619144, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.892, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006613240111619234, 'eval_loss_2': 0.004531562328338623, 'eval_loss_3': -18.301164627075195, 'eval_loss_4': 1.0606169700622559, 'epoch': 17.15}
{'loss': 0.0217, 'grad_norm': 11.123295783996582, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.014900842681527138, 'loss_2': 0.00682830810546875, 'loss_3': -16.516515731811523, 'loss_4': 1.7908339500427246, 'epoch': 17.16}
{'loss': 0.013, 'grad_norm': 5.209017753601074, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.008569056168198586, 'loss_2': 0.00444793701171875, 'loss_3': -16.369949340820312, 'loss_4': 1.3454616069793701, 'epoch': 17.16}
{'loss': 0.0076, 'grad_norm': 5.000422477722168, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.006521069910377264, 'loss_2': 0.0010728836059570312, 'loss_3': -16.474918365478516, 'loss_4': 0.8116636872291565, 'epoch': 17.17}
{'loss': 0.012, 'grad_norm': 5.417877674102783, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.010963558219373226, 'loss_2': 0.0010700225830078125, 'loss_3': -16.562652587890625, 'loss_4': 1.5169525146484375, 'epoch': 17.17}
{'loss': 0.0063, 'grad_norm': 4.350255012512207, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.00414329394698143, 'loss_2': 0.0021343231201171875, 'loss_3': -16.495458602905273, 'loss_4': 1.2554736137390137, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 10:37:09,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:09,680 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:12:59<38:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:17,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009421238675713539, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.77, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006186300422996283, 'eval_loss_2': 0.0032349377870559692, 'eval_loss_3': -18.30108070373535, 'eval_loss_4': 0.9924359321594238, 'epoch': 17.18}
{'loss': 0.0129, 'grad_norm': 4.728367805480957, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.009045980870723724, 'loss_2': 0.00388336181640625, 'loss_3': -16.51580810546875, 'loss_4': 1.8200169801712036, 'epoch': 17.19}
{'loss': 0.0167, 'grad_norm': 8.534316062927246, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.013507622294127941, 'loss_2': 0.00319671630859375, 'loss_3': -16.309885025024414, 'loss_4': 1.736955165863037, 'epoch': 17.19}
{'loss': 0.0118, 'grad_norm': 5.508153915405273, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.007538525387644768, 'loss_2': 0.00431060791015625, 'loss_3': -16.316452026367188, 'loss_4': 1.8568001985549927, 'epoch': 17.2}
{'loss': 0.0081, 'grad_norm': 4.318449974060059, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.006732510402798653, 'loss_2': 0.0014019012451171875, 'loss_3': -16.515869140625, 'loss_4': 1.4884313344955444, 'epoch': 17.2}
{'loss': 0.0076, 'grad_norm': 6.03763484954834, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.005780487321317196, 'loss_2': 0.001811981201171875, 'loss_3': -16.329742431640625, 'loss_4': 1.2823519706726074, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 10:37:17,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:17,018 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:06<37:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:24,360 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01011315081268549, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.542, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006420821882784367, 'eval_loss_2': 0.003692328929901123, 'eval_loss_3': -18.30389404296875, 'eval_loss_4': 0.9384746551513672, 'epoch': 17.21}
{'loss': 0.0124, 'grad_norm': 5.963533401489258, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.00910904910415411, 'loss_2': 0.003253936767578125, 'loss_3': -16.190683364868164, 'loss_4': 1.6240942478179932, 'epoch': 17.22}
{'loss': 0.022, 'grad_norm': 7.752959728240967, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.02078254707157612, 'loss_2': 0.0012598037719726562, 'loss_3': -16.65723991394043, 'loss_4': 1.508422613143921, 'epoch': 17.22}
{'loss': 0.012, 'grad_norm': 5.842400074005127, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.00973745621740818, 'loss_2': 0.002292633056640625, 'loss_3': -16.604473114013672, 'loss_4': 1.6519094705581665, 'epoch': 17.23}
{'loss': 0.0114, 'grad_norm': 5.451910495758057, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.010383876040577888, 'loss_2': 0.000972747802734375, 'loss_3': -16.2604923248291, 'loss_4': 1.4748327732086182, 'epoch': 17.23}
{'loss': 0.0124, 'grad_norm': 5.754070281982422, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.008154218085110188, 'loss_2': 0.0042266845703125, 'loss_3': -16.662586212158203, 'loss_4': 2.083725929260254, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 10:37:24,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:24,361 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:13<37:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:31,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009728695265948772, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.215, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0067696222104132175, 'eval_loss_2': 0.0029590725898742676, 'eval_loss_3': -18.31355857849121, 'eval_loss_4': 0.9459033012390137, 'epoch': 17.24}
{'loss': 0.0104, 'grad_norm': 4.738515853881836, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.007052968256175518, 'loss_2': 0.003337860107421875, 'loss_3': -16.47570037841797, 'loss_4': 1.2493298053741455, 'epoch': 17.24}
{'loss': 0.0152, 'grad_norm': 9.159029006958008, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.013416269794106483, 'loss_2': 0.0017881393432617188, 'loss_3': -16.482425689697266, 'loss_4': 1.6777174472808838, 'epoch': 17.25}
{'loss': 0.0189, 'grad_norm': 7.0275397300720215, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.011660829186439514, 'loss_2': 0.007198333740234375, 'loss_3': -16.529621124267578, 'loss_4': 1.033993124961853, 'epoch': 17.26}
{'loss': 0.0078, 'grad_norm': 5.695261478424072, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.0061981868930161, 'loss_2': 0.0016078948974609375, 'loss_3': -16.442474365234375, 'loss_4': 1.445534586906433, 'epoch': 17.26}
{'loss': 0.0131, 'grad_norm': 5.355603218078613, 'learning_rate': 1.275e-05, 'loss_1': 0.009675607085227966, 'loss_2': 0.003444671630859375, 'loss_3': -16.330047607421875, 'loss_4': 1.576685905456543, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 10:37:31,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:31,712 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:21<37:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:39,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009423512034118176, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.005883263889700174, 'eval_loss_2': 0.003540247678756714, 'eval_loss_3': -18.292436599731445, 'eval_loss_4': 1.0828051567077637, 'epoch': 17.27}
{'loss': 0.0117, 'grad_norm': 4.723917007446289, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.007998286746442318, 'loss_2': 0.00365447998046875, 'loss_3': -16.2894229888916, 'loss_4': 2.2418322563171387, 'epoch': 17.27}
{'loss': 0.0202, 'grad_norm': 5.801525592803955, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.01940101571381092, 'loss_2': 0.0008459091186523438, 'loss_3': -16.59233856201172, 'loss_4': 1.4289462566375732, 'epoch': 17.28}
{'loss': 0.0158, 'grad_norm': 7.082216262817383, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.014044360257685184, 'loss_2': 0.0017223358154296875, 'loss_3': -16.469161987304688, 'loss_4': 1.558508038520813, 'epoch': 17.28}
{'loss': 0.0241, 'grad_norm': 12.67420482635498, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.0241258405148983, 'loss_2': 1.7642974853515625e-05, 'loss_3': -16.378084182739258, 'loss_4': 2.1311511993408203, 'epoch': 17.29}
{'loss': 0.0073, 'grad_norm': 5.843944549560547, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.00694073224440217, 'loss_2': 0.00035262107849121094, 'loss_3': -16.34488868713379, 'loss_4': 1.9486870765686035, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 10:37:39,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:39,058 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:28<37:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:46,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009055687114596367, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.692, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005149629898369312, 'eval_loss_2': 0.00390605628490448, 'eval_loss_3': -18.27543067932129, 'eval_loss_4': 1.1344653367996216, 'epoch': 17.3}
{'loss': 0.0105, 'grad_norm': 6.236546993255615, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.008329212665557861, 'loss_2': 0.0022029876708984375, 'loss_3': -16.067157745361328, 'loss_4': 1.3547366857528687, 'epoch': 17.3}
{'loss': 0.0231, 'grad_norm': 15.181783676147461, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.0220449548214674, 'loss_2': 0.0010709762573242188, 'loss_3': -16.374832153320312, 'loss_4': 1.8263113498687744, 'epoch': 17.31}
{'loss': 0.0057, 'grad_norm': 4.8332319259643555, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.005636606365442276, 'loss_2': 7.593631744384766e-05, 'loss_3': -16.304737091064453, 'loss_4': 1.888540267944336, 'epoch': 17.31}
{'loss': 0.0086, 'grad_norm': 5.0695295333862305, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.007894476875662804, 'loss_2': 0.0007038116455078125, 'loss_3': -16.340124130249023, 'loss_4': 1.7625263929367065, 'epoch': 17.32}
{'loss': 0.0162, 'grad_norm': 6.028476715087891, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.01028207503259182, 'loss_2': 0.005950927734375, 'loss_3': -16.003170013427734, 'loss_4': 1.6777372360229492, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 10:37:46,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:46,416 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:35<37:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:53,762 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009805095382034779, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0049746232107281685, 'eval_loss_2': 0.00483047217130661, 'eval_loss_3': -18.312467575073242, 'eval_loss_4': 1.2363390922546387, 'epoch': 17.33}
{'loss': 0.0143, 'grad_norm': 6.685272216796875, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.012069333344697952, 'loss_2': 0.002231597900390625, 'loss_3': -16.510356903076172, 'loss_4': 1.8608595132827759, 'epoch': 17.33}
{'loss': 0.0113, 'grad_norm': 9.980860710144043, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.011162527836859226, 'loss_2': 8.821487426757812e-05, 'loss_3': -16.461484909057617, 'loss_4': 1.608924150466919, 'epoch': 17.34}
{'loss': 0.0193, 'grad_norm': 9.376798629760742, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.019099202007055283, 'loss_2': 0.00016379356384277344, 'loss_3': -16.238758087158203, 'loss_4': 1.4141242504119873, 'epoch': 17.34}
{'loss': 0.0288, 'grad_norm': 15.69526481628418, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.028019877150654793, 'loss_2': 0.0008106231689453125, 'loss_3': -16.288028717041016, 'loss_4': 2.039578676223755, 'epoch': 17.35}
{'loss': 0.0142, 'grad_norm': 4.774705410003662, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.009835369884967804, 'loss_2': 0.00435638427734375, 'loss_3': -16.355712890625, 'loss_4': 2.2126407623291016, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 10:37:53,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:53,762 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:43<37:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:01,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00853390246629715, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.553, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.004963733721524477, 'eval_loss_2': 0.00357016921043396, 'eval_loss_3': -18.315282821655273, 'eval_loss_4': 1.2733922004699707, 'epoch': 17.35}
{'loss': 0.0101, 'grad_norm': 6.501957416534424, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.007486934773623943, 'loss_2': 0.0025691986083984375, 'loss_3': -16.381969451904297, 'loss_4': 1.290122389793396, 'epoch': 17.36}
{'loss': 0.0252, 'grad_norm': 11.715706825256348, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.02214265987277031, 'loss_2': 0.0030460357666015625, 'loss_3': -16.40291404724121, 'loss_4': 2.411799669265747, 'epoch': 17.37}
{'loss': 0.0139, 'grad_norm': 5.086212158203125, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.0072784945368766785, 'loss_2': 0.00664520263671875, 'loss_3': -16.276111602783203, 'loss_4': 1.9569435119628906, 'epoch': 17.37}
{'loss': 0.0102, 'grad_norm': 4.960559368133545, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.006894291844218969, 'loss_2': 0.003284454345703125, 'loss_3': -16.26462173461914, 'loss_4': 1.699547529220581, 'epoch': 17.38}
{'loss': 0.009, 'grad_norm': 5.60269832611084, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.007032085210084915, 'loss_2': 0.0019683837890625, 'loss_3': -16.321475982666016, 'loss_4': 2.04532790184021, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 10:38:01,098 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:01,098 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:13:50<37:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:08,438 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007529759779572487, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.623, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005369837395846844, 'eval_loss_2': 0.0021599233150482178, 'eval_loss_3': -18.303258895874023, 'eval_loss_4': 1.2470853328704834, 'epoch': 17.38}
{'loss': 0.0125, 'grad_norm': 5.630484104156494, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.00968674011528492, 'loss_2': 0.002834320068359375, 'loss_3': -16.317203521728516, 'loss_4': 2.145763874053955, 'epoch': 17.39}
{'loss': 0.0138, 'grad_norm': 6.24648380279541, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.011945964768528938, 'loss_2': 0.001811981201171875, 'loss_3': -16.54387664794922, 'loss_4': 1.9018783569335938, 'epoch': 17.4}
{'loss': 0.0306, 'grad_norm': 11.779070854187012, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.02640799805521965, 'loss_2': 0.0041656494140625, 'loss_3': -16.299564361572266, 'loss_4': 1.8182978630065918, 'epoch': 17.4}
{'loss': 0.0494, 'grad_norm': 14.206122398376465, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.04426959529519081, 'loss_2': 0.005176544189453125, 'loss_3': -16.333507537841797, 'loss_4': 1.3477834463119507, 'epoch': 17.41}
{'loss': 0.01, 'grad_norm': 5.968031406402588, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.006907141767442226, 'loss_2': 0.003139495849609375, 'loss_3': -16.379737854003906, 'loss_4': 1.8700352907180786, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 10:38:08,438 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:08,438 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:13:57<37:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:15,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008377587422728539, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.683, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.005586331244558096, 'eval_loss_2': 0.0027912557125091553, 'eval_loss_3': -18.29713249206543, 'eval_loss_4': 1.159031629562378, 'epoch': 17.41}
{'loss': 0.0098, 'grad_norm': 5.115196228027344, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.008005321957170963, 'loss_2': 0.0018138885498046875, 'loss_3': -16.297269821166992, 'loss_4': 1.7633785009384155, 'epoch': 17.42}
{'loss': 0.0092, 'grad_norm': 5.389841079711914, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.006846737116575241, 'loss_2': 0.002376556396484375, 'loss_3': -16.410816192626953, 'loss_4': 2.059813976287842, 'epoch': 17.42}
{'loss': 0.0091, 'grad_norm': 5.666029453277588, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.007476351223886013, 'loss_2': 0.0016231536865234375, 'loss_3': -16.566972732543945, 'loss_4': 1.3713839054107666, 'epoch': 17.43}
{'loss': 0.0124, 'grad_norm': 5.043910503387451, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.009821749292314053, 'loss_2': 0.0025768280029296875, 'loss_3': -16.492130279541016, 'loss_4': 1.5486602783203125, 'epoch': 17.44}
{'loss': 0.0165, 'grad_norm': 5.320802688598633, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.00825401023030281, 'loss_2': 0.008270263671875, 'loss_3': -16.48876190185547, 'loss_4': 1.7741622924804688, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 10:38:15,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:15,774 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:05<37:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:23,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007209403440356255, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005042893812060356, 'eval_loss_2': 0.0021665096282958984, 'eval_loss_3': -18.30957794189453, 'eval_loss_4': 1.0745645761489868, 'epoch': 17.44}
{'loss': 0.0073, 'grad_norm': 5.347269058227539, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.005928460042923689, 'loss_2': 0.0013637542724609375, 'loss_3': -16.59859848022461, 'loss_4': 1.6065504550933838, 'epoch': 17.45}
{'loss': 0.0283, 'grad_norm': 13.676207542419434, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.018660930916666985, 'loss_2': 0.00966644287109375, 'loss_3': -16.432174682617188, 'loss_4': 2.059171676635742, 'epoch': 17.45}
{'loss': 0.0235, 'grad_norm': 7.867599964141846, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.014505256898701191, 'loss_2': 0.0090179443359375, 'loss_3': -16.372928619384766, 'loss_4': 1.2616827487945557, 'epoch': 17.46}
{'loss': 0.0116, 'grad_norm': 8.646766662597656, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.008921008557081223, 'loss_2': 0.00270843505859375, 'loss_3': -16.6251220703125, 'loss_4': 2.0066678524017334, 'epoch': 17.47}
{'loss': 0.0169, 'grad_norm': 7.301681041717529, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.014554924331605434, 'loss_2': 0.002376556396484375, 'loss_3': -16.536720275878906, 'loss_4': 2.1191864013671875, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 10:38:23,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:23,122 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:12<37:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:30,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007526179309934378, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0040975408628582954, 'eval_loss_2': 0.003428637981414795, 'eval_loss_3': -18.330860137939453, 'eval_loss_4': 0.9971437454223633, 'epoch': 17.47}
{'loss': 0.0188, 'grad_norm': 5.587449550628662, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.012018924579024315, 'loss_2': 0.006732940673828125, 'loss_3': -16.556888580322266, 'loss_4': 1.3486404418945312, 'epoch': 17.48}
{'loss': 0.0073, 'grad_norm': 5.545793056488037, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.005395948886871338, 'loss_2': 0.0019512176513671875, 'loss_3': -16.315231323242188, 'loss_4': 1.6621406078338623, 'epoch': 17.48}
{'loss': 0.0079, 'grad_norm': 5.29555082321167, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.006313514430075884, 'loss_2': 0.0015583038330078125, 'loss_3': -16.483314514160156, 'loss_4': 2.1063997745513916, 'epoch': 17.49}
{'loss': 0.0147, 'grad_norm': 5.22022008895874, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.008498028852045536, 'loss_2': 0.00624847412109375, 'loss_3': -16.43909454345703, 'loss_4': 1.9857792854309082, 'epoch': 17.49}
{'loss': 0.0109, 'grad_norm': 5.422540664672852, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.00556261045858264, 'loss_2': 0.005298614501953125, 'loss_3': -16.293193817138672, 'loss_4': 1.4216794967651367, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 10:38:30,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:30,470 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:16<37:09,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 10:38:34,273 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-3010
[INFO|configuration_utils.py:420] 2025-01-21 10:38:34,275 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-3010/config.json                                                                             
{'eval_loss': 0.0055117118172347546, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.351, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0034921872429549694, 'eval_loss_2': 0.002019524574279785, 'eval_loss_3': -18.329883575439453, 'eval_loss_4': 1.0981287956237793, 'epoch': 17.5}
[INFO|modeling_utils.py:2988] 2025-01-21 10:38:34,790 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-3010/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:38:34,791 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-3010/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:38:34,791 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-3010/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:38:35,826 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-2305] due to args.save_total_limit
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:21<41:18,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 10:38:39,462 >>
{'loss': 0.0105, 'grad_norm': 5.403026103973389, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.008647957816720009, 'loss_2': 0.0018138885498046875, 'loss_3': -16.497783660888672, 'loss_4': 1.6577346324920654, 'epoch': 17.51}
{'loss': 0.0178, 'grad_norm': 10.631179809570312, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.01696893572807312, 'loss_2': 0.0008478164672851562, 'loss_3': -16.48906898498535, 'loss_4': 2.2517642974853516, 'epoch': 17.51}
{'loss': 0.0216, 'grad_norm': 12.527939796447754, 'learning_rate': 1.25e-05, 'loss_1': 0.02063366398215294, 'loss_2': 0.001003265380859375, 'loss_3': -16.2224178314209, 'loss_4': 1.8153159618377686, 'epoch': 17.52}
{'loss': 0.0105, 'grad_norm': 5.695864200592041, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.00915660709142685, 'loss_2': 0.0013179779052734375, 'loss_3': -16.23921012878418, 'loss_4': 2.3340773582458496, 'epoch': 17.52}
{'loss': 0.0214, 'grad_norm': 10.151474952697754, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.01770290918648243, 'loss_2': 0.003711700439453125, 'loss_3': -16.323537826538086, 'loss_4': 2.149531126022339, 'epoch': 17.53}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:38:39,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:39,462 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:28<37:41,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:38:46,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01168394461274147, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0048412722535431385, 'eval_loss_2': 0.006842672824859619, 'eval_loss_3': -18.311988830566406, 'eval_loss_4': 1.0988352298736572, 'epoch': 17.53}
{'loss': 0.0244, 'grad_norm': 11.693341255187988, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.02033868059515953, 'loss_2': 0.0040435791015625, 'loss_3': -16.327821731567383, 'loss_4': 2.0743019580841064, 'epoch': 17.53}
{'loss': 0.0142, 'grad_norm': 6.587570667266846, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.007229594513773918, 'loss_2': 0.0070037841796875, 'loss_3': -16.55350685119629, 'loss_4': 1.6707096099853516, 'epoch': 17.54}
{'loss': 0.0203, 'grad_norm': 5.379201412200928, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.008805723860859871, 'loss_2': 0.01153564453125, 'loss_3': -16.227519989013672, 'loss_4': 1.2029082775115967, 'epoch': 17.55}
{'loss': 0.0127, 'grad_norm': 6.011043548583984, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.009278702549636364, 'loss_2': 0.0033931732177734375, 'loss_3': -16.462806701660156, 'loss_4': 1.0858769416809082, 'epoch': 17.55}
{'loss': 0.0195, 'grad_norm': 4.430502891540527, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.007126146927475929, 'loss_2': 0.0123291015625, 'loss_3': -16.54157257080078, 'loss_4': 1.9033477306365967, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 10:38:46,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:46,805 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:36<37:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:54,148 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011472586542367935, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0046936324797570705, 'eval_loss_2': 0.0067789554595947266, 'eval_loss_3': -18.313955307006836, 'eval_loss_4': 1.0570824146270752, 'epoch': 17.56}
{'loss': 0.0166, 'grad_norm': 5.030433654785156, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.005933993496000767, 'loss_2': 0.0106201171875, 'loss_3': -16.61473846435547, 'loss_4': 1.5056174993515015, 'epoch': 17.56}
{'loss': 0.0316, 'grad_norm': 12.422174453735352, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.02385726571083069, 'loss_2': 0.00777435302734375, 'loss_3': -16.403291702270508, 'loss_4': 1.7824290990829468, 'epoch': 17.57}
{'loss': 0.0207, 'grad_norm': 15.601802825927734, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.0182467233389616, 'loss_2': 0.002452850341796875, 'loss_3': -16.367897033691406, 'loss_4': 1.767290472984314, 'epoch': 17.58}
{'loss': 0.0141, 'grad_norm': 5.282900810241699, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.0069978609681129456, 'loss_2': 0.0071258544921875, 'loss_3': -16.603702545166016, 'loss_4': 1.7358217239379883, 'epoch': 17.58}
{'loss': 0.0113, 'grad_norm': 5.2193379402160645, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.00791393592953682, 'loss_2': 0.003368377685546875, 'loss_3': -16.47019386291504, 'loss_4': 2.023817777633667, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 10:38:54,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:54,148 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:43<36:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:01,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007966247387230396, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004701447207480669, 'eval_loss_2': 0.00326479971408844, 'eval_loss_3': -18.31056022644043, 'eval_loss_4': 1.096233606338501, 'epoch': 17.59}
{'loss': 0.0132, 'grad_norm': 8.28419017791748, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.011279258877038956, 'loss_2': 0.0019016265869140625, 'loss_3': -16.415939331054688, 'loss_4': 2.1923439502716064, 'epoch': 17.59}
{'loss': 0.0134, 'grad_norm': 5.0766119956970215, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.010194697417318821, 'loss_2': 0.0031890869140625, 'loss_3': -16.6304931640625, 'loss_4': 1.8489762544631958, 'epoch': 17.6}
{'loss': 0.0134, 'grad_norm': 6.488113880157471, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.010059409774839878, 'loss_2': 0.003314971923828125, 'loss_3': -16.479766845703125, 'loss_4': 1.8500280380249023, 'epoch': 17.6}
{'loss': 0.02, 'grad_norm': 6.343886375427246, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.011405264027416706, 'loss_2': 0.008575439453125, 'loss_3': -16.554283142089844, 'loss_4': 2.1386280059814453, 'epoch': 17.61}
{'loss': 0.0279, 'grad_norm': 9.917304992675781, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.018253708258271217, 'loss_2': 0.0096893310546875, 'loss_3': -16.602210998535156, 'loss_4': 1.8268463611602783, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 10:39:01,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:01,488 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:14:51<36:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:08,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008889459073543549, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.685, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005278282333165407, 'eval_loss_2': 0.0036111772060394287, 'eval_loss_3': -18.314302444458008, 'eval_loss_4': 1.126396894454956, 'epoch': 17.62}
{'loss': 0.013, 'grad_norm': 5.564688682556152, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.006964194122701883, 'loss_2': 0.006000518798828125, 'loss_3': -16.504531860351562, 'loss_4': 1.823737382888794, 'epoch': 17.62}
{'loss': 0.0111, 'grad_norm': 4.853829860687256, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.00822178553789854, 'loss_2': 0.00292205810546875, 'loss_3': -16.56727409362793, 'loss_4': 1.427963376045227, 'epoch': 17.63}
{'loss': 0.0134, 'grad_norm': 5.316022872924805, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.00939538050442934, 'loss_2': 0.0040435791015625, 'loss_3': -16.500139236450195, 'loss_4': 2.0472006797790527, 'epoch': 17.63}
{'loss': 0.0087, 'grad_norm': 4.682528018951416, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.0041849189437925816, 'loss_2': 0.0045166015625, 'loss_3': -16.55575180053711, 'loss_4': 1.5347044467926025, 'epoch': 17.64}
{'loss': 0.017, 'grad_norm': 8.365450859069824, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.012460701167583466, 'loss_2': 0.00458526611328125, 'loss_3': -16.56644058227539, 'loss_4': 2.379631280899048, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 10:39:08,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:08,846 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:14:58<36:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:16,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00853230245411396, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.485, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005894309841096401, 'eval_loss_2': 0.0026379935443401337, 'eval_loss_3': -18.304656982421875, 'eval_loss_4': 1.1128720045089722, 'epoch': 17.65}
{'loss': 0.0101, 'grad_norm': 4.973458766937256, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.008345644921064377, 'loss_2': 0.001804351806640625, 'loss_3': -16.437549591064453, 'loss_4': 1.7722405195236206, 'epoch': 17.65}
{'loss': 0.0215, 'grad_norm': 13.939703941345215, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.018687646836042404, 'loss_2': 0.0027790069580078125, 'loss_3': -16.6363582611084, 'loss_4': 1.304355502128601, 'epoch': 17.66}
{'loss': 0.0113, 'grad_norm': 6.246942043304443, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.009445225819945335, 'loss_2': 0.00189208984375, 'loss_3': -16.22431755065918, 'loss_4': 2.023181438446045, 'epoch': 17.66}
{'loss': 0.0136, 'grad_norm': 4.359363555908203, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.005985567346215248, 'loss_2': 0.00763702392578125, 'loss_3': -16.576513290405273, 'loss_4': 1.548744797706604, 'epoch': 17.67}
{'loss': 0.0177, 'grad_norm': 5.288415908813477, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.010170171037316322, 'loss_2': 0.00749969482421875, 'loss_3': -16.412586212158203, 'loss_4': 1.8361539840698242, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 10:39:16,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:16,180 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:05<36:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:23,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009274104610085487, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.399, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0065456717275083065, 'eval_loss_2': 0.0027284324169158936, 'eval_loss_3': -18.305694580078125, 'eval_loss_4': 1.1385360956192017, 'epoch': 17.67}
{'loss': 0.0107, 'grad_norm': 5.167028903961182, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.00798405334353447, 'loss_2': 0.002742767333984375, 'loss_3': -16.528987884521484, 'loss_4': 1.6660349369049072, 'epoch': 17.68}
{'loss': 0.0204, 'grad_norm': 8.633853912353516, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.019624164327979088, 'loss_2': 0.0008249282836914062, 'loss_3': -16.576011657714844, 'loss_4': 2.1128721237182617, 'epoch': 17.69}
{'loss': 0.0079, 'grad_norm': 5.303558826446533, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.007348896935582161, 'loss_2': 0.0005445480346679688, 'loss_3': -16.546871185302734, 'loss_4': 1.736363172531128, 'epoch': 17.69}
{'loss': 0.016, 'grad_norm': 8.352171897888184, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.012883340008556843, 'loss_2': 0.00316619873046875, 'loss_3': -16.399185180664062, 'loss_4': 1.5108821392059326, 'epoch': 17.7}
{'loss': 0.0058, 'grad_norm': 4.329751491546631, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.005499168299138546, 'loss_2': 0.0003185272216796875, 'loss_3': -16.45631980895996, 'loss_4': 1.4222602844238281, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 10:39:23,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:23,526 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:13<36:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:30,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00846698135137558, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.518, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005997032858431339, 'eval_loss_2': 0.002469949424266815, 'eval_loss_3': -18.315547943115234, 'eval_loss_4': 1.1153748035430908, 'epoch': 17.7}
{'loss': 0.01, 'grad_norm': 4.959143161773682, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.0060959262773394585, 'loss_2': 0.0038928985595703125, 'loss_3': -16.388004302978516, 'loss_4': 1.7387900352478027, 'epoch': 17.71}
{'loss': 0.0081, 'grad_norm': 6.387504577636719, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.006237199064344168, 'loss_2': 0.0018463134765625, 'loss_3': -16.485809326171875, 'loss_4': 1.273315191268921, 'epoch': 17.72}
{'loss': 0.0131, 'grad_norm': 6.00216007232666, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.01008128747344017, 'loss_2': 0.002971649169921875, 'loss_3': -16.601726531982422, 'loss_4': 2.080498695373535, 'epoch': 17.72}
{'loss': 0.0107, 'grad_norm': 5.3669939041137695, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.010204566642642021, 'loss_2': 0.000492095947265625, 'loss_3': -16.28660011291504, 'loss_4': 1.8725128173828125, 'epoch': 17.73}
{'loss': 0.0108, 'grad_norm': 5.746967792510986, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.00949475634843111, 'loss_2': 0.0012912750244140625, 'loss_3': -16.444610595703125, 'loss_4': 2.320103645324707, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 10:39:30,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:30,865 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:20<36:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:38,204 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009581519290804863, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005711374804377556, 'eval_loss_2': 0.003870144486427307, 'eval_loss_3': -18.319116592407227, 'eval_loss_4': 1.0564939975738525, 'epoch': 17.73}
{'loss': 0.0236, 'grad_norm': 9.50874137878418, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.02257635071873665, 'loss_2': 0.0010404586791992188, 'loss_3': -16.439403533935547, 'loss_4': 1.3636212348937988, 'epoch': 17.74}
{'loss': 0.009, 'grad_norm': 4.714017391204834, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.00770694250240922, 'loss_2': 0.001300811767578125, 'loss_3': -16.30841064453125, 'loss_4': 1.6593012809753418, 'epoch': 17.74}
{'loss': 0.0135, 'grad_norm': 5.407700061798096, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.007913279347121716, 'loss_2': 0.005580902099609375, 'loss_3': -16.489837646484375, 'loss_4': 1.5317094326019287, 'epoch': 17.75}
{'loss': 0.0137, 'grad_norm': 5.827934265136719, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.01070711575448513, 'loss_2': 0.003025054931640625, 'loss_3': -16.3428897857666, 'loss_4': 1.9307020902633667, 'epoch': 17.76}
{'loss': 0.0129, 'grad_norm': 6.108416557312012, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.012203787453472614, 'loss_2': 0.0007171630859375, 'loss_3': -16.46035385131836, 'loss_4': 1.725917100906372, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 10:39:38,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:38,204 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:27<36:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:45,554 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01107165776193142, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.178, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006250416859984398, 'eval_loss_2': 0.0048212409019470215, 'eval_loss_3': -18.332277297973633, 'eval_loss_4': 1.033611536026001, 'epoch': 17.76}
{'loss': 0.0102, 'grad_norm': 5.330117225646973, 'learning_rate': 1.225e-05, 'loss_1': 0.008562576025724411, 'loss_2': 0.001621246337890625, 'loss_3': -16.300525665283203, 'loss_4': 1.9272944927215576, 'epoch': 17.77}
{'loss': 0.0195, 'grad_norm': 5.761361122131348, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.012448725290596485, 'loss_2': 0.0070953369140625, 'loss_3': -16.47905731201172, 'loss_4': 1.969950795173645, 'epoch': 17.77}
{'loss': 0.0067, 'grad_norm': 5.758843421936035, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.006318192463368177, 'loss_2': 0.0003504753112792969, 'loss_3': -16.575271606445312, 'loss_4': 1.3073043823242188, 'epoch': 17.78}
{'loss': 0.0121, 'grad_norm': 7.299595355987549, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.009925936348736286, 'loss_2': 0.0021648406982421875, 'loss_3': -16.56814956665039, 'loss_4': 2.162717580795288, 'epoch': 17.78}
{'loss': 0.0188, 'grad_norm': 5.453857898712158, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.011936917901039124, 'loss_2': 0.0068817138671875, 'loss_3': -16.515953063964844, 'loss_4': 1.5999516248703003, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 10:39:45,554 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:45,554 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:35<36:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:52,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00953528843820095, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.024, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0061304038390517235, 'eval_loss_2': 0.0034048855304718018, 'eval_loss_3': -18.343469619750977, 'eval_loss_4': 1.0385425090789795, 'epoch': 17.79}
{'loss': 0.0353, 'grad_norm': 18.591903686523438, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.028313109651207924, 'loss_2': 0.00702667236328125, 'loss_3': -16.3856258392334, 'loss_4': 1.715916633605957, 'epoch': 17.8}
{'loss': 0.0145, 'grad_norm': 5.688748359680176, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.009812898933887482, 'loss_2': 0.004703521728515625, 'loss_3': -16.538665771484375, 'loss_4': 1.8131468296051025, 'epoch': 17.8}
{'loss': 0.0131, 'grad_norm': 5.804196357727051, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.00957414973527193, 'loss_2': 0.00353240966796875, 'loss_3': -16.52675437927246, 'loss_4': 2.0303502082824707, 'epoch': 17.81}
{'loss': 0.0098, 'grad_norm': 5.3202924728393555, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.00698184035718441, 'loss_2': 0.002788543701171875, 'loss_3': -16.53540802001953, 'loss_4': 1.521576166152954, 'epoch': 17.81}
{'loss': 0.0172, 'grad_norm': 7.178557872772217, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.011019845493137836, 'loss_2': 0.0062103271484375, 'loss_3': -16.552919387817383, 'loss_4': 1.9997100830078125, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 10:39:52,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:52,905 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:42<36:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:00,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009277144446969032, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.524, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006369869224727154, 'eval_loss_2': 0.002907276153564453, 'eval_loss_3': -18.33734703063965, 'eval_loss_4': 1.0113166570663452, 'epoch': 17.82}
{'loss': 0.0172, 'grad_norm': 6.019007682800293, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.010905357077717781, 'loss_2': 0.006317138671875, 'loss_3': -16.427154541015625, 'loss_4': 2.2496719360351562, 'epoch': 17.83}
{'loss': 0.0085, 'grad_norm': 4.730903625488281, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.004910867195576429, 'loss_2': 0.0036029815673828125, 'loss_3': -16.57863998413086, 'loss_4': 1.4538148641586304, 'epoch': 17.83}
{'loss': 0.0124, 'grad_norm': 6.808666229248047, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.00900188833475113, 'loss_2': 0.003387451171875, 'loss_3': -16.344236373901367, 'loss_4': 1.6225067377090454, 'epoch': 17.84}
{'loss': 0.0162, 'grad_norm': 7.344099998474121, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.013883071020245552, 'loss_2': 0.002300262451171875, 'loss_3': -16.53921127319336, 'loss_4': 1.4921520948410034, 'epoch': 17.84}
{'loss': 0.0231, 'grad_norm': 8.300379753112793, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.014974447898566723, 'loss_2': 0.00811767578125, 'loss_3': -16.444063186645508, 'loss_4': 1.1462651491165161, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 10:40:00,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:00,248 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:15:49<36:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:07,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011563627049326897, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.311, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007038918789476156, 'eval_loss_2': 0.004524707794189453, 'eval_loss_3': -18.32101058959961, 'eval_loss_4': 0.9725073575973511, 'epoch': 17.85}
{'loss': 0.0135, 'grad_norm': 5.338444232940674, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.00863191019743681, 'loss_2': 0.004913330078125, 'loss_3': -16.472488403320312, 'loss_4': 1.362420916557312, 'epoch': 17.85}
{'loss': 0.0091, 'grad_norm': 4.583589553833008, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.00592373451218009, 'loss_2': 0.0031757354736328125, 'loss_3': -16.36393165588379, 'loss_4': 1.4257919788360596, 'epoch': 17.86}
{'loss': 0.0206, 'grad_norm': 8.451342582702637, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.01530098170042038, 'loss_2': 0.0052642822265625, 'loss_3': -16.30474281311035, 'loss_4': 1.278609275817871, 'epoch': 17.87}
{'loss': 0.013, 'grad_norm': 6.1731672286987305, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.011791693978011608, 'loss_2': 0.0011749267578125, 'loss_3': -16.456527709960938, 'loss_4': 1.7785296440124512, 'epoch': 17.87}
{'loss': 0.0151, 'grad_norm': 7.6042327880859375, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.010556074790656567, 'loss_2': 0.004535675048828125, 'loss_3': -16.57866096496582, 'loss_4': 1.804646372795105, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 10:40:07,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:07,592 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:15:57<35:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:14,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012808013707399368, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006998597178608179, 'eval_loss_2': 0.005809415131807327, 'eval_loss_3': -18.309019088745117, 'eval_loss_4': 1.0016297101974487, 'epoch': 17.88}
{'loss': 0.0193, 'grad_norm': 8.282642364501953, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.012223931029438972, 'loss_2': 0.00704193115234375, 'loss_3': -16.465877532958984, 'loss_4': 1.439697504043579, 'epoch': 17.88}
{'loss': 0.0145, 'grad_norm': 5.4541916847229, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.008655068464577198, 'loss_2': 0.00583648681640625, 'loss_3': -16.314453125, 'loss_4': 1.635111927986145, 'epoch': 17.89}
{'loss': 0.0093, 'grad_norm': 5.706023693084717, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.0062270560301840305, 'loss_2': 0.00302886962890625, 'loss_3': -16.460773468017578, 'loss_4': 1.5122454166412354, 'epoch': 17.9}
{'loss': 0.0164, 'grad_norm': 4.977689266204834, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.00717838853597641, 'loss_2': 0.00917816162109375, 'loss_3': -16.243877410888672, 'loss_4': 1.8205676078796387, 'epoch': 17.9}
{'loss': 0.0372, 'grad_norm': 19.183958053588867, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.030384760349988937, 'loss_2': 0.006824493408203125, 'loss_3': -16.45484733581543, 'loss_4': 1.6125543117523193, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 10:40:14,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:14,938 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:04<35:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:22,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011386297643184662, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.516, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007470005191862583, 'eval_loss_2': 0.003916293382644653, 'eval_loss_3': -18.31890296936035, 'eval_loss_4': 0.9249206781387329, 'epoch': 17.91}
{'loss': 0.0182, 'grad_norm': 6.3545451164245605, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.014123051427304745, 'loss_2': 0.0040283203125, 'loss_3': -16.402069091796875, 'loss_4': 1.2305467128753662, 'epoch': 17.91}
{'loss': 0.0264, 'grad_norm': 11.269675254821777, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.021957002580165863, 'loss_2': 0.004486083984375, 'loss_3': -16.541996002197266, 'loss_4': 1.6642873287200928, 'epoch': 17.92}
{'loss': 0.0107, 'grad_norm': 5.526705265045166, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.007255409378558397, 'loss_2': 0.003452301025390625, 'loss_3': -16.575647354125977, 'loss_4': 1.775227427482605, 'epoch': 17.92}
{'loss': 0.0092, 'grad_norm': 4.6624674797058105, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.005536246113479137, 'loss_2': 0.003681182861328125, 'loss_3': -16.61326026916504, 'loss_4': 1.015928030014038, 'epoch': 17.93}
{'loss': 0.0197, 'grad_norm': 6.464378356933594, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.016429711133241653, 'loss_2': 0.003292083740234375, 'loss_3': -16.258726119995117, 'loss_4': 2.125683307647705, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 10:40:22,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:22,280 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:11<35:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:29,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012471815571188927, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008642223663628101, 'eval_loss_2': 0.0038295909762382507, 'eval_loss_3': -18.309329986572266, 'eval_loss_4': 0.9842917919158936, 'epoch': 17.94}
{'loss': 0.0121, 'grad_norm': 6.087006092071533, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.01208276767283678, 'loss_2': 1.4126300811767578e-05, 'loss_3': -16.450340270996094, 'loss_4': 1.772002935409546, 'epoch': 17.94}
{'loss': 0.0182, 'grad_norm': 6.4868574142456055, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.013636215589940548, 'loss_2': 0.00453948974609375, 'loss_3': -16.59476661682129, 'loss_4': 1.1626850366592407, 'epoch': 17.95}
{'loss': 0.0101, 'grad_norm': 5.257171630859375, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.007021795492619276, 'loss_2': 0.0031185150146484375, 'loss_3': -16.509868621826172, 'loss_4': 1.7134671211242676, 'epoch': 17.95}
{'loss': 0.0156, 'grad_norm': 5.838300704956055, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.011601847596466541, 'loss_2': 0.004039764404296875, 'loss_3': -16.396570205688477, 'loss_4': 1.740736722946167, 'epoch': 17.96}
{'loss': 0.0257, 'grad_norm': 12.466306686401367, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.022863326594233513, 'loss_2': 0.0028324127197265625, 'loss_3': -16.218412399291992, 'loss_4': 0.8786089420318604, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 10:40:29,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:29,630 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:19<36:03,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:40:37,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011624489910900593, 'eval_runtime': 4.0006, 'eval_samples_per_second': 255.964, 'eval_steps_per_second': 3.999, 'eval_loss_1': 0.007392306812107563, 'eval_loss_2': 0.00423218309879303, 'eval_loss_3': -18.29873275756836, 'eval_loss_4': 0.9732147455215454, 'epoch': 17.97}
{'loss': 0.0194, 'grad_norm': 8.413264274597168, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.01938285492360592, 'loss_2': 6.151199340820312e-05, 'loss_3': -16.513580322265625, 'loss_4': 1.5335391759872437, 'epoch': 17.97}
{'loss': 0.0136, 'grad_norm': 8.07964038848877, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.010149577632546425, 'loss_2': 0.0034027099609375, 'loss_3': -16.428680419921875, 'loss_4': 1.1542141437530518, 'epoch': 17.98}
{'loss': 0.0119, 'grad_norm': 5.220821380615234, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.008326820097863674, 'loss_2': 0.003620147705078125, 'loss_3': -16.59771728515625, 'loss_4': 1.7443046569824219, 'epoch': 17.98}
{'loss': 0.0052, 'grad_norm': 4.70188045501709, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.005019076634198427, 'loss_2': 0.00022101402282714844, 'loss_3': -16.332286834716797, 'loss_4': 1.625011682510376, 'epoch': 17.99}
{'loss': 0.0078, 'grad_norm': 4.9245734214782715, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.00521507952362299, 'loss_2': 0.0026302337646484375, 'loss_3': -16.367130279541016, 'loss_4': 2.110236883163452, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 10:40:37,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:37,165 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:26<34:59,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:40:44,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011934981681406498, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.87, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007496745325624943, 'eval_loss_2': 0.004438236355781555, 'eval_loss_3': -18.26526641845703, 'eval_loss_4': 0.9790639877319336, 'epoch': 17.99}
{'loss': 0.006, 'grad_norm': 6.085157871246338, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.0047314162366092205, 'loss_2': 0.0012454986572265625, 'loss_3': -16.367292404174805, 'loss_4': 1.4198648929595947, 'epoch': 18.0}
{'loss': 0.0096, 'grad_norm': 5.40986442565918, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.008003554306924343, 'loss_2': 0.001598358154296875, 'loss_3': -16.237882614135742, 'loss_4': 1.4502758979797363, 'epoch': 18.01}
{'loss': 0.0122, 'grad_norm': 5.112142086029053, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.005228294990956783, 'loss_2': 0.0069580078125, 'loss_3': -16.426191329956055, 'loss_4': 1.0880110263824463, 'epoch': 18.01}
{'loss': 0.0074, 'grad_norm': 4.130799770355225, 'learning_rate': 1.2e-05, 'loss_1': 0.00519965635612607, 'loss_2': 0.00220489501953125, 'loss_3': -16.50235939025879, 'loss_4': 1.1994521617889404, 'epoch': 18.02}
{'loss': 0.018, 'grad_norm': 11.096484184265137, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.01757020875811577, 'loss_2': 0.0004711151123046875, 'loss_3': -16.404916763305664, 'loss_4': 1.505110740661621, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 10:40:44,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:44,221 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:33<35:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:40:51,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010722652077674866, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.178, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006888360716402531, 'eval_loss_2': 0.0038342922925949097, 'eval_loss_3': -18.245357513427734, 'eval_loss_4': 1.0089755058288574, 'epoch': 18.02}
{'loss': 0.0104, 'grad_norm': 5.40474271774292, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.006448844913393259, 'loss_2': 0.00399017333984375, 'loss_3': -16.392169952392578, 'loss_4': 1.524618148803711, 'epoch': 18.03}
{'loss': 0.0126, 'grad_norm': 4.784837245941162, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.005689953453838825, 'loss_2': 0.006946563720703125, 'loss_3': -16.384521484375, 'loss_4': 1.148171067237854, 'epoch': 18.03}
{'loss': 0.0141, 'grad_norm': 6.892121315002441, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.009796333499252796, 'loss_2': 0.0043182373046875, 'loss_3': -16.351154327392578, 'loss_4': 1.546226978302002, 'epoch': 18.04}
{'loss': 0.0169, 'grad_norm': 5.219502925872803, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.008766783401370049, 'loss_2': 0.00817108154296875, 'loss_3': -16.49530029296875, 'loss_4': 1.7695966958999634, 'epoch': 18.05}
{'loss': 0.0069, 'grad_norm': 4.919188022613525, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.004848916549235582, 'loss_2': 0.0020465850830078125, 'loss_3': -16.4428653717041, 'loss_4': 1.3848825693130493, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 10:40:51,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:51,569 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:41<35:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:58,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010260037146508694, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.481, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0065007577650249004, 'eval_loss_2': 0.0037592798471450806, 'eval_loss_3': -18.269153594970703, 'eval_loss_4': 0.9351803660392761, 'epoch': 18.05}
{'loss': 0.0136, 'grad_norm': 6.172558784484863, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.008637143298983574, 'loss_2': 0.00499725341796875, 'loss_3': -16.269657135009766, 'loss_4': 2.091571807861328, 'epoch': 18.06}
{'loss': 0.005, 'grad_norm': 4.693657875061035, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.004101035185158253, 'loss_2': 0.0008802413940429688, 'loss_3': -16.3199462890625, 'loss_4': 1.5048991441726685, 'epoch': 18.06}
{'loss': 0.0144, 'grad_norm': 8.650862693786621, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.013454576022922993, 'loss_2': 0.0009598731994628906, 'loss_3': -16.3112850189209, 'loss_4': 1.7813249826431274, 'epoch': 18.07}
{'loss': 0.014, 'grad_norm': 5.441844940185547, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.008387677371501923, 'loss_2': 0.00560760498046875, 'loss_3': -16.28090476989746, 'loss_4': 1.1602108478546143, 'epoch': 18.08}
{'loss': 0.0161, 'grad_norm': 8.731565475463867, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.014428605325520039, 'loss_2': 0.001659393310546875, 'loss_3': -16.322559356689453, 'loss_4': 1.316562533378601, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 10:40:58,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:58,918 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:16:48<35:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:06,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009134568274021149, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005347945727407932, 'eval_loss_2': 0.003786623477935791, 'eval_loss_3': -18.28337860107422, 'eval_loss_4': 0.8928652405738831, 'epoch': 18.08}
{'loss': 0.0097, 'grad_norm': 4.973546028137207, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.008993783965706825, 'loss_2': 0.0006995201110839844, 'loss_3': -16.597415924072266, 'loss_4': 1.6479206085205078, 'epoch': 18.09}
{'loss': 0.0133, 'grad_norm': 5.467111587524414, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.009633440524339676, 'loss_2': 0.00371551513671875, 'loss_3': -16.496444702148438, 'loss_4': 1.2232756614685059, 'epoch': 18.09}
{'loss': 0.0065, 'grad_norm': 5.375255107879639, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.004287844058126211, 'loss_2': 0.002262115478515625, 'loss_3': -16.369033813476562, 'loss_4': 1.0482652187347412, 'epoch': 18.1}
{'loss': 0.0114, 'grad_norm': 4.687067031860352, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.007135600317269564, 'loss_2': 0.004241943359375, 'loss_3': -16.290714263916016, 'loss_4': 1.4557232856750488, 'epoch': 18.1}
{'loss': 0.0398, 'grad_norm': 27.6451416015625, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.035920966416597366, 'loss_2': 0.003902435302734375, 'loss_3': -16.34241485595703, 'loss_4': 1.6238309144973755, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 10:41:06,269 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:06,269 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:16:55<35:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:13,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008716978132724762, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.87, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005070097744464874, 'eval_loss_2': 0.0036468803882598877, 'eval_loss_3': -18.290142059326172, 'eval_loss_4': 0.8859153389930725, 'epoch': 18.11}
{'loss': 0.0178, 'grad_norm': 9.09889030456543, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.01649552956223488, 'loss_2': 0.0013494491577148438, 'loss_3': -16.229764938354492, 'loss_4': 1.1903536319732666, 'epoch': 18.12}
{'loss': 0.0116, 'grad_norm': 4.923111915588379, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.006397206801921129, 'loss_2': 0.00518798828125, 'loss_3': -16.606000900268555, 'loss_4': 2.4802017211914062, 'epoch': 18.12}
{'loss': 0.0082, 'grad_norm': 4.702670097351074, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.0068494719453155994, 'loss_2': 0.0013980865478515625, 'loss_3': -16.426651000976562, 'loss_4': 1.2969293594360352, 'epoch': 18.13}
{'loss': 0.0129, 'grad_norm': 6.330328941345215, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.006707422900944948, 'loss_2': 0.006229400634765625, 'loss_3': -16.226131439208984, 'loss_4': 1.8010481595993042, 'epoch': 18.13}
{'loss': 0.0069, 'grad_norm': 4.428244590759277, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.004463175777345896, 'loss_2': 0.00247955322265625, 'loss_3': -16.231294631958008, 'loss_4': 2.223597526550293, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 10:41:13,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:13,612 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:03<35:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:20,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007731802295893431, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0050048441626131535, 'eval_loss_2': 0.0027269572019577026, 'eval_loss_3': -18.29662322998047, 'eval_loss_4': 0.8587114810943604, 'epoch': 18.14}
{'loss': 0.016, 'grad_norm': 5.992842674255371, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.009496822953224182, 'loss_2': 0.006458282470703125, 'loss_3': -16.359195709228516, 'loss_4': 0.9169431924819946, 'epoch': 18.15}
{'loss': 0.0254, 'grad_norm': 35.04351806640625, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.023194871842861176, 'loss_2': 0.0022125244140625, 'loss_3': -16.5040340423584, 'loss_4': 1.514235258102417, 'epoch': 18.15}
{'loss': 0.0174, 'grad_norm': 6.915609359741211, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.008619456551969051, 'loss_2': 0.008819580078125, 'loss_3': -16.524391174316406, 'loss_4': 1.269458293914795, 'epoch': 18.16}
{'loss': 0.0107, 'grad_norm': 5.50693941116333, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.008287495002150536, 'loss_2': 0.0024566650390625, 'loss_3': -16.585559844970703, 'loss_4': 1.5877879858016968, 'epoch': 18.16}
{'loss': 0.0348, 'grad_norm': 9.462251663208008, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.02421288564801216, 'loss_2': 0.01058197021484375, 'loss_3': -16.48996925354004, 'loss_4': 0.8648792505264282, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 10:41:20,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:20,956 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:10<35:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:28,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006421144586056471, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.003599543124437332, 'eval_loss_2': 0.002821601927280426, 'eval_loss_3': -18.306026458740234, 'eval_loss_4': 0.6763710379600525, 'epoch': 18.17}
{'loss': 0.0107, 'grad_norm': 5.36346960067749, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.009035601280629635, 'loss_2': 0.0016937255859375, 'loss_3': -16.40331268310547, 'loss_4': 1.0477559566497803, 'epoch': 18.17}
{'loss': 0.01, 'grad_norm': 5.557128429412842, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.008575057610869408, 'loss_2': 0.0014667510986328125, 'loss_3': -16.431011199951172, 'loss_4': 1.1561706066131592, 'epoch': 18.18}
{'loss': 0.015, 'grad_norm': 4.85377836227417, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.004961639642715454, 'loss_2': 0.01001739501953125, 'loss_3': -16.28069496154785, 'loss_4': 1.3242030143737793, 'epoch': 18.19}
{'loss': 0.0153, 'grad_norm': 7.477475166320801, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.01390082947909832, 'loss_2': 0.0013990402221679688, 'loss_3': -16.34759521484375, 'loss_4': 1.3641659021377563, 'epoch': 18.19}
{'loss': 0.0073, 'grad_norm': 4.7410101890563965, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.0056404541246593, 'loss_2': 0.0016565322875976562, 'loss_3': -16.367210388183594, 'loss_4': 1.1129668951034546, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 10:41:28,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:28,294 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:17<35:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:35,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006655261851847172, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.722, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0036890371702611446, 'eval_loss_2': 0.0029662251472473145, 'eval_loss_3': -18.310930252075195, 'eval_loss_4': 0.5756739974021912, 'epoch': 18.2}
{'loss': 0.008, 'grad_norm': 4.341791152954102, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.00524237472563982, 'loss_2': 0.002777099609375, 'loss_3': -16.328739166259766, 'loss_4': 1.2076330184936523, 'epoch': 18.2}
{'loss': 0.0083, 'grad_norm': 5.02999210357666, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.005848574917763472, 'loss_2': 0.0024890899658203125, 'loss_3': -16.453901290893555, 'loss_4': 1.5423548221588135, 'epoch': 18.21}
{'loss': 0.0073, 'grad_norm': 4.846073627471924, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.003731444478034973, 'loss_2': 0.003570556640625, 'loss_3': -16.53097915649414, 'loss_4': 0.9819562435150146, 'epoch': 18.22}
{'loss': 0.0098, 'grad_norm': 7.907833099365234, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.008305724710226059, 'loss_2': 0.00145721435546875, 'loss_3': -16.51397705078125, 'loss_4': 1.4134306907653809, 'epoch': 18.22}
{'loss': 0.0107, 'grad_norm': 5.7286200523376465, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.006930375937372446, 'loss_2': 0.0037841796875, 'loss_3': -16.330087661743164, 'loss_4': 0.7144407033920288, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 10:41:35,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:35,637 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:25<34:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:42,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007762144785374403, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0036146147176623344, 'eval_loss_2': 0.004147529602050781, 'eval_loss_3': -18.3076114654541, 'eval_loss_4': 0.5571074485778809, 'epoch': 18.23}
{'loss': 0.0215, 'grad_norm': 6.592347621917725, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.017606563866138458, 'loss_2': 0.00388336181640625, 'loss_3': -16.355506896972656, 'loss_4': 1.4920731782913208, 'epoch': 18.23}
{'loss': 0.0085, 'grad_norm': 4.822401523590088, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.0051238699816167355, 'loss_2': 0.0034046173095703125, 'loss_3': -16.25055694580078, 'loss_4': 1.073409080505371, 'epoch': 18.24}
{'loss': 0.0093, 'grad_norm': 5.305024147033691, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.00819848757237196, 'loss_2': 0.0011081695556640625, 'loss_3': -16.13297462463379, 'loss_4': 1.8196392059326172, 'epoch': 18.24}
{'loss': 0.0206, 'grad_norm': 12.068693161010742, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.017109861597418785, 'loss_2': 0.003452301025390625, 'loss_3': -16.47726058959961, 'loss_4': 1.193229079246521, 'epoch': 18.25}
{'loss': 0.0087, 'grad_norm': 5.95458459854126, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.006822778377681971, 'loss_2': 0.0018520355224609375, 'loss_3': -16.565937042236328, 'loss_4': 2.106250524520874, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 10:41:42,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:42,979 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:32<34:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:50,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006026599556207657, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.003693047910928726, 'eval_loss_2': 0.0023335516452789307, 'eval_loss_3': -18.301597595214844, 'eval_loss_4': 0.6821845769882202, 'epoch': 18.26}
{'loss': 0.0082, 'grad_norm': 5.359978675842285, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.006997276097536087, 'loss_2': 0.0011997222900390625, 'loss_3': -16.384807586669922, 'loss_4': 1.5043551921844482, 'epoch': 18.26}
{'loss': 0.013, 'grad_norm': 5.72953987121582, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.01249477919191122, 'loss_2': 0.0004978179931640625, 'loss_3': -16.243976593017578, 'loss_4': 0.998212456703186, 'epoch': 18.27}
{'loss': 0.0235, 'grad_norm': 8.950846672058105, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.01861261948943138, 'loss_2': 0.0048828125, 'loss_3': -16.05194664001465, 'loss_4': 1.0799847841262817, 'epoch': 18.27}
{'loss': 0.0072, 'grad_norm': 5.17907190322876, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.006216191686689854, 'loss_2': 0.0009365081787109375, 'loss_3': -16.39025115966797, 'loss_4': 1.7908655405044556, 'epoch': 18.28}
{'loss': 0.0155, 'grad_norm': 6.5860395431518555, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.008452710695564747, 'loss_2': 0.007091522216796875, 'loss_3': -16.480480194091797, 'loss_4': 1.2509605884552002, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 10:41:50,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:50,334 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:39<34:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:57,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0066009568981826305, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.36, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0038007907569408417, 'eval_loss_2': 0.002800166606903076, 'eval_loss_3': -18.302581787109375, 'eval_loss_4': 0.7235418558120728, 'epoch': 18.28}
{'loss': 0.0045, 'grad_norm': 5.383819103240967, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.004118551500141621, 'loss_2': 0.0003376007080078125, 'loss_3': -16.397125244140625, 'loss_4': 1.199190616607666, 'epoch': 18.29}
{'loss': 0.0112, 'grad_norm': 5.470439910888672, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.007620283402502537, 'loss_2': 0.003543853759765625, 'loss_3': -16.393943786621094, 'loss_4': 1.355327844619751, 'epoch': 18.3}
{'loss': 0.0103, 'grad_norm': 6.567412853240967, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.009669909253716469, 'loss_2': 0.0005960464477539062, 'loss_3': -16.313751220703125, 'loss_4': 1.3836957216262817, 'epoch': 18.3}
{'loss': 0.014, 'grad_norm': 4.989558219909668, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.00715556601062417, 'loss_2': 0.0068511962890625, 'loss_3': -16.565303802490234, 'loss_4': 1.03541100025177, 'epoch': 18.31}
{'loss': 0.0165, 'grad_norm': 12.810587882995605, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.015507394447922707, 'loss_2': 0.0010290145874023438, 'loss_3': -16.471580505371094, 'loss_4': 2.061295986175537, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 10:41:57,683 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:57,683 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:17:47<34:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:05,032 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007471535354852676, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.175, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.003921728581190109, 'eval_loss_2': 0.003549806773662567, 'eval_loss_3': -18.30160140991211, 'eval_loss_4': 0.6218321323394775, 'epoch': 18.31}
{'loss': 0.0096, 'grad_norm': 6.5721540451049805, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.009037681855261326, 'loss_2': 0.0005998611450195312, 'loss_3': -16.537511825561523, 'loss_4': 1.2939205169677734, 'epoch': 18.32}
{'loss': 0.0105, 'grad_norm': 6.6801300048828125, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.008905744180083275, 'loss_2': 0.001567840576171875, 'loss_3': -16.47704315185547, 'loss_4': 1.3887438774108887, 'epoch': 18.33}
{'loss': 0.0162, 'grad_norm': 7.458276271820068, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.010725856758654118, 'loss_2': 0.00547027587890625, 'loss_3': -16.315996170043945, 'loss_4': 1.5577061176300049, 'epoch': 18.33}
{'loss': 0.0103, 'grad_norm': 5.153022289276123, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.006845253054052591, 'loss_2': 0.003437042236328125, 'loss_3': -16.492645263671875, 'loss_4': 1.4403260946273804, 'epoch': 18.34}
{'loss': 0.0175, 'grad_norm': 6.5658721923828125, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.008466844446957111, 'loss_2': 0.0090789794921875, 'loss_3': -16.531234741210938, 'loss_4': 1.4818849563598633, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 10:42:05,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:05,032 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:17:54<34:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:12,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007538861129432917, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004446070641279221, 'eval_loss_2': 0.003092791885137558, 'eval_loss_3': -18.322004318237305, 'eval_loss_4': 0.5535531640052795, 'epoch': 18.34}
{'loss': 0.0191, 'grad_norm': 7.026342391967773, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.016494134441018105, 'loss_2': 0.0025844573974609375, 'loss_3': -16.56340789794922, 'loss_4': 1.141440510749817, 'epoch': 18.35}
{'loss': 0.0147, 'grad_norm': 4.58865213394165, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.008244043216109276, 'loss_2': 0.00643157958984375, 'loss_3': -16.47511100769043, 'loss_4': 1.3650648593902588, 'epoch': 18.35}
{'loss': 0.0088, 'grad_norm': 7.05562686920166, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.008383584208786488, 'loss_2': 0.0003952980041503906, 'loss_3': -16.32712173461914, 'loss_4': 0.9562769532203674, 'epoch': 18.36}
{'loss': 0.0175, 'grad_norm': 8.936429977416992, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.014667888171970844, 'loss_2': 0.00281524658203125, 'loss_3': -16.359018325805664, 'loss_4': 0.6969966888427734, 'epoch': 18.37}
{'loss': 0.0159, 'grad_norm': 5.279316425323486, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.011962926015257835, 'loss_2': 0.0039520263671875, 'loss_3': -16.514841079711914, 'loss_4': 1.8879563808441162, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 10:42:12,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:12,374 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:01<34:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:19,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010020125657320023, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.422, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005348791368305683, 'eval_loss_2': 0.004671335220336914, 'eval_loss_3': -18.299762725830078, 'eval_loss_4': 0.5483580231666565, 'epoch': 18.37}
{'loss': 0.0144, 'grad_norm': 7.452498912811279, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.010874624364078045, 'loss_2': 0.003570556640625, 'loss_3': -16.53211784362793, 'loss_4': 1.0612947940826416, 'epoch': 18.38}
{'loss': 0.0077, 'grad_norm': 5.499722480773926, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.006589741911739111, 'loss_2': 0.0011129379272460938, 'loss_3': -16.407005310058594, 'loss_4': 1.8049852848052979, 'epoch': 18.38}
{'loss': 0.0233, 'grad_norm': 6.848721981048584, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.007646091282367706, 'loss_2': 0.0156097412109375, 'loss_3': -16.377939224243164, 'loss_4': 0.8938051462173462, 'epoch': 18.39}
{'loss': 0.0071, 'grad_norm': 4.493226528167725, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.0060566747561097145, 'loss_2': 0.0010051727294921875, 'loss_3': -16.544410705566406, 'loss_4': 1.7725870609283447, 'epoch': 18.4}
{'loss': 0.0202, 'grad_norm': 5.432806491851807, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.011585279367864132, 'loss_2': 0.0085906982421875, 'loss_3': -16.53330421447754, 'loss_4': 0.8550730347633362, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 10:42:19,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:19,720 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:09<34:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:27,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01099591888487339, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005229526199400425, 'eval_loss_2': 0.005766391754150391, 'eval_loss_3': -18.305458068847656, 'eval_loss_4': 0.426502525806427, 'epoch': 18.4}
{'loss': 0.012, 'grad_norm': 5.274881839752197, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.006192449014633894, 'loss_2': 0.005855560302734375, 'loss_3': -16.593542098999023, 'loss_4': 1.6848814487457275, 'epoch': 18.41}
{'loss': 0.0131, 'grad_norm': 6.039076805114746, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.009820748120546341, 'loss_2': 0.00328826904296875, 'loss_3': -16.344951629638672, 'loss_4': 1.3023264408111572, 'epoch': 18.41}
{'loss': 0.0195, 'grad_norm': 8.557158470153809, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.01730211451649666, 'loss_2': 0.00217437744140625, 'loss_3': -16.38920021057129, 'loss_4': 0.5296791195869446, 'epoch': 18.42}
{'loss': 0.0103, 'grad_norm': 4.931306838989258, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.008158009499311447, 'loss_2': 0.00218963623046875, 'loss_3': -16.60906219482422, 'loss_4': 0.6229262351989746, 'epoch': 18.42}
{'loss': 0.0098, 'grad_norm': 4.892635345458984, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.005392091814428568, 'loss_2': 0.00441741943359375, 'loss_3': -16.573965072631836, 'loss_4': 1.091003656387329, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 10:42:27,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:27,062 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:16<34:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:34,413 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009861666709184647, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.979, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005172710865736008, 'eval_loss_2': 0.004688955843448639, 'eval_loss_3': -18.29782485961914, 'eval_loss_4': 0.42625850439071655, 'epoch': 18.43}
{'loss': 0.0076, 'grad_norm': 5.313925743103027, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.007527880370616913, 'loss_2': 6.079673767089844e-05, 'loss_3': -16.41598892211914, 'loss_4': 1.3623511791229248, 'epoch': 18.44}
{'loss': 0.0183, 'grad_norm': 6.343862533569336, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.015129709616303444, 'loss_2': 0.0031948089599609375, 'loss_3': -16.276596069335938, 'loss_4': 1.0890029668807983, 'epoch': 18.44}
{'loss': 0.0094, 'grad_norm': 6.339367866516113, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.008161591365933418, 'loss_2': 0.0012760162353515625, 'loss_3': -16.478248596191406, 'loss_4': 1.202622413635254, 'epoch': 18.45}
{'loss': 0.0154, 'grad_norm': 8.439208030700684, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.013763072900474072, 'loss_2': 0.0016584396362304688, 'loss_3': -16.54729461669922, 'loss_4': 1.031175971031189, 'epoch': 18.45}
{'loss': 0.024, 'grad_norm': 11.376198768615723, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.021281644701957703, 'loss_2': 0.002685546875, 'loss_3': -16.596012115478516, 'loss_4': 1.0652377605438232, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 10:42:34,413 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:34,413 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:23<34:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:41,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0093703493475914, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.469, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0060335611924529076, 'eval_loss_2': 0.003336787223815918, 'eval_loss_3': -18.32149314880371, 'eval_loss_4': 0.5063187479972839, 'epoch': 18.46}
{'loss': 0.0087, 'grad_norm': 5.071964740753174, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.006051913369446993, 'loss_2': 0.002658843994140625, 'loss_3': -16.485809326171875, 'loss_4': 1.0394939184188843, 'epoch': 18.47}
{'loss': 0.0156, 'grad_norm': 5.561626434326172, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.011342296376824379, 'loss_2': 0.004253387451171875, 'loss_3': -16.430633544921875, 'loss_4': 1.189117193222046, 'epoch': 18.47}
{'loss': 0.0075, 'grad_norm': 4.741818904876709, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.005899809766560793, 'loss_2': 0.0015716552734375, 'loss_3': -16.5571346282959, 'loss_4': 1.0215157270431519, 'epoch': 18.48}
{'loss': 0.0179, 'grad_norm': 6.853966236114502, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.012568234466016293, 'loss_2': 0.005352020263671875, 'loss_3': -16.7047119140625, 'loss_4': 1.8379697799682617, 'epoch': 18.48}
{'loss': 0.0146, 'grad_norm': 5.078838348388672, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.011954412795603275, 'loss_2': 0.0026454925537109375, 'loss_3': -16.431652069091797, 'loss_4': 1.7285122871398926, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 10:42:41,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:41,750 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:31<34:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:49,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00802365317940712, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004855846054852009, 'eval_loss_2': 0.0031678080558776855, 'eval_loss_3': -18.348764419555664, 'eval_loss_4': 0.6931092739105225, 'epoch': 18.49}
{'loss': 0.0119, 'grad_norm': 4.665505886077881, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.007649634033441544, 'loss_2': 0.004215240478515625, 'loss_3': -16.510631561279297, 'loss_4': 1.46710205078125, 'epoch': 18.49}
{'loss': 0.0195, 'grad_norm': 8.993882179260254, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.018528256565332413, 'loss_2': 0.0009555816650390625, 'loss_3': -16.59562110900879, 'loss_4': 1.578437089920044, 'epoch': 18.5}
{'loss': 0.0176, 'grad_norm': 6.6443071365356445, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.013336559757590294, 'loss_2': 0.00426483154296875, 'loss_3': -16.42495346069336, 'loss_4': 1.8394708633422852, 'epoch': 18.51}
{'loss': 0.0203, 'grad_norm': 5.73808479309082, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.01354433037340641, 'loss_2': 0.006771087646484375, 'loss_3': -16.58956527709961, 'loss_4': 1.5737367868423462, 'epoch': 18.51}
{'loss': 0.0131, 'grad_norm': 5.069586277008057, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.008148039691150188, 'loss_2': 0.004985809326171875, 'loss_3': -16.66904640197754, 'loss_4': 1.8226085901260376, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 10:42:49,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:49,093 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:38<34:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:56,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008699167519807816, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.244, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0050729745998978615, 'eval_loss_2': 0.0036261938512325287, 'eval_loss_3': -18.350017547607422, 'eval_loss_4': 0.7541059851646423, 'epoch': 18.52}
{'loss': 0.0122, 'grad_norm': 4.773300647735596, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.007765418384224176, 'loss_2': 0.00438690185546875, 'loss_3': -16.615222930908203, 'loss_4': 1.361259937286377, 'epoch': 18.52}
{'loss': 0.0137, 'grad_norm': 6.911680698394775, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.009777912870049477, 'loss_2': 0.00392913818359375, 'loss_3': -16.510597229003906, 'loss_4': 1.8292399644851685, 'epoch': 18.53}
{'loss': 0.0205, 'grad_norm': 10.347461700439453, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.018830817192792892, 'loss_2': 0.0016965866088867188, 'loss_3': -16.363649368286133, 'loss_4': 1.7726516723632812, 'epoch': 18.53}
{'loss': 0.0401, 'grad_norm': 17.177854537963867, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.032686714082956314, 'loss_2': 0.007366180419921875, 'loss_3': -16.333513259887695, 'loss_4': 1.8708696365356445, 'epoch': 18.54}
{'loss': 0.0102, 'grad_norm': 5.551937580108643, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.009417851455509663, 'loss_2': 0.0007719993591308594, 'loss_3': -16.455078125, 'loss_4': 1.4478873014450073, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 10:42:56,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:56,441 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:18:45<33:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:03,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008492639288306236, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.004533430095762014, 'eval_loss_2': 0.003959208726882935, 'eval_loss_3': -18.370031356811523, 'eval_loss_4': 0.8216619491577148, 'epoch': 18.55}
{'loss': 0.01, 'grad_norm': 5.708521842956543, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.008965869434177876, 'loss_2': 0.0010242462158203125, 'loss_3': -16.411216735839844, 'loss_4': 1.2056050300598145, 'epoch': 18.55}
{'loss': 0.0154, 'grad_norm': 5.839469909667969, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.010476600378751755, 'loss_2': 0.004913330078125, 'loss_3': -16.523496627807617, 'loss_4': 1.7296255826950073, 'epoch': 18.56}
{'loss': 0.0064, 'grad_norm': 5.001299858093262, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.0054734982550144196, 'loss_2': 0.0009479522705078125, 'loss_3': -16.532115936279297, 'loss_4': 1.6292591094970703, 'epoch': 18.56}
{'loss': 0.0199, 'grad_norm': 6.321741580963135, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.014307157136499882, 'loss_2': 0.005550384521484375, 'loss_3': -16.647396087646484, 'loss_4': 1.719994306564331, 'epoch': 18.57}
{'loss': 0.0125, 'grad_norm': 5.3535943031311035, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.011322672478854656, 'loss_2': 0.001201629638671875, 'loss_3': -16.621583938598633, 'loss_4': 1.5595768690109253, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 10:43:03,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:03,783 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:18:53<33:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:11,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008918573148548603, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004963328596204519, 'eval_loss_2': 0.003955245018005371, 'eval_loss_3': -18.36393928527832, 'eval_loss_4': 0.9068965911865234, 'epoch': 18.58}
{'loss': 0.0164, 'grad_norm': 6.09766149520874, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.01114526204764843, 'loss_2': 0.005260467529296875, 'loss_3': -16.757661819458008, 'loss_4': 2.067950487136841, 'epoch': 18.58}
{'loss': 0.0175, 'grad_norm': 6.462710857391357, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.01712968572974205, 'loss_2': 0.0003783702850341797, 'loss_3': -16.581995010375977, 'loss_4': 1.8941218852996826, 'epoch': 18.59}
{'loss': 0.0145, 'grad_norm': 6.91640043258667, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.011050796136260033, 'loss_2': 0.003437042236328125, 'loss_3': -16.488523483276367, 'loss_4': 1.7059805393218994, 'epoch': 18.59}
{'loss': 0.0363, 'grad_norm': 14.911652565002441, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.03330430015921593, 'loss_2': 0.003017425537109375, 'loss_3': -16.47984504699707, 'loss_4': 1.9462306499481201, 'epoch': 18.6}
{'loss': 0.0126, 'grad_norm': 5.66522741317749, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.007906459271907806, 'loss_2': 0.00469970703125, 'loss_3': -16.80923080444336, 'loss_4': 1.7923710346221924, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 10:43:11,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:11,135 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:00<33:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:18,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009409626945853233, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.202, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004799565300345421, 'eval_loss_2': 0.0046100616455078125, 'eval_loss_3': -18.3515682220459, 'eval_loss_4': 0.8378100395202637, 'epoch': 18.6}
{'loss': 0.0328, 'grad_norm': 17.8795223236084, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.032570891082286835, 'loss_2': 0.00027751922607421875, 'loss_3': -16.590444564819336, 'loss_4': 1.788465976715088, 'epoch': 18.61}
{'loss': 0.0091, 'grad_norm': 4.470736503601074, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.0042739505879580975, 'loss_2': 0.0048370361328125, 'loss_3': -16.573314666748047, 'loss_4': 1.0635441541671753, 'epoch': 18.62}
{'loss': 0.0167, 'grad_norm': 7.360293388366699, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.013376411981880665, 'loss_2': 0.0033416748046875, 'loss_3': -16.580345153808594, 'loss_4': 1.4692370891571045, 'epoch': 18.62}
{'loss': 0.0222, 'grad_norm': 12.116437911987305, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.01798820123076439, 'loss_2': 0.00424957275390625, 'loss_3': -16.56768035888672, 'loss_4': 1.2091948986053467, 'epoch': 18.63}
{'loss': 0.0144, 'grad_norm': 5.167230129241943, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.00889646541327238, 'loss_2': 0.00547027587890625, 'loss_3': -16.750476837158203, 'loss_4': 1.0145702362060547, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 10:43:18,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:18,480 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:07<33:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:25,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008816211484372616, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.446, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004747695289552212, 'eval_loss_2': 0.004068516194820404, 'eval_loss_3': -18.35563087463379, 'eval_loss_4': 0.8128378987312317, 'epoch': 18.63}
{'loss': 0.0109, 'grad_norm': 5.759242057800293, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.008393813855946064, 'loss_2': 0.002490997314453125, 'loss_3': -16.6932315826416, 'loss_4': 1.4809249639511108, 'epoch': 18.64}
{'loss': 0.013, 'grad_norm': 5.065263271331787, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.008693361654877663, 'loss_2': 0.00429534912109375, 'loss_3': -16.85306167602539, 'loss_4': 1.5722055435180664, 'epoch': 18.65}
{'loss': 0.0093, 'grad_norm': 5.705417633056641, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.008567599579691887, 'loss_2': 0.0007205009460449219, 'loss_3': -16.591510772705078, 'loss_4': 1.4876606464385986, 'epoch': 18.65}
{'loss': 0.0168, 'grad_norm': 5.861649990081787, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.010040415450930595, 'loss_2': 0.00675201416015625, 'loss_3': -16.292325973510742, 'loss_4': 2.2335987091064453, 'epoch': 18.66}
{'loss': 0.0181, 'grad_norm': 5.492394924163818, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.01206942554563284, 'loss_2': 0.006072998046875, 'loss_3': -16.723876953125, 'loss_4': 1.6682558059692383, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 10:43:25,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:25,818 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:15<33:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:33,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00886758603155613, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005437540356069803, 'eval_loss_2': 0.0034300461411476135, 'eval_loss_3': -18.350093841552734, 'eval_loss_4': 0.762260913848877, 'epoch': 18.66}
{'loss': 0.015, 'grad_norm': 5.062557697296143, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.010654302313923836, 'loss_2': 0.004375457763671875, 'loss_3': -16.515819549560547, 'loss_4': 1.717392921447754, 'epoch': 18.67}
{'loss': 0.0298, 'grad_norm': 9.551383018493652, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.026994362473487854, 'loss_2': 0.002773284912109375, 'loss_3': -16.51548957824707, 'loss_4': 1.3186180591583252, 'epoch': 18.67}
{'loss': 0.0159, 'grad_norm': 9.044757843017578, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.014671078883111477, 'loss_2': 0.0012731552124023438, 'loss_3': -16.672380447387695, 'loss_4': 1.1949951648712158, 'epoch': 18.68}
{'loss': 0.0116, 'grad_norm': 6.834453582763672, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.011469774879515171, 'loss_2': 0.00010514259338378906, 'loss_3': -16.61745834350586, 'loss_4': 1.49056077003479, 'epoch': 18.69}
{'loss': 0.0077, 'grad_norm': 4.69024658203125, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.007639212999492884, 'loss_2': 3.153085708618164e-05, 'loss_3': -16.63408660888672, 'loss_4': 1.6487250328063965, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 10:43:33,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:33,159 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:22<33:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:40,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009474062360823154, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.293, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005771152675151825, 'eval_loss_2': 0.003702908754348755, 'eval_loss_3': -18.326175689697266, 'eval_loss_4': 0.7144238948822021, 'epoch': 18.69}
{'loss': 0.0077, 'grad_norm': 5.117968559265137, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.004806144628673792, 'loss_2': 0.0029296875, 'loss_3': -16.546077728271484, 'loss_4': 1.5028691291809082, 'epoch': 18.7}
{'loss': 0.0164, 'grad_norm': 6.220367908477783, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.010688448324799538, 'loss_2': 0.005748748779296875, 'loss_3': -16.723220825195312, 'loss_4': 1.3735673427581787, 'epoch': 18.7}
{'loss': 0.0134, 'grad_norm': 5.544711589813232, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.008945105597376823, 'loss_2': 0.004474639892578125, 'loss_3': -16.342166900634766, 'loss_4': 1.1280373334884644, 'epoch': 18.71}
{'loss': 0.0066, 'grad_norm': 4.856513977050781, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.00547429034486413, 'loss_2': 0.0011081695556640625, 'loss_3': -16.672561645507812, 'loss_4': 1.4518864154815674, 'epoch': 18.72}
{'loss': 0.0083, 'grad_norm': 5.252851963043213, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.007834209129214287, 'loss_2': 0.0004534721374511719, 'loss_3': -16.462987899780273, 'loss_4': 1.6517471075057983, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 10:43:40,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:40,507 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:30<33:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:47,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010796252638101578, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.641, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007297995500266552, 'eval_loss_2': 0.003498256206512451, 'eval_loss_3': -18.317846298217773, 'eval_loss_4': 0.8425709009170532, 'epoch': 18.72}
{'loss': 0.0052, 'grad_norm': 4.589739799499512, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.004374053329229355, 'loss_2': 0.0007839202880859375, 'loss_3': -16.592729568481445, 'loss_4': 1.7146949768066406, 'epoch': 18.73}
{'loss': 0.0127, 'grad_norm': 4.8448662757873535, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.009139439091086388, 'loss_2': 0.0036029815673828125, 'loss_3': -16.57227897644043, 'loss_4': 1.1549606323242188, 'epoch': 18.73}
{'loss': 0.0103, 'grad_norm': 6.13653039932251, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.010101962834596634, 'loss_2': 0.0002105236053466797, 'loss_3': -16.594982147216797, 'loss_4': 1.2081211805343628, 'epoch': 18.74}
{'loss': 0.0197, 'grad_norm': 8.279796600341797, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.009966304525732994, 'loss_2': 0.0097503662109375, 'loss_3': -16.244548797607422, 'loss_4': 1.3025814294815063, 'epoch': 18.74}
{'loss': 0.0091, 'grad_norm': 4.99418830871582, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.005252123810350895, 'loss_2': 0.003894805908203125, 'loss_3': -16.587051391601562, 'loss_4': 1.5051064491271973, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 10:43:47,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:47,846 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:37<33:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:55,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010775085538625717, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.244, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006960083730518818, 'eval_loss_2': 0.003815002739429474, 'eval_loss_3': -18.312515258789062, 'eval_loss_4': 0.9124342203140259, 'epoch': 18.75}
{'loss': 0.02, 'grad_norm': 6.5033345222473145, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.01430062111467123, 'loss_2': 0.00568389892578125, 'loss_3': -16.438892364501953, 'loss_4': 1.6319350004196167, 'epoch': 18.76}
{'loss': 0.0091, 'grad_norm': 4.637882709503174, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.005219419486820698, 'loss_2': 0.00389862060546875, 'loss_3': -16.574283599853516, 'loss_4': 1.5810906887054443, 'epoch': 18.76}
{'loss': 0.0051, 'grad_norm': 4.86821174621582, 'learning_rate': 1.125e-05, 'loss_1': 0.003976677544414997, 'loss_2': 0.0010938644409179688, 'loss_3': -16.45650863647461, 'loss_4': 1.3940073251724243, 'epoch': 18.77}
{'loss': 0.0251, 'grad_norm': 12.171696662902832, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.017786575481295586, 'loss_2': 0.00728607177734375, 'loss_3': -16.514583587646484, 'loss_4': 1.3228695392608643, 'epoch': 18.77}
{'loss': 0.0217, 'grad_norm': 7.863940238952637, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.015256990678608418, 'loss_2': 0.0063934326171875, 'loss_3': -16.565065383911133, 'loss_4': 1.6144764423370361, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 10:43:55,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:55,192 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:19:44<33:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:02,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011829705908894539, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006468477193266153, 'eval_loss_2': 0.005361229181289673, 'eval_loss_3': -18.308408737182617, 'eval_loss_4': 0.956445038318634, 'epoch': 18.78}
{'loss': 0.0136, 'grad_norm': 10.725802421569824, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.012550785206258297, 'loss_2': 0.0010509490966796875, 'loss_3': -16.46908950805664, 'loss_4': 1.1729931831359863, 'epoch': 18.78}
{'loss': 0.0125, 'grad_norm': 8.05817699432373, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.012200874276459217, 'loss_2': 0.0002837181091308594, 'loss_3': -16.70711898803711, 'loss_4': 1.802181601524353, 'epoch': 18.79}
{'loss': 0.0154, 'grad_norm': 6.665774822235107, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.013090485706925392, 'loss_2': 0.002338409423828125, 'loss_3': -16.46040916442871, 'loss_4': 1.3909578323364258, 'epoch': 18.8}
{'loss': 0.0383, 'grad_norm': 10.358455657958984, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.023771312087774277, 'loss_2': 0.0144805908203125, 'loss_3': -16.420852661132812, 'loss_4': 1.6747007369995117, 'epoch': 18.8}
{'loss': 0.0178, 'grad_norm': 6.33458137512207, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.01527334749698639, 'loss_2': 0.0025234222412109375, 'loss_3': -16.219879150390625, 'loss_4': 1.5954632759094238, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 10:44:02,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:02,533 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:19:52<33:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:09,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009867311455309391, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005723067093640566, 'eval_loss_2': 0.004144243896007538, 'eval_loss_3': -18.302513122558594, 'eval_loss_4': 1.0904736518859863, 'epoch': 18.81}
{'loss': 0.0208, 'grad_norm': 8.73645305633545, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.018209952861070633, 'loss_2': 0.002574920654296875, 'loss_3': -16.50107192993164, 'loss_4': 1.9374996423721313, 'epoch': 18.81}
{'loss': 0.0118, 'grad_norm': 5.1779985427856445, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.006806169170886278, 'loss_2': 0.0050048828125, 'loss_3': -16.313140869140625, 'loss_4': 2.0492143630981445, 'epoch': 18.82}
{'loss': 0.0158, 'grad_norm': 4.868858814239502, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.005621427670121193, 'loss_2': 0.0102081298828125, 'loss_3': -16.45246124267578, 'loss_4': 1.4571619033813477, 'epoch': 18.83}
{'loss': 0.0091, 'grad_norm': 4.67848539352417, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.005482614506036043, 'loss_2': 0.0035762786865234375, 'loss_3': -16.52577781677246, 'loss_4': 1.5263354778289795, 'epoch': 18.83}
{'loss': 0.0059, 'grad_norm': 4.5505781173706055, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.004576849285513163, 'loss_2': 0.0012798309326171875, 'loss_3': -16.525686264038086, 'loss_4': 2.115086317062378, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 10:44:09,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:09,872 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:19:59<33:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:17,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009529350325465202, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005786595866084099, 'eval_loss_2': 0.0037427544593811035, 'eval_loss_3': -18.295970916748047, 'eval_loss_4': 1.206284523010254, 'epoch': 18.84}
{'loss': 0.0098, 'grad_norm': 6.37978982925415, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.007814864628016949, 'loss_2': 0.00197601318359375, 'loss_3': -16.497024536132812, 'loss_4': 2.0417349338531494, 'epoch': 18.84}
{'loss': 0.0051, 'grad_norm': 4.193058490753174, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.0046610464341938496, 'loss_2': 0.0004124641418457031, 'loss_3': -16.432374954223633, 'loss_4': 1.7421958446502686, 'epoch': 18.85}
{'loss': 0.0106, 'grad_norm': 5.599158763885498, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.008974234573543072, 'loss_2': 0.001605987548828125, 'loss_3': -16.292930603027344, 'loss_4': 1.8356328010559082, 'epoch': 18.85}
{'loss': 0.0299, 'grad_norm': 16.269372940063477, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.024892058223485947, 'loss_2': 0.0050201416015625, 'loss_3': -16.52092742919922, 'loss_4': 1.627964735031128, 'epoch': 18.86}
{'loss': 0.0284, 'grad_norm': 10.743279457092285, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.013726632110774517, 'loss_2': 0.0146331787109375, 'loss_3': -16.409337997436523, 'loss_4': 1.5431345701217651, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 10:44:17,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:17,215 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:06<33:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:24,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010961893945932388, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0052713495679199696, 'eval_loss_2': 0.005690544843673706, 'eval_loss_3': -18.303199768066406, 'eval_loss_4': 1.4408628940582275, 'epoch': 18.87}
{'loss': 0.0152, 'grad_norm': 9.496986389160156, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.010768844746053219, 'loss_2': 0.00445556640625, 'loss_3': -16.380168914794922, 'loss_4': 2.322629690170288, 'epoch': 18.87}
{'loss': 0.0109, 'grad_norm': 5.009286880493164, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.00672577042132616, 'loss_2': 0.004146575927734375, 'loss_3': -16.43380355834961, 'loss_4': 2.499443769454956, 'epoch': 18.88}
{'loss': 0.0237, 'grad_norm': 9.469488143920898, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.016505897045135498, 'loss_2': 0.0072021484375, 'loss_3': -16.57003402709961, 'loss_4': 1.9120309352874756, 'epoch': 18.88}
{'loss': 0.0079, 'grad_norm': 4.673438549041748, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.004542396869510412, 'loss_2': 0.003353118896484375, 'loss_3': -16.600303649902344, 'loss_4': 2.164487361907959, 'epoch': 18.89}
{'loss': 0.0075, 'grad_norm': 4.248368263244629, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.00387185113504529, 'loss_2': 0.0036773681640625, 'loss_3': -16.645736694335938, 'loss_4': 2.2896533012390137, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 10:44:24,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:24,549 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:14<32:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:31,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011268272995948792, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.243, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005779726896435022, 'eval_loss_2': 0.005488544702529907, 'eval_loss_3': -18.297988891601562, 'eval_loss_4': 1.5184545516967773, 'epoch': 18.9}
{'loss': 0.0239, 'grad_norm': 6.576835632324219, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.014924673363566399, 'loss_2': 0.009002685546875, 'loss_3': -16.482685089111328, 'loss_4': 1.7854245901107788, 'epoch': 18.9}
{'loss': 0.011, 'grad_norm': 5.5105791091918945, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.007854638621211052, 'loss_2': 0.003162384033203125, 'loss_3': -16.37276840209961, 'loss_4': 2.2681946754455566, 'epoch': 18.91}
{'loss': 0.0122, 'grad_norm': 8.662347793579102, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.0108801843598485, 'loss_2': 0.0013027191162109375, 'loss_3': -16.462430953979492, 'loss_4': 1.7850983142852783, 'epoch': 18.91}
{'loss': 0.0056, 'grad_norm': 4.119274616241455, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.003529708134010434, 'loss_2': 0.0020503997802734375, 'loss_3': -16.653274536132812, 'loss_4': 2.100313425064087, 'epoch': 18.92}
{'loss': 0.0143, 'grad_norm': 7.519575595855713, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.013554036617279053, 'loss_2': 0.0007042884826660156, 'loss_3': -16.34162139892578, 'loss_4': 2.688406229019165, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 10:44:31,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:31,897 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:21<32:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:39,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010073566809296608, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006203436758369207, 'eval_loss_2': 0.0038701295852661133, 'eval_loss_3': -18.28335189819336, 'eval_loss_4': 1.5827925205230713, 'epoch': 18.92}
{'loss': 0.0053, 'grad_norm': 4.682212829589844, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.004851717501878738, 'loss_2': 0.0004968643188476562, 'loss_3': -16.303749084472656, 'loss_4': 2.4921579360961914, 'epoch': 18.93}
{'loss': 0.0203, 'grad_norm': 11.337079048156738, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.01936914399266243, 'loss_2': 0.0008869171142578125, 'loss_3': -16.46276092529297, 'loss_4': 2.162693977355957, 'epoch': 18.94}
{'loss': 0.0234, 'grad_norm': 7.247202396392822, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.014248497784137726, 'loss_2': 0.009185791015625, 'loss_3': -16.391563415527344, 'loss_4': 2.005979061126709, 'epoch': 18.94}
{'loss': 0.0071, 'grad_norm': 4.824341773986816, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.0047890120185911655, 'loss_2': 0.00231170654296875, 'loss_3': -16.51172637939453, 'loss_4': 1.7302050590515137, 'epoch': 18.95}
{'loss': 0.0078, 'grad_norm': 4.373626708984375, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.004980851896107197, 'loss_2': 0.002788543701171875, 'loss_3': -16.46770477294922, 'loss_4': 2.2268013954162598, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 10:44:39,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:39,243 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:28<32:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:46,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010658077895641327, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.297, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006869279779493809, 'eval_loss_2': 0.0037887990474700928, 'eval_loss_3': -18.276050567626953, 'eval_loss_4': 1.6296736001968384, 'epoch': 18.95}
{'loss': 0.0132, 'grad_norm': 4.99464225769043, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.00570960808545351, 'loss_2': 0.00753021240234375, 'loss_3': -16.563251495361328, 'loss_4': 1.8721215724945068, 'epoch': 18.96}
{'loss': 0.0136, 'grad_norm': 7.412679672241211, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.010260609909892082, 'loss_2': 0.0033626556396484375, 'loss_3': -16.390893936157227, 'loss_4': 2.46173357963562, 'epoch': 18.97}
{'loss': 0.0117, 'grad_norm': 8.202229499816895, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.009786691516637802, 'loss_2': 0.001941680908203125, 'loss_3': -16.557247161865234, 'loss_4': 2.5537824630737305, 'epoch': 18.97}
{'loss': 0.0161, 'grad_norm': 4.863905906677246, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.005782057531177998, 'loss_2': 0.0103607177734375, 'loss_3': -16.490468978881836, 'loss_4': 2.015737771987915, 'epoch': 18.98}
{'loss': 0.0173, 'grad_norm': 4.890190601348877, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.00629477808251977, 'loss_2': 0.0110015869140625, 'loss_3': -16.47449493408203, 'loss_4': 2.1839065551757812, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 10:44:46,586 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:46,586 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:35<31:20,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 10:44:53,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010183153674006462, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006923822686076164, 'eval_loss_2': 0.003259330987930298, 'eval_loss_3': -18.285324096679688, 'eval_loss_4': 1.7246301174163818, 'epoch': 18.98}
{'loss': 0.0063, 'grad_norm': 5.165151596069336, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.005529467482119799, 'loss_2': 0.0007228851318359375, 'loss_3': -16.361961364746094, 'loss_4': 2.51352596282959, 'epoch': 18.99}
{'loss': 0.0112, 'grad_norm': 5.297780990600586, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.009062088094651699, 'loss_2': 0.002170562744140625, 'loss_3': -16.141328811645508, 'loss_4': 1.9514784812927246, 'epoch': 18.99}
{'loss': 0.0083, 'grad_norm': 7.274737358093262, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.004768888466060162, 'loss_2': 0.003490447998046875, 'loss_3': -16.4227294921875, 'loss_4': 2.4830708503723145, 'epoch': 19.0}
{'loss': 0.0143, 'grad_norm': 8.490421295166016, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.008388493210077286, 'loss_2': 0.005893707275390625, 'loss_3': -16.49971580505371, 'loss_4': 2.0356383323669434, 'epoch': 19.01}
{'loss': 0.0132, 'grad_norm': 8.245307922363281, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.013105886057019234, 'loss_2': 4.649162292480469e-05, 'loss_3': -16.511226654052734, 'loss_4': 2.4416961669921875, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 10:44:53,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:53,620 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:43<32:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:45:00,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011636162176728249, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007448228541761637, 'eval_loss_2': 0.004187934100627899, 'eval_loss_3': -18.28253173828125, 'eval_loss_4': 1.8457088470458984, 'epoch': 19.01}
{'loss': 0.0119, 'grad_norm': 5.583322048187256, 'learning_rate': 1.1e-05, 'loss_1': 0.007559905759990215, 'loss_2': 0.004344940185546875, 'loss_3': -15.978582382202148, 'loss_4': 2.1186208724975586, 'epoch': 19.02}
{'loss': 0.0105, 'grad_norm': 5.211511135101318, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.007081659510731697, 'loss_2': 0.00341033935546875, 'loss_3': -16.257404327392578, 'loss_4': 2.6293416023254395, 'epoch': 19.02}
{'loss': 0.0213, 'grad_norm': 12.211576461791992, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.016625382006168365, 'loss_2': 0.00469970703125, 'loss_3': -16.45529556274414, 'loss_4': 2.5685839653015137, 'epoch': 19.03}
{'loss': 0.0108, 'grad_norm': 4.822861671447754, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.006280668079853058, 'loss_2': 0.0045318603515625, 'loss_3': -16.48808479309082, 'loss_4': 2.242905855178833, 'epoch': 19.03}
{'loss': 0.011, 'grad_norm': 5.332271099090576, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.00841495767235756, 'loss_2': 0.002536773681640625, 'loss_3': -16.433609008789062, 'loss_4': 2.5131754875183105, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 10:45:00,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:00,960 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:20:50<32:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:08,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011922456324100494, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.572, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0071273259818553925, 'eval_loss_2': 0.004795130342245102, 'eval_loss_3': -18.258094787597656, 'eval_loss_4': 1.9891738891601562, 'epoch': 19.04}
{'loss': 0.0047, 'grad_norm': 4.349284648895264, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.003986289259046316, 'loss_2': 0.000713348388671875, 'loss_3': -16.647789001464844, 'loss_4': 2.647909164428711, 'epoch': 19.05}
{'loss': 0.0065, 'grad_norm': 5.017387866973877, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.005894968751817942, 'loss_2': 0.0005736351013183594, 'loss_3': -16.372913360595703, 'loss_4': 2.1827874183654785, 'epoch': 19.05}
{'loss': 0.0185, 'grad_norm': 6.811020851135254, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.014034681022167206, 'loss_2': 0.00444793701171875, 'loss_3': -16.364046096801758, 'loss_4': 3.110131025314331, 'epoch': 19.06}
{'loss': 0.0184, 'grad_norm': 5.641916275024414, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.014323174022138119, 'loss_2': 0.004062652587890625, 'loss_3': -16.218494415283203, 'loss_4': 2.224562644958496, 'epoch': 19.06}
{'loss': 0.0084, 'grad_norm': 4.886437892913818, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.0025970416609197855, 'loss_2': 0.00582122802734375, 'loss_3': -16.343564987182617, 'loss_4': 1.9565027952194214, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 10:45:08,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:08,301 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:20:57<32:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:15,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012434208765625954, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.917, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006731356028467417, 'eval_loss_2': 0.005702853202819824, 'eval_loss_3': -18.278396606445312, 'eval_loss_4': 1.960561990737915, 'epoch': 19.07}
{'loss': 0.006, 'grad_norm': 5.066009998321533, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.005468904040753841, 'loss_2': 0.0005035400390625, 'loss_3': -16.442138671875, 'loss_4': 2.7754266262054443, 'epoch': 19.08}
{'loss': 0.0102, 'grad_norm': 5.045645713806152, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.007573963608592749, 'loss_2': 0.0026569366455078125, 'loss_3': -16.489173889160156, 'loss_4': 2.2881531715393066, 'epoch': 19.08}
{'loss': 0.01, 'grad_norm': 5.39326286315918, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.009267652407288551, 'loss_2': 0.0007047653198242188, 'loss_3': -16.33730125427246, 'loss_4': 1.7348473072052002, 'epoch': 19.09}
{'loss': 0.01, 'grad_norm': 5.432431697845459, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.006775088142603636, 'loss_2': 0.003223419189453125, 'loss_3': -16.437774658203125, 'loss_4': 2.2442312240600586, 'epoch': 19.09}
{'loss': 0.0129, 'grad_norm': 11.052891731262207, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.01172027550637722, 'loss_2': 0.00113677978515625, 'loss_3': -16.316539764404297, 'loss_4': 2.4853274822235107, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 10:45:15,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:15,667 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:05<32:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:23,006 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010340800508856773, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.873, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.006690134759992361, 'eval_loss_2': 0.003650665283203125, 'eval_loss_3': -18.274978637695312, 'eval_loss_4': 1.9720191955566406, 'epoch': 19.1}
{'loss': 0.0081, 'grad_norm': 5.746729850769043, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.005423371680080891, 'loss_2': 0.00269317626953125, 'loss_3': -16.283597946166992, 'loss_4': 2.7993967533111572, 'epoch': 19.1}
{'loss': 0.0061, 'grad_norm': 5.230781555175781, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.005870190914720297, 'loss_2': 0.0002040863037109375, 'loss_3': -16.510696411132812, 'loss_4': 2.221956491470337, 'epoch': 19.11}
{'loss': 0.0111, 'grad_norm': 6.255207061767578, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.0077619245275855064, 'loss_2': 0.0033206939697265625, 'loss_3': -16.374706268310547, 'loss_4': 2.4911351203918457, 'epoch': 19.12}
{'loss': 0.0214, 'grad_norm': 12.4105224609375, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.017676666378974915, 'loss_2': 0.0037078857421875, 'loss_3': -16.372379302978516, 'loss_4': 2.86293888092041, 'epoch': 19.12}
{'loss': 0.0194, 'grad_norm': 6.309901714324951, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.010648620314896107, 'loss_2': 0.0087738037109375, 'loss_3': -16.597864151000977, 'loss_4': 2.3857624530792236, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 10:45:23,006 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:23,006 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:12<32:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:30,342 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009618174284696579, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.784, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0062905363738536835, 'eval_loss_2': 0.0033276379108428955, 'eval_loss_3': -18.288267135620117, 'eval_loss_4': 1.963629961013794, 'epoch': 19.13}
{'loss': 0.0062, 'grad_norm': 4.5445733070373535, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.003983079921454191, 'loss_2': 0.0022125244140625, 'loss_3': -16.267419815063477, 'loss_4': 2.1388680934906006, 'epoch': 19.13}
{'loss': 0.0088, 'grad_norm': 4.515270709991455, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.004493790213018656, 'loss_2': 0.0042572021484375, 'loss_3': -16.213417053222656, 'loss_4': 2.4465248584747314, 'epoch': 19.14}
{'loss': 0.0131, 'grad_norm': 5.069821834564209, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.00633443845435977, 'loss_2': 0.00675201416015625, 'loss_3': -16.401552200317383, 'loss_4': 2.628356456756592, 'epoch': 19.15}
{'loss': 0.006, 'grad_norm': 4.869298934936523, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.005545610561966896, 'loss_2': 0.0004916191101074219, 'loss_3': -16.496173858642578, 'loss_4': 2.408953905105591, 'epoch': 19.15}
{'loss': 0.0228, 'grad_norm': 9.446723937988281, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.018546782433986664, 'loss_2': 0.00428009033203125, 'loss_3': -16.629833221435547, 'loss_4': 2.2265372276306152, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 10:45:30,342 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:30,342 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:19<32:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:37,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009234744124114513, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005597448907792568, 'eval_loss_2': 0.003637295216321945, 'eval_loss_3': -18.305706024169922, 'eval_loss_4': 1.976583480834961, 'epoch': 19.16}
{'loss': 0.0098, 'grad_norm': 5.236067771911621, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.00668100081384182, 'loss_2': 0.003101348876953125, 'loss_3': -16.399860382080078, 'loss_4': 2.6319422721862793, 'epoch': 19.16}
{'loss': 0.0162, 'grad_norm': 5.475988864898682, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.010378601960837841, 'loss_2': 0.00586700439453125, 'loss_3': -16.596935272216797, 'loss_4': 1.6760706901550293, 'epoch': 19.17}
{'loss': 0.0241, 'grad_norm': 6.5580596923828125, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.011152232065796852, 'loss_2': 0.0129547119140625, 'loss_3': -16.240184783935547, 'loss_4': 2.2409467697143555, 'epoch': 19.17}
{'loss': 0.0196, 'grad_norm': 7.670191764831543, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.015263664536178112, 'loss_2': 0.004291534423828125, 'loss_3': -16.288551330566406, 'loss_4': 3.196552276611328, 'epoch': 19.18}
{'loss': 0.0091, 'grad_norm': 5.2826924324035645, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.006278251763433218, 'loss_2': 0.0028591156005859375, 'loss_3': -16.37139892578125, 'loss_4': 1.9104520082473755, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 10:45:37,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:37,682 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:27<32:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:45,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00929981842637062, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.568, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006200152449309826, 'eval_loss_2': 0.00309966504573822, 'eval_loss_3': -18.301958084106445, 'eval_loss_4': 1.9861706495285034, 'epoch': 19.19}
{'loss': 0.0071, 'grad_norm': 5.280731678009033, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.00488450238481164, 'loss_2': 0.00222015380859375, 'loss_3': -16.37996482849121, 'loss_4': 2.9078681468963623, 'epoch': 19.19}
{'loss': 0.0159, 'grad_norm': 8.643780708312988, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.008726363070309162, 'loss_2': 0.007144927978515625, 'loss_3': -16.629283905029297, 'loss_4': 2.6843297481536865, 'epoch': 19.2}
{'loss': 0.0054, 'grad_norm': 5.335864543914795, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.0052360650151968, 'loss_2': 0.0001474618911743164, 'loss_3': -16.193891525268555, 'loss_4': 2.690253257751465, 'epoch': 19.2}
{'loss': 0.0312, 'grad_norm': 25.628406524658203, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.027332786470651627, 'loss_2': 0.003849029541015625, 'loss_3': -16.28643798828125, 'loss_4': 2.765368700027466, 'epoch': 19.21}
{'loss': 0.009, 'grad_norm': 5.053121089935303, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.0056623476557433605, 'loss_2': 0.0032939910888671875, 'loss_3': -16.377716064453125, 'loss_4': 2.661290168762207, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 10:45:45,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:45,018 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:34<31:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:52,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00955415703356266, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.816, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0062776305712759495, 'eval_loss_2': 0.003276526927947998, 'eval_loss_3': -18.306209564208984, 'eval_loss_4': 2.015244960784912, 'epoch': 19.22}
{'loss': 0.0105, 'grad_norm': 5.022765636444092, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.004675252363085747, 'loss_2': 0.0058746337890625, 'loss_3': -16.214468002319336, 'loss_4': 2.735935926437378, 'epoch': 19.22}
{'loss': 0.0051, 'grad_norm': 4.450492858886719, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.003622287418693304, 'loss_2': 0.0014858245849609375, 'loss_3': -16.279266357421875, 'loss_4': 2.7207589149475098, 'epoch': 19.23}
{'loss': 0.0143, 'grad_norm': 6.46382474899292, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.013436419889330864, 'loss_2': 0.0008420944213867188, 'loss_3': -16.24342918395996, 'loss_4': 2.527339220046997, 'epoch': 19.23}
{'loss': 0.0096, 'grad_norm': 5.830149173736572, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.007383277639746666, 'loss_2': 0.002239227294921875, 'loss_3': -16.483089447021484, 'loss_4': 2.400613307952881, 'epoch': 19.24}
{'loss': 0.0234, 'grad_norm': 12.912535667419434, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.01771867834031582, 'loss_2': 0.00569915771484375, 'loss_3': -16.299068450927734, 'loss_4': 2.2670271396636963, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 10:45:52,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:52,356 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:41<31:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:59,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008900297805666924, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005941735114902258, 'eval_loss_2': 0.0029585622251033783, 'eval_loss_3': -18.32164192199707, 'eval_loss_4': 2.0277323722839355, 'epoch': 19.24}
{'loss': 0.022, 'grad_norm': 7.983068466186523, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.01819329708814621, 'loss_2': 0.00376129150390625, 'loss_3': -16.372529983520508, 'loss_4': 2.384469985961914, 'epoch': 19.25}
{'loss': 0.0182, 'grad_norm': 7.9014573097229, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.011040551587939262, 'loss_2': 0.00714111328125, 'loss_3': -16.376422882080078, 'loss_4': 2.2848095893859863, 'epoch': 19.26}
{'loss': 0.011, 'grad_norm': 5.04094934463501, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.00809764489531517, 'loss_2': 0.002887725830078125, 'loss_3': -16.469268798828125, 'loss_4': 2.239166498184204, 'epoch': 19.26}
{'loss': 0.0154, 'grad_norm': 6.7131571769714355, 'learning_rate': 1.075e-05, 'loss_1': 0.009269294328987598, 'loss_2': 0.00609588623046875, 'loss_3': -16.47488021850586, 'loss_4': 2.8152761459350586, 'epoch': 19.27}
{'loss': 0.0091, 'grad_norm': 4.476680755615234, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.0030215615406632423, 'loss_2': 0.00609588623046875, 'loss_3': -16.28329849243164, 'loss_4': 2.081672430038452, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 10:45:59,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:59,704 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:21:49<31:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:07,047 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008829830214381218, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.545, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0064107016660273075, 'eval_loss_2': 0.0024191290140151978, 'eval_loss_3': -18.346664428710938, 'eval_loss_4': 2.0361990928649902, 'epoch': 19.27}
{'loss': 0.01, 'grad_norm': 5.129131317138672, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.0064979600720107555, 'loss_2': 0.0034942626953125, 'loss_3': -16.36322021484375, 'loss_4': 2.809927463531494, 'epoch': 19.28}
{'loss': 0.0098, 'grad_norm': 5.3453850746154785, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.006729654036462307, 'loss_2': 0.0030975341796875, 'loss_3': -16.29216766357422, 'loss_4': 2.898305892944336, 'epoch': 19.28}
{'loss': 0.0133, 'grad_norm': 7.891620635986328, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.010242413729429245, 'loss_2': 0.00301361083984375, 'loss_3': -16.338794708251953, 'loss_4': 2.6215755939483643, 'epoch': 19.29}
{'loss': 0.0097, 'grad_norm': 4.920334815979004, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.005580454599112272, 'loss_2': 0.00412750244140625, 'loss_3': -16.605030059814453, 'loss_4': 3.2391490936279297, 'epoch': 19.3}
{'loss': 0.0051, 'grad_norm': 4.538234710693359, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.003939499147236347, 'loss_2': 0.0011587142944335938, 'loss_3': -16.577157974243164, 'loss_4': 2.912825584411621, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 10:46:07,047 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:07,047 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:21:56<31:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:14,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007418136112391949, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.753, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005244205240160227, 'eval_loss_2': 0.0021739304065704346, 'eval_loss_3': -18.345516204833984, 'eval_loss_4': 2.029426097869873, 'epoch': 19.3}
{'loss': 0.0069, 'grad_norm': 4.944666385650635, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.006425608415156603, 'loss_2': 0.0004639625549316406, 'loss_3': -16.45492172241211, 'loss_4': 2.551225185394287, 'epoch': 19.31}
{'loss': 0.008, 'grad_norm': 4.739988327026367, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.004633045755326748, 'loss_2': 0.0033245086669921875, 'loss_3': -16.434051513671875, 'loss_4': 2.449955940246582, 'epoch': 19.31}
{'loss': 0.015, 'grad_norm': 6.415371894836426, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.011724811978638172, 'loss_2': 0.003284454345703125, 'loss_3': -16.373355865478516, 'loss_4': 2.4069643020629883, 'epoch': 19.32}
{'loss': 0.0175, 'grad_norm': 6.344379425048828, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.01657586172223091, 'loss_2': 0.0009474754333496094, 'loss_3': -16.104700088500977, 'loss_4': 2.6288576126098633, 'epoch': 19.33}
{'loss': 0.0165, 'grad_norm': 5.371768951416016, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.00945662334561348, 'loss_2': 0.0070037841796875, 'loss_3': -16.454818725585938, 'loss_4': 2.590679407119751, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 10:46:14,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:14,385 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:03<31:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:21,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007398249581456184, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.867, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.004855618812143803, 'eval_loss_2': 0.002542629837989807, 'eval_loss_3': -18.356643676757812, 'eval_loss_4': 1.8071012496948242, 'epoch': 19.33}
{'loss': 0.0115, 'grad_norm': 8.137659072875977, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.010033918544650078, 'loss_2': 0.0014581680297851562, 'loss_3': -16.521480560302734, 'loss_4': 2.7096927165985107, 'epoch': 19.34}
{'loss': 0.0067, 'grad_norm': 4.718185901641846, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.0035507776774466038, 'loss_2': 0.003143310546875, 'loss_3': -16.500038146972656, 'loss_4': 2.4827442169189453, 'epoch': 19.34}
{'loss': 0.0043, 'grad_norm': 4.668105602264404, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.004203330725431442, 'loss_2': 0.00010323524475097656, 'loss_3': -16.512874603271484, 'loss_4': 2.7038652896881104, 'epoch': 19.35}
{'loss': 0.0107, 'grad_norm': 5.342573642730713, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.0065923165529966354, 'loss_2': 0.00409698486328125, 'loss_3': -16.480541229248047, 'loss_4': 2.532681465148926, 'epoch': 19.35}
{'loss': 0.0079, 'grad_norm': 5.624820232391357, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.006851231679320335, 'loss_2': 0.0010814666748046875, 'loss_3': -16.23656463623047, 'loss_4': 2.3773345947265625, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 10:46:21,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:21,724 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:11<31:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:29,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007474993355572224, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.805, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.004832726437598467, 'eval_loss_2': 0.0026422664523124695, 'eval_loss_3': -18.360811233520508, 'eval_loss_4': 1.597306728363037, 'epoch': 19.36}
{'loss': 0.0133, 'grad_norm': 10.305892944335938, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.012311561964452267, 'loss_2': 0.0010318756103515625, 'loss_3': -16.17441749572754, 'loss_4': 1.9768891334533691, 'epoch': 19.37}
{'loss': 0.0076, 'grad_norm': 4.4596266746521, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.004741918761283159, 'loss_2': 0.00283050537109375, 'loss_3': -16.337738037109375, 'loss_4': 2.529233932495117, 'epoch': 19.37}
{'loss': 0.0136, 'grad_norm': 4.794372081756592, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.009767593815922737, 'loss_2': 0.00382232666015625, 'loss_3': -16.609676361083984, 'loss_4': 2.1999387741088867, 'epoch': 19.38}
{'loss': 0.0092, 'grad_norm': 4.616124629974365, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.008776974864304066, 'loss_2': 0.0004086494445800781, 'loss_3': -16.585670471191406, 'loss_4': 2.12172532081604, 'epoch': 19.38}
{'loss': 0.0181, 'grad_norm': 9.440104484558105, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.016527950763702393, 'loss_2': 0.0015850067138671875, 'loss_3': -16.34684944152832, 'loss_4': 2.6901700496673584, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 10:46:29,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:29,062 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:18<31:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:36,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007658933289349079, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.363, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004923973698168993, 'eval_loss_2': 0.002734959125518799, 'eval_loss_3': -18.366493225097656, 'eval_loss_4': 1.4983271360397339, 'epoch': 19.39}
{'loss': 0.0286, 'grad_norm': 16.989091873168945, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.022960251197218895, 'loss_2': 0.0055999755859375, 'loss_3': -16.311336517333984, 'loss_4': 2.234788417816162, 'epoch': 19.4}
{'loss': 0.0209, 'grad_norm': 7.213791370391846, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.011861163191497326, 'loss_2': 0.009033203125, 'loss_3': -16.37044906616211, 'loss_4': 1.6213250160217285, 'epoch': 19.4}
{'loss': 0.011, 'grad_norm': 6.626769065856934, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.009086268953979015, 'loss_2': 0.0019397735595703125, 'loss_3': -16.302825927734375, 'loss_4': 2.1630053520202637, 'epoch': 19.41}
{'loss': 0.0216, 'grad_norm': 7.701631546020508, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.011635505594313145, 'loss_2': 0.010009765625, 'loss_3': -16.43353843688965, 'loss_4': 1.7788701057434082, 'epoch': 19.41}
{'loss': 0.0138, 'grad_norm': 4.500195503234863, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.006877176929265261, 'loss_2': 0.00696563720703125, 'loss_3': -16.480327606201172, 'loss_4': 2.816762924194336, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 10:46:36,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:36,407 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:25<31:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:43,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008308937773108482, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005276475567370653, 'eval_loss_2': 0.0030324608087539673, 'eval_loss_3': -18.346925735473633, 'eval_loss_4': 1.4566177129745483, 'epoch': 19.42}
{'loss': 0.0346, 'grad_norm': 17.573759078979492, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.031393054872751236, 'loss_2': 0.0031833648681640625, 'loss_3': -16.439830780029297, 'loss_4': 1.7244882583618164, 'epoch': 19.42}
{'loss': 0.0137, 'grad_norm': 4.763937950134277, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.0069765616208314896, 'loss_2': 0.0067596435546875, 'loss_3': -16.431428909301758, 'loss_4': 2.3164851665496826, 'epoch': 19.43}
{'loss': 0.0126, 'grad_norm': 5.755687713623047, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.008594263345003128, 'loss_2': 0.0040130615234375, 'loss_3': -16.499038696289062, 'loss_4': 2.267728328704834, 'epoch': 19.44}
{'loss': 0.0136, 'grad_norm': 5.846578598022461, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.006778396666049957, 'loss_2': 0.00678253173828125, 'loss_3': -16.372737884521484, 'loss_4': 1.8162956237792969, 'epoch': 19.44}
{'loss': 0.0172, 'grad_norm': 7.3883185386657715, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.014959484338760376, 'loss_2': 0.002239227294921875, 'loss_3': -16.397506713867188, 'loss_4': 1.783663034439087, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 10:46:43,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:43,751 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:33<31:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:51,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00818287581205368, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.922, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.004993443377315998, 'eval_loss_2': 0.003189433366060257, 'eval_loss_3': -18.32556915283203, 'eval_loss_4': 1.416598916053772, 'epoch': 19.45}
{'loss': 0.0097, 'grad_norm': 5.675293445587158, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.007316102739423513, 'loss_2': 0.002429962158203125, 'loss_3': -16.478984832763672, 'loss_4': 2.269686460494995, 'epoch': 19.45}
{'loss': 0.0046, 'grad_norm': 4.574867248535156, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.0033237978350371122, 'loss_2': 0.001308441162109375, 'loss_3': -16.33576202392578, 'loss_4': 2.2017598152160645, 'epoch': 19.46}
{'loss': 0.0056, 'grad_norm': 4.873464584350586, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.004456945229321718, 'loss_2': 0.0011234283447265625, 'loss_3': -16.43010711669922, 'loss_4': 2.02360200881958, 'epoch': 19.47}
{'loss': 0.0043, 'grad_norm': 4.700620651245117, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.0033591249957680702, 'loss_2': 0.0009241104125976562, 'loss_3': -16.398855209350586, 'loss_4': 2.19326114654541, 'epoch': 19.47}
{'loss': 0.0134, 'grad_norm': 5.012678623199463, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.00500565767288208, 'loss_2': 0.0083770751953125, 'loss_3': -16.2493896484375, 'loss_4': 2.095954418182373, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 10:46:51,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:51,087 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:40<31:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:58,421 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008799377828836441, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.679, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.005400660447776318, 'eval_loss_2': 0.003398716449737549, 'eval_loss_3': -18.309463500976562, 'eval_loss_4': 1.4245764017105103, 'epoch': 19.48}
{'loss': 0.0211, 'grad_norm': 7.92797327041626, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.014560780487954617, 'loss_2': 0.00649261474609375, 'loss_3': -16.09357261657715, 'loss_4': 2.0617659091949463, 'epoch': 19.48}
{'loss': 0.0143, 'grad_norm': 8.222484588623047, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.013924135826528072, 'loss_2': 0.00036072731018066406, 'loss_3': -16.480070114135742, 'loss_4': 1.9135240316390991, 'epoch': 19.49}
{'loss': 0.0131, 'grad_norm': 8.156803131103516, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.008291360922157764, 'loss_2': 0.004817962646484375, 'loss_3': -16.39730453491211, 'loss_4': 1.7337427139282227, 'epoch': 19.49}
{'loss': 0.0079, 'grad_norm': 5.059033393859863, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.007021044380962849, 'loss_2': 0.0008454322814941406, 'loss_3': -16.539642333984375, 'loss_4': 2.0187675952911377, 'epoch': 19.5}
{'loss': 0.0077, 'grad_norm': 5.229979515075684, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.005964274983853102, 'loss_2': 0.0017852783203125, 'loss_3': -16.318708419799805, 'loss_4': 2.0668203830718994, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 10:46:58,421 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:58,421 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:22:47<31:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:05,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009701600298285484, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.736, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005606552120298147, 'eval_loss_2': 0.00409504771232605, 'eval_loss_3': -18.29142189025879, 'eval_loss_4': 1.3532506227493286, 'epoch': 19.51}
{'loss': 0.0151, 'grad_norm': 7.441296100616455, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.012154962867498398, 'loss_2': 0.0029277801513671875, 'loss_3': -16.30974578857422, 'loss_4': 1.8171255588531494, 'epoch': 19.51}
{'loss': 0.0168, 'grad_norm': 5.1298956871032715, 'learning_rate': 1.05e-05, 'loss_1': 0.005501196254044771, 'loss_2': 0.0113372802734375, 'loss_3': -16.466732025146484, 'loss_4': 1.6968376636505127, 'epoch': 19.52}
{'loss': 0.0052, 'grad_norm': 4.508602619171143, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.004554235376417637, 'loss_2': 0.0006527900695800781, 'loss_3': -16.468538284301758, 'loss_4': 2.2352752685546875, 'epoch': 19.52}
{'loss': 0.011, 'grad_norm': 4.700870990753174, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.004045644775032997, 'loss_2': 0.0069732666015625, 'loss_3': -16.628070831298828, 'loss_4': 1.7354097366333008, 'epoch': 19.53}
{'loss': 0.0133, 'grad_norm': 6.360354900360107, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.011394278146326542, 'loss_2': 0.0019168853759765625, 'loss_3': -16.165847778320312, 'loss_4': 2.278935432434082, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 10:47:05,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:05,757 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:22:55<31:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:13,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009112954139709473, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.802, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.005473761353641748, 'eval_loss_2': 0.0036391913890838623, 'eval_loss_3': -18.291397094726562, 'eval_loss_4': 1.384406328201294, 'epoch': 19.53}
{'loss': 0.0108, 'grad_norm': 5.365001201629639, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.0081052640452981, 'loss_2': 0.0026760101318359375, 'loss_3': -16.48760986328125, 'loss_4': 1.396834135055542, 'epoch': 19.54}
{'loss': 0.0151, 'grad_norm': 5.929630279541016, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.007712316699326038, 'loss_2': 0.007419586181640625, 'loss_3': -16.4478759765625, 'loss_4': 1.4283541440963745, 'epoch': 19.55}
{'loss': 0.0341, 'grad_norm': 13.089372634887695, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.02406681515276432, 'loss_2': 0.01000213623046875, 'loss_3': -16.45159149169922, 'loss_4': 1.5497307777404785, 'epoch': 19.55}
{'loss': 0.0067, 'grad_norm': 4.9564619064331055, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.004733668174594641, 'loss_2': 0.00194549560546875, 'loss_3': -16.396953582763672, 'loss_4': 1.9817848205566406, 'epoch': 19.56}
{'loss': 0.0075, 'grad_norm': 5.241109371185303, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.006266859360039234, 'loss_2': 0.0012502670288085938, 'loss_3': -16.370206832885742, 'loss_4': 1.5355523824691772, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 10:47:13,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:13,100 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:02<30:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:20,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009883055463433266, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.02, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0060777198523283005, 'eval_loss_2': 0.003805335611104965, 'eval_loss_3': -18.290239334106445, 'eval_loss_4': 1.518227219581604, 'epoch': 19.56}
{'loss': 0.0082, 'grad_norm': 4.549333572387695, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.005636409856379032, 'loss_2': 0.0025653839111328125, 'loss_3': -16.282148361206055, 'loss_4': 2.0215704441070557, 'epoch': 19.57}
{'loss': 0.0121, 'grad_norm': 5.612585544586182, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.007563074119389057, 'loss_2': 0.004535675048828125, 'loss_3': -16.571327209472656, 'loss_4': 2.4408953189849854, 'epoch': 19.58}
{'loss': 0.0088, 'grad_norm': 5.531107425689697, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.008540055714547634, 'loss_2': 0.0002598762512207031, 'loss_3': -16.519134521484375, 'loss_4': 2.068612575531006, 'epoch': 19.58}
{'loss': 0.0182, 'grad_norm': 12.713050842285156, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.015940038487315178, 'loss_2': 0.0022602081298828125, 'loss_3': -16.301532745361328, 'loss_4': 2.5719637870788574, 'epoch': 19.59}
{'loss': 0.01, 'grad_norm': 5.925209999084473, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.008012516424059868, 'loss_2': 0.0020008087158203125, 'loss_3': -16.324827194213867, 'loss_4': 2.5295052528381348, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 10:47:20,452 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:20,452 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:09<30:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:27,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010455542244017124, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.022, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.006147035397589207, 'eval_loss_2': 0.0043085068464279175, 'eval_loss_3': -18.299524307250977, 'eval_loss_4': 1.6505727767944336, 'epoch': 19.59}
{'loss': 0.013, 'grad_norm': 5.99946403503418, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.008241157047450542, 'loss_2': 0.00472259521484375, 'loss_3': -16.43977165222168, 'loss_4': 2.5853235721588135, 'epoch': 19.6}
{'loss': 0.0039, 'grad_norm': 4.603536605834961, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.003547542728483677, 'loss_2': 0.0003371238708496094, 'loss_3': -16.506267547607422, 'loss_4': 1.9325547218322754, 'epoch': 19.6}
{'loss': 0.0112, 'grad_norm': 6.622730255126953, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.007768531329929829, 'loss_2': 0.003459930419921875, 'loss_3': -16.47409439086914, 'loss_4': 1.724697470664978, 'epoch': 19.61}
{'loss': 0.0168, 'grad_norm': 5.867383003234863, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.011594156734645367, 'loss_2': 0.005218505859375, 'loss_3': -16.35565757751465, 'loss_4': 1.9263736009597778, 'epoch': 19.62}
{'loss': 0.0114, 'grad_norm': 7.144766330718994, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.010606974363327026, 'loss_2': 0.00075531005859375, 'loss_3': -16.50140953063965, 'loss_4': 2.0026206970214844, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 10:47:27,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:27,788 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:17<30:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:35,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009935559704899788, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006523788906633854, 'eval_loss_2': 0.0034117698669433594, 'eval_loss_3': -18.303943634033203, 'eval_loss_4': 1.7654238939285278, 'epoch': 19.62}
{'loss': 0.0065, 'grad_norm': 4.525318622589111, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.004501298535615206, 'loss_2': 0.001995086669921875, 'loss_3': -16.584400177001953, 'loss_4': 1.7536976337432861, 'epoch': 19.63}
{'loss': 0.0118, 'grad_norm': 4.646544933319092, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.005589134059846401, 'loss_2': 0.00617218017578125, 'loss_3': -16.451824188232422, 'loss_4': 2.189833641052246, 'epoch': 19.63}
{'loss': 0.0091, 'grad_norm': 5.074752330780029, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.008134539239108562, 'loss_2': 0.0010137557983398438, 'loss_3': -16.427234649658203, 'loss_4': 2.1912894248962402, 'epoch': 19.64}
{'loss': 0.0239, 'grad_norm': 9.29029655456543, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.01603665202856064, 'loss_2': 0.00785064697265625, 'loss_3': -16.2708683013916, 'loss_4': 2.5032296180725098, 'epoch': 19.65}
{'loss': 0.0326, 'grad_norm': 14.142909049987793, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.03015044517815113, 'loss_2': 0.002445220947265625, 'loss_3': -16.399213790893555, 'loss_4': 2.414149761199951, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 10:47:35,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:35,119 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:24<30:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:42,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010419470258057117, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007529799826443195, 'eval_loss_2': 0.002889670431613922, 'eval_loss_3': -18.304471969604492, 'eval_loss_4': 1.8962982892990112, 'epoch': 19.65}
{'loss': 0.0104, 'grad_norm': 4.8768744468688965, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.008625106886029243, 'loss_2': 0.0018148422241210938, 'loss_3': -16.610658645629883, 'loss_4': 2.968074321746826, 'epoch': 19.66}
{'loss': 0.0093, 'grad_norm': 4.853235244750977, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.0071969726122915745, 'loss_2': 0.002124786376953125, 'loss_3': -16.482975006103516, 'loss_4': 1.7136952877044678, 'epoch': 19.66}
{'loss': 0.0227, 'grad_norm': 8.040319442749023, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.0168021097779274, 'loss_2': 0.005924224853515625, 'loss_3': -16.456228256225586, 'loss_4': 2.646864414215088, 'epoch': 19.67}
{'loss': 0.0089, 'grad_norm': 4.415768146514893, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.006586418952792883, 'loss_2': 0.0022983551025390625, 'loss_3': -16.32478141784668, 'loss_4': 2.4212331771850586, 'epoch': 19.67}
{'loss': 0.02, 'grad_norm': 16.293066024780273, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.018680818378925323, 'loss_2': 0.00128173828125, 'loss_3': -16.455480575561523, 'loss_4': 2.631838321685791, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 10:47:42,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:42,459 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:31<30:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:49,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011152183637022972, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.758, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007883613929152489, 'eval_loss_2': 0.0032685697078704834, 'eval_loss_3': -18.301177978515625, 'eval_loss_4': 1.8992323875427246, 'epoch': 19.68}
{'loss': 0.0127, 'grad_norm': 5.84320068359375, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.0095229996368289, 'loss_2': 0.00321197509765625, 'loss_3': -16.27642822265625, 'loss_4': 2.060985803604126, 'epoch': 19.69}
{'loss': 0.0267, 'grad_norm': 15.23723030090332, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.023862866684794426, 'loss_2': 0.0027980804443359375, 'loss_3': -16.25667953491211, 'loss_4': 2.7594337463378906, 'epoch': 19.69}
{'loss': 0.0098, 'grad_norm': 4.37462043762207, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.0038015227764844894, 'loss_2': 0.00604248046875, 'loss_3': -16.6414794921875, 'loss_4': 2.1170220375061035, 'epoch': 19.7}
{'loss': 0.0116, 'grad_norm': 4.256807804107666, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.006641805171966553, 'loss_2': 0.004917144775390625, 'loss_3': -16.70310401916504, 'loss_4': 1.8110814094543457, 'epoch': 19.7}
{'loss': 0.0193, 'grad_norm': 7.206226348876953, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.011323116719722748, 'loss_2': 0.0079498291015625, 'loss_3': -16.489646911621094, 'loss_4': 3.3169782161712646, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 10:47:49,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:49,797 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:39<30:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:57,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012783326208591461, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007845647633075714, 'eval_loss_2': 0.004937678575515747, 'eval_loss_3': -18.282901763916016, 'eval_loss_4': 1.9801726341247559, 'epoch': 19.71}
{'loss': 0.0139, 'grad_norm': 5.97511100769043, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.010033616796135902, 'loss_2': 0.00391387939453125, 'loss_3': -16.50078582763672, 'loss_4': 2.8665771484375, 'epoch': 19.72}
{'loss': 0.0304, 'grad_norm': 15.093077659606934, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.02168971113860607, 'loss_2': 0.00872039794921875, 'loss_3': -16.381256103515625, 'loss_4': 2.0791759490966797, 'epoch': 19.72}
{'loss': 0.0191, 'grad_norm': 6.081488609313965, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.01142527349293232, 'loss_2': 0.007659912109375, 'loss_3': -16.6198787689209, 'loss_4': 2.7034413814544678, 'epoch': 19.73}
{'loss': 0.0114, 'grad_norm': 6.937494277954102, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.009114697575569153, 'loss_2': 0.0022525787353515625, 'loss_3': -16.293033599853516, 'loss_4': 2.7898812294006348, 'epoch': 19.73}
{'loss': 0.0138, 'grad_norm': 6.262765884399414, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.009022931568324566, 'loss_2': 0.00476837158203125, 'loss_3': -16.594148635864258, 'loss_4': 2.4258816242218018, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 10:47:57,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:57,142 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:23:46<30:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:04,502 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012544248253107071, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.619, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008083629421889782, 'eval_loss_2': 0.004460617899894714, 'eval_loss_3': -18.25480842590332, 'eval_loss_4': 2.073115348815918, 'epoch': 19.74}
{'loss': 0.0056, 'grad_norm': 4.630439758300781, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.004380939528346062, 'loss_2': 0.0012636184692382812, 'loss_3': -16.720094680786133, 'loss_4': 3.192444086074829, 'epoch': 19.74}
{'loss': 0.0361, 'grad_norm': 9.891281127929688, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.035951342433691025, 'loss_2': 0.00017404556274414062, 'loss_3': -16.372644424438477, 'loss_4': 2.5189504623413086, 'epoch': 19.75}
{'loss': 0.0131, 'grad_norm': 5.883767604827881, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.009746364317834377, 'loss_2': 0.003376007080078125, 'loss_3': -16.422916412353516, 'loss_4': 2.6771326065063477, 'epoch': 19.76}
{'loss': 0.0115, 'grad_norm': 6.712912082672119, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.010592211969196796, 'loss_2': 0.0009336471557617188, 'loss_3': -16.422996520996094, 'loss_4': 2.8376994132995605, 'epoch': 19.76}
{'loss': 0.0082, 'grad_norm': 5.476119041442871, 'learning_rate': 1.025e-05, 'loss_1': 0.0074628847651183605, 'loss_2': 0.0007748603820800781, 'loss_3': -16.29134178161621, 'loss_4': 1.9106686115264893, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 10:48:04,503 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:04,503 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:23:54<30:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:11,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01161607913672924, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.597, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008031311444938183, 'eval_loss_2': 0.003584768623113632, 'eval_loss_3': -18.24843978881836, 'eval_loss_4': 1.9862980842590332, 'epoch': 19.77}
{'loss': 0.0175, 'grad_norm': 4.9973015785217285, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.0069603705778717995, 'loss_2': 0.0105438232421875, 'loss_3': -16.46419906616211, 'loss_4': 2.45884108543396, 'epoch': 19.77}
{'loss': 0.0066, 'grad_norm': 5.088062286376953, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.00530982855707407, 'loss_2': 0.0012454986572265625, 'loss_3': -16.442190170288086, 'loss_4': 2.0118420124053955, 'epoch': 19.78}
{'loss': 0.0102, 'grad_norm': 4.959289073944092, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.0076560210436582565, 'loss_2': 0.0025348663330078125, 'loss_3': -16.465641021728516, 'loss_4': 2.537266254425049, 'epoch': 19.78}
{'loss': 0.0229, 'grad_norm': 16.210250854492188, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.019403239712119102, 'loss_2': 0.0035343170166015625, 'loss_3': -16.573074340820312, 'loss_4': 2.8081650733947754, 'epoch': 19.79}
{'loss': 0.0089, 'grad_norm': 4.736405849456787, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.005247985012829304, 'loss_2': 0.00360870361328125, 'loss_3': -16.427087783813477, 'loss_4': 2.2990736961364746, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 10:48:11,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:11,844 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:01<30:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:19,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010035823099315166, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.807, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.006745542399585247, 'eval_loss_2': 0.0032902806997299194, 'eval_loss_3': -18.228147506713867, 'eval_loss_4': 1.9929074048995972, 'epoch': 19.8}
{'loss': 0.0127, 'grad_norm': 5.774356365203857, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.012047992087900639, 'loss_2': 0.0006036758422851562, 'loss_3': -16.461816787719727, 'loss_4': 2.2636122703552246, 'epoch': 19.8}
{'loss': 0.0074, 'grad_norm': 5.175123691558838, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.006670908536761999, 'loss_2': 0.0007495880126953125, 'loss_3': -16.458984375, 'loss_4': 2.8417088985443115, 'epoch': 19.81}
{'loss': 0.0189, 'grad_norm': 8.767027854919434, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.017629891633987427, 'loss_2': 0.0012664794921875, 'loss_3': -16.4626522064209, 'loss_4': 2.068053960800171, 'epoch': 19.81}
{'loss': 0.0244, 'grad_norm': 7.111960411071777, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.01644383743405342, 'loss_2': 0.0079345703125, 'loss_3': -16.30972671508789, 'loss_4': 2.0169310569763184, 'epoch': 19.82}
{'loss': 0.0193, 'grad_norm': 6.446335315704346, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.014800310134887695, 'loss_2': 0.00446319580078125, 'loss_3': -16.400428771972656, 'loss_4': 2.616821765899658, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 10:48:19,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:19,184 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:08<30:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:26,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011667245998978615, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.856, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.005979532841593027, 'eval_loss_2': 0.005687713623046875, 'eval_loss_3': -18.24207878112793, 'eval_loss_4': 1.9416980743408203, 'epoch': 19.83}
{'loss': 0.0119, 'grad_norm': 5.733232498168945, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.008595878258347511, 'loss_2': 0.0033111572265625, 'loss_3': -16.373022079467773, 'loss_4': 2.234142541885376, 'epoch': 19.83}
{'loss': 0.0156, 'grad_norm': 5.065830230712891, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.005675486288964748, 'loss_2': 0.0099639892578125, 'loss_3': -16.508331298828125, 'loss_4': 2.3422982692718506, 'epoch': 19.84}
{'loss': 0.028, 'grad_norm': 10.79718017578125, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.02351769432425499, 'loss_2': 0.0045166015625, 'loss_3': -16.413175582885742, 'loss_4': 2.2805001735687256, 'epoch': 19.84}
{'loss': 0.0088, 'grad_norm': 4.848607540130615, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.004709722939878702, 'loss_2': 0.004085540771484375, 'loss_3': -16.28472328186035, 'loss_4': 2.5473263263702393, 'epoch': 19.85}
{'loss': 0.0179, 'grad_norm': 5.92384147644043, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.0071286652237176895, 'loss_2': 0.01078033447265625, 'loss_3': -16.47201156616211, 'loss_4': 2.5181884765625, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 10:48:26,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:26,520 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:16<30:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:33,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008853127248585224, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.645, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00522999931126833, 'eval_loss_2': 0.0036231279373168945, 'eval_loss_3': -18.25660514831543, 'eval_loss_4': 1.875118374824524, 'epoch': 19.85}
{'loss': 0.023, 'grad_norm': 8.34904670715332, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.021468129009008408, 'loss_2': 0.0015506744384765625, 'loss_3': -16.31609344482422, 'loss_4': 2.409471035003662, 'epoch': 19.86}
{'loss': 0.0143, 'grad_norm': 4.590167045593262, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.0052972277626395226, 'loss_2': 0.0090179443359375, 'loss_3': -16.44270133972168, 'loss_4': 2.1634044647216797, 'epoch': 19.87}
{'loss': 0.0182, 'grad_norm': 9.855911254882812, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.011364775709807873, 'loss_2': 0.00685882568359375, 'loss_3': -16.74609375, 'loss_4': 2.117816209793091, 'epoch': 19.87}
{'loss': 0.0098, 'grad_norm': 5.242276668548584, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.008685442619025707, 'loss_2': 0.0010662078857421875, 'loss_3': -16.502166748046875, 'loss_4': 2.1473941802978516, 'epoch': 19.88}
{'loss': 0.0136, 'grad_norm': 6.4302167892456055, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.011971170082688332, 'loss_2': 0.0016565322875976562, 'loss_3': -16.574535369873047, 'loss_4': 2.9353508949279785, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 10:48:33,857 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:33,857 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:23<30:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:41,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0071055348962545395, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.885, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004540210589766502, 'eval_loss_2': 0.002565324306488037, 'eval_loss_3': -18.271326065063477, 'eval_loss_4': 1.8998064994812012, 'epoch': 19.88}
{'loss': 0.0063, 'grad_norm': 5.432452201843262, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.006174284964799881, 'loss_2': 0.00016355514526367188, 'loss_3': -16.44955825805664, 'loss_4': 2.29451060295105, 'epoch': 19.89}
{'loss': 0.0086, 'grad_norm': 4.952938079833984, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.006668818183243275, 'loss_2': 0.001964569091796875, 'loss_3': -16.41043472290039, 'loss_4': 3.0420827865600586, 'epoch': 19.9}
{'loss': 0.0088, 'grad_norm': 5.212642192840576, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.007543330080807209, 'loss_2': 0.001239776611328125, 'loss_3': -16.549236297607422, 'loss_4': 2.397362232208252, 'epoch': 19.9}
{'loss': 0.0165, 'grad_norm': 5.6985883712768555, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.010012494400143623, 'loss_2': 0.0065155029296875, 'loss_3': -16.32032012939453, 'loss_4': 2.2625932693481445, 'epoch': 19.91}
{'loss': 0.008, 'grad_norm': 5.2512102127075195, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.006736540235579014, 'loss_2': 0.0012264251708984375, 'loss_3': -16.589462280273438, 'loss_4': 2.6833078861236572, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 10:48:41,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:41,213 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:30<29:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:48,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007989659905433655, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.602, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0049361130222678185, 'eval_loss_2': 0.0030535459518432617, 'eval_loss_3': -18.277690887451172, 'eval_loss_4': 2.0982143878936768, 'epoch': 19.91}
{'loss': 0.0096, 'grad_norm': 4.216976642608643, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.006875562481582165, 'loss_2': 0.002696990966796875, 'loss_3': -16.44499969482422, 'loss_4': 2.456514358520508, 'epoch': 19.92}
{'loss': 0.0056, 'grad_norm': 4.620615005493164, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.005248905625194311, 'loss_2': 0.00030159950256347656, 'loss_3': -16.40833282470703, 'loss_4': 2.446589946746826, 'epoch': 19.92}
{'loss': 0.0104, 'grad_norm': 4.762801170349121, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.00400429405272007, 'loss_2': 0.00637054443359375, 'loss_3': -16.327009201049805, 'loss_4': 2.1902761459350586, 'epoch': 19.93}
{'loss': 0.0095, 'grad_norm': 5.521899700164795, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.00860750861465931, 'loss_2': 0.000904083251953125, 'loss_3': -16.39008331298828, 'loss_4': 3.0224967002868652, 'epoch': 19.94}
{'loss': 0.0113, 'grad_norm': 5.264621257781982, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.009329271502792835, 'loss_2': 0.0019245147705078125, 'loss_3': -16.491809844970703, 'loss_4': 2.593472957611084, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 10:48:48,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:48,553 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:38<29:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:55,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007971420884132385, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005444572307169437, 'eval_loss_2': 0.0025268495082855225, 'eval_loss_3': -18.283315658569336, 'eval_loss_4': 2.5063207149505615, 'epoch': 19.94}
{'loss': 0.0077, 'grad_norm': 4.782114028930664, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.006314115598797798, 'loss_2': 0.001346588134765625, 'loss_3': -16.53037452697754, 'loss_4': 3.2792086601257324, 'epoch': 19.95}
{'loss': 0.0112, 'grad_norm': 6.252997875213623, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.009589379653334618, 'loss_2': 0.001590728759765625, 'loss_3': -16.47057342529297, 'loss_4': 2.8330931663513184, 'epoch': 19.95}
{'loss': 0.0107, 'grad_norm': 4.92287540435791, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.004548388533294201, 'loss_2': 0.00615692138671875, 'loss_3': -16.317432403564453, 'loss_4': 2.614551305770874, 'epoch': 19.96}
{'loss': 0.0095, 'grad_norm': 4.877666473388672, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.007611739449203014, 'loss_2': 0.0019254684448242188, 'loss_3': -16.375892639160156, 'loss_4': 3.0185441970825195, 'epoch': 19.97}
{'loss': 0.0231, 'grad_norm': 7.382841110229492, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.016340171918272972, 'loss_2': 0.00673675537109375, 'loss_3': -16.581298828125, 'loss_4': 3.1601061820983887, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 10:48:55,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:55,897 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:24:45<26:45,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:49:02,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008380475454032421, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.592, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005849781446158886, 'eval_loss_2': 0.002530694007873535, 'eval_loss_3': -18.292207717895508, 'eval_loss_4': 2.880190849304199, 'epoch': 19.97}
{'loss': 0.0129, 'grad_norm': 5.609798431396484, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.0076008024625480175, 'loss_2': 0.00527191162109375, 'loss_3': -16.413848876953125, 'loss_4': 3.7907028198242188, 'epoch': 19.98}
{'loss': 0.0106, 'grad_norm': 4.668531894683838, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.009265275672078133, 'loss_2': 0.0013179779052734375, 'loss_3': -16.376434326171875, 'loss_4': 2.8103957176208496, 'epoch': 19.98}
{'loss': 0.0094, 'grad_norm': 4.961752891540527, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.006608050782233477, 'loss_2': 0.00274658203125, 'loss_3': -16.15630340576172, 'loss_4': 3.319467067718506, 'epoch': 19.99}
{'loss': 0.0147, 'grad_norm': 5.687133312225342, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.013738379813730717, 'loss_2': 0.0009632110595703125, 'loss_3': -16.260683059692383, 'loss_4': 3.5223186016082764, 'epoch': 19.99}
{'loss': 0.0069, 'grad_norm': 5.671639442443848, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.0014001827221363783, 'loss_2': 0.005451202392578125, 'loss_3': -16.40959930419922, 'loss_4': 4.17801570892334, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 10:49:02,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:02,891 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:24:52<29:15,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:49:10,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008738575503230095, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.431, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005789994262158871, 'eval_loss_2': 0.002948582172393799, 'eval_loss_3': -18.322906494140625, 'eval_loss_4': 3.124890089035034, 'epoch': 20.0}
{'loss': 0.0127, 'grad_norm': 6.572887897491455, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.010280216112732887, 'loss_2': 0.0024509429931640625, 'loss_3': -16.59955596923828, 'loss_4': 3.9219417572021484, 'epoch': 20.01}
{'loss': 0.0123, 'grad_norm': 5.082123756408691, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.006605727598071098, 'loss_2': 0.0056610107421875, 'loss_3': -16.50088119506836, 'loss_4': 3.8025522232055664, 'epoch': 20.01}
{'loss': 0.0108, 'grad_norm': 5.023819446563721, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.006319808773696423, 'loss_2': 0.0045166015625, 'loss_3': -16.715721130371094, 'loss_4': 4.171677112579346, 'epoch': 20.02}
{'loss': 0.0204, 'grad_norm': 6.104689121246338, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.009492769837379456, 'loss_2': 0.010894775390625, 'loss_3': -16.55828094482422, 'loss_4': 3.7239203453063965, 'epoch': 20.02}
{'loss': 0.0377, 'grad_norm': 15.313200950622559, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.032109182327985764, 'loss_2': 0.00556182861328125, 'loss_3': -16.495037078857422, 'loss_4': 4.002029895782471, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 10:49:10,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:10,277 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:24:59<29:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:17,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008445550687611103, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.737, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005249042995274067, 'eval_loss_2': 0.003196507692337036, 'eval_loss_3': -18.331151962280273, 'eval_loss_4': 3.3170065879821777, 'epoch': 20.03}
{'loss': 0.0283, 'grad_norm': 10.766377449035645, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.021113062277436256, 'loss_2': 0.0072174072265625, 'loss_3': -16.602346420288086, 'loss_4': 3.6641485691070557, 'epoch': 20.03}
{'loss': 0.0097, 'grad_norm': 5.11157751083374, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.007693400606513023, 'loss_2': 0.0019702911376953125, 'loss_3': -16.533124923706055, 'loss_4': 3.9541385173797607, 'epoch': 20.04}
{'loss': 0.0101, 'grad_norm': 5.609420299530029, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.008166138082742691, 'loss_2': 0.0019683837890625, 'loss_3': -16.476299285888672, 'loss_4': 3.8006410598754883, 'epoch': 20.05}
{'loss': 0.0096, 'grad_norm': 4.94551944732666, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.009210854768753052, 'loss_2': 0.00037860870361328125, 'loss_3': -16.59409523010254, 'loss_4': 4.082829475402832, 'epoch': 20.05}
{'loss': 0.0091, 'grad_norm': 5.509243011474609, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.007898539304733276, 'loss_2': 0.0011692047119140625, 'loss_3': -16.368392944335938, 'loss_4': 3.988436222076416, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 10:49:17,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:17,621 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:07<29:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:24,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008060410618782043, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004889114759862423, 'eval_loss_2': 0.003171294927597046, 'eval_loss_3': -18.315780639648438, 'eval_loss_4': 3.3608078956604004, 'epoch': 20.06}
{'loss': 0.0053, 'grad_norm': 5.068809986114502, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.0041203368455171585, 'loss_2': 0.0011968612670898438, 'loss_3': -16.41094970703125, 'loss_4': 3.8424417972564697, 'epoch': 20.06}
{'loss': 0.0085, 'grad_norm': 5.5356316566467285, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.008288916200399399, 'loss_2': 0.0002541542053222656, 'loss_3': -16.529151916503906, 'loss_4': 4.033524036407471, 'epoch': 20.07}
{'loss': 0.0175, 'grad_norm': 5.508302211761475, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.009348887018859386, 'loss_2': 0.0081787109375, 'loss_3': -16.315717697143555, 'loss_4': 4.4604034423828125, 'epoch': 20.08}
{'loss': 0.0156, 'grad_norm': 6.303403377532959, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.009177508763968945, 'loss_2': 0.00644683837890625, 'loss_3': -16.60076141357422, 'loss_4': 3.6494860649108887, 'epoch': 20.08}
{'loss': 0.0096, 'grad_norm': 6.301072597503662, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.009196567349135876, 'loss_2': 0.0004374980926513672, 'loss_3': -16.459999084472656, 'loss_4': 3.3091683387756348, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 10:49:24,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:24,972 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:14<29:48,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:49:32,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007653328590095043, 'eval_runtime': 4.0055, 'eval_samples_per_second': 255.646, 'eval_steps_per_second': 3.994, 'eval_loss_1': 0.004582914523780346, 'eval_loss_2': 0.0030704140663146973, 'eval_loss_3': -18.29746437072754, 'eval_loss_4': 3.2902255058288574, 'epoch': 20.09}
{'loss': 0.0181, 'grad_norm': 6.612009525299072, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.017254138365387917, 'loss_2': 0.0008907318115234375, 'loss_3': -16.52975082397461, 'loss_4': 4.093804836273193, 'epoch': 20.09}
{'loss': 0.0313, 'grad_norm': 8.560487747192383, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.02481110580265522, 'loss_2': 0.0064849853515625, 'loss_3': -16.294281005859375, 'loss_4': 3.655824661254883, 'epoch': 20.1}
{'loss': 0.0161, 'grad_norm': 5.989200115203857, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.014151636511087418, 'loss_2': 0.0019073486328125, 'loss_3': -16.29141616821289, 'loss_4': 3.9531381130218506, 'epoch': 20.1}
{'loss': 0.0069, 'grad_norm': 4.326707363128662, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.005916405003517866, 'loss_2': 0.0009489059448242188, 'loss_3': -16.611331939697266, 'loss_4': 3.5028939247131348, 'epoch': 20.11}
{'loss': 0.0092, 'grad_norm': 4.779934406280518, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.007961411029100418, 'loss_2': 0.0011968612670898438, 'loss_3': -16.684703826904297, 'loss_4': 4.0156450271606445, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 10:49:32,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:32,521 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:22<29:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:39,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008377631194889545, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005013454705476761, 'eval_loss_2': 0.00336417555809021, 'eval_loss_3': -18.315654754638672, 'eval_loss_4': 3.2370429039001465, 'epoch': 20.12}
{'loss': 0.0163, 'grad_norm': 5.178727149963379, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.006737109273672104, 'loss_2': 0.00951385498046875, 'loss_3': -16.487445831298828, 'loss_4': 3.7570786476135254, 'epoch': 20.12}
{'loss': 0.007, 'grad_norm': 5.023797035217285, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.005790701601654291, 'loss_2': 0.001255035400390625, 'loss_3': -16.40395736694336, 'loss_4': 3.7412986755371094, 'epoch': 20.13}
{'loss': 0.0074, 'grad_norm': 5.305746078491211, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.0060845897532999516, 'loss_2': 0.00131988525390625, 'loss_3': -16.473426818847656, 'loss_4': 3.3146824836730957, 'epoch': 20.13}
{'loss': 0.0283, 'grad_norm': 8.738812446594238, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.02115870639681816, 'loss_2': 0.00717926025390625, 'loss_3': -16.64838981628418, 'loss_4': 4.460545539855957, 'epoch': 20.14}
{'loss': 0.0201, 'grad_norm': 6.828920364379883, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.019389670342206955, 'loss_2': 0.0006723403930664062, 'loss_3': -16.506591796875, 'loss_4': 3.856222152709961, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 10:49:39,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:39,864 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:29<29:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:47,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008686131797730923, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.005222982726991177, 'eval_loss_2': 0.003463149070739746, 'eval_loss_3': -18.313636779785156, 'eval_loss_4': 3.2145750522613525, 'epoch': 20.15}
{'loss': 0.0038, 'grad_norm': 4.4908671379089355, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.0037105996161699295, 'loss_2': 9.238719940185547e-05, 'loss_3': -16.496604919433594, 'loss_4': 3.3701415061950684, 'epoch': 20.15}
{'loss': 0.009, 'grad_norm': 6.848150730133057, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.00873128604143858, 'loss_2': 0.0002923011779785156, 'loss_3': -16.64091682434082, 'loss_4': 3.538234233856201, 'epoch': 20.16}
{'loss': 0.0089, 'grad_norm': 4.755264759063721, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.005599498748779297, 'loss_2': 0.003307342529296875, 'loss_3': -16.444297790527344, 'loss_4': 3.774415969848633, 'epoch': 20.16}
{'loss': 0.0079, 'grad_norm': 5.985370635986328, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.006641329266130924, 'loss_2': 0.0012617111206054688, 'loss_3': -16.616140365600586, 'loss_4': 3.7236735820770264, 'epoch': 20.17}
{'loss': 0.0266, 'grad_norm': 16.655128479003906, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.02628405950963497, 'loss_2': 0.00036215782165527344, 'loss_3': -16.39453887939453, 'loss_4': 3.979595184326172, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 10:49:47,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:47,202 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:36<29:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:54,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00864816177636385, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.582, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005140786059200764, 'eval_loss_2': 0.003507375717163086, 'eval_loss_3': -18.320087432861328, 'eval_loss_4': 3.2022366523742676, 'epoch': 20.17}
{'loss': 0.0206, 'grad_norm': 13.861604690551758, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.019357483834028244, 'loss_2': 0.0012569427490234375, 'loss_3': -16.38343048095703, 'loss_4': 3.6464123725891113, 'epoch': 20.18}
{'loss': 0.0139, 'grad_norm': 7.962018013000488, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.008582967333495617, 'loss_2': 0.0052947998046875, 'loss_3': -16.576866149902344, 'loss_4': 3.5872936248779297, 'epoch': 20.19}
{'loss': 0.0214, 'grad_norm': 7.537389755249023, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.017353693023324013, 'loss_2': 0.0040435791015625, 'loss_3': -16.373199462890625, 'loss_4': 3.5119214057922363, 'epoch': 20.19}
{'loss': 0.0125, 'grad_norm': 5.180335521697998, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.008931782096624374, 'loss_2': 0.0035610198974609375, 'loss_3': -16.432819366455078, 'loss_4': 4.019796371459961, 'epoch': 20.2}
{'loss': 0.0079, 'grad_norm': 5.35541296005249, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.004432485438883305, 'loss_2': 0.003444671630859375, 'loss_3': -16.64321517944336, 'loss_4': 3.8370933532714844, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 10:49:54,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:54,557 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:25:44<29:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:01,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009284472092986107, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.784, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0058748917654156685, 'eval_loss_2': 0.0034095793962478638, 'eval_loss_3': -18.329618453979492, 'eval_loss_4': 3.176435947418213, 'epoch': 20.2}
{'loss': 0.0066, 'grad_norm': 5.593585968017578, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.006156703922897577, 'loss_2': 0.0004742145538330078, 'loss_3': -16.65491485595703, 'loss_4': 3.352647304534912, 'epoch': 20.21}
{'loss': 0.0129, 'grad_norm': 4.799056053161621, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.008256380446255207, 'loss_2': 0.004669189453125, 'loss_3': -16.534957885742188, 'loss_4': 3.9405617713928223, 'epoch': 20.22}
{'loss': 0.0094, 'grad_norm': 4.723330497741699, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.004421533085405827, 'loss_2': 0.004974365234375, 'loss_3': -16.393564224243164, 'loss_4': 3.7920961380004883, 'epoch': 20.22}
{'loss': 0.0081, 'grad_norm': 4.844917297363281, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.004441618919372559, 'loss_2': 0.0037078857421875, 'loss_3': -16.470874786376953, 'loss_4': 3.403505325317383, 'epoch': 20.23}
{'loss': 0.0121, 'grad_norm': 4.431032657623291, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.003906232537701726, 'loss_2': 0.00820159912109375, 'loss_3': -16.519861221313477, 'loss_4': 3.7395012378692627, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 10:50:01,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:01,918 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:25:51<28:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:09,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010380209423601627, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.63, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00568705890327692, 'eval_loss_2': 0.004693150520324707, 'eval_loss_3': -18.338407516479492, 'eval_loss_4': 3.1176247596740723, 'epoch': 20.23}
{'loss': 0.0144, 'grad_norm': 5.076843738555908, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.009267540648579597, 'loss_2': 0.005138397216796875, 'loss_3': -16.242525100708008, 'loss_4': 4.0200910568237305, 'epoch': 20.24}
{'loss': 0.0221, 'grad_norm': 5.316464424133301, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.01000713836401701, 'loss_2': 0.0121307373046875, 'loss_3': -16.51543426513672, 'loss_4': 3.5281596183776855, 'epoch': 20.24}
{'loss': 0.0323, 'grad_norm': 9.193928718566895, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.019686270505189896, 'loss_2': 0.01256561279296875, 'loss_3': -16.573699951171875, 'loss_4': 3.9167938232421875, 'epoch': 20.25}
{'loss': 0.0088, 'grad_norm': 6.235826015472412, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.007221734616905451, 'loss_2': 0.0016040802001953125, 'loss_3': -16.34791374206543, 'loss_4': 3.3431499004364014, 'epoch': 20.26}
{'loss': 0.0128, 'grad_norm': 5.695858478546143, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.007430625148117542, 'loss_2': 0.0053253173828125, 'loss_3': -16.61389923095703, 'loss_4': 3.4303534030914307, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 10:50:09,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:09,264 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:25:58<28:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:16,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010547385551035404, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.286, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00610069977119565, 'eval_loss_2': 0.004446685314178467, 'eval_loss_3': -18.352693557739258, 'eval_loss_4': 2.9672555923461914, 'epoch': 20.26}
{'loss': 0.01, 'grad_norm': 5.245791912078857, 'learning_rate': 9.75e-06, 'loss_1': 0.006528121419250965, 'loss_2': 0.003437042236328125, 'loss_3': -16.454139709472656, 'loss_4': 3.980313301086426, 'epoch': 20.27}
{'loss': 0.0157, 'grad_norm': 6.281899929046631, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.010428047738969326, 'loss_2': 0.00525665283203125, 'loss_3': -16.439687728881836, 'loss_4': 3.0893819332122803, 'epoch': 20.27}
{'loss': 0.0087, 'grad_norm': 4.9532389640808105, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.007259792648255825, 'loss_2': 0.001422882080078125, 'loss_3': -16.46783447265625, 'loss_4': 3.1761860847473145, 'epoch': 20.28}
{'loss': 0.0074, 'grad_norm': 5.360543251037598, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.005982389207929373, 'loss_2': 0.00145721435546875, 'loss_3': -16.310386657714844, 'loss_4': 3.0622501373291016, 'epoch': 20.28}
{'loss': 0.0117, 'grad_norm': 5.637747764587402, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.00799784529954195, 'loss_2': 0.00373077392578125, 'loss_3': -16.316621780395508, 'loss_4': 3.8755698204040527, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 10:50:16,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:16,608 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:06<28:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:23,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01052854023873806, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006805529352277517, 'eval_loss_2': 0.0037230104207992554, 'eval_loss_3': -18.356250762939453, 'eval_loss_4': 2.905035972595215, 'epoch': 20.29}
{'loss': 0.0237, 'grad_norm': 9.767343521118164, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.021738164126873016, 'loss_2': 0.001953125, 'loss_3': -16.341888427734375, 'loss_4': 3.1914498805999756, 'epoch': 20.3}
{'loss': 0.0096, 'grad_norm': 4.695533275604248, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.004614011850208044, 'loss_2': 0.00496673583984375, 'loss_3': -16.61227035522461, 'loss_4': 3.699437379837036, 'epoch': 20.3}
{'loss': 0.0079, 'grad_norm': 5.427079677581787, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.0073198238387703896, 'loss_2': 0.0005464553833007812, 'loss_3': -16.44275665283203, 'loss_4': 3.992549419403076, 'epoch': 20.31}
{'loss': 0.0131, 'grad_norm': 5.801938056945801, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.008495793677866459, 'loss_2': 0.004608154296875, 'loss_3': -16.57811737060547, 'loss_4': 3.3550329208374023, 'epoch': 20.31}
{'loss': 0.0051, 'grad_norm': 4.514003276824951, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.0027877462562173605, 'loss_2': 0.00231170654296875, 'loss_3': -16.292089462280273, 'loss_4': 3.535128593444824, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 10:50:23,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:23,955 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:13<28:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:31,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01049414835870266, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007366557605564594, 'eval_loss_2': 0.0031275898218154907, 'eval_loss_3': -18.360157012939453, 'eval_loss_4': 2.8626434803009033, 'epoch': 20.32}
{'loss': 0.0111, 'grad_norm': 5.549633502960205, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.005940526723861694, 'loss_2': 0.00518798828125, 'loss_3': -16.463096618652344, 'loss_4': 3.4163877964019775, 'epoch': 20.33}
{'loss': 0.0119, 'grad_norm': 5.724095821380615, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.00961313210427761, 'loss_2': 0.002269744873046875, 'loss_3': -16.414220809936523, 'loss_4': 3.226040840148926, 'epoch': 20.33}
{'loss': 0.0169, 'grad_norm': 8.93002700805664, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.014218089170753956, 'loss_2': 0.0027313232421875, 'loss_3': -16.47216033935547, 'loss_4': 3.248305320739746, 'epoch': 20.34}
{'loss': 0.0323, 'grad_norm': 7.3845343589782715, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.02952205389738083, 'loss_2': 0.0027313232421875, 'loss_3': -16.38684844970703, 'loss_4': 3.5310144424438477, 'epoch': 20.34}
{'loss': 0.0173, 'grad_norm': 7.108668327331543, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.01052025705575943, 'loss_2': 0.00676727294921875, 'loss_3': -16.286272048950195, 'loss_4': 3.212944507598877, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 10:50:31,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:31,303 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:20<28:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:38,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010799551382660866, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007372288499027491, 'eval_loss_2': 0.0034272633492946625, 'eval_loss_3': -18.346437454223633, 'eval_loss_4': 2.6875195503234863, 'epoch': 20.35}
{'loss': 0.0189, 'grad_norm': 6.587427139282227, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.014714262448251247, 'loss_2': 0.0042266845703125, 'loss_3': -16.55656623840332, 'loss_4': 3.4633026123046875, 'epoch': 20.35}
{'loss': 0.0285, 'grad_norm': 11.028897285461426, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.023056715726852417, 'loss_2': 0.00543975830078125, 'loss_3': -16.411209106445312, 'loss_4': 3.7456178665161133, 'epoch': 20.36}
{'loss': 0.0185, 'grad_norm': 8.289619445800781, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.01311481837183237, 'loss_2': 0.005401611328125, 'loss_3': -16.278079986572266, 'loss_4': 3.2943451404571533, 'epoch': 20.37}
{'loss': 0.0123, 'grad_norm': 6.542392253875732, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.010583315044641495, 'loss_2': 0.0017547607421875, 'loss_3': -16.3388671875, 'loss_4': 3.1601035594940186, 'epoch': 20.37}
{'loss': 0.0243, 'grad_norm': 7.5854620933532715, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.01676180027425289, 'loss_2': 0.00756072998046875, 'loss_3': -16.222423553466797, 'loss_4': 2.6132500171661377, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 10:50:38,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:38,651 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:28<28:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:46,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010078106075525284, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.561, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0070221093483269215, 'eval_loss_2': 0.0030559971928596497, 'eval_loss_3': -18.328149795532227, 'eval_loss_4': 2.5990140438079834, 'epoch': 20.38}
{'loss': 0.0091, 'grad_norm': 4.336975574493408, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.008765503764152527, 'loss_2': 0.0002989768981933594, 'loss_3': -16.310401916503906, 'loss_4': 3.7192139625549316, 'epoch': 20.38}
{'loss': 0.0212, 'grad_norm': 5.494324684143066, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.00991753488779068, 'loss_2': 0.011260986328125, 'loss_3': -16.612844467163086, 'loss_4': 3.3719184398651123, 'epoch': 20.39}
{'loss': 0.0108, 'grad_norm': 5.129031181335449, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.006425946950912476, 'loss_2': 0.00437164306640625, 'loss_3': -16.511001586914062, 'loss_4': 3.117837429046631, 'epoch': 20.4}
{'loss': 0.0078, 'grad_norm': 5.654402256011963, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.00584389828145504, 'loss_2': 0.0019254684448242188, 'loss_3': -16.282569885253906, 'loss_4': 2.852646827697754, 'epoch': 20.4}
{'loss': 0.0108, 'grad_norm': 5.952503204345703, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.009332271292805672, 'loss_2': 0.001499176025390625, 'loss_3': -16.352258682250977, 'loss_4': 2.9646406173706055, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 10:50:46,008 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:46,008 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:35<28:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:53,350 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010932095348834991, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.696, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006636836566030979, 'eval_loss_2': 0.004295259714126587, 'eval_loss_3': -18.326778411865234, 'eval_loss_4': 2.5756235122680664, 'epoch': 20.41}
{'loss': 0.0086, 'grad_norm': 5.112982273101807, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.007067518308758736, 'loss_2': 0.00156402587890625, 'loss_3': -16.38700294494629, 'loss_4': 2.814513921737671, 'epoch': 20.41}
{'loss': 0.0092, 'grad_norm': 5.0818867683410645, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.006029366981238127, 'loss_2': 0.00316619873046875, 'loss_3': -16.475515365600586, 'loss_4': 3.2296361923217773, 'epoch': 20.42}
{'loss': 0.0132, 'grad_norm': 5.727200508117676, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.009734650142490864, 'loss_2': 0.003467559814453125, 'loss_3': -16.54813003540039, 'loss_4': 2.8461356163024902, 'epoch': 20.42}
{'loss': 0.01, 'grad_norm': 5.5700154304504395, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.008212650194764137, 'loss_2': 0.001796722412109375, 'loss_3': -16.357223510742188, 'loss_4': 3.089521646499634, 'epoch': 20.43}
{'loss': 0.0117, 'grad_norm': 6.0652666091918945, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.010438299737870693, 'loss_2': 0.0012416839599609375, 'loss_3': -16.411571502685547, 'loss_4': 3.2074832916259766, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 10:50:53,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:53,351 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:42<28:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:00,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010802872478961945, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.631, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007170893717557192, 'eval_loss_2': 0.00363197922706604, 'eval_loss_3': -18.314468383789062, 'eval_loss_4': 2.5569050312042236, 'epoch': 20.44}
{'loss': 0.0084, 'grad_norm': 5.169422149658203, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.006697357632219791, 'loss_2': 0.001705169677734375, 'loss_3': -16.486522674560547, 'loss_4': 3.0580899715423584, 'epoch': 20.44}
{'loss': 0.0146, 'grad_norm': 5.748730659484863, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.007763572037220001, 'loss_2': 0.006866455078125, 'loss_3': -16.414264678955078, 'loss_4': 2.66085147857666, 'epoch': 20.45}
{'loss': 0.0081, 'grad_norm': 4.706267356872559, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.007535143289715052, 'loss_2': 0.0005216598510742188, 'loss_3': -16.581485748291016, 'loss_4': 3.0047430992126465, 'epoch': 20.45}
{'loss': 0.0101, 'grad_norm': 5.792346954345703, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.008873538114130497, 'loss_2': 0.00121307373046875, 'loss_3': -16.457820892333984, 'loss_4': 2.7979984283447266, 'epoch': 20.46}
{'loss': 0.0125, 'grad_norm': 4.465407848358154, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.005965597927570343, 'loss_2': 0.006511688232421875, 'loss_3': -15.971850395202637, 'loss_4': 2.8785552978515625, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 10:51:00,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:00,725 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:26:50<28:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:08,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011373446322977543, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.213, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007327482104301453, 'eval_loss_2': 0.004045963287353516, 'eval_loss_3': -18.313291549682617, 'eval_loss_4': 2.5307304859161377, 'epoch': 20.47}
{'loss': 0.0236, 'grad_norm': 9.444550514221191, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.019724907353520393, 'loss_2': 0.003894805908203125, 'loss_3': -16.096778869628906, 'loss_4': 3.0593578815460205, 'epoch': 20.47}
{'loss': 0.0209, 'grad_norm': 10.007102012634277, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.018694546073675156, 'loss_2': 0.00217437744140625, 'loss_3': -16.415868759155273, 'loss_4': 3.175720691680908, 'epoch': 20.48}
{'loss': 0.0256, 'grad_norm': 4.822984218597412, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.020187092944979668, 'loss_2': 0.005401611328125, 'loss_3': -16.350645065307617, 'loss_4': 2.6909165382385254, 'epoch': 20.48}
{'loss': 0.0153, 'grad_norm': 5.856391906738281, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.009238599799573421, 'loss_2': 0.0060882568359375, 'loss_3': -16.331077575683594, 'loss_4': 3.402448892593384, 'epoch': 20.49}
{'loss': 0.0438, 'grad_norm': 21.711437225341797, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.037790220230817795, 'loss_2': 0.00604248046875, 'loss_3': -16.149059295654297, 'loss_4': 2.8497142791748047, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 10:51:08,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:08,082 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:26:57<28:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:15,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011269047856330872, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.028, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006570294499397278, 'eval_loss_2': 0.004698753356933594, 'eval_loss_3': -18.3133544921875, 'eval_loss_4': 2.51108717918396, 'epoch': 20.49}
{'loss': 0.0142, 'grad_norm': 4.871593952178955, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.0049129812978208065, 'loss_2': 0.00931549072265625, 'loss_3': -16.325439453125, 'loss_4': 2.903186798095703, 'epoch': 20.5}
{'loss': 0.0124, 'grad_norm': 5.108459949493408, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.006489978637546301, 'loss_2': 0.00592041015625, 'loss_3': -16.385784149169922, 'loss_4': 2.8514485359191895, 'epoch': 20.51}
{'loss': 0.0117, 'grad_norm': 5.3413472175598145, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.00908629596233368, 'loss_2': 0.00263214111328125, 'loss_3': -16.28411865234375, 'loss_4': 3.023132801055908, 'epoch': 20.51}
{'loss': 0.0121, 'grad_norm': 5.491882801055908, 'learning_rate': 9.5e-06, 'loss_1': 0.006217522546648979, 'loss_2': 0.005878448486328125, 'loss_3': -16.419612884521484, 'loss_4': 3.1396453380584717, 'epoch': 20.52}
{'loss': 0.014, 'grad_norm': 7.0326433181762695, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.012440960854291916, 'loss_2': 0.0015163421630859375, 'loss_3': -16.63446807861328, 'loss_4': 3.221554756164551, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 10:51:15,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:15,450 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:04<28:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:22,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010825657285749912, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.495, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00641498900949955, 'eval_loss_2': 0.004410669207572937, 'eval_loss_3': -18.29924964904785, 'eval_loss_4': 2.494349718093872, 'epoch': 20.52}
{'loss': 0.0084, 'grad_norm': 5.306197166442871, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.004625194706022739, 'loss_2': 0.0038089752197265625, 'loss_3': -16.522201538085938, 'loss_4': 2.700193405151367, 'epoch': 20.53}
{'loss': 0.0141, 'grad_norm': 4.692476272583008, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.00602154154330492, 'loss_2': 0.00811767578125, 'loss_3': -16.44762420654297, 'loss_4': 3.2211947441101074, 'epoch': 20.53}
{'loss': 0.0131, 'grad_norm': 5.369917869567871, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.006065974943339825, 'loss_2': 0.007068634033203125, 'loss_3': -16.32682991027832, 'loss_4': 2.8852148056030273, 'epoch': 20.54}
{'loss': 0.0178, 'grad_norm': 8.70482063293457, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.012145363725721836, 'loss_2': 0.00565338134765625, 'loss_3': -16.294757843017578, 'loss_4': 2.8021392822265625, 'epoch': 20.55}
{'loss': 0.0061, 'grad_norm': 5.3750104904174805, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.005824615713208914, 'loss_2': 0.0003170967102050781, 'loss_3': -16.183263778686523, 'loss_4': 2.4663310050964355, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 10:51:22,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:22,808 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:12<28:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:30,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009734116494655609, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006341359578073025, 'eval_loss_2': 0.0033927559852600098, 'eval_loss_3': -18.26692771911621, 'eval_loss_4': 2.3971714973449707, 'epoch': 20.55}
{'loss': 0.0088, 'grad_norm': 4.73101806640625, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.003955180291086435, 'loss_2': 0.00487518310546875, 'loss_3': -16.35599136352539, 'loss_4': 2.9698143005371094, 'epoch': 20.56}
{'loss': 0.0104, 'grad_norm': 6.7360734939575195, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.008180787786841393, 'loss_2': 0.00218963623046875, 'loss_3': -16.258960723876953, 'loss_4': 2.357001781463623, 'epoch': 20.56}
{'loss': 0.0121, 'grad_norm': 6.764616966247559, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.009685219265520573, 'loss_2': 0.002452850341796875, 'loss_3': -16.331008911132812, 'loss_4': 2.217254638671875, 'epoch': 20.57}
{'loss': 0.007, 'grad_norm': 4.948737144470215, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.005692293401807547, 'loss_2': 0.0012912750244140625, 'loss_3': -16.36739730834961, 'loss_4': 2.479830265045166, 'epoch': 20.58}
{'loss': 0.0207, 'grad_norm': 8.075518608093262, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.018227210268378258, 'loss_2': 0.0024566650390625, 'loss_3': -16.34600067138672, 'loss_4': 2.198030948638916, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 10:51:30,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:30,165 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:19<27:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:37,503 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010133604519069195, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0068235197104513645, 'eval_loss_2': 0.003310084342956543, 'eval_loss_3': -18.276275634765625, 'eval_loss_4': 2.3116018772125244, 'epoch': 20.58}
{'loss': 0.0121, 'grad_norm': 6.775707721710205, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.008994437754154205, 'loss_2': 0.003070831298828125, 'loss_3': -16.324432373046875, 'loss_4': 2.326258420944214, 'epoch': 20.59}
{'loss': 0.0037, 'grad_norm': 4.5276689529418945, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.0026051776949316263, 'loss_2': 0.0010471343994140625, 'loss_3': -16.26350212097168, 'loss_4': 2.3566415309906006, 'epoch': 20.59}
{'loss': 0.0179, 'grad_norm': 9.193731307983398, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.017444681376218796, 'loss_2': 0.00040912628173828125, 'loss_3': -16.476600646972656, 'loss_4': 2.8411035537719727, 'epoch': 20.6}
{'loss': 0.0067, 'grad_norm': 4.453056335449219, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.0059388428926467896, 'loss_2': 0.0007901191711425781, 'loss_3': -16.444656372070312, 'loss_4': 3.00329852104187, 'epoch': 20.6}
{'loss': 0.0087, 'grad_norm': 4.504993438720703, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.005259370431303978, 'loss_2': 0.0034847259521484375, 'loss_3': -16.419212341308594, 'loss_4': 2.907914638519287, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 10:51:37,503 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:37,503 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:27<27:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:44,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011163981631398201, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007684024050831795, 'eval_loss_2': 0.0034799575805664062, 'eval_loss_3': -18.271331787109375, 'eval_loss_4': 2.3446176052093506, 'epoch': 20.61}
{'loss': 0.0057, 'grad_norm': 5.154565811157227, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.004378999583423138, 'loss_2': 0.0013628005981445312, 'loss_3': -16.405967712402344, 'loss_4': 2.551525115966797, 'epoch': 20.62}
{'loss': 0.0062, 'grad_norm': 4.570111274719238, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.004261488560587168, 'loss_2': 0.001972198486328125, 'loss_3': -16.524620056152344, 'loss_4': 2.223884344100952, 'epoch': 20.62}
{'loss': 0.009, 'grad_norm': 4.674789905548096, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.004394346848130226, 'loss_2': 0.00461578369140625, 'loss_3': -16.31879997253418, 'loss_4': 2.323058605194092, 'epoch': 20.63}
{'loss': 0.0069, 'grad_norm': 5.901479244232178, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.0068435510620474815, 'loss_2': 1.811981201171875e-05, 'loss_3': -16.404041290283203, 'loss_4': 2.134530782699585, 'epoch': 20.63}
{'loss': 0.0113, 'grad_norm': 5.0946502685546875, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.008938572369515896, 'loss_2': 0.0023345947265625, 'loss_3': -16.40460968017578, 'loss_4': 3.068556308746338, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 10:51:44,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:44,845 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:34<27:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:52,196 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011768944561481476, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008197628892958164, 'eval_loss_2': 0.0035713165998458862, 'eval_loss_3': -18.28268051147461, 'eval_loss_4': 2.4189693927764893, 'epoch': 20.64}
{'loss': 0.0105, 'grad_norm': 5.397080421447754, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.006290270481258631, 'loss_2': 0.004241943359375, 'loss_3': -16.31627655029297, 'loss_4': 3.0058865547180176, 'epoch': 20.65}
{'loss': 0.0106, 'grad_norm': 5.546396255493164, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.007624635472893715, 'loss_2': 0.003021240234375, 'loss_3': -16.195798873901367, 'loss_4': 2.801712989807129, 'epoch': 20.65}
{'loss': 0.0117, 'grad_norm': 5.75635290145874, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.008337309584021568, 'loss_2': 0.00334930419921875, 'loss_3': -16.428918838500977, 'loss_4': 2.884976863861084, 'epoch': 20.66}
{'loss': 0.0361, 'grad_norm': 15.290836334228516, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.026532337069511414, 'loss_2': 0.0095977783203125, 'loss_3': -16.416086196899414, 'loss_4': 2.99564790725708, 'epoch': 20.66}
{'loss': 0.0097, 'grad_norm': 4.826493740081787, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.006371332798153162, 'loss_2': 0.0033416748046875, 'loss_3': -16.557510375976562, 'loss_4': 2.6532959938049316, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 10:51:52,196 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:52,196 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:41<27:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:59,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011039379984140396, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.578, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008051129989326, 'eval_loss_2': 0.0029882490634918213, 'eval_loss_3': -18.2828426361084, 'eval_loss_4': 2.39522123336792, 'epoch': 20.67}
{'loss': 0.0062, 'grad_norm': 5.3906121253967285, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.006004516035318375, 'loss_2': 0.00022530555725097656, 'loss_3': -16.441349029541016, 'loss_4': 2.345226526260376, 'epoch': 20.67}
{'loss': 0.0106, 'grad_norm': 4.2547478675842285, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.003223257139325142, 'loss_2': 0.00734710693359375, 'loss_3': -16.296689987182617, 'loss_4': 2.6972782611846924, 'epoch': 20.68}
{'loss': 0.0057, 'grad_norm': 4.716284275054932, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.004952718038111925, 'loss_2': 0.0007524490356445312, 'loss_3': -16.17697525024414, 'loss_4': 2.8601267337799072, 'epoch': 20.69}
{'loss': 0.0062, 'grad_norm': 5.449037551879883, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.004684703890234232, 'loss_2': 0.0014896392822265625, 'loss_3': -16.310409545898438, 'loss_4': 2.277266025543213, 'epoch': 20.69}
{'loss': 0.005, 'grad_norm': 5.340076446533203, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.004022996407002211, 'loss_2': 0.0009765625, 'loss_3': -16.390331268310547, 'loss_4': 2.370556592941284, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 10:51:59,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:59,538 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:27:49<27:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:06,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010926572605967522, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.921, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00785207562148571, 'eval_loss_2': 0.0030744969844818115, 'eval_loss_3': -18.296112060546875, 'eval_loss_4': 2.339203357696533, 'epoch': 20.7}
{'loss': 0.0066, 'grad_norm': 4.383382797241211, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.003809178015217185, 'loss_2': 0.002838134765625, 'loss_3': -16.53266143798828, 'loss_4': 2.8200461864471436, 'epoch': 20.7}
{'loss': 0.0072, 'grad_norm': 4.831947326660156, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.005533350165933371, 'loss_2': 0.0016393661499023438, 'loss_3': -16.529743194580078, 'loss_4': 3.1921515464782715, 'epoch': 20.71}
{'loss': 0.0055, 'grad_norm': 6.366640090942383, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.005381780676543713, 'loss_2': 0.00012946128845214844, 'loss_3': -16.520368576049805, 'loss_4': 2.6251413822174072, 'epoch': 20.72}
{'loss': 0.0079, 'grad_norm': 4.958837985992432, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.005696536507457495, 'loss_2': 0.002155303955078125, 'loss_3': -16.469377517700195, 'loss_4': 2.6214728355407715, 'epoch': 20.72}
{'loss': 0.0042, 'grad_norm': 5.011316299438477, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.003085353644564748, 'loss_2': 0.001155853271484375, 'loss_3': -16.255001068115234, 'loss_4': 2.2248780727386475, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 10:52:06,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:06,896 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:27:56<27:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:14,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010274155996739864, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006732136011123657, 'eval_loss_2': 0.0035420209169387817, 'eval_loss_3': -18.292924880981445, 'eval_loss_4': 2.2405359745025635, 'epoch': 20.73}
{'loss': 0.0099, 'grad_norm': 5.010917663574219, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.005439218133687973, 'loss_2': 0.00444793701171875, 'loss_3': -16.41287612915039, 'loss_4': 2.200629472732544, 'epoch': 20.73}
{'loss': 0.0065, 'grad_norm': 4.280757904052734, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.004960467107594013, 'loss_2': 0.001556396484375, 'loss_3': -16.36261558532715, 'loss_4': 2.8943026065826416, 'epoch': 20.74}
{'loss': 0.0147, 'grad_norm': 5.868213176727295, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.009578410536050797, 'loss_2': 0.00514984130859375, 'loss_3': -16.188627243041992, 'loss_4': 2.056675910949707, 'epoch': 20.74}
{'loss': 0.0075, 'grad_norm': 4.44282341003418, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.003907280042767525, 'loss_2': 0.0036163330078125, 'loss_3': -16.44107437133789, 'loss_4': 2.491889238357544, 'epoch': 20.75}
{'loss': 0.0058, 'grad_norm': 4.7317423820495605, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.003938854206353426, 'loss_2': 0.0018405914306640625, 'loss_3': -16.263832092285156, 'loss_4': 2.5057578086853027, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 10:52:14,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:14,240 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:03<27:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:21,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011047886684536934, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007867966778576374, 'eval_loss_2': 0.0031799189746379852, 'eval_loss_3': -18.28533363342285, 'eval_loss_4': 2.1713569164276123, 'epoch': 20.76}
{'loss': 0.0088, 'grad_norm': 4.924798011779785, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.005472766701132059, 'loss_2': 0.0033416748046875, 'loss_3': -16.273759841918945, 'loss_4': 2.7080228328704834, 'epoch': 20.76}
{'loss': 0.0039, 'grad_norm': 4.695797443389893, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.0022957641631364822, 'loss_2': 0.00159454345703125, 'loss_3': -16.37368392944336, 'loss_4': 2.8283863067626953, 'epoch': 20.77}
{'loss': 0.0061, 'grad_norm': 4.640842437744141, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.00321042537689209, 'loss_2': 0.0028629302978515625, 'loss_3': -16.44017791748047, 'loss_4': 2.639652967453003, 'epoch': 20.77}
{'loss': 0.0147, 'grad_norm': 4.887800216674805, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.004612274467945099, 'loss_2': 0.010101318359375, 'loss_3': -16.41632843017578, 'loss_4': 2.4783077239990234, 'epoch': 20.78}
{'loss': 0.0139, 'grad_norm': 5.696622371673584, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.006649527698755264, 'loss_2': 0.00726318359375, 'loss_3': -16.389989852905273, 'loss_4': 2.2678935527801514, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 10:52:21,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:21,593 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:11<27:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:28,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011780872941017151, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.59, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008419892750680447, 'eval_loss_2': 0.0033609792590141296, 'eval_loss_3': -18.282482147216797, 'eval_loss_4': 2.0644757747650146, 'epoch': 20.78}
{'loss': 0.0066, 'grad_norm': 4.49439001083374, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.0021131245885044336, 'loss_2': 0.004486083984375, 'loss_3': -16.17729949951172, 'loss_4': 2.1375231742858887, 'epoch': 20.79}
{'loss': 0.0067, 'grad_norm': 5.078909397125244, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.004346119239926338, 'loss_2': 0.0023403167724609375, 'loss_3': -16.200443267822266, 'loss_4': 2.304135322570801, 'epoch': 20.8}
{'loss': 0.0062, 'grad_norm': 4.746113300323486, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.00368565134704113, 'loss_2': 0.0025196075439453125, 'loss_3': -16.46249008178711, 'loss_4': 2.3459277153015137, 'epoch': 20.8}
{'loss': 0.0117, 'grad_norm': 8.295647621154785, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.01113118790090084, 'loss_2': 0.0006122589111328125, 'loss_3': -16.216989517211914, 'loss_4': 1.858966588973999, 'epoch': 20.81}
{'loss': 0.0068, 'grad_norm': 4.539515018463135, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.005180851090699434, 'loss_2': 0.0016689300537109375, 'loss_3': -16.439956665039062, 'loss_4': 2.4343249797821045, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 10:52:28,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:28,930 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:18<27:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:36,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01152444165199995, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008741576224565506, 'eval_loss_2': 0.002782866358757019, 'eval_loss_3': -18.269142150878906, 'eval_loss_4': 2.018639087677002, 'epoch': 20.81}
{'loss': 0.0058, 'grad_norm': 4.642725467681885, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.003056404646486044, 'loss_2': 0.0027179718017578125, 'loss_3': -16.4362850189209, 'loss_4': 2.2685070037841797, 'epoch': 20.82}
{'loss': 0.0082, 'grad_norm': 4.863184928894043, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.005279271863400936, 'loss_2': 0.00289154052734375, 'loss_3': -16.118871688842773, 'loss_4': 2.7094030380249023, 'epoch': 20.83}
{'loss': 0.0061, 'grad_norm': 4.571290493011475, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.004995322786271572, 'loss_2': 0.0011501312255859375, 'loss_3': -16.419775009155273, 'loss_4': 2.0349221229553223, 'epoch': 20.83}
{'loss': 0.0057, 'grad_norm': 4.620546817779541, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.0031662266701459885, 'loss_2': 0.00250244140625, 'loss_3': -16.546295166015625, 'loss_4': 2.2399866580963135, 'epoch': 20.84}
{'loss': 0.0173, 'grad_norm': 9.649662017822266, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.01149080228060484, 'loss_2': 0.00582122802734375, 'loss_3': -16.095287322998047, 'loss_4': 1.9940185546875, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 10:52:36,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:36,271 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:25<27:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:43,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014166520908474922, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.086, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008673655800521374, 'eval_loss_2': 0.005492866039276123, 'eval_loss_3': -18.253768920898438, 'eval_loss_4': 1.9315311908721924, 'epoch': 20.84}
{'loss': 0.0117, 'grad_norm': 5.0292744636535645, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.005688519682735205, 'loss_2': 0.00598907470703125, 'loss_3': -16.23303985595703, 'loss_4': 2.2465202808380127, 'epoch': 20.85}
{'loss': 0.0165, 'grad_norm': 6.397602081298828, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.0065828245133161545, 'loss_2': 0.0099029541015625, 'loss_3': -16.186996459960938, 'loss_4': 2.166287422180176, 'epoch': 20.85}
{'loss': 0.0166, 'grad_norm': 8.089095115661621, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.008661298081278801, 'loss_2': 0.0079803466796875, 'loss_3': -16.35654067993164, 'loss_4': 1.6338706016540527, 'epoch': 20.86}
{'loss': 0.0097, 'grad_norm': 4.882970333099365, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.0045641749165952206, 'loss_2': 0.0051116943359375, 'loss_3': -16.253982543945312, 'loss_4': 2.2915000915527344, 'epoch': 20.87}
{'loss': 0.0046, 'grad_norm': 4.753299236297607, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.004481724929064512, 'loss_2': 0.0001595020294189453, 'loss_3': -16.37626838684082, 'loss_4': 2.712761878967285, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 10:52:43,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:43,623 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:33<27:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:50,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01307847909629345, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.844, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008839425630867481, 'eval_loss_2': 0.0042390525341033936, 'eval_loss_3': -18.23891830444336, 'eval_loss_4': 1.88432776927948, 'epoch': 20.87}
{'loss': 0.009, 'grad_norm': 4.509856224060059, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.004640635568648577, 'loss_2': 0.004390716552734375, 'loss_3': -16.356733322143555, 'loss_4': 2.2929630279541016, 'epoch': 20.88}
{'loss': 0.009, 'grad_norm': 5.067482948303223, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.005029324442148209, 'loss_2': 0.00396728515625, 'loss_3': -16.2591552734375, 'loss_4': 2.214963674545288, 'epoch': 20.88}
{'loss': 0.0108, 'grad_norm': 6.124220848083496, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.006947840563952923, 'loss_2': 0.00388336181640625, 'loss_3': -16.26598358154297, 'loss_4': 2.155860185623169, 'epoch': 20.89}
{'loss': 0.0134, 'grad_norm': 5.444481372833252, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.007489094510674477, 'loss_2': 0.00589752197265625, 'loss_3': -16.19076156616211, 'loss_4': 2.250417470932007, 'epoch': 20.9}
{'loss': 0.0061, 'grad_norm': 5.093733310699463, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.005277563352137804, 'loss_2': 0.000827789306640625, 'loss_3': -16.37722396850586, 'loss_4': 2.114225387573242, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 10:52:50,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:50,973 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:40<26:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:58,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011244340799748898, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.301, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008790596388280392, 'eval_loss_2': 0.002453744411468506, 'eval_loss_3': -18.22747230529785, 'eval_loss_4': 1.9238672256469727, 'epoch': 20.9}
{'loss': 0.0083, 'grad_norm': 5.568199634552002, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.007542186416685581, 'loss_2': 0.0007619857788085938, 'loss_3': -16.444351196289062, 'loss_4': 1.6982511281967163, 'epoch': 20.91}
{'loss': 0.0074, 'grad_norm': 4.4800286293029785, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.0030775335617363453, 'loss_2': 0.004302978515625, 'loss_3': -16.427379608154297, 'loss_4': 1.738863229751587, 'epoch': 20.91}
{'loss': 0.0056, 'grad_norm': 4.756771087646484, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.004475233610719442, 'loss_2': 0.00109100341796875, 'loss_3': -16.304508209228516, 'loss_4': 2.096457004547119, 'epoch': 20.92}
{'loss': 0.0045, 'grad_norm': 4.41816520690918, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.0038602447602897882, 'loss_2': 0.000591278076171875, 'loss_3': -16.396984100341797, 'loss_4': 2.3362231254577637, 'epoch': 20.92}
{'loss': 0.0198, 'grad_norm': 12.27872371673584, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.018245909363031387, 'loss_2': 0.0016002655029296875, 'loss_3': -16.23603630065918, 'loss_4': 2.2327284812927246, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 10:52:58,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:58,321 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:28:47<26:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:05,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012933000922203064, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009509666822850704, 'eval_loss_2': 0.003423333168029785, 'eval_loss_3': -18.22646713256836, 'eval_loss_4': 2.0199005603790283, 'epoch': 20.93}
{'loss': 0.0078, 'grad_norm': 7.052367687225342, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.007309355307370424, 'loss_2': 0.0004630088806152344, 'loss_3': -16.413249969482422, 'loss_4': 2.62278413772583, 'epoch': 20.94}
{'loss': 0.0046, 'grad_norm': 4.633749961853027, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.003486356930807233, 'loss_2': 0.0010805130004882812, 'loss_3': -16.35061264038086, 'loss_4': 2.315680980682373, 'epoch': 20.94}
{'loss': 0.0072, 'grad_norm': 4.916861534118652, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.00513652665540576, 'loss_2': 0.002101898193359375, 'loss_3': -16.314876556396484, 'loss_4': 2.377697467803955, 'epoch': 20.95}
{'loss': 0.0054, 'grad_norm': 4.524862289428711, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.0027579974848777056, 'loss_2': 0.0026264190673828125, 'loss_3': -16.40984344482422, 'loss_4': 2.315769672393799, 'epoch': 20.95}
{'loss': 0.0164, 'grad_norm': 12.265908241271973, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.013937080278992653, 'loss_2': 0.002429962158203125, 'loss_3': -16.17645835876465, 'loss_4': 2.2937891483306885, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 10:53:05,659 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:05,659 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:28:55<26:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:13,013 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013411312364041805, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008906422182917595, 'eval_loss_2': 0.004504889249801636, 'eval_loss_3': -18.23653793334961, 'eval_loss_4': 2.193358898162842, 'epoch': 20.96}
{'loss': 0.0212, 'grad_norm': 6.434170246124268, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.00675259530544281, 'loss_2': 0.01447296142578125, 'loss_3': -16.283275604248047, 'loss_4': 2.1683945655822754, 'epoch': 20.97}
{'loss': 0.0084, 'grad_norm': 5.93690299987793, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.0067430841736495495, 'loss_2': 0.00170135498046875, 'loss_3': -16.325416564941406, 'loss_4': 2.9095373153686523, 'epoch': 20.97}
{'loss': 0.0095, 'grad_norm': 5.57197380065918, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.0056738415732979774, 'loss_2': 0.003875732421875, 'loss_3': -16.16356658935547, 'loss_4': 2.424499034881592, 'epoch': 20.98}
{'loss': 0.0134, 'grad_norm': 5.698041915893555, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.0071753766387701035, 'loss_2': 0.00626373291015625, 'loss_3': -16.46735382080078, 'loss_4': 2.9072999954223633, 'epoch': 20.98}
{'loss': 0.0159, 'grad_norm': 11.711111068725586, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.013992728665471077, 'loss_2': 0.0019359588623046875, 'loss_3': -16.314746856689453, 'loss_4': 2.8609871864318848, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 10:53:13,013 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:13,013 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:02<25:56,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:53:20,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013066582381725311, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008701793849468231, 'eval_loss_2': 0.00436478853225708, 'eval_loss_3': -18.25429916381836, 'eval_loss_4': 2.3641748428344727, 'epoch': 20.99}
{'loss': 0.0071, 'grad_norm': 4.541598320007324, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.004019330721348524, 'loss_2': 0.0030841827392578125, 'loss_3': -16.36210060119629, 'loss_4': 2.634169101715088, 'epoch': 20.99}
{'loss': 0.0024, 'grad_norm': 6.336281776428223, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.0009913641260936856, 'loss_2': 0.001434326171875, 'loss_3': -16.55768585205078, 'loss_4': 2.423901319503784, 'epoch': 21.0}
{'loss': 0.0178, 'grad_norm': 5.512185573577881, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.007566789630800486, 'loss_2': 0.0102386474609375, 'loss_3': -16.47439193725586, 'loss_4': 2.4952826499938965, 'epoch': 21.01}
{'loss': 0.0176, 'grad_norm': 6.13079309463501, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.006823266390711069, 'loss_2': 0.01080322265625, 'loss_3': -16.24930763244629, 'loss_4': 2.285956621170044, 'epoch': 21.01}
{'loss': 0.0077, 'grad_norm': 4.47974157333374, 'learning_rate': 9e-06, 'loss_1': 0.0037607408594340086, 'loss_2': 0.00390625, 'loss_3': -16.506418228149414, 'loss_4': 2.795483350753784, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 10:53:20,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:20,042 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:09<26:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:53:27,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011895623989403248, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.955, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008840886875987053, 'eval_loss_2': 0.0030547380447387695, 'eval_loss_3': -18.275644302368164, 'eval_loss_4': 2.2481956481933594, 'epoch': 21.02}
{'loss': 0.0078, 'grad_norm': 5.449366569519043, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.005304711405187845, 'loss_2': 0.0024700164794921875, 'loss_3': -16.23512077331543, 'loss_4': 2.540133237838745, 'epoch': 21.02}
{'loss': 0.0069, 'grad_norm': 5.758113861083984, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.006537326145917177, 'loss_2': 0.0003604888916015625, 'loss_3': -16.427364349365234, 'loss_4': 2.412248134613037, 'epoch': 21.03}
{'loss': 0.0113, 'grad_norm': 7.677109241485596, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.009060995653271675, 'loss_2': 0.002269744873046875, 'loss_3': -16.25566864013672, 'loss_4': 2.7399611473083496, 'epoch': 21.03}
{'loss': 0.0115, 'grad_norm': 5.949052810668945, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.008129237219691277, 'loss_2': 0.003322601318359375, 'loss_3': -16.4541015625, 'loss_4': 2.5516021251678467, 'epoch': 21.04}
{'loss': 0.008, 'grad_norm': 4.8024396896362305, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.00434475252404809, 'loss_2': 0.003673553466796875, 'loss_3': -16.380876541137695, 'loss_4': 2.8835010528564453, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 10:53:27,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:27,392 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:16<26:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:34,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011752672493457794, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008624665439128876, 'eval_loss_2': 0.0031280070543289185, 'eval_loss_3': -18.29674530029297, 'eval_loss_4': 2.1436805725097656, 'epoch': 21.05}
{'loss': 0.0121, 'grad_norm': 4.834051609039307, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.006271156948059797, 'loss_2': 0.005779266357421875, 'loss_3': -16.298063278198242, 'loss_4': 3.1096389293670654, 'epoch': 21.05}
{'loss': 0.0158, 'grad_norm': 5.119057655334473, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.00973639264702797, 'loss_2': 0.006069183349609375, 'loss_3': -16.46216583251953, 'loss_4': 2.3496947288513184, 'epoch': 21.06}
{'loss': 0.0124, 'grad_norm': 5.784140586853027, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.00809209793806076, 'loss_2': 0.0043182373046875, 'loss_3': -16.514890670776367, 'loss_4': 2.1347222328186035, 'epoch': 21.06}
{'loss': 0.006, 'grad_norm': 5.108243465423584, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.004812972620129585, 'loss_2': 0.0011444091796875, 'loss_3': -16.349342346191406, 'loss_4': 2.2691705226898193, 'epoch': 21.07}
{'loss': 0.0106, 'grad_norm': 6.199674606323242, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.00946801621466875, 'loss_2': 0.0011615753173828125, 'loss_3': -16.446178436279297, 'loss_4': 3.1504387855529785, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 10:53:34,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:34,737 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:24<26:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:42,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01243946235626936, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008374456316232681, 'eval_loss_2': 0.004065006971359253, 'eval_loss_3': -18.313264846801758, 'eval_loss_4': 2.1674671173095703, 'epoch': 21.08}
{'loss': 0.0117, 'grad_norm': 5.957879543304443, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.01091479230672121, 'loss_2': 0.0007491111755371094, 'loss_3': -16.187822341918945, 'loss_4': 2.341306447982788, 'epoch': 21.08}
{'loss': 0.0169, 'grad_norm': 6.371112823486328, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.011404129676520824, 'loss_2': 0.0055389404296875, 'loss_3': -16.20363426208496, 'loss_4': 2.310892105102539, 'epoch': 21.09}
{'loss': 0.0111, 'grad_norm': 4.530367851257324, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.0042470707558095455, 'loss_2': 0.0068206787109375, 'loss_3': -16.340377807617188, 'loss_4': 2.443136692047119, 'epoch': 21.09}
{'loss': 0.0171, 'grad_norm': 4.15724515914917, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.005525238811969757, 'loss_2': 0.011566162109375, 'loss_3': -16.37451934814453, 'loss_4': 2.7208564281463623, 'epoch': 21.1}
{'loss': 0.0081, 'grad_norm': 5.058130741119385, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.004290156066417694, 'loss_2': 0.003795623779296875, 'loss_3': -16.2817440032959, 'loss_4': 2.4371657371520996, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 10:53:42,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:42,077 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:31<26:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:49,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01175808347761631, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007394546642899513, 'eval_loss_2': 0.004363536834716797, 'eval_loss_3': -18.323312759399414, 'eval_loss_4': 2.1817069053649902, 'epoch': 21.1}
{'loss': 0.0133, 'grad_norm': 5.438381195068359, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.011088228784501553, 'loss_2': 0.0021820068359375, 'loss_3': -16.399179458618164, 'loss_4': 2.638155221939087, 'epoch': 21.11}
{'loss': 0.0161, 'grad_norm': 5.570437431335449, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.008441567420959473, 'loss_2': 0.00769805908203125, 'loss_3': -16.47356605529785, 'loss_4': 2.7390973567962646, 'epoch': 21.12}
{'loss': 0.0092, 'grad_norm': 5.632451057434082, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.007961764000356197, 'loss_2': 0.0012378692626953125, 'loss_3': -16.263092041015625, 'loss_4': 2.8809328079223633, 'epoch': 21.12}
{'loss': 0.0069, 'grad_norm': 5.274123191833496, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.006537402514368296, 'loss_2': 0.00032711029052734375, 'loss_3': -16.307477951049805, 'loss_4': 2.6892218589782715, 'epoch': 21.13}
{'loss': 0.0111, 'grad_norm': 4.923083305358887, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.003515545977279544, 'loss_2': 0.00754547119140625, 'loss_3': -16.4465389251709, 'loss_4': 2.4744958877563477, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 10:53:49,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:49,425 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:38<26:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:56,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010210024192929268, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.065, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007291416171938181, 'eval_loss_2': 0.0029186084866523743, 'eval_loss_3': -18.34226417541504, 'eval_loss_4': 2.155524969100952, 'epoch': 21.13}
{'loss': 0.0038, 'grad_norm': 4.571004390716553, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.003570247907191515, 'loss_2': 0.00023639202117919922, 'loss_3': -16.218029022216797, 'loss_4': 2.100508689880371, 'epoch': 21.14}
{'loss': 0.0167, 'grad_norm': 4.825006484985352, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.0064172702841460705, 'loss_2': 0.010284423828125, 'loss_3': -16.378868103027344, 'loss_4': 2.633021116256714, 'epoch': 21.15}
{'loss': 0.0073, 'grad_norm': 5.2161359786987305, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.0054299733601510525, 'loss_2': 0.0018415451049804688, 'loss_3': -16.327316284179688, 'loss_4': 2.837350368499756, 'epoch': 21.15}
{'loss': 0.0054, 'grad_norm': 4.173099994659424, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.003974652849137783, 'loss_2': 0.001399993896484375, 'loss_3': -16.357078552246094, 'loss_4': 2.0517468452453613, 'epoch': 21.16}
{'loss': 0.0165, 'grad_norm': 11.632822036743164, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.014545038342475891, 'loss_2': 0.0019073486328125, 'loss_3': -16.38127326965332, 'loss_4': 3.018465757369995, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 10:53:56,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:56,771 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:46<26:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:04,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011837463825941086, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.662, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007669026963412762, 'eval_loss_2': 0.0041684359312057495, 'eval_loss_3': -18.347177505493164, 'eval_loss_4': 2.2058403491973877, 'epoch': 21.16}
{'loss': 0.0097, 'grad_norm': 5.926383018493652, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.008909200318157673, 'loss_2': 0.0008134841918945312, 'loss_3': -16.279216766357422, 'loss_4': 2.894317388534546, 'epoch': 21.17}
{'loss': 0.0137, 'grad_norm': 5.0881757736206055, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.006306245923042297, 'loss_2': 0.00734710693359375, 'loss_3': -16.370590209960938, 'loss_4': 2.472072124481201, 'epoch': 21.17}
{'loss': 0.0065, 'grad_norm': 6.532954216003418, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.005776115693151951, 'loss_2': 0.0007343292236328125, 'loss_3': -16.606853485107422, 'loss_4': 2.610342264175415, 'epoch': 21.18}
{'loss': 0.0049, 'grad_norm': 4.598334789276123, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.003998920787125826, 'loss_2': 0.0008788108825683594, 'loss_3': -16.433818817138672, 'loss_4': 2.6270031929016113, 'epoch': 21.19}
{'loss': 0.0057, 'grad_norm': 4.664262294769287, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.004537534434348345, 'loss_2': 0.0012054443359375, 'loss_3': -16.56427574157715, 'loss_4': 2.6420488357543945, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 10:54:04,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:04,121 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:29:53<26:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:11,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012449260801076889, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.471, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.007851776666939259, 'eval_loss_2': 0.004597485065460205, 'eval_loss_3': -18.353464126586914, 'eval_loss_4': 2.196722984313965, 'epoch': 21.19}
{'loss': 0.0149, 'grad_norm': 5.2365617752075195, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.0068075270392000675, 'loss_2': 0.00811767578125, 'loss_3': -16.259536743164062, 'loss_4': 2.583183526992798, 'epoch': 21.2}
{'loss': 0.0184, 'grad_norm': 9.61439037322998, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.01834828406572342, 'loss_2': 5.841255187988281e-05, 'loss_3': -16.107072830200195, 'loss_4': 2.451878786087036, 'epoch': 21.2}
{'loss': 0.0206, 'grad_norm': 7.259495735168457, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.01705235056579113, 'loss_2': 0.003559112548828125, 'loss_3': -16.200687408447266, 'loss_4': 2.7928266525268555, 'epoch': 21.21}
{'loss': 0.0066, 'grad_norm': 6.416048526763916, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.006375193130224943, 'loss_2': 0.00023674964904785156, 'loss_3': -16.3594970703125, 'loss_4': 2.8316123485565186, 'epoch': 21.22}
{'loss': 0.007, 'grad_norm': 4.961790084838867, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.006639660801738501, 'loss_2': 0.0003304481506347656, 'loss_3': -16.298189163208008, 'loss_4': 2.682009696960449, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 10:54:11,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:11,478 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:00<26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:18,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011302853003144264, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007706310134381056, 'eval_loss_2': 0.0035965442657470703, 'eval_loss_3': -18.355268478393555, 'eval_loss_4': 2.084076404571533, 'epoch': 21.22}
{'loss': 0.013, 'grad_norm': 5.225722789764404, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.005308615975081921, 'loss_2': 0.00769805908203125, 'loss_3': -16.355850219726562, 'loss_4': 2.3178040981292725, 'epoch': 21.23}
{'loss': 0.0049, 'grad_norm': 4.286740779876709, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.0030570579692721367, 'loss_2': 0.001827239990234375, 'loss_3': -16.451902389526367, 'loss_4': 2.1151318550109863, 'epoch': 21.23}
{'loss': 0.007, 'grad_norm': 4.718255043029785, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.004959833808243275, 'loss_2': 0.0019931793212890625, 'loss_3': -16.30208969116211, 'loss_4': 2.4793481826782227, 'epoch': 21.24}
{'loss': 0.0144, 'grad_norm': 6.956099987030029, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.012164623476564884, 'loss_2': 0.0022735595703125, 'loss_3': -16.392791748046875, 'loss_4': 2.5017342567443848, 'epoch': 21.24}
{'loss': 0.0115, 'grad_norm': 7.308016777038574, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.010727161541581154, 'loss_2': 0.0007238388061523438, 'loss_3': -16.212636947631836, 'loss_4': 2.368293523788452, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 10:54:18,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:18,829 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:08<25:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:26,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009378468617796898, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006727095227688551, 'eval_loss_2': 0.002651374787092209, 'eval_loss_3': -18.36129379272461, 'eval_loss_4': 1.8621923923492432, 'epoch': 21.25}
{'loss': 0.0079, 'grad_norm': 4.9394450187683105, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.007791245821863413, 'loss_2': 0.00013208389282226562, 'loss_3': -16.56515884399414, 'loss_4': 2.239614248275757, 'epoch': 21.26}
{'loss': 0.0051, 'grad_norm': 5.436314105987549, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.004268924705684185, 'loss_2': 0.000827789306640625, 'loss_3': -16.412616729736328, 'loss_4': 1.9740681648254395, 'epoch': 21.26}
{'loss': 0.0079, 'grad_norm': 5.3290839195251465, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.006522845476865768, 'loss_2': 0.001422882080078125, 'loss_3': -16.406421661376953, 'loss_4': 2.3267688751220703, 'epoch': 21.27}
{'loss': 0.0041, 'grad_norm': 4.69373083114624, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.002600964391604066, 'loss_2': 0.0015411376953125, 'loss_3': -16.38840675354004, 'loss_4': 1.976948618888855, 'epoch': 21.27}
{'loss': 0.0178, 'grad_norm': 8.461610794067383, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.009909549728035927, 'loss_2': 0.00787353515625, 'loss_3': -16.267642974853516, 'loss_4': 1.8871161937713623, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 10:54:26,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:26,175 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:15<25:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:33,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010229171253740788, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.543, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0077179973013699055, 'eval_loss_2': 0.0025111734867095947, 'eval_loss_3': -18.352449417114258, 'eval_loss_4': 1.7453007698059082, 'epoch': 21.28}
{'loss': 0.0132, 'grad_norm': 4.953948974609375, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.008797760121524334, 'loss_2': 0.00444793701171875, 'loss_3': -16.45960235595703, 'loss_4': 2.248835802078247, 'epoch': 21.28}
{'loss': 0.0075, 'grad_norm': 5.440016269683838, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.005427321884781122, 'loss_2': 0.00209808349609375, 'loss_3': -16.206924438476562, 'loss_4': 1.8879725933074951, 'epoch': 21.29}
{'loss': 0.0044, 'grad_norm': 4.807778358459473, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.0029239323921501637, 'loss_2': 0.0015172958374023438, 'loss_3': -16.37934112548828, 'loss_4': 1.8781075477600098, 'epoch': 21.3}
{'loss': 0.0073, 'grad_norm': 4.413564682006836, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.004639412742108107, 'loss_2': 0.0026493072509765625, 'loss_3': -16.329320907592773, 'loss_4': 1.8148304224014282, 'epoch': 21.3}
{'loss': 0.0042, 'grad_norm': 5.125568389892578, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.004044832196086645, 'loss_2': 0.0002014636993408203, 'loss_3': -16.45132064819336, 'loss_4': 2.1512136459350586, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 10:54:33,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:33,511 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:23<25:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:40,854 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01179882138967514, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.735, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008464298211038113, 'eval_loss_2': 0.003334522247314453, 'eval_loss_3': -18.32411003112793, 'eval_loss_4': 1.6244840621948242, 'epoch': 21.31}
{'loss': 0.0064, 'grad_norm': 4.948004245758057, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.004438816104084253, 'loss_2': 0.00197601318359375, 'loss_3': -16.27964973449707, 'loss_4': 1.8582589626312256, 'epoch': 21.31}
{'loss': 0.0109, 'grad_norm': 6.645203590393066, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.008527551777660847, 'loss_2': 0.00240325927734375, 'loss_3': -16.47891616821289, 'loss_4': 1.8242675065994263, 'epoch': 21.32}
{'loss': 0.0061, 'grad_norm': 4.716368675231934, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.004344604443758726, 'loss_2': 0.001781463623046875, 'loss_3': -16.22591781616211, 'loss_4': 2.3592023849487305, 'epoch': 21.33}
{'loss': 0.0074, 'grad_norm': 4.8118696212768555, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.005463141482323408, 'loss_2': 0.00189208984375, 'loss_3': -16.354190826416016, 'loss_4': 2.000995635986328, 'epoch': 21.33}
{'loss': 0.0115, 'grad_norm': 5.253371238708496, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.005420035682618618, 'loss_2': 0.00612640380859375, 'loss_3': -16.354888916015625, 'loss_4': 2.017211437225342, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 10:54:40,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:40,854 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:30<25:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:48,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010890009813010693, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008520768955349922, 'eval_loss_2': 0.002369239926338196, 'eval_loss_3': -18.336727142333984, 'eval_loss_4': 1.585516333580017, 'epoch': 21.34}
{'loss': 0.0125, 'grad_norm': 5.142204284667969, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.005136127583682537, 'loss_2': 0.0073699951171875, 'loss_3': -16.25017547607422, 'loss_4': 1.9307501316070557, 'epoch': 21.34}
{'loss': 0.0104, 'grad_norm': 5.134388446807861, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.008287793956696987, 'loss_2': 0.0021495819091796875, 'loss_3': -16.410985946655273, 'loss_4': 2.307681083679199, 'epoch': 21.35}
{'loss': 0.0167, 'grad_norm': 5.498563289642334, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.006105103064328432, 'loss_2': 0.0106048583984375, 'loss_3': -16.222490310668945, 'loss_4': 1.8384807109832764, 'epoch': 21.35}
{'loss': 0.0047, 'grad_norm': 4.805374622344971, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.004297366365790367, 'loss_2': 0.0004444122314453125, 'loss_3': -16.34417724609375, 'loss_4': 2.0973620414733887, 'epoch': 21.36}
{'loss': 0.0137, 'grad_norm': 5.396200180053711, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.008304812014102936, 'loss_2': 0.005367279052734375, 'loss_3': -16.325803756713867, 'loss_4': 1.7319269180297852, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 10:54:48,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:48,199 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:37<25:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:55,543 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011095044203102589, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008540687151253223, 'eval_loss_2': 0.0025543570518493652, 'eval_loss_3': -18.32199478149414, 'eval_loss_4': 1.6796541213989258, 'epoch': 21.37}
{'loss': 0.0143, 'grad_norm': 5.795777320861816, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.011512608267366886, 'loss_2': 0.002765655517578125, 'loss_3': -16.377595901489258, 'loss_4': 2.3774046897888184, 'epoch': 21.37}
{'loss': 0.0032, 'grad_norm': 4.6475982666015625, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.0020021020900458097, 'loss_2': 0.001148223876953125, 'loss_3': -16.204998016357422, 'loss_4': 1.4753122329711914, 'epoch': 21.38}
{'loss': 0.0172, 'grad_norm': 11.812264442443848, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.015771906822919846, 'loss_2': 0.0014476776123046875, 'loss_3': -16.38133430480957, 'loss_4': 1.5297051668167114, 'epoch': 21.38}
{'loss': 0.0068, 'grad_norm': 4.359923362731934, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.00469303410500288, 'loss_2': 0.00206756591796875, 'loss_3': -16.407949447631836, 'loss_4': 2.0637598037719727, 'epoch': 21.39}
{'loss': 0.0191, 'grad_norm': 13.665602684020996, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.01491182018071413, 'loss_2': 0.004192352294921875, 'loss_3': -16.09880828857422, 'loss_4': 2.299367666244507, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 10:54:55,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:55,543 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:30:45<25:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:02,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011150510050356388, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.703, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008656949736177921, 'eval_loss_2': 0.002493560314178467, 'eval_loss_3': -18.33050537109375, 'eval_loss_4': 1.7784634828567505, 'epoch': 21.4}
{'loss': 0.0039, 'grad_norm': 4.966991901397705, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.0035382655914872885, 'loss_2': 0.0003829002380371094, 'loss_3': -16.327884674072266, 'loss_4': 1.5056099891662598, 'epoch': 21.4}
{'loss': 0.0107, 'grad_norm': 6.168932914733887, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.007992849685251713, 'loss_2': 0.0027523040771484375, 'loss_3': -16.28428077697754, 'loss_4': 1.6678853034973145, 'epoch': 21.41}
{'loss': 0.0089, 'grad_norm': 6.2710466384887695, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.007327196188271046, 'loss_2': 0.00153350830078125, 'loss_3': -16.405216217041016, 'loss_4': 2.1340198516845703, 'epoch': 21.41}
{'loss': 0.0182, 'grad_norm': 7.8786187171936035, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.012785117141902447, 'loss_2': 0.00539398193359375, 'loss_3': -16.55860710144043, 'loss_4': 2.2000272274017334, 'epoch': 21.42}
{'loss': 0.0124, 'grad_norm': 8.98327922821045, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.01113493088632822, 'loss_2': 0.0012922286987304688, 'loss_3': -16.42999267578125, 'loss_4': 2.211033582687378, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 10:55:02,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:02,884 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:30:52<25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:10,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010747978463768959, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.524, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008501896634697914, 'eval_loss_2': 0.002246081829071045, 'eval_loss_3': -18.319747924804688, 'eval_loss_4': 1.7017077207565308, 'epoch': 21.42}
{'loss': 0.0082, 'grad_norm': 6.228247165679932, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.006463056430220604, 'loss_2': 0.0017032623291015625, 'loss_3': -16.30814552307129, 'loss_4': 1.57899010181427, 'epoch': 21.43}
{'loss': 0.0076, 'grad_norm': 5.052413463592529, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.005423626862466335, 'loss_2': 0.002170562744140625, 'loss_3': -16.26800537109375, 'loss_4': 2.0215744972229004, 'epoch': 21.44}
{'loss': 0.0093, 'grad_norm': 6.023128986358643, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.007662221323698759, 'loss_2': 0.0016040802001953125, 'loss_3': -16.39363670349121, 'loss_4': 1.9712753295898438, 'epoch': 21.44}
{'loss': 0.0053, 'grad_norm': 5.274618625640869, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.004650586750358343, 'loss_2': 0.0006170272827148438, 'loss_3': -16.160078048706055, 'loss_4': 1.9849051237106323, 'epoch': 21.45}
{'loss': 0.0222, 'grad_norm': 15.002082824707031, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.02078981325030327, 'loss_2': 0.0013904571533203125, 'loss_3': -16.426036834716797, 'loss_4': 2.197608709335327, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 10:55:10,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:10,229 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:30:59<25:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:17,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01105516217648983, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008515401743352413, 'eval_loss_2': 0.0025397613644599915, 'eval_loss_3': -18.312650680541992, 'eval_loss_4': 1.5983426570892334, 'epoch': 21.45}
{'loss': 0.0111, 'grad_norm': 5.086735248565674, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.0063551622442901134, 'loss_2': 0.00472259521484375, 'loss_3': -16.06389617919922, 'loss_4': 1.205751657485962, 'epoch': 21.46}
{'loss': 0.0079, 'grad_norm': 4.6450514793396, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.004210032057017088, 'loss_2': 0.003688812255859375, 'loss_3': -16.384389877319336, 'loss_4': 1.9687384366989136, 'epoch': 21.47}
{'loss': 0.0138, 'grad_norm': 6.752857685089111, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.009925387799739838, 'loss_2': 0.00386810302734375, 'loss_3': -16.352968215942383, 'loss_4': 1.3163530826568604, 'epoch': 21.47}
{'loss': 0.0061, 'grad_norm': 5.205230712890625, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.005671277176588774, 'loss_2': 0.00041103363037109375, 'loss_3': -16.289825439453125, 'loss_4': 1.935190200805664, 'epoch': 21.48}
{'loss': 0.0087, 'grad_norm': 5.386762619018555, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.007559328805655241, 'loss_2': 0.0011348724365234375, 'loss_3': -16.32794952392578, 'loss_4': 1.8961480855941772, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 10:55:17,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:17,577 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:07<25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:24,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01067663636058569, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.241, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008117659017443657, 'eval_loss_2': 0.002558976411819458, 'eval_loss_3': -18.304927825927734, 'eval_loss_4': 1.4738775491714478, 'epoch': 21.48}
{'loss': 0.0071, 'grad_norm': 4.402324199676514, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.004336099606007338, 'loss_2': 0.002716064453125, 'loss_3': -16.502262115478516, 'loss_4': 1.7818336486816406, 'epoch': 21.49}
{'loss': 0.0068, 'grad_norm': 4.361281871795654, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0046193660236895084, 'loss_2': 0.00222015380859375, 'loss_3': -16.49636459350586, 'loss_4': 1.703691005706787, 'epoch': 21.49}
{'loss': 0.0049, 'grad_norm': 4.4068779945373535, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.003356620902195573, 'loss_2': 0.001529693603515625, 'loss_3': -16.233976364135742, 'loss_4': 1.7931703329086304, 'epoch': 21.5}
{'loss': 0.0068, 'grad_norm': 4.941091060638428, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.0039015235379338264, 'loss_2': 0.00289154052734375, 'loss_3': -16.19796371459961, 'loss_4': 1.5910173654556274, 'epoch': 21.51}
{'loss': 0.0157, 'grad_norm': 4.554145812988281, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.00388339813798666, 'loss_2': 0.01181793212890625, 'loss_3': -16.595726013183594, 'loss_4': 1.3842883110046387, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 10:55:24,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:24,916 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:14<25:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:32,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010664925910532475, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.811, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007426300086081028, 'eval_loss_2': 0.0032386258244514465, 'eval_loss_3': -18.292932510375977, 'eval_loss_4': 1.2688331604003906, 'epoch': 21.51}
{'loss': 0.0052, 'grad_norm': 4.952079772949219, 'learning_rate': 8.5e-06, 'loss_1': 0.004429180640727282, 'loss_2': 0.000782012939453125, 'loss_3': -16.393375396728516, 'loss_4': 1.8270015716552734, 'epoch': 21.52}
{'loss': 0.0086, 'grad_norm': 5.294421195983887, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.003669232362881303, 'loss_2': 0.0048828125, 'loss_3': -16.334209442138672, 'loss_4': 1.2349739074707031, 'epoch': 21.52}
{'loss': 0.0128, 'grad_norm': 5.181743621826172, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.0042073484510183334, 'loss_2': 0.0085906982421875, 'loss_3': -16.174392700195312, 'loss_4': 1.7038753032684326, 'epoch': 21.53}
{'loss': 0.0075, 'grad_norm': 4.984045028686523, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.005706413183361292, 'loss_2': 0.0017690658569335938, 'loss_3': -16.332250595092773, 'loss_4': 1.51277756690979, 'epoch': 21.53}
{'loss': 0.0035, 'grad_norm': 4.799252986907959, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.0031601327937096357, 'loss_2': 0.0003342628479003906, 'loss_3': -16.124723434448242, 'loss_4': 1.161081075668335, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 10:55:32,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:32,272 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:21<25:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:39,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009683565236628056, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00707231555134058, 'eval_loss_2': 0.0026112496852874756, 'eval_loss_3': -18.289201736450195, 'eval_loss_4': 1.0309576988220215, 'epoch': 21.54}
{'loss': 0.0077, 'grad_norm': 4.986416339874268, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.0037835827097296715, 'loss_2': 0.003936767578125, 'loss_3': -16.356130599975586, 'loss_4': 1.770774245262146, 'epoch': 21.55}
{'loss': 0.0079, 'grad_norm': 4.527581691741943, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.0035166246816515923, 'loss_2': 0.0043792724609375, 'loss_3': -16.226268768310547, 'loss_4': 1.211116075515747, 'epoch': 21.55}
{'loss': 0.0043, 'grad_norm': 4.755236625671387, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.003393401624634862, 'loss_2': 0.0009326934814453125, 'loss_3': -16.474933624267578, 'loss_4': 1.1484427452087402, 'epoch': 21.56}
{'loss': 0.0073, 'grad_norm': 4.271798610687256, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.004304224159568548, 'loss_2': 0.0029926300048828125, 'loss_3': -16.227970123291016, 'loss_4': 0.5237765908241272, 'epoch': 21.56}
{'loss': 0.0074, 'grad_norm': 4.833256721496582, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.004247007425874472, 'loss_2': 0.003177642822265625, 'loss_3': -16.13735580444336, 'loss_4': 0.6333526372909546, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 10:55:39,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:39,620 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:29<24:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:46,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008811606094241142, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.641, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.006482226774096489, 'eval_loss_2': 0.0023293793201446533, 'eval_loss_3': -18.284278869628906, 'eval_loss_4': 0.9414327144622803, 'epoch': 21.57}
{'loss': 0.0057, 'grad_norm': 4.5682220458984375, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.004716125316917896, 'loss_2': 0.000957489013671875, 'loss_3': -16.036758422851562, 'loss_4': 1.358104944229126, 'epoch': 21.58}
{'loss': 0.0117, 'grad_norm': 6.7733154296875, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.008694742806255817, 'loss_2': 0.0029773712158203125, 'loss_3': -16.25310516357422, 'loss_4': 0.691885232925415, 'epoch': 21.58}
{'loss': 0.0157, 'grad_norm': 7.229455947875977, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.010871713981032372, 'loss_2': 0.00481414794921875, 'loss_3': -16.35165786743164, 'loss_4': 1.4076411724090576, 'epoch': 21.59}
{'loss': 0.0089, 'grad_norm': 5.660484790802002, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.00783816259354353, 'loss_2': 0.0010671615600585938, 'loss_3': -16.189014434814453, 'loss_4': 1.6861655712127686, 'epoch': 21.59}
{'loss': 0.027, 'grad_norm': 11.439781188964844, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.023694179952144623, 'loss_2': 0.0033092498779296875, 'loss_3': -15.943990707397461, 'loss_4': 0.9571713209152222, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 10:55:46,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:46,956 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:36<24:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:54,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008962597697973251, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0061437455005943775, 'eval_loss_2': 0.002818852663040161, 'eval_loss_3': -18.28346824645996, 'eval_loss_4': 1.0049636363983154, 'epoch': 21.6}
{'loss': 0.0054, 'grad_norm': 4.804558753967285, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.0029220418073236942, 'loss_2': 0.00251007080078125, 'loss_3': -16.37937355041504, 'loss_4': 1.6690112352371216, 'epoch': 21.6}
{'loss': 0.0135, 'grad_norm': 5.581715106964111, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.006276643369346857, 'loss_2': 0.007213592529296875, 'loss_3': -16.32367706298828, 'loss_4': 1.557037115097046, 'epoch': 21.61}
{'loss': 0.0113, 'grad_norm': 5.314136028289795, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.00409863842651248, 'loss_2': 0.007160186767578125, 'loss_3': -16.29901885986328, 'loss_4': 1.1338452100753784, 'epoch': 21.62}
{'loss': 0.013, 'grad_norm': 5.685934066772461, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.00587642565369606, 'loss_2': 0.007152557373046875, 'loss_3': -16.57681655883789, 'loss_4': 1.7724450826644897, 'epoch': 21.62}
{'loss': 0.0138, 'grad_norm': 4.655999183654785, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.00220184656791389, 'loss_2': 0.01163482666015625, 'loss_3': -16.42767906188965, 'loss_4': 1.2760798931121826, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 10:55:54,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:54,292 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:31:43<24:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:01,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009854026138782501, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006313703488558531, 'eval_loss_2': 0.003540322184562683, 'eval_loss_3': -18.276050567626953, 'eval_loss_4': 1.1251980066299438, 'epoch': 21.63}
{'loss': 0.0097, 'grad_norm': 5.626070976257324, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.005398264620453119, 'loss_2': 0.0043182373046875, 'loss_3': -16.3699951171875, 'loss_4': 1.7002665996551514, 'epoch': 21.63}
{'loss': 0.0068, 'grad_norm': 4.936944007873535, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.0036284876987338066, 'loss_2': 0.0031452178955078125, 'loss_3': -16.417335510253906, 'loss_4': 1.6548689603805542, 'epoch': 21.64}
{'loss': 0.0124, 'grad_norm': 5.851624011993408, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.011387454345822334, 'loss_2': 0.0010585784912109375, 'loss_3': -16.22882652282715, 'loss_4': 2.016775131225586, 'epoch': 21.65}
{'loss': 0.0152, 'grad_norm': 10.542524337768555, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.011078528128564358, 'loss_2': 0.0040740966796875, 'loss_3': -16.32189178466797, 'loss_4': 1.6675347089767456, 'epoch': 21.65}
{'loss': 0.011, 'grad_norm': 4.38283109664917, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.002001299988478422, 'loss_2': 0.0090179443359375, 'loss_3': -16.519203186035156, 'loss_4': 1.902966856956482, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 10:56:01,635 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:01,635 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:31:51<24:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:08,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008435843512415886, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0060289776884019375, 'eval_loss_2': 0.002406865358352661, 'eval_loss_3': -18.28597068786621, 'eval_loss_4': 1.2613192796707153, 'epoch': 21.66}
{'loss': 0.0055, 'grad_norm': 4.5950446128845215, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.004235202446579933, 'loss_2': 0.00130462646484375, 'loss_3': -16.244226455688477, 'loss_4': 1.5021636486053467, 'epoch': 21.66}
{'loss': 0.019, 'grad_norm': 8.891335487365723, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.016541171818971634, 'loss_2': 0.002414703369140625, 'loss_3': -16.289501190185547, 'loss_4': 2.165830612182617, 'epoch': 21.67}
{'loss': 0.0172, 'grad_norm': 12.601194381713867, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.013827420771121979, 'loss_2': 0.0033416748046875, 'loss_3': -16.403491973876953, 'loss_4': 1.6862225532531738, 'epoch': 21.67}
{'loss': 0.0096, 'grad_norm': 4.828943252563477, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.003774645272642374, 'loss_2': 0.00577545166015625, 'loss_3': -16.508464813232422, 'loss_4': 1.9365612268447876, 'epoch': 21.68}
{'loss': 0.0075, 'grad_norm': 5.007872104644775, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.005423858296126127, 'loss_2': 0.002086639404296875, 'loss_3': -16.35517692565918, 'loss_4': 1.6216540336608887, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 10:56:08,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:08,987 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:31:58<24:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:16,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009964942932128906, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.684, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006284958682954311, 'eval_loss_2': 0.0036799833178520203, 'eval_loss_3': -18.289506912231445, 'eval_loss_4': 1.3840583562850952, 'epoch': 21.69}
{'loss': 0.0033, 'grad_norm': 4.469282627105713, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.0032685422338545322, 'loss_2': 5.823373794555664e-05, 'loss_3': -16.467369079589844, 'loss_4': 2.089855194091797, 'epoch': 21.69}
{'loss': 0.009, 'grad_norm': 5.041287422180176, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.005697313230484724, 'loss_2': 0.0033016204833984375, 'loss_3': -16.342439651489258, 'loss_4': 1.9167461395263672, 'epoch': 21.7}
{'loss': 0.007, 'grad_norm': 4.952394962310791, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.0048166667111217976, 'loss_2': 0.00213623046875, 'loss_3': -16.322458267211914, 'loss_4': 2.0591464042663574, 'epoch': 21.7}
{'loss': 0.0108, 'grad_norm': 5.240837574005127, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.005634783301502466, 'loss_2': 0.005214691162109375, 'loss_3': -16.48748779296875, 'loss_4': 1.5163054466247559, 'epoch': 21.71}
{'loss': 0.0095, 'grad_norm': 4.473194599151611, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.0047730328515172005, 'loss_2': 0.00470733642578125, 'loss_3': -16.21095848083496, 'loss_4': 1.7628018856048584, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 10:56:16,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:16,341 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:05<24:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:23,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01193825714290142, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.716, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006199819967150688, 'eval_loss_2': 0.005738437175750732, 'eval_loss_3': -18.32037925720215, 'eval_loss_4': 1.3444149494171143, 'epoch': 21.72}
{'loss': 0.0115, 'grad_norm': 4.257646560668945, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.002197566907852888, 'loss_2': 0.0092620849609375, 'loss_3': -16.53148651123047, 'loss_4': 1.7759509086608887, 'epoch': 21.72}
{'loss': 0.0128, 'grad_norm': 4.364819049835205, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.006755303591489792, 'loss_2': 0.00606536865234375, 'loss_3': -16.304088592529297, 'loss_4': 1.7662099599838257, 'epoch': 21.73}
{'loss': 0.0117, 'grad_norm': 7.38663911819458, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.008621392771601677, 'loss_2': 0.003078460693359375, 'loss_3': -16.258544921875, 'loss_4': 1.7398000955581665, 'epoch': 21.73}
{'loss': 0.0133, 'grad_norm': 5.95430850982666, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.00801789853721857, 'loss_2': 0.0052642822265625, 'loss_3': -16.700237274169922, 'loss_4': 1.5842022895812988, 'epoch': 21.74}
{'loss': 0.0087, 'grad_norm': 4.81429386138916, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.0039102425798773766, 'loss_2': 0.004741668701171875, 'loss_3': -16.34888458251953, 'loss_4': 1.8782455921173096, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 10:56:23,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:23,695 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:13<24:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:31,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009373466484248638, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005917648784816265, 'eval_loss_2': 0.003455817699432373, 'eval_loss_3': -18.329147338867188, 'eval_loss_4': 1.3788260221481323, 'epoch': 21.74}
{'loss': 0.0163, 'grad_norm': 5.086456298828125, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.007952328771352768, 'loss_2': 0.00833892822265625, 'loss_3': -16.2822208404541, 'loss_4': 2.188002824783325, 'epoch': 21.75}
{'loss': 0.0184, 'grad_norm': 7.0138163566589355, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.011689872480928898, 'loss_2': 0.006702423095703125, 'loss_3': -16.383502960205078, 'loss_4': 2.0356943607330322, 'epoch': 21.76}
{'loss': 0.0084, 'grad_norm': 4.522125244140625, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.005279568023979664, 'loss_2': 0.00307464599609375, 'loss_3': -16.54022789001465, 'loss_4': 1.7585630416870117, 'epoch': 21.76}
{'loss': 0.015, 'grad_norm': 5.847492694854736, 'learning_rate': 8.25e-06, 'loss_1': 0.009343130514025688, 'loss_2': 0.005615234375, 'loss_3': -16.38943099975586, 'loss_4': 1.8849773406982422, 'epoch': 21.77}
{'loss': 0.0134, 'grad_norm': 5.219682693481445, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.006876820232719183, 'loss_2': 0.00649261474609375, 'loss_3': -16.345077514648438, 'loss_4': 1.646193504333496, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 10:56:31,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:31,049 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:20<24:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:38,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009502601809799671, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005521428771317005, 'eval_loss_2': 0.003981173038482666, 'eval_loss_3': -18.35077476501465, 'eval_loss_4': 1.4447615146636963, 'epoch': 21.77}
{'loss': 0.0181, 'grad_norm': 7.750523090362549, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.00967145524919033, 'loss_2': 0.00839996337890625, 'loss_3': -16.46544647216797, 'loss_4': 1.4706103801727295, 'epoch': 21.78}
{'loss': 0.0202, 'grad_norm': 7.958837032318115, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.013511409983038902, 'loss_2': 0.00673675537109375, 'loss_3': -16.350326538085938, 'loss_4': 2.4380316734313965, 'epoch': 21.78}
{'loss': 0.0136, 'grad_norm': 7.0184221267700195, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.010441035963594913, 'loss_2': 0.003108978271484375, 'loss_3': -16.379453659057617, 'loss_4': 1.6904520988464355, 'epoch': 21.79}
{'loss': 0.0129, 'grad_norm': 7.4706950187683105, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.010088704526424408, 'loss_2': 0.002796173095703125, 'loss_3': -16.36861801147461, 'loss_4': 2.2407562732696533, 'epoch': 21.8}
{'loss': 0.0096, 'grad_norm': 5.3894429206848145, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.008708581328392029, 'loss_2': 0.0008993148803710938, 'loss_3': -16.561206817626953, 'loss_4': 1.7983207702636719, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 10:56:38,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:38,386 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:27<24:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:45,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011424273252487183, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006403415463864803, 'eval_loss_2': 0.005020856857299805, 'eval_loss_3': -18.354114532470703, 'eval_loss_4': 1.5030169486999512, 'epoch': 21.8}
{'loss': 0.0165, 'grad_norm': 6.427062034606934, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.006514143664389849, 'loss_2': 0.00998687744140625, 'loss_3': -16.501049041748047, 'loss_4': 2.347360134124756, 'epoch': 21.81}
{'loss': 0.0067, 'grad_norm': 4.735961437225342, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.004047865979373455, 'loss_2': 0.00262451171875, 'loss_3': -16.659931182861328, 'loss_4': 1.647186040878296, 'epoch': 21.81}
{'loss': 0.0199, 'grad_norm': 5.466246604919434, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.006983977276831865, 'loss_2': 0.012939453125, 'loss_3': -16.541019439697266, 'loss_4': 2.1677114963531494, 'epoch': 21.82}
{'loss': 0.0131, 'grad_norm': 5.598784446716309, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.006282015237957239, 'loss_2': 0.0068511962890625, 'loss_3': -16.447208404541016, 'loss_4': 2.0489540100097656, 'epoch': 21.83}
{'loss': 0.0084, 'grad_norm': 5.818736553192139, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.00709071010351181, 'loss_2': 0.001346588134765625, 'loss_3': -16.53224754333496, 'loss_4': 1.7951905727386475, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 10:56:45,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:45,732 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:35<24:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:53,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010833116248250008, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0070219943299889565, 'eval_loss_2': 0.0038111209869384766, 'eval_loss_3': -18.355953216552734, 'eval_loss_4': 1.4511710405349731, 'epoch': 21.83}
{'loss': 0.0114, 'grad_norm': 5.999159336090088, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.008019167929887772, 'loss_2': 0.003383636474609375, 'loss_3': -16.55845832824707, 'loss_4': 2.094593048095703, 'epoch': 21.84}
{'loss': 0.0133, 'grad_norm': 4.826113224029541, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.006015310995280743, 'loss_2': 0.007293701171875, 'loss_3': -16.44662857055664, 'loss_4': 1.908159852027893, 'epoch': 21.84}
{'loss': 0.0092, 'grad_norm': 5.620166301727295, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.008019317872822285, 'loss_2': 0.0012273788452148438, 'loss_3': -16.69771957397461, 'loss_4': 2.0907533168792725, 'epoch': 21.85}
{'loss': 0.0108, 'grad_norm': 7.360041618347168, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.008633148856461048, 'loss_2': 0.002132415771484375, 'loss_3': -16.540138244628906, 'loss_4': 1.7553073167800903, 'epoch': 21.85}
{'loss': 0.0162, 'grad_norm': 6.115861415863037, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.010211557149887085, 'loss_2': 0.005992889404296875, 'loss_3': -16.418636322021484, 'loss_4': 1.7517666816711426, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 10:56:53,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:53,081 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:42<24:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:00,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010822094045579433, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0077223023399710655, 'eval_loss_2': 0.003099791705608368, 'eval_loss_3': -18.344959259033203, 'eval_loss_4': 1.352972388267517, 'epoch': 21.86}
{'loss': 0.0155, 'grad_norm': 5.345763206481934, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.011437506414949894, 'loss_2': 0.0041046142578125, 'loss_3': -16.290115356445312, 'loss_4': 1.7542197704315186, 'epoch': 21.87}
{'loss': 0.0219, 'grad_norm': 7.515448570251465, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.01620417647063732, 'loss_2': 0.00571441650390625, 'loss_3': -16.485078811645508, 'loss_4': 1.8928325176239014, 'epoch': 21.87}
{'loss': 0.0109, 'grad_norm': 4.718216896057129, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.004071519244462252, 'loss_2': 0.00679779052734375, 'loss_3': -16.63443946838379, 'loss_4': 2.209170341491699, 'epoch': 21.88}
{'loss': 0.019, 'grad_norm': 7.072419166564941, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.016797423362731934, 'loss_2': 0.00222015380859375, 'loss_3': -16.411806106567383, 'loss_4': 1.6125764846801758, 'epoch': 21.88}
{'loss': 0.008, 'grad_norm': 5.063928127288818, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.006126151420176029, 'loss_2': 0.0018634796142578125, 'loss_3': -16.486330032348633, 'loss_4': 1.4719038009643555, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 10:57:00,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:00,418 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:32:49<24:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:07,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010172674432396889, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007526957429945469, 'eval_loss_2': 0.002645716071128845, 'eval_loss_3': -18.357044219970703, 'eval_loss_4': 1.2978440523147583, 'epoch': 21.89}
{'loss': 0.0065, 'grad_norm': 4.920899868011475, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.0059003811329603195, 'loss_2': 0.0006041526794433594, 'loss_3': -16.429725646972656, 'loss_4': 1.8016095161437988, 'epoch': 21.9}
{'loss': 0.0092, 'grad_norm': 4.386184215545654, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.004330112598836422, 'loss_2': 0.004852294921875, 'loss_3': -16.332054138183594, 'loss_4': 1.5895735025405884, 'epoch': 21.9}
{'loss': 0.0099, 'grad_norm': 4.605448246002197, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.006361941806972027, 'loss_2': 0.0035419464111328125, 'loss_3': -16.543682098388672, 'loss_4': 1.662508249282837, 'epoch': 21.91}
{'loss': 0.0133, 'grad_norm': 5.112785339355469, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.010418355464935303, 'loss_2': 0.002880096435546875, 'loss_3': -16.440887451171875, 'loss_4': 2.0354747772216797, 'epoch': 21.91}
{'loss': 0.0112, 'grad_norm': 5.270094394683838, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.00603057537227869, 'loss_2': 0.0051727294921875, 'loss_3': -16.725616455078125, 'loss_4': 1.7245877981185913, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 10:57:07,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:07,764 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:32:57<23:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:15,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011881659738719463, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.636, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008114452473819256, 'eval_loss_2': 0.0037672072649002075, 'eval_loss_3': -18.35974884033203, 'eval_loss_4': 1.332287311553955, 'epoch': 21.92}
{'loss': 0.0313, 'grad_norm': 17.281259536743164, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.029125574976205826, 'loss_2': 0.0022029876708984375, 'loss_3': -16.528358459472656, 'loss_4': 1.5664458274841309, 'epoch': 21.92}
{'loss': 0.0101, 'grad_norm': 4.732118606567383, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.005716692190617323, 'loss_2': 0.00438690185546875, 'loss_3': -16.503692626953125, 'loss_4': 1.3848830461502075, 'epoch': 21.93}
{'loss': 0.0157, 'grad_norm': 6.801689624786377, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.00866794865578413, 'loss_2': 0.00707244873046875, 'loss_3': -16.62358856201172, 'loss_4': 1.2037549018859863, 'epoch': 21.94}
{'loss': 0.0193, 'grad_norm': 6.930830001831055, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.015727968886494637, 'loss_2': 0.003570556640625, 'loss_3': -16.7579345703125, 'loss_4': 1.9290871620178223, 'epoch': 21.94}
{'loss': 0.0089, 'grad_norm': 5.320903301239014, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.006443277467042208, 'loss_2': 0.0024089813232421875, 'loss_3': -16.62480926513672, 'loss_4': 1.3855228424072266, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 10:57:15,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:15,119 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:04<23:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:22,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012216297909617424, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008128506131470203, 'eval_loss_2': 0.004087790846824646, 'eval_loss_3': -18.376108169555664, 'eval_loss_4': 1.3926392793655396, 'epoch': 21.95}
{'loss': 0.0143, 'grad_norm': 5.221863269805908, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.00704149017110467, 'loss_2': 0.0072784423828125, 'loss_3': -16.681745529174805, 'loss_4': 1.4142186641693115, 'epoch': 21.95}
{'loss': 0.0108, 'grad_norm': 5.108134746551514, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.008397049270570278, 'loss_2': 0.00235748291015625, 'loss_3': -16.481201171875, 'loss_4': 1.694888949394226, 'epoch': 21.96}
{'loss': 0.0119, 'grad_norm': 4.664770603179932, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.007623506709933281, 'loss_2': 0.004299163818359375, 'loss_3': -16.43488311767578, 'loss_4': 1.713228464126587, 'epoch': 21.97}
{'loss': 0.0277, 'grad_norm': 24.407609939575195, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.02580978162586689, 'loss_2': 0.00191497802734375, 'loss_3': -16.392837524414062, 'loss_4': 1.8815701007843018, 'epoch': 21.97}
{'loss': 0.0173, 'grad_norm': 5.430950164794922, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.007714744657278061, 'loss_2': 0.0096282958984375, 'loss_3': -16.48834228515625, 'loss_4': 1.7465397119522095, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 10:57:22,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:22,463 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:11<22:25,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:57:29,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010678766295313835, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.389, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007691558916121721, 'eval_loss_2': 0.002987205982208252, 'eval_loss_3': -18.388134002685547, 'eval_loss_4': 1.5000817775726318, 'epoch': 21.98}
{'loss': 0.0141, 'grad_norm': 5.330904483795166, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.012476876378059387, 'loss_2': 0.0015964508056640625, 'loss_3': -16.46982765197754, 'loss_4': 1.9014873504638672, 'epoch': 21.98}
{'loss': 0.0064, 'grad_norm': 4.378511428833008, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.005149227101355791, 'loss_2': 0.0012722015380859375, 'loss_3': -16.492258071899414, 'loss_4': 1.5221407413482666, 'epoch': 21.99}
{'loss': 0.012, 'grad_norm': 5.271804332733154, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.007375701330602169, 'loss_2': 0.004669189453125, 'loss_3': -16.41431427001953, 'loss_4': 1.7913691997528076, 'epoch': 21.99}
{'loss': 0.0149, 'grad_norm': 7.450967311859131, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.007312570232897997, 'loss_2': 0.0075531005859375, 'loss_3': -16.797046661376953, 'loss_4': 2.7852909564971924, 'epoch': 22.0}
{'loss': 0.0113, 'grad_norm': 5.206162452697754, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.005952315405011177, 'loss_2': 0.00539398193359375, 'loss_3': -16.55078887939453, 'loss_4': 2.5486555099487305, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 10:57:29,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:29,500 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:19<23:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:57:36,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01271815411746502, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.377, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007969571277499199, 'eval_loss_2': 0.00474858283996582, 'eval_loss_3': -18.396278381347656, 'eval_loss_4': 1.4812078475952148, 'epoch': 22.01}
{'loss': 0.0128, 'grad_norm': 4.501766681671143, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.009136631153523922, 'loss_2': 0.0036563873291015625, 'loss_3': -16.519357681274414, 'loss_4': 1.2931687831878662, 'epoch': 22.01}
{'loss': 0.0093, 'grad_norm': 4.90455436706543, 'learning_rate': 8e-06, 'loss_1': 0.006859696004539728, 'loss_2': 0.002468109130859375, 'loss_3': -16.407548904418945, 'loss_4': 1.8443726301193237, 'epoch': 22.02}
{'loss': 0.0107, 'grad_norm': 4.827422142028809, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.0054129427298903465, 'loss_2': 0.0052642822265625, 'loss_3': -16.70055389404297, 'loss_4': 1.8635247945785522, 'epoch': 22.02}
{'loss': 0.009, 'grad_norm': 4.9379119873046875, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.005935976281762123, 'loss_2': 0.0030803680419921875, 'loss_3': -16.627010345458984, 'loss_4': 1.7802214622497559, 'epoch': 22.03}
{'loss': 0.0117, 'grad_norm': 4.761338233947754, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.005171041004359722, 'loss_2': 0.006519317626953125, 'loss_3': -16.426149368286133, 'loss_4': 1.812126636505127, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 10:57:36,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:36,850 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:26<23:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:44,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011874726042151451, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.895, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0084505220875144, 'eval_loss_2': 0.0034242048859596252, 'eval_loss_3': -18.390827178955078, 'eval_loss_4': 1.2918670177459717, 'epoch': 22.03}
{'loss': 0.0113, 'grad_norm': 5.032986164093018, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.008895166218280792, 'loss_2': 0.0023860931396484375, 'loss_3': -16.58204460144043, 'loss_4': 1.3125272989273071, 'epoch': 22.04}
{'loss': 0.011, 'grad_norm': 5.323034763336182, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.0080915791913867, 'loss_2': 0.00286865234375, 'loss_3': -16.532791137695312, 'loss_4': 1.495539665222168, 'epoch': 22.05}
{'loss': 0.0184, 'grad_norm': 5.395130634307861, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.01058498490601778, 'loss_2': 0.00782012939453125, 'loss_3': -16.37502098083496, 'loss_4': 1.8862385749816895, 'epoch': 22.05}
{'loss': 0.0073, 'grad_norm': 4.869487285614014, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.005464673507958651, 'loss_2': 0.0018215179443359375, 'loss_3': -16.54499053955078, 'loss_4': 2.0767741203308105, 'epoch': 22.06}
{'loss': 0.0117, 'grad_norm': 5.965205669403076, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.009807431139051914, 'loss_2': 0.0018711090087890625, 'loss_3': -16.573532104492188, 'loss_4': 1.529598355293274, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 10:57:44,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:44,204 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:33<23:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:51,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011558962985873222, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.604, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007887735031545162, 'eval_loss_2': 0.0036712288856506348, 'eval_loss_3': -18.38748550415039, 'eval_loss_4': 1.0581326484680176, 'epoch': 22.06}
{'loss': 0.0126, 'grad_norm': 5.483018398284912, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.009490521624684334, 'loss_2': 0.00311279296875, 'loss_3': -16.462493896484375, 'loss_4': 1.592027187347412, 'epoch': 22.07}
{'loss': 0.0093, 'grad_norm': 5.107300281524658, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.006670580245554447, 'loss_2': 0.002620697021484375, 'loss_3': -16.422826766967773, 'loss_4': 1.5145220756530762, 'epoch': 22.08}
{'loss': 0.0185, 'grad_norm': 5.687553882598877, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.00941047165542841, 'loss_2': 0.00904083251953125, 'loss_3': -16.646501541137695, 'loss_4': 2.1500163078308105, 'epoch': 22.08}
{'loss': 0.0109, 'grad_norm': 4.581894397735596, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.0071964263916015625, 'loss_2': 0.003704071044921875, 'loss_3': -16.543073654174805, 'loss_4': 1.6551485061645508, 'epoch': 22.09}
{'loss': 0.0214, 'grad_norm': 12.024710655212402, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.021098321303725243, 'loss_2': 0.00025773048400878906, 'loss_3': -16.38782501220703, 'loss_4': 1.6098496913909912, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 10:57:51,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:51,538 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:41<23:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:58,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011127586476504803, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.377, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00795286800712347, 'eval_loss_2': 0.0031747184693813324, 'eval_loss_3': -18.384897232055664, 'eval_loss_4': 0.9899420738220215, 'epoch': 22.09}
{'loss': 0.0123, 'grad_norm': 4.412246227264404, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.005256451666355133, 'loss_2': 0.00708770751953125, 'loss_3': -16.393827438354492, 'loss_4': 1.126839280128479, 'epoch': 22.1}
{'loss': 0.0104, 'grad_norm': 4.983588695526123, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.008326887153089046, 'loss_2': 0.0020923614501953125, 'loss_3': -16.414913177490234, 'loss_4': 0.9666764140129089, 'epoch': 22.1}
{'loss': 0.0095, 'grad_norm': 4.8925018310546875, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.006105978973209858, 'loss_2': 0.003368377685546875, 'loss_3': -16.6666259765625, 'loss_4': 0.5846755504608154, 'epoch': 22.11}
{'loss': 0.009, 'grad_norm': 4.904388427734375, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.005938180256634951, 'loss_2': 0.0030422210693359375, 'loss_3': -16.256961822509766, 'loss_4': 1.6624332666397095, 'epoch': 22.12}
{'loss': 0.0072, 'grad_norm': 5.06355094909668, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.005884077865630388, 'loss_2': 0.0013647079467773438, 'loss_3': -16.465869903564453, 'loss_4': 1.4233441352844238, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 10:57:58,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:58,879 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:33:48<23:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:06,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011689065024256706, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.667, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008303193375468254, 'eval_loss_2': 0.003385871648788452, 'eval_loss_3': -18.37885284423828, 'eval_loss_4': 1.0614380836486816, 'epoch': 22.12}
{'loss': 0.0079, 'grad_norm': 5.75655460357666, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.007617892697453499, 'loss_2': 0.0002532005310058594, 'loss_3': -16.394920349121094, 'loss_4': 1.6515774726867676, 'epoch': 22.13}
{'loss': 0.0111, 'grad_norm': 4.241397380828857, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.007952847518026829, 'loss_2': 0.003154754638671875, 'loss_3': -16.486156463623047, 'loss_4': 1.78534734249115, 'epoch': 22.13}
{'loss': 0.0167, 'grad_norm': 6.483549118041992, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.00859257485717535, 'loss_2': 0.0080718994140625, 'loss_3': -16.585430145263672, 'loss_4': 2.040188789367676, 'epoch': 22.14}
{'loss': 0.0112, 'grad_norm': 5.307985782623291, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.007286029402166605, 'loss_2': 0.003894805908203125, 'loss_3': -16.379589080810547, 'loss_4': 1.3352222442626953, 'epoch': 22.15}
{'loss': 0.0262, 'grad_norm': 9.669757843017578, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.022656409069895744, 'loss_2': 0.003543853759765625, 'loss_3': -16.486780166625977, 'loss_4': 1.4589358568191528, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 10:58:06,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:06,216 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:33:55<23:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:13,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011857408098876476, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.864, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008004981093108654, 'eval_loss_2': 0.0038524270057678223, 'eval_loss_3': -18.367259979248047, 'eval_loss_4': 1.1087247133255005, 'epoch': 22.15}
{'loss': 0.0102, 'grad_norm': 4.142630100250244, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.0038229895289987326, 'loss_2': 0.00635528564453125, 'loss_3': -16.603567123413086, 'loss_4': 1.2574138641357422, 'epoch': 22.16}
{'loss': 0.0039, 'grad_norm': 4.390054702758789, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.002666722983121872, 'loss_2': 0.00122833251953125, 'loss_3': -16.510908126831055, 'loss_4': 1.1001659631729126, 'epoch': 22.16}
{'loss': 0.0119, 'grad_norm': 7.115504264831543, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.010255102999508381, 'loss_2': 0.0016803741455078125, 'loss_3': -16.4896240234375, 'loss_4': 1.5059071779251099, 'epoch': 22.17}
{'loss': 0.0118, 'grad_norm': 5.000955104827881, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.005626368802040815, 'loss_2': 0.00614166259765625, 'loss_3': -16.33993148803711, 'loss_4': 1.6634231805801392, 'epoch': 22.17}
{'loss': 0.0066, 'grad_norm': 4.964722156524658, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.0059277694672346115, 'loss_2': 0.0006604194641113281, 'loss_3': -16.31832504272461, 'loss_4': 1.2146787643432617, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 10:58:13,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:13,566 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:03<23:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:20,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012558942660689354, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00800625141710043, 'eval_loss_2': 0.004552692174911499, 'eval_loss_3': -18.34512710571289, 'eval_loss_4': 1.0407441854476929, 'epoch': 22.18}
{'loss': 0.0131, 'grad_norm': 6.039342403411865, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.007773785386234522, 'loss_2': 0.005279541015625, 'loss_3': -16.398548126220703, 'loss_4': 1.6914260387420654, 'epoch': 22.19}
{'loss': 0.013, 'grad_norm': 5.809184551239014, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.00937487743794918, 'loss_2': 0.00365447998046875, 'loss_3': -16.50580596923828, 'loss_4': 1.559672474861145, 'epoch': 22.19}
{'loss': 0.0089, 'grad_norm': 4.889495372772217, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.004864367190748453, 'loss_2': 0.0040130615234375, 'loss_3': -16.46819305419922, 'loss_4': 1.193232774734497, 'epoch': 22.2}
{'loss': 0.0249, 'grad_norm': 8.485694885253906, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.013931061141192913, 'loss_2': 0.0109405517578125, 'loss_3': -16.544170379638672, 'loss_4': 1.3205204010009766, 'epoch': 22.2}
{'loss': 0.0089, 'grad_norm': 5.776463508605957, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.005035469774156809, 'loss_2': 0.003833770751953125, 'loss_3': -16.449840545654297, 'loss_4': 1.2007064819335938, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 10:58:20,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:20,914 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:10<23:24,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:58:28,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013053704053163528, 'eval_runtime': 4.0005, 'eval_samples_per_second': 255.968, 'eval_steps_per_second': 3.999, 'eval_loss_1': 0.008357930928468704, 'eval_loss_2': 0.004695773124694824, 'eval_loss_3': -18.33403778076172, 'eval_loss_4': 0.9562804698944092, 'epoch': 22.21}
{'loss': 0.0142, 'grad_norm': 5.925887584686279, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.009794363752007484, 'loss_2': 0.00435638427734375, 'loss_3': -16.583969116210938, 'loss_4': 1.3153523206710815, 'epoch': 22.22}
{'loss': 0.0098, 'grad_norm': 4.6363935470581055, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.0074822744354605675, 'loss_2': 0.00235748291015625, 'loss_3': -16.46570587158203, 'loss_4': 1.9958362579345703, 'epoch': 22.22}
{'loss': 0.0121, 'grad_norm': 5.347088813781738, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.00738102151080966, 'loss_2': 0.004741668701171875, 'loss_3': -16.49335479736328, 'loss_4': 1.2802046537399292, 'epoch': 22.23}
{'loss': 0.0097, 'grad_norm': 4.744503021240234, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.00709910225123167, 'loss_2': 0.002605438232421875, 'loss_3': -16.55683708190918, 'loss_4': 1.3770583868026733, 'epoch': 22.23}
{'loss': 0.014, 'grad_norm': 6.79622220993042, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.011437148787081242, 'loss_2': 0.002559661865234375, 'loss_3': -16.544727325439453, 'loss_4': 1.6523116827011108, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 10:58:28,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:28,458 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:17<23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:35,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012720629572868347, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.811, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008844808675348759, 'eval_loss_2': 0.003875821828842163, 'eval_loss_3': -18.3094425201416, 'eval_loss_4': 0.8448631763458252, 'epoch': 22.24}
{'loss': 0.0098, 'grad_norm': 5.288573265075684, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.006518335081636906, 'loss_2': 0.0032558441162109375, 'loss_3': -16.69503402709961, 'loss_4': 1.550645351409912, 'epoch': 22.24}
{'loss': 0.006, 'grad_norm': 4.261861324310303, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.004156113602221012, 'loss_2': 0.0018911361694335938, 'loss_3': -16.586265563964844, 'loss_4': 1.395419716835022, 'epoch': 22.25}
{'loss': 0.0103, 'grad_norm': 6.007978916168213, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.008563865907490253, 'loss_2': 0.0017642974853515625, 'loss_3': -16.3704891204834, 'loss_4': 1.4985554218292236, 'epoch': 22.26}
{'loss': 0.0166, 'grad_norm': 6.360428333282471, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.013123291544616222, 'loss_2': 0.0034694671630859375, 'loss_3': -16.335521697998047, 'loss_4': 1.5784575939178467, 'epoch': 22.26}
{'loss': 0.0077, 'grad_norm': 4.85676908493042, 'learning_rate': 7.75e-06, 'loss_1': 0.0035677833948284388, 'loss_2': 0.00408935546875, 'loss_3': -16.491363525390625, 'loss_4': 0.9725780487060547, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 10:58:35,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:35,809 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:25<22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:43,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012105638161301613, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.003, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009033644571900368, 'eval_loss_2': 0.003071993589401245, 'eval_loss_3': -18.303884506225586, 'eval_loss_4': 0.5867716073989868, 'epoch': 22.27}
{'loss': 0.0082, 'grad_norm': 5.483877658843994, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.007196189370006323, 'loss_2': 0.00098419189453125, 'loss_3': -16.35867691040039, 'loss_4': 1.061784029006958, 'epoch': 22.27}
{'loss': 0.0052, 'grad_norm': 4.556443691253662, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.004636683966964483, 'loss_2': 0.0005917549133300781, 'loss_3': -16.10924530029297, 'loss_4': 1.3994009494781494, 'epoch': 22.28}
{'loss': 0.0081, 'grad_norm': 4.8219804763793945, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.006651184521615505, 'loss_2': 0.0014142990112304688, 'loss_3': -16.39295196533203, 'loss_4': 0.9366720914840698, 'epoch': 22.28}
{'loss': 0.0179, 'grad_norm': 9.499496459960938, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.014753434807062149, 'loss_2': 0.003177642822265625, 'loss_3': -16.215991973876953, 'loss_4': 0.49316301941871643, 'epoch': 22.29}
{'loss': 0.0044, 'grad_norm': 4.529536247253418, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.0030313439201563597, 'loss_2': 0.001415252685546875, 'loss_3': -16.42333984375, 'loss_4': 0.39048823714256287, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 10:58:43,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:43,154 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:32<22:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:50,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011940831318497658, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00933311227709055, 'eval_loss_2': 0.0026077181100845337, 'eval_loss_3': -18.286766052246094, 'eval_loss_4': 0.4378897547721863, 'epoch': 22.3}
{'loss': 0.0033, 'grad_norm': 4.928864002227783, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.002961589489132166, 'loss_2': 0.0003681182861328125, 'loss_3': -16.19975471496582, 'loss_4': 1.1740604639053345, 'epoch': 22.3}
{'loss': 0.0079, 'grad_norm': 4.746232986450195, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.005317850038409233, 'loss_2': 0.0025463104248046875, 'loss_3': -16.43755340576172, 'loss_4': 0.708238959312439, 'epoch': 22.31}
{'loss': 0.0198, 'grad_norm': 14.207233428955078, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.019085125997662544, 'loss_2': 0.0006952285766601562, 'loss_3': -16.310321807861328, 'loss_4': 0.7965676188468933, 'epoch': 22.31}
{'loss': 0.0099, 'grad_norm': 4.069546699523926, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.003759041428565979, 'loss_2': 0.00618743896484375, 'loss_3': -16.32373046875, 'loss_4': 0.11341337859630585, 'epoch': 22.32}
{'loss': 0.0087, 'grad_norm': 4.792527198791504, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.005848913453519344, 'loss_2': 0.0028324127197265625, 'loss_3': -16.295217514038086, 'loss_4': 0.8021510243415833, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 10:58:50,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:50,505 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:40<22:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:57,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012109579518437386, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.001, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009283870458602905, 'eval_loss_2': 0.002825707197189331, 'eval_loss_3': -18.270206451416016, 'eval_loss_4': 0.4750198423862457, 'epoch': 22.33}
{'loss': 0.0084, 'grad_norm': 4.669310569763184, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.006077896803617477, 'loss_2': 0.002307891845703125, 'loss_3': -16.442737579345703, 'loss_4': 0.8076094388961792, 'epoch': 22.33}
{'loss': 0.0131, 'grad_norm': 4.43893575668335, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.005749392788857222, 'loss_2': 0.00734710693359375, 'loss_3': -16.360828399658203, 'loss_4': 0.7730368375778198, 'epoch': 22.34}
{'loss': 0.0186, 'grad_norm': 8.884088516235352, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.013402794487774372, 'loss_2': 0.00524139404296875, 'loss_3': -16.42209243774414, 'loss_4': 0.7901627421379089, 'epoch': 22.34}
{'loss': 0.0052, 'grad_norm': 5.226261615753174, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.005201681517064571, 'loss_2': 3.695487976074219e-05, 'loss_3': -16.351776123046875, 'loss_4': 0.859765350818634, 'epoch': 22.35}
{'loss': 0.0068, 'grad_norm': 4.925926685333252, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.004043754190206528, 'loss_2': 0.0027313232421875, 'loss_3': -16.32147979736328, 'loss_4': 0.27037015557289124, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 10:58:57,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:57,852 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:34:47<22:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:05,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011836917139589787, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.61, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009309173561632633, 'eval_loss_2': 0.0025277435779571533, 'eval_loss_3': -18.268028259277344, 'eval_loss_4': 0.5241403579711914, 'epoch': 22.35}
{'loss': 0.0172, 'grad_norm': 12.038172721862793, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.014415770769119263, 'loss_2': 0.00276947021484375, 'loss_3': -16.231393814086914, 'loss_4': 1.1587833166122437, 'epoch': 22.36}
{'loss': 0.006, 'grad_norm': 4.813328266143799, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.005289305001497269, 'loss_2': 0.0006971359252929688, 'loss_3': -16.326372146606445, 'loss_4': 0.8792885541915894, 'epoch': 22.37}
{'loss': 0.0077, 'grad_norm': 4.612505912780762, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.0027158341836184263, 'loss_2': 0.0049896240234375, 'loss_3': -16.426145553588867, 'loss_4': 0.7164092659950256, 'epoch': 22.37}
{'loss': 0.0086, 'grad_norm': 5.122303485870361, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.004210670478641987, 'loss_2': 0.0043792724609375, 'loss_3': -16.515710830688477, 'loss_4': 1.3360984325408936, 'epoch': 22.38}
{'loss': 0.0084, 'grad_norm': 5.08301305770874, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.004070655908435583, 'loss_2': 0.004302978515625, 'loss_3': -16.15706443786621, 'loss_4': 0.5956674814224243, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 10:59:05,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:05,192 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:34:54<22:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:12,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012077223509550095, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009432371705770493, 'eval_loss_2': 0.002644851803779602, 'eval_loss_3': -18.271841049194336, 'eval_loss_4': 0.5846703052520752, 'epoch': 22.38}
{'loss': 0.0092, 'grad_norm': 5.9227213859558105, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.007221383508294821, 'loss_2': 0.0019626617431640625, 'loss_3': -16.543758392333984, 'loss_4': 0.6266874074935913, 'epoch': 22.39}
{'loss': 0.0087, 'grad_norm': 5.065141201019287, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.005147146061062813, 'loss_2': 0.003536224365234375, 'loss_3': -16.39700698852539, 'loss_4': 0.5466241836547852, 'epoch': 22.4}
{'loss': 0.0112, 'grad_norm': 5.07985258102417, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.006967952940613031, 'loss_2': 0.00418853759765625, 'loss_3': -16.40411949157715, 'loss_4': 1.1565062999725342, 'epoch': 22.4}
{'loss': 0.0058, 'grad_norm': 4.915541648864746, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.003744106972590089, 'loss_2': 0.0020618438720703125, 'loss_3': -16.55378532409668, 'loss_4': 0.8626341819763184, 'epoch': 22.41}
{'loss': 0.0115, 'grad_norm': 6.4339118003845215, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.004280170425772667, 'loss_2': 0.0072021484375, 'loss_3': -16.421688079833984, 'loss_4': 0.5474402904510498, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 10:59:12,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:12,532 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:02<22:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:19,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012112969532608986, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009067034348845482, 'eval_loss_2': 0.003045935183763504, 'eval_loss_3': -18.278961181640625, 'eval_loss_4': 0.5568596720695496, 'epoch': 22.41}
{'loss': 0.022, 'grad_norm': 12.699074745178223, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.02038733847439289, 'loss_2': 0.0015697479248046875, 'loss_3': -16.23124122619629, 'loss_4': 0.71816086769104, 'epoch': 22.42}
{'loss': 0.0141, 'grad_norm': 4.511465072631836, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.004179832525551319, 'loss_2': 0.0098876953125, 'loss_3': -16.485271453857422, 'loss_4': 0.9663981199264526, 'epoch': 22.42}
{'loss': 0.0104, 'grad_norm': 4.519528865814209, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.0042160251177847385, 'loss_2': 0.00615692138671875, 'loss_3': -16.400470733642578, 'loss_4': 0.9692118167877197, 'epoch': 22.43}
{'loss': 0.0052, 'grad_norm': 4.381502151489258, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.0037475351709872484, 'loss_2': 0.0014667510986328125, 'loss_3': -16.437965393066406, 'loss_4': 1.259861707687378, 'epoch': 22.44}
{'loss': 0.0041, 'grad_norm': 4.545228958129883, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.0031898622401058674, 'loss_2': 0.0008974075317382812, 'loss_3': -16.223739624023438, 'loss_4': 1.2993208169937134, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 10:59:19,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:19,867 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:09<22:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:27,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011664965189993382, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009107233956456184, 'eval_loss_2': 0.0025577321648597717, 'eval_loss_3': -18.274913787841797, 'eval_loss_4': 0.5095969438552856, 'epoch': 22.44}
{'loss': 0.0084, 'grad_norm': 4.9640793800354, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.0025288178585469723, 'loss_2': 0.0058746337890625, 'loss_3': -16.407329559326172, 'loss_4': 0.7317589521408081, 'epoch': 22.45}
{'loss': 0.0198, 'grad_norm': 8.939247131347656, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.01802101545035839, 'loss_2': 0.001800537109375, 'loss_3': -16.41081428527832, 'loss_4': 1.0102609395980835, 'epoch': 22.45}
{'loss': 0.0115, 'grad_norm': 6.94993782043457, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.009184128604829311, 'loss_2': 0.00235748291015625, 'loss_3': -16.373252868652344, 'loss_4': 0.7863504886627197, 'epoch': 22.46}
{'loss': 0.0109, 'grad_norm': 4.567215442657471, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.004926374182105064, 'loss_2': 0.005950927734375, 'loss_3': -16.302024841308594, 'loss_4': 1.022233486175537, 'epoch': 22.47}
{'loss': 0.0096, 'grad_norm': 4.555614948272705, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.004025465343147516, 'loss_2': 0.0055694580078125, 'loss_3': -16.356069564819336, 'loss_4': 0.9002277255058289, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 10:59:27,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:27,202 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:16<22:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:34,544 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011562182568013668, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008983738720417023, 'eval_loss_2': 0.00257844477891922, 'eval_loss_3': -18.275558471679688, 'eval_loss_4': 0.5012142658233643, 'epoch': 22.47}
{'loss': 0.0072, 'grad_norm': 4.537734508514404, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.004484015982598066, 'loss_2': 0.00270843505859375, 'loss_3': -16.4357967376709, 'loss_4': 0.48407065868377686, 'epoch': 22.48}
{'loss': 0.0067, 'grad_norm': 5.189995765686035, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.0044888840056955814, 'loss_2': 0.0022182464599609375, 'loss_3': -16.025909423828125, 'loss_4': 0.6610865592956543, 'epoch': 22.48}
{'loss': 0.0132, 'grad_norm': 6.973210334777832, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.012820462696254253, 'loss_2': 0.00036716461181640625, 'loss_3': -16.174205780029297, 'loss_4': 1.098588466644287, 'epoch': 22.49}
{'loss': 0.0088, 'grad_norm': 5.4027533531188965, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.006419994868338108, 'loss_2': 0.0024261474609375, 'loss_3': -16.155906677246094, 'loss_4': 0.4922142028808594, 'epoch': 22.49}
{'loss': 0.0083, 'grad_norm': 7.7964935302734375, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.004740481730550528, 'loss_2': 0.003528594970703125, 'loss_3': -16.473461151123047, 'loss_4': 0.45777076482772827, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 10:59:34,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:34,544 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:24<22:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:41,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013409174978733063, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01030243095010519, 'eval_loss_2': 0.003106743097305298, 'eval_loss_3': -18.26796531677246, 'eval_loss_4': 0.5387570858001709, 'epoch': 22.5}
{'loss': 0.0155, 'grad_norm': 9.877179145812988, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.010397716425359249, 'loss_2': 0.00505828857421875, 'loss_3': -16.01971435546875, 'loss_4': 0.9315797686576843, 'epoch': 22.51}
{'loss': 0.009, 'grad_norm': 4.988941192626953, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.005473657511174679, 'loss_2': 0.003536224365234375, 'loss_3': -16.21532440185547, 'loss_4': 1.1718525886535645, 'epoch': 22.51}
{'loss': 0.0085, 'grad_norm': 4.706765651702881, 'learning_rate': 7.5e-06, 'loss_1': 0.006047684233635664, 'loss_2': 0.0024776458740234375, 'loss_3': -16.307783126831055, 'loss_4': 0.689873218536377, 'epoch': 22.52}
{'loss': 0.016, 'grad_norm': 5.992514610290527, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.009830658324062824, 'loss_2': 0.00616455078125, 'loss_3': -16.305145263671875, 'loss_4': 0.7826030254364014, 'epoch': 22.52}
{'loss': 0.0176, 'grad_norm': 7.408370494842529, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.010148131288588047, 'loss_2': 0.0074920654296875, 'loss_3': -16.103906631469727, 'loss_4': 0.9953498244285583, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 10:59:41,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:41,890 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:31<22:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:49,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014009378850460052, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010482311248779297, 'eval_loss_2': 0.0035270676016807556, 'eval_loss_3': -18.260608673095703, 'eval_loss_4': 0.5626242756843567, 'epoch': 22.53}
{'loss': 0.0057, 'grad_norm': 4.446826934814453, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.004037695471197367, 'loss_2': 0.0016832351684570312, 'loss_3': -16.47222900390625, 'loss_4': 0.8706652522087097, 'epoch': 22.53}
{'loss': 0.0098, 'grad_norm': 7.043111801147461, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.008982643485069275, 'loss_2': 0.0008335113525390625, 'loss_3': -16.274394989013672, 'loss_4': 1.3235772848129272, 'epoch': 22.54}
{'loss': 0.017, 'grad_norm': 7.912056922912598, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.014443274587392807, 'loss_2': 0.002552032470703125, 'loss_3': -16.381717681884766, 'loss_4': 0.5819243788719177, 'epoch': 22.55}
{'loss': 0.0074, 'grad_norm': 6.073042869567871, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.006184179335832596, 'loss_2': 0.0012235641479492188, 'loss_3': -16.451641082763672, 'loss_4': 1.127507209777832, 'epoch': 22.55}
{'loss': 0.0062, 'grad_norm': 4.421467304229736, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.00568401301279664, 'loss_2': 0.0005435943603515625, 'loss_3': -16.272415161132812, 'loss_4': 0.7385322451591492, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 10:59:49,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:49,236 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:38<22:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:56,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014477373100817204, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010267496109008789, 'eval_loss_2': 0.00420987606048584, 'eval_loss_3': -18.261463165283203, 'eval_loss_4': 0.5609999895095825, 'epoch': 22.56}
{'loss': 0.0083, 'grad_norm': 4.88585901260376, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.00339171988889575, 'loss_2': 0.00494384765625, 'loss_3': -16.3165283203125, 'loss_4': 0.1332131028175354, 'epoch': 22.56}
{'loss': 0.0159, 'grad_norm': 5.4197587966918945, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.010692352429032326, 'loss_2': 0.005199432373046875, 'loss_3': -16.07398223876953, 'loss_4': 0.4145994782447815, 'epoch': 22.57}
{'loss': 0.0066, 'grad_norm': 5.173549175262451, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.005973106250166893, 'loss_2': 0.0006098747253417969, 'loss_3': -16.32884979248047, 'loss_4': 0.9244499206542969, 'epoch': 22.58}
{'loss': 0.0067, 'grad_norm': 5.0691046714782715, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.004347724374383688, 'loss_2': 0.0024013519287109375, 'loss_3': -16.21415901184082, 'loss_4': 0.2679584324359894, 'epoch': 22.58}
{'loss': 0.0149, 'grad_norm': 5.652121543884277, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.008038034662604332, 'loss_2': 0.00685882568359375, 'loss_3': -16.155925750732422, 'loss_4': 0.6722264289855957, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 10:59:56,578 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:56,578 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:35:46<21:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:03,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014454375952482224, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.699, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010342131368815899, 'eval_loss_2': 0.00411224365234375, 'eval_loss_3': -18.257150650024414, 'eval_loss_4': 0.63113933801651, 'epoch': 22.59}
{'loss': 0.0088, 'grad_norm': 4.745087623596191, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.0027422693092375994, 'loss_2': 0.00601959228515625, 'loss_3': -16.264389038085938, 'loss_4': 0.9822461605072021, 'epoch': 22.59}
{'loss': 0.0167, 'grad_norm': 10.223045349121094, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.009219960309565067, 'loss_2': 0.007476806640625, 'loss_3': -16.334003448486328, 'loss_4': 1.0227184295654297, 'epoch': 22.6}
{'loss': 0.0061, 'grad_norm': 5.579531669616699, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.004534498322755098, 'loss_2': 0.0016031265258789062, 'loss_3': -16.291221618652344, 'loss_4': 0.6561859846115112, 'epoch': 22.6}
{'loss': 0.0033, 'grad_norm': 4.831502914428711, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.0031836514826864004, 'loss_2': 0.00012230873107910156, 'loss_3': -16.31669807434082, 'loss_4': 1.063307285308838, 'epoch': 22.61}
{'loss': 0.0071, 'grad_norm': 5.469397068023682, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.004361034836620092, 'loss_2': 0.002716064453125, 'loss_3': -16.395061492919922, 'loss_4': 1.249236822128296, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 11:00:03,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:03,917 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:35:53<21:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:11,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01359698735177517, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.448, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010381479747593403, 'eval_loss_2': 0.003215506672859192, 'eval_loss_3': -18.23811149597168, 'eval_loss_4': 0.7002528309822083, 'epoch': 22.62}
{'loss': 0.0035, 'grad_norm': 4.292881488800049, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.0030889157205820084, 'loss_2': 0.0004048347473144531, 'loss_3': -16.424030303955078, 'loss_4': 1.6230790615081787, 'epoch': 22.62}
{'loss': 0.0159, 'grad_norm': 4.767266750335693, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.005270280875265598, 'loss_2': 0.0106353759765625, 'loss_3': -16.22645378112793, 'loss_4': 0.8011361360549927, 'epoch': 22.63}
{'loss': 0.011, 'grad_norm': 4.602185249328613, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.0051267556846141815, 'loss_2': 0.005878448486328125, 'loss_3': -16.150558471679688, 'loss_4': 0.7245638966560364, 'epoch': 22.63}
{'loss': 0.0205, 'grad_norm': 7.802383899688721, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.010059744119644165, 'loss_2': 0.01039886474609375, 'loss_3': -16.389476776123047, 'loss_4': 0.6135827898979187, 'epoch': 22.64}
{'loss': 0.0036, 'grad_norm': 4.568295478820801, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.0033284462988376617, 'loss_2': 0.0002894401550292969, 'loss_3': -16.22728729248047, 'loss_4': 1.1432727575302124, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 11:00:11,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:11,267 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:00<21:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:18,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014293909072875977, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01074275467544794, 'eval_loss_2': 0.0035511553287506104, 'eval_loss_3': -18.242639541625977, 'eval_loss_4': 0.7550191879272461, 'epoch': 22.65}
{'loss': 0.0152, 'grad_norm': 5.473335266113281, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.0051267025992274284, 'loss_2': 0.0100250244140625, 'loss_3': -16.30423927307129, 'loss_4': 0.878555953502655, 'epoch': 22.65}
{'loss': 0.0157, 'grad_norm': 5.611146926879883, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.009476078674197197, 'loss_2': 0.0061798095703125, 'loss_3': -16.297775268554688, 'loss_4': 1.1149661540985107, 'epoch': 22.66}
{'loss': 0.0202, 'grad_norm': 7.3738484382629395, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.018618499860167503, 'loss_2': 0.001613616943359375, 'loss_3': -16.291702270507812, 'loss_4': 1.0087883472442627, 'epoch': 22.66}
{'loss': 0.0078, 'grad_norm': 4.202117919921875, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.002508761128410697, 'loss_2': 0.0052490234375, 'loss_3': -16.497718811035156, 'loss_4': 0.9118809700012207, 'epoch': 22.67}
{'loss': 0.0153, 'grad_norm': 7.218975067138672, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.012765483930706978, 'loss_2': 0.002529144287109375, 'loss_3': -16.277999877929688, 'loss_4': 1.8221228122711182, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 11:00:18,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:18,616 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:08<21:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:25,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014978257939219475, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.386, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011053098365664482, 'eval_loss_2': 0.003925159573554993, 'eval_loss_3': -18.24484634399414, 'eval_loss_4': 0.9118593335151672, 'epoch': 22.67}
{'loss': 0.0047, 'grad_norm': 4.62180233001709, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.004124146420508623, 'loss_2': 0.0005998611450195312, 'loss_3': -16.2507381439209, 'loss_4': 1.5491530895233154, 'epoch': 22.68}
{'loss': 0.0127, 'grad_norm': 7.532263278961182, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.010466856881976128, 'loss_2': 0.0022125244140625, 'loss_3': -16.241436004638672, 'loss_4': 1.3626153469085693, 'epoch': 22.69}
{'loss': 0.0147, 'grad_norm': 8.042516708374023, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.013459843583405018, 'loss_2': 0.0012187957763671875, 'loss_3': -16.551116943359375, 'loss_4': 1.781545877456665, 'epoch': 22.69}
{'loss': 0.0138, 'grad_norm': 4.749462127685547, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.005905968137085438, 'loss_2': 0.0078582763671875, 'loss_3': -16.248336791992188, 'loss_4': 1.578520655632019, 'epoch': 22.7}
{'loss': 0.0124, 'grad_norm': 4.965224266052246, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.004771001636981964, 'loss_2': 0.007595062255859375, 'loss_3': -16.441051483154297, 'loss_4': 1.7709388732910156, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 11:00:25,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:25,954 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:15<21:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:33,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014097560197114944, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010803150944411755, 'eval_loss_2': 0.0032944083213806152, 'eval_loss_3': -18.239839553833008, 'eval_loss_4': 1.1525508165359497, 'epoch': 22.7}
{'loss': 0.0084, 'grad_norm': 6.0366339683532715, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.005486277397722006, 'loss_2': 0.002872467041015625, 'loss_3': -16.209022521972656, 'loss_4': 1.5398452281951904, 'epoch': 22.71}
{'loss': 0.0068, 'grad_norm': 5.344293117523193, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.0034539978951215744, 'loss_2': 0.003387451171875, 'loss_3': -16.251724243164062, 'loss_4': 1.1083431243896484, 'epoch': 22.72}
{'loss': 0.0074, 'grad_norm': 36.21125411987305, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.00626888033002615, 'loss_2': 0.0011129379272460938, 'loss_3': -16.264991760253906, 'loss_4': 1.4645891189575195, 'epoch': 22.72}
{'loss': 0.0066, 'grad_norm': 4.843632698059082, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.00379903893917799, 'loss_2': 0.002849578857421875, 'loss_3': -16.216428756713867, 'loss_4': 1.2406790256500244, 'epoch': 22.73}
{'loss': 0.003, 'grad_norm': 4.529617786407471, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.002795254113152623, 'loss_2': 0.00021409988403320312, 'loss_3': -16.340984344482422, 'loss_4': 1.4193289279937744, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 11:00:33,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:33,292 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:22<21:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:40,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0136675164103508, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.615, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010758907534182072, 'eval_loss_2': 0.0029086098074913025, 'eval_loss_3': -18.244874954223633, 'eval_loss_4': 1.2609598636627197, 'epoch': 22.73}
{'loss': 0.0241, 'grad_norm': 14.864340782165527, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.019895970821380615, 'loss_2': 0.004154205322265625, 'loss_3': -16.329421997070312, 'loss_4': 1.445738434791565, 'epoch': 22.74}
{'loss': 0.0081, 'grad_norm': 4.853237152099609, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.003877802984789014, 'loss_2': 0.00418853759765625, 'loss_3': -16.439247131347656, 'loss_4': 1.4539251327514648, 'epoch': 22.74}
{'loss': 0.028, 'grad_norm': 12.5162935256958, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.02191808819770813, 'loss_2': 0.00612640380859375, 'loss_3': -16.07375144958496, 'loss_4': 1.5805997848510742, 'epoch': 22.75}
{'loss': 0.0065, 'grad_norm': 4.1808905601501465, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.002681941958144307, 'loss_2': 0.003787994384765625, 'loss_3': -16.324792861938477, 'loss_4': 0.7449239492416382, 'epoch': 22.76}
{'loss': 0.0063, 'grad_norm': 5.227348804473877, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.006088166031986475, 'loss_2': 0.00019931793212890625, 'loss_3': -16.48858642578125, 'loss_4': 1.5234977006912231, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 11:00:40,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:40,630 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:30<21:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:47,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014059378765523434, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010745514184236526, 'eval_loss_2': 0.003313865512609482, 'eval_loss_3': -18.268447875976562, 'eval_loss_4': 1.29478919506073, 'epoch': 22.76}
{'loss': 0.0074, 'grad_norm': 5.395846843719482, 'learning_rate': 7.25e-06, 'loss_1': 0.00508436793461442, 'loss_2': 0.0022792816162109375, 'loss_3': -16.242107391357422, 'loss_4': 1.314579963684082, 'epoch': 22.77}
{'loss': 0.0216, 'grad_norm': 9.822546005249023, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.012030284851789474, 'loss_2': 0.009552001953125, 'loss_3': -16.378875732421875, 'loss_4': 1.8926138877868652, 'epoch': 22.77}
{'loss': 0.0077, 'grad_norm': 5.0799994468688965, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.005776088684797287, 'loss_2': 0.0019054412841796875, 'loss_3': -16.38892364501953, 'loss_4': 1.1843228340148926, 'epoch': 22.78}
{'loss': 0.0056, 'grad_norm': 4.547678470611572, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.0033052759245038033, 'loss_2': 0.002300262451171875, 'loss_3': -16.329689025878906, 'loss_4': 1.6801458597183228, 'epoch': 22.78}
{'loss': 0.0073, 'grad_norm': 4.655585289001465, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.002611517207697034, 'loss_2': 0.00464630126953125, 'loss_3': -16.37512969970703, 'loss_4': 1.5085614919662476, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 11:00:47,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:47,980 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:37<21:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:55,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014495114795863628, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01105989795178175, 'eval_loss_2': 0.0034352168440818787, 'eval_loss_3': -18.275781631469727, 'eval_loss_4': 1.3507823944091797, 'epoch': 22.79}
{'loss': 0.028, 'grad_norm': 8.363178253173828, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.022560758516192436, 'loss_2': 0.0054168701171875, 'loss_3': -16.63899040222168, 'loss_4': 2.3258066177368164, 'epoch': 22.8}
{'loss': 0.0066, 'grad_norm': 4.917849063873291, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.003733227960765362, 'loss_2': 0.0029087066650390625, 'loss_3': -16.392229080200195, 'loss_4': 1.6716325283050537, 'epoch': 22.8}
{'loss': 0.0084, 'grad_norm': 6.762011528015137, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.006703546736389399, 'loss_2': 0.0017070770263671875, 'loss_3': -16.398401260375977, 'loss_4': 1.4623249769210815, 'epoch': 22.81}
{'loss': 0.0083, 'grad_norm': 5.171606540679932, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.008127066306769848, 'loss_2': 0.00020062923431396484, 'loss_3': -16.233654022216797, 'loss_4': 1.3366217613220215, 'epoch': 22.81}
{'loss': 0.0059, 'grad_norm': 4.900516033172607, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.0034145719837397337, 'loss_2': 0.00250244140625, 'loss_3': -16.359487533569336, 'loss_4': 1.746603012084961, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 11:00:55,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:55,330 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:36:44<21:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:02,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01321217231452465, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010518727824091911, 'eval_loss_2': 0.0026934444904327393, 'eval_loss_3': -18.26738739013672, 'eval_loss_4': 1.3704466819763184, 'epoch': 22.82}
{'loss': 0.0198, 'grad_norm': 11.00442123413086, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.017821839079260826, 'loss_2': 0.0019989013671875, 'loss_3': -16.248779296875, 'loss_4': 1.9895691871643066, 'epoch': 22.83}
{'loss': 0.0174, 'grad_norm': 8.797205924987793, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.015411833301186562, 'loss_2': 0.0019817352294921875, 'loss_3': -16.264507293701172, 'loss_4': 2.2807536125183105, 'epoch': 22.83}
{'loss': 0.009, 'grad_norm': 4.88091516494751, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.004605784080922604, 'loss_2': 0.0044403076171875, 'loss_3': -16.29083251953125, 'loss_4': 1.860952615737915, 'epoch': 22.84}
{'loss': 0.0185, 'grad_norm': 12.188420295715332, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.010606784373521805, 'loss_2': 0.00785064697265625, 'loss_3': -16.19515609741211, 'loss_4': 1.6501471996307373, 'epoch': 22.84}
{'loss': 0.007, 'grad_norm': 4.723958969116211, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.002115810289978981, 'loss_2': 0.004848480224609375, 'loss_3': -16.379589080810547, 'loss_4': 1.1418280601501465, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 11:01:02,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:02,676 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:36:52<21:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:10,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013010846450924873, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010681495070457458, 'eval_loss_2': 0.0023293495178222656, 'eval_loss_3': -18.254840850830078, 'eval_loss_4': 1.3804714679718018, 'epoch': 22.85}
{'loss': 0.007, 'grad_norm': 5.1094560623168945, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.0033872234635055065, 'loss_2': 0.003627777099609375, 'loss_3': -16.367919921875, 'loss_4': 1.6585203409194946, 'epoch': 22.85}
{'loss': 0.0122, 'grad_norm': 5.743287563323975, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.006314882077276707, 'loss_2': 0.005886077880859375, 'loss_3': -16.38273048400879, 'loss_4': 1.346705436706543, 'epoch': 22.86}
{'loss': 0.0055, 'grad_norm': 4.715078353881836, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.004125204402953386, 'loss_2': 0.0013570785522460938, 'loss_3': -16.204683303833008, 'loss_4': 1.8203763961791992, 'epoch': 22.87}
{'loss': 0.0187, 'grad_norm': 6.811206340789795, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.009580656886100769, 'loss_2': 0.0090789794921875, 'loss_3': -16.227842330932617, 'loss_4': 1.8511344194412231, 'epoch': 22.87}
{'loss': 0.0056, 'grad_norm': 5.188030242919922, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.004974485374987125, 'loss_2': 0.0006461143493652344, 'loss_3': -16.19601821899414, 'loss_4': 1.1790165901184082, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 11:01:10,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:10,012 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:36:59<21:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:17,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013580052182078362, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.329, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009927164763212204, 'eval_loss_2': 0.0036528855562210083, 'eval_loss_3': -18.25616455078125, 'eval_loss_4': 1.3034470081329346, 'epoch': 22.88}
{'loss': 0.0065, 'grad_norm': 4.671388626098633, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.005009089130908251, 'loss_2': 0.001453399658203125, 'loss_3': -16.418119430541992, 'loss_4': 1.112748384475708, 'epoch': 22.88}
{'loss': 0.0047, 'grad_norm': 4.8344407081604, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.004366363864392042, 'loss_2': 0.0003490447998046875, 'loss_3': -16.41156768798828, 'loss_4': 1.4303629398345947, 'epoch': 22.89}
{'loss': 0.0074, 'grad_norm': 4.799859046936035, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.0026341238990426064, 'loss_2': 0.00476837158203125, 'loss_3': -16.313907623291016, 'loss_4': 1.4624550342559814, 'epoch': 22.9}
{'loss': 0.0099, 'grad_norm': 5.531375885009766, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.00611375505104661, 'loss_2': 0.003803253173828125, 'loss_3': -16.19192123413086, 'loss_4': 1.3576277494430542, 'epoch': 22.9}
{'loss': 0.0039, 'grad_norm': 4.851693153381348, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.0022992300800979137, 'loss_2': 0.0015840530395507812, 'loss_3': -16.38228416442871, 'loss_4': 1.4270083904266357, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 11:01:17,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:17,356 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:06<20:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:24,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012365911155939102, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009762016125023365, 'eval_loss_2': 0.0026038959622383118, 'eval_loss_3': -18.266895294189453, 'eval_loss_4': 1.199147343635559, 'epoch': 22.91}
{'loss': 0.0048, 'grad_norm': 4.690087795257568, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.0029953885823488235, 'loss_2': 0.0018367767333984375, 'loss_3': -16.350605010986328, 'loss_4': 1.477128505706787, 'epoch': 22.91}
{'loss': 0.0052, 'grad_norm': 4.749941825866699, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.003079791786149144, 'loss_2': 0.0021533966064453125, 'loss_3': -16.492815017700195, 'loss_4': 1.4145729541778564, 'epoch': 22.92}
{'loss': 0.005, 'grad_norm': 5.393889904022217, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.0034995523747056723, 'loss_2': 0.0015411376953125, 'loss_3': -16.425262451171875, 'loss_4': 1.1258090734481812, 'epoch': 22.92}
{'loss': 0.0077, 'grad_norm': 5.342966079711914, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.0064089130610227585, 'loss_2': 0.0013065338134765625, 'loss_3': -16.298568725585938, 'loss_4': 1.560255765914917, 'epoch': 22.93}
{'loss': 0.0032, 'grad_norm': 4.646021842956543, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.0027634177822619677, 'loss_2': 0.00041294097900390625, 'loss_3': -16.375839233398438, 'loss_4': 1.683370590209961, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 11:01:24,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:24,696 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:14<20:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:32,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014225143007934093, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009413677267730236, 'eval_loss_2': 0.004811465740203857, 'eval_loss_3': -18.259246826171875, 'eval_loss_4': 1.1726998090744019, 'epoch': 22.94}
{'loss': 0.0086, 'grad_norm': 4.3096466064453125, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.0022467756643891335, 'loss_2': 0.006336212158203125, 'loss_3': -16.405672073364258, 'loss_4': 1.4581294059753418, 'epoch': 22.94}
{'loss': 0.0137, 'grad_norm': 4.767378330230713, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.0019849881064146757, 'loss_2': 0.01171875, 'loss_3': -16.320032119750977, 'loss_4': 2.105203151702881, 'epoch': 22.95}
{'loss': 0.0065, 'grad_norm': 5.143561363220215, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.003321239957585931, 'loss_2': 0.003162384033203125, 'loss_3': -16.334623336791992, 'loss_4': 1.475278377532959, 'epoch': 22.95}
{'loss': 0.0068, 'grad_norm': 6.246267318725586, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.006076878868043423, 'loss_2': 0.0007228851318359375, 'loss_3': -16.588424682617188, 'loss_4': 1.7205835580825806, 'epoch': 22.96}
{'loss': 0.0049, 'grad_norm': 4.5704345703125, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.0030165344942361116, 'loss_2': 0.00186920166015625, 'loss_3': -16.259750366210938, 'loss_4': 1.067439079284668, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 11:01:32,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:32,038 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:21<20:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:01:39,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015704190358519554, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.965, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009684449061751366, 'eval_loss_2': 0.0060197412967681885, 'eval_loss_3': -18.26824951171875, 'eval_loss_4': 1.1539002656936646, 'epoch': 22.97}
{'loss': 0.0248, 'grad_norm': 12.599759101867676, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.01597258634865284, 'loss_2': 0.00884246826171875, 'loss_3': -16.430086135864258, 'loss_4': 1.1845457553863525, 'epoch': 22.97}
{'loss': 0.0177, 'grad_norm': 5.144312381744385, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.0054218098521232605, 'loss_2': 0.01226043701171875, 'loss_3': -16.431921005249023, 'loss_4': 1.8699219226837158, 'epoch': 22.98}
{'loss': 0.0079, 'grad_norm': 4.716060638427734, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.0044364542700350285, 'loss_2': 0.003513336181640625, 'loss_3': -16.372365951538086, 'loss_4': 1.5624330043792725, 'epoch': 22.98}
{'loss': 0.009, 'grad_norm': 5.3193159103393555, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.00779703026637435, 'loss_2': 0.0012369155883789062, 'loss_3': -16.161540985107422, 'loss_4': 1.7941672801971436, 'epoch': 22.99}
{'loss': 0.0084, 'grad_norm': 5.401659965515137, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.003821943886578083, 'loss_2': 0.00461578369140625, 'loss_3': -16.314105987548828, 'loss_4': 1.8052728176116943, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 11:01:39,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:39,370 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:28<20:21,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:01:46,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013696766458451748, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.661, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009366041049361229, 'eval_loss_2': 0.004330724477767944, 'eval_loss_3': -18.263904571533203, 'eval_loss_4': 1.2572195529937744, 'epoch': 22.99}
{'loss': 0.0038, 'grad_norm': 6.206665515899658, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.0009383361903019249, 'loss_2': 0.002887725830078125, 'loss_3': -16.18734359741211, 'loss_4': 2.08038330078125, 'epoch': 23.0}
{'loss': 0.0054, 'grad_norm': 4.31378173828125, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.0035090686287730932, 'loss_2': 0.0019168853759765625, 'loss_3': -16.42001724243164, 'loss_4': 1.2066584825515747, 'epoch': 23.01}
{'loss': 0.025, 'grad_norm': 7.259109973907471, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.01764499582350254, 'loss_2': 0.00737762451171875, 'loss_3': -16.502872467041016, 'loss_4': 2.0672805309295654, 'epoch': 23.01}
{'loss': 0.0074, 'grad_norm': 4.439831733703613, 'learning_rate': 7e-06, 'loss_1': 0.002743619028478861, 'loss_2': 0.00461578369140625, 'loss_3': -16.470500946044922, 'loss_4': 1.5114777088165283, 'epoch': 23.02}
{'loss': 0.0085, 'grad_norm': 4.802641868591309, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.0043125939555466175, 'loss_2': 0.004161834716796875, 'loss_3': -16.312915802001953, 'loss_4': 2.064361572265625, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 11:01:46,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:46,432 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:35<20:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:01:53,775 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012880164198577404, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009257587604224682, 'eval_loss_2': 0.003622576594352722, 'eval_loss_3': -18.271800994873047, 'eval_loss_4': 1.4280928373336792, 'epoch': 23.02}
{'loss': 0.0225, 'grad_norm': 7.161799430847168, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.015065492130815983, 'loss_2': 0.007415771484375, 'loss_3': -16.322948455810547, 'loss_4': 1.537212610244751, 'epoch': 23.03}
{'loss': 0.0099, 'grad_norm': 5.0914106369018555, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.005308548454195261, 'loss_2': 0.0045928955078125, 'loss_3': -16.270347595214844, 'loss_4': 1.838059425354004, 'epoch': 23.03}
{'loss': 0.0095, 'grad_norm': 5.022656440734863, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.0039030443876981735, 'loss_2': 0.005565643310546875, 'loss_3': -16.443115234375, 'loss_4': 1.560518503189087, 'epoch': 23.04}
{'loss': 0.0072, 'grad_norm': 4.957605361938477, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.004415809642523527, 'loss_2': 0.0027713775634765625, 'loss_3': -16.273780822753906, 'loss_4': 1.8565843105316162, 'epoch': 23.05}
{'loss': 0.0041, 'grad_norm': 4.631466865539551, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.003964771516621113, 'loss_2': 9.322166442871094e-05, 'loss_3': -16.167024612426758, 'loss_4': 1.6220052242279053, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 11:01:53,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:53,776 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:43<20:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:01,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013234434649348259, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.5, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00933018233627081, 'eval_loss_2': 0.0039042532444000244, 'eval_loss_3': -18.25946807861328, 'eval_loss_4': 1.543906569480896, 'epoch': 23.05}
{'loss': 0.018, 'grad_norm': 4.914703845977783, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.005085577256977558, 'loss_2': 0.012939453125, 'loss_3': -16.458786010742188, 'loss_4': 1.3561750650405884, 'epoch': 23.06}
{'loss': 0.012, 'grad_norm': 5.92819881439209, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.0078900046646595, 'loss_2': 0.004077911376953125, 'loss_3': -16.468372344970703, 'loss_4': 1.6375129222869873, 'epoch': 23.06}
{'loss': 0.0074, 'grad_norm': 4.929389953613281, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.004217041190713644, 'loss_2': 0.00316619873046875, 'loss_3': -16.398801803588867, 'loss_4': 1.6599223613739014, 'epoch': 23.07}
{'loss': 0.0126, 'grad_norm': 5.843024253845215, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.007298975717276335, 'loss_2': 0.00525665283203125, 'loss_3': -16.344579696655273, 'loss_4': 2.157849073410034, 'epoch': 23.08}
{'loss': 0.0062, 'grad_norm': 4.961731910705566, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.005776031408458948, 'loss_2': 0.0004506111145019531, 'loss_3': -16.30215835571289, 'loss_4': 1.5700960159301758, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 11:02:01,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:01,120 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:37:50<20:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:08,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014184363186359406, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010144360363483429, 'eval_loss_2': 0.0040400028228759766, 'eval_loss_3': -18.24880027770996, 'eval_loss_4': 1.5212570428848267, 'epoch': 23.08}
{'loss': 0.0044, 'grad_norm': 4.737792015075684, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.0037746443413197994, 'loss_2': 0.0006594657897949219, 'loss_3': -16.35395050048828, 'loss_4': 1.7915936708450317, 'epoch': 23.09}
{'loss': 0.0164, 'grad_norm': 6.259707927703857, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.010349618270993233, 'loss_2': 0.0060882568359375, 'loss_3': -16.21866226196289, 'loss_4': 1.8149619102478027, 'epoch': 23.09}
{'loss': 0.0038, 'grad_norm': 4.619164943695068, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.0030786991119384766, 'loss_2': 0.000720977783203125, 'loss_3': -16.392189025878906, 'loss_4': 1.35854971408844, 'epoch': 23.1}
{'loss': 0.0057, 'grad_norm': 4.1978888511657715, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.0031470118556171656, 'loss_2': 0.002536773681640625, 'loss_3': -16.440959930419922, 'loss_4': 1.8670282363891602, 'epoch': 23.1}
{'loss': 0.0087, 'grad_norm': 4.827966690063477, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.0026980778202414513, 'loss_2': 0.0059967041015625, 'loss_3': -16.3127498626709, 'loss_4': 1.4599733352661133, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 11:02:08,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:08,470 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:37:57<20:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:15,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01349548064172268, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.252, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010573899373412132, 'eval_loss_2': 0.002921581268310547, 'eval_loss_3': -18.24930763244629, 'eval_loss_4': 1.473745584487915, 'epoch': 23.11}
{'loss': 0.0044, 'grad_norm': 4.401973724365234, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.0034086464438587427, 'loss_2': 0.001033782958984375, 'loss_3': -16.372665405273438, 'loss_4': 1.7641236782073975, 'epoch': 23.12}
{'loss': 0.0099, 'grad_norm': 5.297422409057617, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.003997069783508778, 'loss_2': 0.00594329833984375, 'loss_3': -16.4930477142334, 'loss_4': 1.9989882707595825, 'epoch': 23.12}
{'loss': 0.0034, 'grad_norm': 4.603692054748535, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.0028406106866896152, 'loss_2': 0.0005464553833007812, 'loss_3': -16.375646591186523, 'loss_4': 1.512092113494873, 'epoch': 23.13}
{'loss': 0.0117, 'grad_norm': 4.939716815948486, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.006583693902939558, 'loss_2': 0.005096435546875, 'loss_3': -16.36870765686035, 'loss_4': 2.0549449920654297, 'epoch': 23.13}
{'loss': 0.0202, 'grad_norm': 7.187368869781494, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.012293296866118908, 'loss_2': 0.0079345703125, 'loss_3': -16.159435272216797, 'loss_4': 1.7913563251495361, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 11:02:15,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:15,813 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:05<20:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:23,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015125063247978687, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.624, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011117654852569103, 'eval_loss_2': 0.004007406532764435, 'eval_loss_3': -18.26519775390625, 'eval_loss_4': 1.4591432809829712, 'epoch': 23.14}
{'loss': 0.014, 'grad_norm': 5.798057556152344, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.011662977747619152, 'loss_2': 0.0023860931396484375, 'loss_3': -16.330902099609375, 'loss_4': 1.1283010244369507, 'epoch': 23.15}
{'loss': 0.0128, 'grad_norm': 4.902271747589111, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.003436662955209613, 'loss_2': 0.00937652587890625, 'loss_3': -16.422346115112305, 'loss_4': 2.7278189659118652, 'epoch': 23.15}
{'loss': 0.0104, 'grad_norm': 5.095331192016602, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.005111949052661657, 'loss_2': 0.00525665283203125, 'loss_3': -16.22390365600586, 'loss_4': 1.7823559045791626, 'epoch': 23.16}
{'loss': 0.0064, 'grad_norm': 6.959707260131836, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.00593130337074399, 'loss_2': 0.00041961669921875, 'loss_3': -16.45238494873047, 'loss_4': 1.96928870677948, 'epoch': 23.16}
{'loss': 0.0143, 'grad_norm': 6.91667366027832, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.009331364184617996, 'loss_2': 0.00498199462890625, 'loss_3': -16.139326095581055, 'loss_4': 1.4388113021850586, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 11:02:23,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:23,168 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:12<20:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:30,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01456280704587698, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010384820401668549, 'eval_loss_2': 0.004177987575531006, 'eval_loss_3': -18.253389358520508, 'eval_loss_4': 1.4206640720367432, 'epoch': 23.17}
{'loss': 0.0074, 'grad_norm': 5.127216339111328, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.006737282034009695, 'loss_2': 0.00066375732421875, 'loss_3': -16.38182258605957, 'loss_4': 1.3352034091949463, 'epoch': 23.17}
{'loss': 0.0104, 'grad_norm': 6.423528671264648, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.010003686882555485, 'loss_2': 0.0003814697265625, 'loss_3': -16.27054786682129, 'loss_4': 1.3263130187988281, 'epoch': 23.18}
{'loss': 0.0068, 'grad_norm': 4.6106648445129395, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.0028290566988289356, 'loss_2': 0.0040130615234375, 'loss_3': -16.42225456237793, 'loss_4': 1.0830457210540771, 'epoch': 23.19}
{'loss': 0.0033, 'grad_norm': 4.312122821807861, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.0017250332748517394, 'loss_2': 0.0015621185302734375, 'loss_3': -16.483549118041992, 'loss_4': 1.7078224420547485, 'epoch': 23.19}
{'loss': 0.0088, 'grad_norm': 4.520047187805176, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.0017251984681934118, 'loss_2': 0.00705718994140625, 'loss_3': -16.584896087646484, 'loss_4': 1.208418607711792, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 11:02:30,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:30,507 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:20<20:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:37,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014629052020609379, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.444, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010785537771880627, 'eval_loss_2': 0.0038435161113739014, 'eval_loss_3': -18.255802154541016, 'eval_loss_4': 1.3969924449920654, 'epoch': 23.2}
{'loss': 0.0147, 'grad_norm': 6.424591064453125, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.00943784974515438, 'loss_2': 0.0052642822265625, 'loss_3': -16.479585647583008, 'loss_4': 2.092327117919922, 'epoch': 23.2}
{'loss': 0.0047, 'grad_norm': 4.353477954864502, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.0028480764012783766, 'loss_2': 0.0018558502197265625, 'loss_3': -16.353103637695312, 'loss_4': 1.6877119541168213, 'epoch': 23.21}
{'loss': 0.0315, 'grad_norm': 12.91329574584961, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.030905194580554962, 'loss_2': 0.0005536079406738281, 'loss_3': -16.468570709228516, 'loss_4': 1.2510786056518555, 'epoch': 23.22}
{'loss': 0.0047, 'grad_norm': 4.65189266204834, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.003789335023611784, 'loss_2': 0.0009412765502929688, 'loss_3': -16.550678253173828, 'loss_4': 1.5594075918197632, 'epoch': 23.22}
{'loss': 0.0098, 'grad_norm': 6.3808393478393555, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.007392556872218847, 'loss_2': 0.00241851806640625, 'loss_3': -16.33435821533203, 'loss_4': 1.2013802528381348, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 11:02:37,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:37,853 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:27<20:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:45,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013574089854955673, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.225, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010070172138512135, 'eval_loss_2': 0.0035039186477661133, 'eval_loss_3': -18.25697898864746, 'eval_loss_4': 1.4062750339508057, 'epoch': 23.23}
{'loss': 0.0131, 'grad_norm': 5.96430778503418, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.007948767393827438, 'loss_2': 0.0051727294921875, 'loss_3': -16.269794464111328, 'loss_4': 1.7319180965423584, 'epoch': 23.23}
{'loss': 0.0098, 'grad_norm': 4.692070960998535, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.003757554804906249, 'loss_2': 0.0060577392578125, 'loss_3': -16.158920288085938, 'loss_4': 1.4452191591262817, 'epoch': 23.24}
{'loss': 0.004, 'grad_norm': 4.449173450469971, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.0036294092424213886, 'loss_2': 0.000377655029296875, 'loss_3': -16.472583770751953, 'loss_4': 1.200784683227539, 'epoch': 23.24}
{'loss': 0.0231, 'grad_norm': 11.22553825378418, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.022112727165222168, 'loss_2': 0.0009589195251464844, 'loss_3': -16.292919158935547, 'loss_4': 1.8684431314468384, 'epoch': 23.25}
{'loss': 0.0065, 'grad_norm': 4.782957077026367, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.0028767779003828764, 'loss_2': 0.0035991668701171875, 'loss_3': -16.561887741088867, 'loss_4': 1.679086685180664, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 11:02:45,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:45,195 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:34<19:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:52,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0134041178971529, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010211989283561707, 'eval_loss_2': 0.003192126750946045, 'eval_loss_3': -18.251623153686523, 'eval_loss_4': 1.362062692642212, 'epoch': 23.26}
{'loss': 0.0122, 'grad_norm': 6.589356422424316, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.00858553871512413, 'loss_2': 0.003635406494140625, 'loss_3': -16.25552749633789, 'loss_4': 1.428896188735962, 'epoch': 23.26}
{'loss': 0.0054, 'grad_norm': 4.813793182373047, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.0032041645608842373, 'loss_2': 0.002178192138671875, 'loss_3': -16.37381935119629, 'loss_4': 1.4853647947311401, 'epoch': 23.27}
{'loss': 0.0075, 'grad_norm': 5.099459648132324, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.004173638764768839, 'loss_2': 0.0033416748046875, 'loss_3': -16.228759765625, 'loss_4': 1.4196642637252808, 'epoch': 23.27}
{'loss': 0.0126, 'grad_norm': 5.274000644683838, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.006187888793647289, 'loss_2': 0.0064239501953125, 'loss_3': -16.22867202758789, 'loss_4': 1.2063353061676025, 'epoch': 23.28}
{'loss': 0.0219, 'grad_norm': 8.368764877319336, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.015541276894509792, 'loss_2': 0.00640106201171875, 'loss_3': -16.312122344970703, 'loss_4': 1.5364795923233032, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 11:02:52,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:52,533 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:42<19:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:59,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013351155444979668, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009702516719698906, 'eval_loss_2': 0.0036486387252807617, 'eval_loss_3': -18.246904373168945, 'eval_loss_4': 1.368208646774292, 'epoch': 23.28}
{'loss': 0.0086, 'grad_norm': 6.404118061065674, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.0070563689805567265, 'loss_2': 0.0015821456909179688, 'loss_3': -16.369443893432617, 'loss_4': 1.7733075618743896, 'epoch': 23.29}
{'loss': 0.0135, 'grad_norm': 5.303162574768066, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.005861809477210045, 'loss_2': 0.0076751708984375, 'loss_3': -16.253589630126953, 'loss_4': 1.7275149822235107, 'epoch': 23.3}
{'loss': 0.0072, 'grad_norm': 4.431608200073242, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.0026310058310627937, 'loss_2': 0.004558563232421875, 'loss_3': -16.44088363647461, 'loss_4': 1.6934715509414673, 'epoch': 23.3}
{'loss': 0.0081, 'grad_norm': 4.408358573913574, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.002631643321365118, 'loss_2': 0.00550079345703125, 'loss_3': -16.300983428955078, 'loss_4': 1.6073040962219238, 'epoch': 23.31}
{'loss': 0.0129, 'grad_norm': 4.922854900360107, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.006690089590847492, 'loss_2': 0.006198883056640625, 'loss_3': -16.33757781982422, 'loss_4': 1.9321258068084717, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 11:02:59,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:59,882 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:38:49<19:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:07,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013120702467858791, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0095480065792799, 'eval_loss_2': 0.003572694957256317, 'eval_loss_3': -18.245277404785156, 'eval_loss_4': 1.364755630493164, 'epoch': 23.31}
{'loss': 0.0028, 'grad_norm': 4.731584072113037, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.0026537489611655474, 'loss_2': 0.0001373291015625, 'loss_3': -16.285860061645508, 'loss_4': 1.3439466953277588, 'epoch': 23.32}
{'loss': 0.009, 'grad_norm': 5.678713798522949, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.006050420925021172, 'loss_2': 0.002986907958984375, 'loss_3': -16.48459815979004, 'loss_4': 1.3799736499786377, 'epoch': 23.33}
{'loss': 0.0029, 'grad_norm': 4.615152359008789, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.002846051473170519, 'loss_2': 9.357929229736328e-05, 'loss_3': -16.52507781982422, 'loss_4': 1.4696218967437744, 'epoch': 23.33}
{'loss': 0.0101, 'grad_norm': 5.150617599487305, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.005360713694244623, 'loss_2': 0.004756927490234375, 'loss_3': -16.44739532470703, 'loss_4': 1.0468307733535767, 'epoch': 23.34}
{'loss': 0.0128, 'grad_norm': 4.894745826721191, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.002474184613674879, 'loss_2': 0.01036834716796875, 'loss_3': -16.36323356628418, 'loss_4': 1.7741727828979492, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 11:03:07,230 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:07,230 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:38:56<19:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:14,582 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013724868185818195, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009883884340524673, 'eval_loss_2': 0.0038409829139709473, 'eval_loss_3': -18.24135971069336, 'eval_loss_4': 1.3036984205245972, 'epoch': 23.34}
{'loss': 0.0044, 'grad_norm': 4.6608099937438965, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.0038733293768018484, 'loss_2': 0.0005431175231933594, 'loss_3': -16.289241790771484, 'loss_4': 1.433875322341919, 'epoch': 23.35}
{'loss': 0.0055, 'grad_norm': 4.491663932800293, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.0037105928640812635, 'loss_2': 0.001743316650390625, 'loss_3': -16.349071502685547, 'loss_4': 1.3642487525939941, 'epoch': 23.35}
{'loss': 0.0089, 'grad_norm': 4.842845439910889, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.004406402353197336, 'loss_2': 0.00453948974609375, 'loss_3': -16.355026245117188, 'loss_4': 1.1298737525939941, 'epoch': 23.36}
{'loss': 0.005, 'grad_norm': 4.69272518157959, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.0036065017338842154, 'loss_2': 0.0014247894287109375, 'loss_3': -16.41063690185547, 'loss_4': 1.928114652633667, 'epoch': 23.37}
{'loss': 0.0151, 'grad_norm': 11.502476692199707, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.013455944135785103, 'loss_2': 0.001674652099609375, 'loss_3': -16.311105728149414, 'loss_4': 1.4516959190368652, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 11:03:14,582 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:14,582 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:04<19:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:21,924 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013293616473674774, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00963817723095417, 'eval_loss_2': 0.0036554373800754547, 'eval_loss_3': -18.2362117767334, 'eval_loss_4': 1.2727986574172974, 'epoch': 23.37}
{'loss': 0.0031, 'grad_norm': 4.806300640106201, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.0027695754542946815, 'loss_2': 0.0003008842468261719, 'loss_3': -16.51662826538086, 'loss_4': 1.5402023792266846, 'epoch': 23.38}
{'loss': 0.0038, 'grad_norm': 4.019683361053467, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.0037046426441520452, 'loss_2': 9.274482727050781e-05, 'loss_3': -16.093425750732422, 'loss_4': 1.5380734205245972, 'epoch': 23.38}
{'loss': 0.0089, 'grad_norm': 4.240908622741699, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.003056936664506793, 'loss_2': 0.005859375, 'loss_3': -16.44894027709961, 'loss_4': 1.5556585788726807, 'epoch': 23.39}
{'loss': 0.0121, 'grad_norm': 5.114080905914307, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.004923671949654818, 'loss_2': 0.007152557373046875, 'loss_3': -16.256881713867188, 'loss_4': 1.3094102144241333, 'epoch': 23.4}
{'loss': 0.0156, 'grad_norm': 8.113025665283203, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.011994785629212856, 'loss_2': 0.00363922119140625, 'loss_3': -16.1729736328125, 'loss_4': 1.7806105613708496, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 11:03:21,924 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:21,924 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:11<19:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:29,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012802932411432266, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00930661428719759, 'eval_loss_2': 0.003496319055557251, 'eval_loss_3': -18.235628128051758, 'eval_loss_4': 1.2465481758117676, 'epoch': 23.4}
{'loss': 0.0058, 'grad_norm': 4.904564380645752, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.004422112368047237, 'loss_2': 0.0013494491577148438, 'loss_3': -16.297197341918945, 'loss_4': 1.1488184928894043, 'epoch': 23.41}
{'loss': 0.0068, 'grad_norm': 4.551779270172119, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.0025473032146692276, 'loss_2': 0.004268646240234375, 'loss_3': -16.453157424926758, 'loss_4': 2.0418519973754883, 'epoch': 23.41}
{'loss': 0.0041, 'grad_norm': 4.499859809875488, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.002722210716456175, 'loss_2': 0.0013971328735351562, 'loss_3': -16.467039108276367, 'loss_4': 0.8354772925376892, 'epoch': 23.42}
{'loss': 0.0127, 'grad_norm': 4.514825344085693, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.0030806453432887793, 'loss_2': 0.0096588134765625, 'loss_3': -16.47604751586914, 'loss_4': 1.3433899879455566, 'epoch': 23.42}
{'loss': 0.0089, 'grad_norm': 5.854931831359863, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.008629200048744678, 'loss_2': 0.00023889541625976562, 'loss_3': -16.144779205322266, 'loss_4': 1.279805064201355, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 11:03:29,274 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:29,274 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:18<19:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:36,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013600260950624943, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00899475533515215, 'eval_loss_2': 0.004605505615472794, 'eval_loss_3': -18.240999221801758, 'eval_loss_4': 1.2093346118927002, 'epoch': 23.43}
{'loss': 0.0038, 'grad_norm': 4.602574825286865, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.0026748552918434143, 'loss_2': 0.0011005401611328125, 'loss_3': -16.56179428100586, 'loss_4': 1.408995270729065, 'epoch': 23.44}
{'loss': 0.0039, 'grad_norm': 4.604413032531738, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.0035698628053069115, 'loss_2': 0.0003414154052734375, 'loss_3': -16.280370712280273, 'loss_4': 1.4294434785842896, 'epoch': 23.44}
{'loss': 0.0054, 'grad_norm': 4.830445289611816, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.005158870480954647, 'loss_2': 0.0002536773681640625, 'loss_3': -16.446733474731445, 'loss_4': 1.5661466121673584, 'epoch': 23.45}
{'loss': 0.0119, 'grad_norm': 5.164801120758057, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.008303489536046982, 'loss_2': 0.00362396240234375, 'loss_3': -16.328500747680664, 'loss_4': 1.593217372894287, 'epoch': 23.45}
{'loss': 0.0096, 'grad_norm': 4.958807468414307, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.004820019938051701, 'loss_2': 0.00481414794921875, 'loss_3': -16.497215270996094, 'loss_4': 1.0931743383407593, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 11:03:36,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:36,623 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:26<19:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:43,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013036447577178478, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.998, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008345234207808971, 'eval_loss_2': 0.004691213369369507, 'eval_loss_3': -18.260862350463867, 'eval_loss_4': 1.095935583114624, 'epoch': 23.46}
{'loss': 0.0082, 'grad_norm': 5.526021480560303, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.006644187495112419, 'loss_2': 0.00157928466796875, 'loss_3': -16.236005783081055, 'loss_4': 1.3397505283355713, 'epoch': 23.47}
{'loss': 0.0162, 'grad_norm': 11.525129318237305, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.012089626863598824, 'loss_2': 0.0041046142578125, 'loss_3': -16.224111557006836, 'loss_4': 1.7100178003311157, 'epoch': 23.47}
{'loss': 0.0094, 'grad_norm': 4.583512306213379, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.004489491693675518, 'loss_2': 0.00487518310546875, 'loss_3': -16.268198013305664, 'loss_4': 1.621343731880188, 'epoch': 23.48}
{'loss': 0.0059, 'grad_norm': 5.369982719421387, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.005555801093578339, 'loss_2': 0.0003421306610107422, 'loss_3': -16.38845443725586, 'loss_4': 1.4220325946807861, 'epoch': 23.48}
{'loss': 0.0103, 'grad_norm': 4.831454277038574, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.004923895001411438, 'loss_2': 0.00539398193359375, 'loss_3': -16.269081115722656, 'loss_4': 1.9087693691253662, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 11:03:43,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:43,973 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:33<19:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:51,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01294726599007845, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.581, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008817768655717373, 'eval_loss_2': 0.004129499197006226, 'eval_loss_3': -18.256324768066406, 'eval_loss_4': 1.1296310424804688, 'epoch': 23.49}
{'loss': 0.0088, 'grad_norm': 5.55150842666626, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.008254175074398518, 'loss_2': 0.0005702972412109375, 'loss_3': -16.24573516845703, 'loss_4': 1.5069036483764648, 'epoch': 23.49}
{'loss': 0.0136, 'grad_norm': 11.514392852783203, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.010378232225775719, 'loss_2': 0.00318145751953125, 'loss_3': -16.013816833496094, 'loss_4': 1.5140260457992554, 'epoch': 23.5}
{'loss': 0.007, 'grad_norm': 5.182700157165527, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.00513564795255661, 'loss_2': 0.0018291473388671875, 'loss_3': -16.608470916748047, 'loss_4': 1.8994947671890259, 'epoch': 23.51}
{'loss': 0.0065, 'grad_norm': 4.491461753845215, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.002613234566524625, 'loss_2': 0.00386810302734375, 'loss_3': -16.375898361206055, 'loss_4': 1.377606749534607, 'epoch': 23.51}
{'loss': 0.0103, 'grad_norm': 4.846166610717773, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.005896460730582476, 'loss_2': 0.00443267822265625, 'loss_3': -16.3704776763916, 'loss_4': 1.7509419918060303, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 11:03:51,316 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:51,316 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:40<19:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:58,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01307840459048748, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009228354319930077, 'eval_loss_2': 0.0038500502705574036, 'eval_loss_3': -18.25210189819336, 'eval_loss_4': 1.234602689743042, 'epoch': 23.52}
{'loss': 0.0107, 'grad_norm': 6.021543502807617, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.00465028639882803, 'loss_2': 0.00604248046875, 'loss_3': -16.31689453125, 'loss_4': 1.4046885967254639, 'epoch': 23.52}
{'loss': 0.0052, 'grad_norm': 4.461764812469482, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.0023903653491288424, 'loss_2': 0.002838134765625, 'loss_3': -16.27700424194336, 'loss_4': 1.76266348361969, 'epoch': 23.53}
{'loss': 0.0048, 'grad_norm': 4.754975318908691, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.0029253377579152584, 'loss_2': 0.0018339157104492188, 'loss_3': -16.33414077758789, 'loss_4': 1.305241346359253, 'epoch': 23.53}
{'loss': 0.005, 'grad_norm': 5.325717449188232, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.004191636107861996, 'loss_2': 0.0008106231689453125, 'loss_3': -16.207250595092773, 'loss_4': 1.348649024963379, 'epoch': 23.54}
{'loss': 0.0055, 'grad_norm': 5.233131408691406, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.004265161696821451, 'loss_2': 0.001220703125, 'loss_3': -16.443824768066406, 'loss_4': 1.5269101858139038, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 11:03:58,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:58,661 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:39:48<19:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:06,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012627474963665009, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008917233906686306, 'eval_loss_2': 0.003710240125656128, 'eval_loss_3': -18.266263961791992, 'eval_loss_4': 1.3217499256134033, 'epoch': 23.55}
{'loss': 0.0235, 'grad_norm': 8.246659278869629, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.014878594316542149, 'loss_2': 0.00860595703125, 'loss_3': -16.474023818969727, 'loss_4': 2.045009136199951, 'epoch': 23.55}
{'loss': 0.0193, 'grad_norm': 7.550323486328125, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.013105567544698715, 'loss_2': 0.006160736083984375, 'loss_3': -16.425376892089844, 'loss_4': 1.4303193092346191, 'epoch': 23.56}
{'loss': 0.002, 'grad_norm': 4.581535816192627, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.001995612634345889, 'loss_2': 4.6253204345703125e-05, 'loss_3': -16.307035446166992, 'loss_4': 1.8232706785202026, 'epoch': 23.56}
{'loss': 0.0054, 'grad_norm': 4.270206451416016, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.0027190716937184334, 'loss_2': 0.002658843994140625, 'loss_3': -16.39960479736328, 'loss_4': 1.2830318212509155, 'epoch': 23.57}
{'loss': 0.0053, 'grad_norm': 4.095657825469971, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.0021346397697925568, 'loss_2': 0.0031280517578125, 'loss_3': -16.24097442626953, 'loss_4': 1.734297752380371, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 11:04:06,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:06,004 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:39:55<19:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:13,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012877421453595161, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.507, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008902298286557198, 'eval_loss_2': 0.003975123167037964, 'eval_loss_3': -18.266210556030273, 'eval_loss_4': 1.3031127452850342, 'epoch': 23.58}
{'loss': 0.0109, 'grad_norm': 5.594791412353516, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.006254290230572224, 'loss_2': 0.004650115966796875, 'loss_3': -16.197978973388672, 'loss_4': 1.7610942125320435, 'epoch': 23.58}
{'loss': 0.0036, 'grad_norm': 4.217952251434326, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.0032433418091386557, 'loss_2': 0.0004024505615234375, 'loss_3': -16.321128845214844, 'loss_4': 1.6069649457931519, 'epoch': 23.59}
{'loss': 0.0049, 'grad_norm': 5.061604022979736, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.003833760740235448, 'loss_2': 0.0010213851928710938, 'loss_3': -16.438335418701172, 'loss_4': 1.6225533485412598, 'epoch': 23.59}
{'loss': 0.0096, 'grad_norm': 6.205897331237793, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.0076804012060165405, 'loss_2': 0.001903533935546875, 'loss_3': -16.31814956665039, 'loss_4': 1.389083743095398, 'epoch': 23.6}
{'loss': 0.0086, 'grad_norm': 4.840463638305664, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.0019262098940089345, 'loss_2': 0.006679534912109375, 'loss_3': -16.328125, 'loss_4': 1.7469367980957031, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 11:04:13,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:13,346 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:02<18:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:20,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014704154804348946, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01010441966354847, 'eval_loss_2': 0.004599735140800476, 'eval_loss_3': -18.260353088378906, 'eval_loss_4': 1.2674095630645752, 'epoch': 23.6}
{'loss': 0.0078, 'grad_norm': 4.501679420471191, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.0052820248529314995, 'loss_2': 0.00247955322265625, 'loss_3': -16.117460250854492, 'loss_4': 1.770634412765503, 'epoch': 23.61}
{'loss': 0.0088, 'grad_norm': 5.0799078941345215, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.006646126043051481, 'loss_2': 0.00213623046875, 'loss_3': -16.287212371826172, 'loss_4': 1.7945209741592407, 'epoch': 23.62}
{'loss': 0.0145, 'grad_norm': 5.667839050292969, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.007307219784706831, 'loss_2': 0.007221221923828125, 'loss_3': -16.056127548217773, 'loss_4': 1.3141522407531738, 'epoch': 23.62}
{'loss': 0.0195, 'grad_norm': 4.3304033279418945, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.0028950523119419813, 'loss_2': 0.0165863037109375, 'loss_3': -16.354001998901367, 'loss_4': 1.3980357646942139, 'epoch': 23.63}
{'loss': 0.0107, 'grad_norm': 4.771270751953125, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.0040456377901136875, 'loss_2': 0.0066375732421875, 'loss_3': -16.353899002075195, 'loss_4': 1.4205563068389893, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 11:04:20,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:20,691 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:10<18:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:28,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015470718964934349, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00990436039865017, 'eval_loss_2': 0.00556635856628418, 'eval_loss_3': -18.272159576416016, 'eval_loss_4': 1.2108651399612427, 'epoch': 23.63}
{'loss': 0.015, 'grad_norm': 7.830361843109131, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.009508681483566761, 'loss_2': 0.005512237548828125, 'loss_3': -16.320213317871094, 'loss_4': 1.7556302547454834, 'epoch': 23.64}
{'loss': 0.0178, 'grad_norm': 5.91610860824585, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.011842597275972366, 'loss_2': 0.00592041015625, 'loss_3': -16.258758544921875, 'loss_4': 1.8385977745056152, 'epoch': 23.65}
{'loss': 0.0126, 'grad_norm': 6.762779712677002, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.007799074519425631, 'loss_2': 0.004817962646484375, 'loss_3': -16.41905975341797, 'loss_4': 1.966909408569336, 'epoch': 23.65}
{'loss': 0.0094, 'grad_norm': 4.574395179748535, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.003505886532366276, 'loss_2': 0.005886077880859375, 'loss_3': -16.261390686035156, 'loss_4': 1.8180208206176758, 'epoch': 23.66}
{'loss': 0.01, 'grad_norm': 4.51423978805542, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.00250829104334116, 'loss_2': 0.007526397705078125, 'loss_3': -16.27813148498535, 'loss_4': 1.7527251243591309, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 11:04:28,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:28,040 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:17<18:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:35,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013906441628932953, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00952365342527628, 'eval_loss_2': 0.004382789134979248, 'eval_loss_3': -18.269346237182617, 'eval_loss_4': 1.2039090394973755, 'epoch': 23.66}
{'loss': 0.0218, 'grad_norm': 16.183015823364258, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.01711863838136196, 'loss_2': 0.00466156005859375, 'loss_3': -16.273536682128906, 'loss_4': 1.121748447418213, 'epoch': 23.67}
{'loss': 0.0115, 'grad_norm': 4.909298896789551, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.007019933313131332, 'loss_2': 0.0045166015625, 'loss_3': -16.31839942932129, 'loss_4': 1.7662324905395508, 'epoch': 23.67}
{'loss': 0.0145, 'grad_norm': 5.27098274230957, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.006149880588054657, 'loss_2': 0.0083160400390625, 'loss_3': -16.257047653198242, 'loss_4': 0.8941314220428467, 'epoch': 23.68}
{'loss': 0.0038, 'grad_norm': 4.561746120452881, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.0035888359416276217, 'loss_2': 0.00023484230041503906, 'loss_3': -16.162246704101562, 'loss_4': 1.2514487504959106, 'epoch': 23.69}
{'loss': 0.0065, 'grad_norm': 4.799429893493652, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.006366911344230175, 'loss_2': 0.00014495849609375, 'loss_3': -16.219696044921875, 'loss_4': 1.2205848693847656, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 11:04:35,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:35,384 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:24<18:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:42,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013767218217253685, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.385, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00993597973138094, 'eval_loss_2': 0.003831237554550171, 'eval_loss_3': -18.271024703979492, 'eval_loss_4': 1.1879266500473022, 'epoch': 23.69}
{'loss': 0.009, 'grad_norm': 5.564208507537842, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.008007370866835117, 'loss_2': 0.0009517669677734375, 'loss_3': -16.24144172668457, 'loss_4': 1.1378941535949707, 'epoch': 23.7}
{'loss': 0.0205, 'grad_norm': 8.127171516418457, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.013847696594893932, 'loss_2': 0.00666046142578125, 'loss_3': -16.1770076751709, 'loss_4': 1.6652541160583496, 'epoch': 23.7}
{'loss': 0.0162, 'grad_norm': 9.614089965820312, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.011384431272745132, 'loss_2': 0.004791259765625, 'loss_3': -16.202213287353516, 'loss_4': 1.5666446685791016, 'epoch': 23.71}
{'loss': 0.0069, 'grad_norm': 4.5047125816345215, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.0032731988467276096, 'loss_2': 0.00365447998046875, 'loss_3': -16.296838760375977, 'loss_4': 1.577479362487793, 'epoch': 23.72}
{'loss': 0.0119, 'grad_norm': 6.575935363769531, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.009579511359333992, 'loss_2': 0.00232696533203125, 'loss_3': -16.286170959472656, 'loss_4': 1.6906037330627441, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 11:04:42,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:42,731 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:32<18:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:50,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014311123639345169, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.646, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01033245399594307, 'eval_loss_2': 0.0039786696434021, 'eval_loss_3': -18.289758682250977, 'eval_loss_4': 1.1901569366455078, 'epoch': 23.72}
{'loss': 0.0067, 'grad_norm': 4.717221260070801, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.004148156847804785, 'loss_2': 0.0025634765625, 'loss_3': -16.23606300354004, 'loss_4': 1.4794244766235352, 'epoch': 23.73}
{'loss': 0.008, 'grad_norm': 4.862232208251953, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.007141804322600365, 'loss_2': 0.0008263587951660156, 'loss_3': -16.293901443481445, 'loss_4': 1.3504571914672852, 'epoch': 23.73}
{'loss': 0.015, 'grad_norm': 6.977993488311768, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.013640697114169598, 'loss_2': 0.0013570785522460938, 'loss_3': -16.482498168945312, 'loss_4': 1.4778951406478882, 'epoch': 23.74}
{'loss': 0.0031, 'grad_norm': 4.288595199584961, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.0020780081395059824, 'loss_2': 0.0010051727294921875, 'loss_3': -16.278743743896484, 'loss_4': 1.3925275802612305, 'epoch': 23.74}
{'loss': 0.0097, 'grad_norm': 5.194276332855225, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.005531331058591604, 'loss_2': 0.004199981689453125, 'loss_3': -16.387523651123047, 'loss_4': 1.6960256099700928, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 11:04:50,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:50,072 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:39<18:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:57,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013687493279576302, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009901368990540504, 'eval_loss_2': 0.003786124289035797, 'eval_loss_3': -18.298072814941406, 'eval_loss_4': 1.2573003768920898, 'epoch': 23.75}
{'loss': 0.008, 'grad_norm': 5.228041172027588, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.005745918024331331, 'loss_2': 0.002300262451171875, 'loss_3': -16.34744644165039, 'loss_4': 1.800675630569458, 'epoch': 23.76}
{'loss': 0.0109, 'grad_norm': 4.948902130126953, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.0065100230276584625, 'loss_2': 0.00440216064453125, 'loss_3': -16.072093963623047, 'loss_4': 1.6392735242843628, 'epoch': 23.76}
{'loss': 0.0107, 'grad_norm': 6.186975479125977, 'learning_rate': 6.25e-06, 'loss_1': 0.009083294309675694, 'loss_2': 0.0016622543334960938, 'loss_3': -16.211872100830078, 'loss_4': 1.3727588653564453, 'epoch': 23.77}
{'loss': 0.0032, 'grad_norm': 4.558759689331055, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.003067968413233757, 'loss_2': 0.00015854835510253906, 'loss_3': -16.323848724365234, 'loss_4': 1.6533892154693604, 'epoch': 23.77}
{'loss': 0.0097, 'grad_norm': 4.57286262512207, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.002409023232758045, 'loss_2': 0.007289886474609375, 'loss_3': -16.374832153320312, 'loss_4': 1.5323290824890137, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 11:04:57,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:57,417 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:40:46<18:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:04,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013707992620766163, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010207440704107285, 'eval_loss_2': 0.0035005509853363037, 'eval_loss_3': -18.309709548950195, 'eval_loss_4': 1.2973361015319824, 'epoch': 23.78}
{'loss': 0.0087, 'grad_norm': 5.346060276031494, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.006815784610807896, 'loss_2': 0.0018405914306640625, 'loss_3': -16.248586654663086, 'loss_4': 1.7918329238891602, 'epoch': 23.78}
{'loss': 0.0055, 'grad_norm': 4.51494026184082, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.0029770780820399523, 'loss_2': 0.0025691986083984375, 'loss_3': -16.154630661010742, 'loss_4': 1.38771653175354, 'epoch': 23.79}
{'loss': 0.0079, 'grad_norm': 4.598285675048828, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.005203993991017342, 'loss_2': 0.0027332305908203125, 'loss_3': -16.490421295166016, 'loss_4': 1.632878065109253, 'epoch': 23.8}
{'loss': 0.0133, 'grad_norm': 6.088210105895996, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.011747155338525772, 'loss_2': 0.0015735626220703125, 'loss_3': -16.28439712524414, 'loss_4': 1.7726728916168213, 'epoch': 23.8}
{'loss': 0.0071, 'grad_norm': 4.330830097198486, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.004433248657733202, 'loss_2': 0.0027065277099609375, 'loss_3': -16.369583129882812, 'loss_4': 1.6470175981521606, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 11:05:04,767 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:04,767 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:40:54<18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:12,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013372564688324928, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00984963122755289, 'eval_loss_2': 0.003522932529449463, 'eval_loss_3': -18.322664260864258, 'eval_loss_4': 1.3804843425750732, 'epoch': 23.81}
{'loss': 0.0051, 'grad_norm': 4.597241401672363, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.004794151987880468, 'loss_2': 0.00026106834411621094, 'loss_3': -16.480533599853516, 'loss_4': 1.8045718669891357, 'epoch': 23.81}
{'loss': 0.009, 'grad_norm': 5.676121234893799, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.006850749254226685, 'loss_2': 0.002185821533203125, 'loss_3': -16.281967163085938, 'loss_4': 1.2337114810943604, 'epoch': 23.82}
{'loss': 0.005, 'grad_norm': 4.354536533355713, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.00335023389197886, 'loss_2': 0.0016651153564453125, 'loss_3': -16.322505950927734, 'loss_4': 1.6801249980926514, 'epoch': 23.83}
{'loss': 0.0109, 'grad_norm': 5.699159145355225, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.010626708157360554, 'loss_2': 0.0002455711364746094, 'loss_3': -16.296335220336914, 'loss_4': 1.4257394075393677, 'epoch': 23.83}
{'loss': 0.0155, 'grad_norm': 5.321661472320557, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.0068988557904958725, 'loss_2': 0.00858306884765625, 'loss_3': -16.286128997802734, 'loss_4': 1.831709384918213, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 11:05:12,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:12,118 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:01<18:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:19,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014315459877252579, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009708975441753864, 'eval_loss_2': 0.004606485366821289, 'eval_loss_3': -18.327220916748047, 'eval_loss_4': 1.3462271690368652, 'epoch': 23.84}
{'loss': 0.0084, 'grad_norm': 4.930510997772217, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.004849743098020554, 'loss_2': 0.0035858154296875, 'loss_3': -16.34185028076172, 'loss_4': 1.741355299949646, 'epoch': 23.84}
{'loss': 0.0125, 'grad_norm': 4.800037860870361, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.003482640953734517, 'loss_2': 0.009033203125, 'loss_3': -16.385473251342773, 'loss_4': 1.7279722690582275, 'epoch': 23.85}
{'loss': 0.0108, 'grad_norm': 4.270336151123047, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.003932476509362459, 'loss_2': 0.00688934326171875, 'loss_3': -16.35475730895996, 'loss_4': 2.0040998458862305, 'epoch': 23.85}
{'loss': 0.0137, 'grad_norm': 5.632870197296143, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.005748612806200981, 'loss_2': 0.007904052734375, 'loss_3': -16.441211700439453, 'loss_4': 1.5393295288085938, 'epoch': 23.86}
{'loss': 0.0079, 'grad_norm': 4.016503810882568, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.0029806497041136026, 'loss_2': 0.00496673583984375, 'loss_3': -16.36822509765625, 'loss_4': 1.3799480199813843, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 11:05:19,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:19,465 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:08<18:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:26,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014573676511645317, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009771463461220264, 'eval_loss_2': 0.004802212119102478, 'eval_loss_3': -18.33397674560547, 'eval_loss_4': 1.2955372333526611, 'epoch': 23.87}
{'loss': 0.0067, 'grad_norm': 4.814650535583496, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.0044555957429111, 'loss_2': 0.00225067138671875, 'loss_3': -16.471405029296875, 'loss_4': 1.2047333717346191, 'epoch': 23.87}
{'loss': 0.013, 'grad_norm': 4.429119110107422, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.008064638823270798, 'loss_2': 0.0049591064453125, 'loss_3': -16.249168395996094, 'loss_4': 1.8143606185913086, 'epoch': 23.88}
{'loss': 0.017, 'grad_norm': 17.22632598876953, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.016082854941487312, 'loss_2': 0.0009212493896484375, 'loss_3': -16.285953521728516, 'loss_4': 1.4948046207427979, 'epoch': 23.88}
{'loss': 0.0034, 'grad_norm': 6.926711082458496, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.002908331574872136, 'loss_2': 0.0004839897155761719, 'loss_3': -16.361736297607422, 'loss_4': 1.6655511856079102, 'epoch': 23.89}
{'loss': 0.0165, 'grad_norm': 4.833677768707275, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.005897946655750275, 'loss_2': 0.01058197021484375, 'loss_3': -16.37688446044922, 'loss_4': 1.4875719547271729, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 11:05:26,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:26,817 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:16<18:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:34,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012960532680153847, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.428, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008979970589280128, 'eval_loss_2': 0.003980562090873718, 'eval_loss_3': -18.331966400146484, 'eval_loss_4': 1.3220112323760986, 'epoch': 23.9}
{'loss': 0.0083, 'grad_norm': 4.987868309020996, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.00673579191789031, 'loss_2': 0.0015735626220703125, 'loss_3': -16.309326171875, 'loss_4': 1.3308453559875488, 'epoch': 23.9}
{'loss': 0.0111, 'grad_norm': 4.787436008453369, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.006783193442970514, 'loss_2': 0.00433349609375, 'loss_3': -16.316402435302734, 'loss_4': 1.294055700302124, 'epoch': 23.91}
{'loss': 0.0052, 'grad_norm': 4.47684383392334, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.004115104675292969, 'loss_2': 0.0010471343994140625, 'loss_3': -16.328227996826172, 'loss_4': 1.7392308712005615, 'epoch': 23.91}
{'loss': 0.0175, 'grad_norm': 15.388936042785645, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.01276033092290163, 'loss_2': 0.00478363037109375, 'loss_3': -16.209957122802734, 'loss_4': 1.4603904485702515, 'epoch': 23.92}
{'loss': 0.0145, 'grad_norm': 10.376358985900879, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.012943390756845474, 'loss_2': 0.0015115737915039062, 'loss_3': -16.37752914428711, 'loss_4': 1.2911076545715332, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 11:05:34,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:34,161 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:23<17:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:41,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012852955609560013, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00881301797926426, 'eval_loss_2': 0.004039935767650604, 'eval_loss_3': -18.31405258178711, 'eval_loss_4': 1.3089861869812012, 'epoch': 23.92}
{'loss': 0.0093, 'grad_norm': 5.325477123260498, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.00491031538695097, 'loss_2': 0.00441741943359375, 'loss_3': -16.378299713134766, 'loss_4': 1.810997724533081, 'epoch': 23.93}
{'loss': 0.0065, 'grad_norm': 4.86866569519043, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.0053046816028654575, 'loss_2': 0.001186370849609375, 'loss_3': -16.38810157775879, 'loss_4': 1.0525890588760376, 'epoch': 23.94}
{'loss': 0.0117, 'grad_norm': 4.939923286437988, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.006347933318465948, 'loss_2': 0.00536346435546875, 'loss_3': -16.466012954711914, 'loss_4': 1.2378664016723633, 'epoch': 23.94}
{'loss': 0.0103, 'grad_norm': 10.623702049255371, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.005100699607282877, 'loss_2': 0.0052337646484375, 'loss_3': -16.430469512939453, 'loss_4': 1.6677472591400146, 'epoch': 23.95}
{'loss': 0.0129, 'grad_norm': 5.670597553253174, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.006631527096033096, 'loss_2': 0.00630950927734375, 'loss_3': -16.439041137695312, 'loss_4': 1.3824090957641602, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 11:05:41,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:41,512 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:31<17:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:48,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014364801347255707, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008836439810693264, 'eval_loss_2': 0.005528360605239868, 'eval_loss_3': -18.301544189453125, 'eval_loss_4': 1.264064908027649, 'epoch': 23.95}
{'loss': 0.0241, 'grad_norm': 7.181036472320557, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.012548312544822693, 'loss_2': 0.0115203857421875, 'loss_3': -16.434720993041992, 'loss_4': 1.7084307670593262, 'epoch': 23.96}
{'loss': 0.0414, 'grad_norm': 16.778606414794922, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.038103628903627396, 'loss_2': 0.003253936767578125, 'loss_3': -16.26422119140625, 'loss_4': 1.8394839763641357, 'epoch': 23.97}
{'loss': 0.0092, 'grad_norm': 4.493767261505127, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.005293603055179119, 'loss_2': 0.00394439697265625, 'loss_3': -16.354724884033203, 'loss_4': 1.5484358072280884, 'epoch': 23.97}
{'loss': 0.0153, 'grad_norm': 10.423970222473145, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.014468485489487648, 'loss_2': 0.0008296966552734375, 'loss_3': -16.41336441040039, 'loss_4': 1.4282252788543701, 'epoch': 23.98}
{'loss': 0.0042, 'grad_norm': 4.550663948059082, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.0023853962775319815, 'loss_2': 0.0018310546875, 'loss_3': -16.282747268676758, 'loss_4': 1.4803985357284546, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 11:05:48,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:48,860 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:38<17:04,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 11:05:55,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013492017053067684, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008411050774157047, 'eval_loss_2': 0.005080964416265488, 'eval_loss_3': -18.296918869018555, 'eval_loss_4': 1.249700903892517, 'epoch': 23.98}
{'loss': 0.0081, 'grad_norm': 4.228851795196533, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.0028747664764523506, 'loss_2': 0.0052032470703125, 'loss_3': -16.310382843017578, 'loss_4': 1.7257170677185059, 'epoch': 23.99}
{'loss': 0.0116, 'grad_norm': 5.747347354888916, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.007407261524349451, 'loss_2': 0.0041961669921875, 'loss_3': -16.45287322998047, 'loss_4': 1.89024817943573, 'epoch': 23.99}
{'loss': 0.0087, 'grad_norm': 5.612004280090332, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.003326150355860591, 'loss_2': 0.00534820556640625, 'loss_3': -16.20783805847168, 'loss_4': 1.2825090885162354, 'epoch': 24.0}
{'loss': 0.0211, 'grad_norm': 6.433377265930176, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.011222579516470432, 'loss_2': 0.0098419189453125, 'loss_3': -16.23577117919922, 'loss_4': 1.3292577266693115, 'epoch': 24.01}
{'loss': 0.016, 'grad_norm': 4.376638889312744, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.00529079744592309, 'loss_2': 0.01074981689453125, 'loss_3': -16.30130386352539, 'loss_4': 1.746157169342041, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 11:05:55,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:55,891 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:41:45<17:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:06:03,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012016466818749905, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.392, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008224103599786758, 'eval_loss_2': 0.003792364150285721, 'eval_loss_3': -18.289020538330078, 'eval_loss_4': 1.2404667139053345, 'epoch': 24.01}
{'loss': 0.0137, 'grad_norm': 4.873610496520996, 'learning_rate': 6e-06, 'loss_1': 0.00656670518219471, 'loss_2': 0.007099151611328125, 'loss_3': -16.443262100219727, 'loss_4': 1.6777340173721313, 'epoch': 24.02}
{'loss': 0.0104, 'grad_norm': 4.924020767211914, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.004177790600806475, 'loss_2': 0.0062408447265625, 'loss_3': -16.140607833862305, 'loss_4': 1.7269346714019775, 'epoch': 24.02}
{'loss': 0.0045, 'grad_norm': 4.442682266235352, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.0034449389204382896, 'loss_2': 0.0010251998901367188, 'loss_3': -16.407711029052734, 'loss_4': 1.593181848526001, 'epoch': 24.03}
{'loss': 0.0237, 'grad_norm': 9.35580062866211, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.01963743567466736, 'loss_2': 0.00403594970703125, 'loss_3': -16.31812286376953, 'loss_4': 0.9945743083953857, 'epoch': 24.03}
{'loss': 0.0079, 'grad_norm': 5.836358070373535, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.007383906282484531, 'loss_2': 0.000560760498046875, 'loss_3': -16.27178192138672, 'loss_4': 1.1045540571212769, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 11:06:03,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:03,247 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:41:52<17:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:10,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012030191719532013, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008437699638307095, 'eval_loss_2': 0.0035924911499023438, 'eval_loss_3': -18.28830337524414, 'eval_loss_4': 1.260307788848877, 'epoch': 24.04}
{'loss': 0.0053, 'grad_norm': 5.872110843658447, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.0046888985671103, 'loss_2': 0.0005993843078613281, 'loss_3': -16.416147232055664, 'loss_4': 0.6227094531059265, 'epoch': 24.05}
{'loss': 0.0143, 'grad_norm': 7.193258762359619, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.012040440924465656, 'loss_2': 0.00225830078125, 'loss_3': -16.38793182373047, 'loss_4': 1.5533406734466553, 'epoch': 24.05}
{'loss': 0.0061, 'grad_norm': 5.55635929107666, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.005423541180789471, 'loss_2': 0.0006647109985351562, 'loss_3': -16.407489776611328, 'loss_4': 1.5093762874603271, 'epoch': 24.06}
{'loss': 0.007, 'grad_norm': 4.272355079650879, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.0032222820445895195, 'loss_2': 0.0037937164306640625, 'loss_3': -16.44874382019043, 'loss_4': 1.627251386642456, 'epoch': 24.06}
{'loss': 0.0107, 'grad_norm': 7.771989822387695, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.007862175814807415, 'loss_2': 0.00279998779296875, 'loss_3': -16.297000885009766, 'loss_4': 2.0490050315856934, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 11:06:10,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:10,597 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:00<17:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:17,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012497598305344582, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007963948883116245, 'eval_loss_2': 0.004533648490905762, 'eval_loss_3': -18.294330596923828, 'eval_loss_4': 1.3268707990646362, 'epoch': 24.07}
{'loss': 0.0122, 'grad_norm': 4.334982872009277, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.003991909325122833, 'loss_2': 0.00823211669921875, 'loss_3': -16.489227294921875, 'loss_4': 1.7679195404052734, 'epoch': 24.08}
{'loss': 0.0095, 'grad_norm': 4.753438472747803, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.004712682217359543, 'loss_2': 0.00482177734375, 'loss_3': -16.398090362548828, 'loss_4': 1.3623459339141846, 'epoch': 24.08}
{'loss': 0.0078, 'grad_norm': 4.582487106323242, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.002780354581773281, 'loss_2': 0.005035400390625, 'loss_3': -16.348997116088867, 'loss_4': 1.542216181755066, 'epoch': 24.09}
{'loss': 0.0097, 'grad_norm': 5.2767839431762695, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.005245956592261791, 'loss_2': 0.004413604736328125, 'loss_3': -16.456085205078125, 'loss_4': 1.5799075365066528, 'epoch': 24.09}
{'loss': 0.0109, 'grad_norm': 4.718379020690918, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.0042319814674556255, 'loss_2': 0.00669097900390625, 'loss_3': -16.39028549194336, 'loss_4': 1.3745532035827637, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 11:06:17,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:17,940 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:07<17:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:25,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012835226021707058, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.847, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008215762674808502, 'eval_loss_2': 0.00461946427822113, 'eval_loss_3': -18.29433250427246, 'eval_loss_4': 1.3696064949035645, 'epoch': 24.1}
{'loss': 0.0079, 'grad_norm': 4.795825004577637, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.0035167497117072344, 'loss_2': 0.00441741943359375, 'loss_3': -16.32793617248535, 'loss_4': 2.150543212890625, 'epoch': 24.1}
{'loss': 0.0226, 'grad_norm': 8.756867408752441, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.013496626168489456, 'loss_2': 0.00914764404296875, 'loss_3': -16.293941497802734, 'loss_4': 1.956594467163086, 'epoch': 24.11}
{'loss': 0.0064, 'grad_norm': 4.464165210723877, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.002830528188496828, 'loss_2': 0.003570556640625, 'loss_3': -16.343997955322266, 'loss_4': 1.4906704425811768, 'epoch': 24.12}
{'loss': 0.0168, 'grad_norm': 6.485403060913086, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.008376735262572765, 'loss_2': 0.008392333984375, 'loss_3': -16.61025619506836, 'loss_4': 1.4066754579544067, 'epoch': 24.12}
{'loss': 0.0184, 'grad_norm': 6.316012382507324, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.010953404009342194, 'loss_2': 0.00740814208984375, 'loss_3': -16.275657653808594, 'loss_4': 1.7000707387924194, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 11:06:25,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:25,296 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:14<17:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:32,644 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012673180550336838, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.291, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008840125054121017, 'eval_loss_2': 0.0038330554962158203, 'eval_loss_3': -18.2878475189209, 'eval_loss_4': 1.3923360109329224, 'epoch': 24.13}
{'loss': 0.0076, 'grad_norm': 4.22728967666626, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.0031394697725772858, 'loss_2': 0.00450897216796875, 'loss_3': -16.433940887451172, 'loss_4': 1.76224946975708, 'epoch': 24.13}
{'loss': 0.0096, 'grad_norm': 4.1752166748046875, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.0026738073211163282, 'loss_2': 0.00689697265625, 'loss_3': -16.390464782714844, 'loss_4': 1.3632287979125977, 'epoch': 24.14}
{'loss': 0.0104, 'grad_norm': 8.11748218536377, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.00776915205642581, 'loss_2': 0.00266265869140625, 'loss_3': -16.386404037475586, 'loss_4': 1.3236079216003418, 'epoch': 24.15}
{'loss': 0.0078, 'grad_norm': 5.7764892578125, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.005225597880780697, 'loss_2': 0.002544403076171875, 'loss_3': -16.479745864868164, 'loss_4': 2.146811008453369, 'epoch': 24.15}
{'loss': 0.0054, 'grad_norm': 4.314984321594238, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.005344880744814873, 'loss_2': 7.587671279907227e-05, 'loss_3': -16.385089874267578, 'loss_4': 2.0357203483581543, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 11:06:32,644 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:32,644 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:22<17:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:39,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012555188499391079, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.473, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00924984272569418, 'eval_loss_2': 0.0033053457736968994, 'eval_loss_3': -18.273744583129883, 'eval_loss_4': 1.3735381364822388, 'epoch': 24.16}
{'loss': 0.011, 'grad_norm': 4.464638710021973, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.00503490399569273, 'loss_2': 0.0059814453125, 'loss_3': -16.229921340942383, 'loss_4': 1.4223175048828125, 'epoch': 24.16}
{'loss': 0.0095, 'grad_norm': 6.729085922241211, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.006072849966585636, 'loss_2': 0.0034084320068359375, 'loss_3': -16.234054565429688, 'loss_4': 1.6614007949829102, 'epoch': 24.17}
{'loss': 0.0066, 'grad_norm': 4.497594356536865, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.005003186874091625, 'loss_2': 0.0016155242919921875, 'loss_3': -16.44580078125, 'loss_4': 1.6400935649871826, 'epoch': 24.17}
{'loss': 0.0107, 'grad_norm': 5.693565845489502, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.006715497467666864, 'loss_2': 0.00399017333984375, 'loss_3': -16.10592269897461, 'loss_4': 2.00567889213562, 'epoch': 24.18}
{'loss': 0.0094, 'grad_norm': 4.989073276519775, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.00625865813344717, 'loss_2': 0.00318145751953125, 'loss_3': -16.3750057220459, 'loss_4': 1.5633026361465454, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 11:06:39,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:39,994 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:29<17:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:47,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014724919572472572, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.407, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010187933221459389, 'eval_loss_2': 0.004536986351013184, 'eval_loss_3': -18.26531410217285, 'eval_loss_4': 1.3806504011154175, 'epoch': 24.19}
{'loss': 0.0029, 'grad_norm': 4.478676795959473, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.002923656953498721, 'loss_2': 1.52587890625e-05, 'loss_3': -16.355297088623047, 'loss_4': 1.2400144338607788, 'epoch': 24.19}
{'loss': 0.0204, 'grad_norm': 14.120230674743652, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.01702609285712242, 'loss_2': 0.003414154052734375, 'loss_3': -16.2384090423584, 'loss_4': 1.4548401832580566, 'epoch': 24.2}
{'loss': 0.0071, 'grad_norm': 5.626164436340332, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.0068725720047950745, 'loss_2': 0.00019288063049316406, 'loss_3': -16.271549224853516, 'loss_4': 1.5974783897399902, 'epoch': 24.2}
{'loss': 0.0041, 'grad_norm': 4.410732269287109, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.0032746666111052036, 'loss_2': 0.000797271728515625, 'loss_3': -16.29232406616211, 'loss_4': 1.7048437595367432, 'epoch': 24.21}
{'loss': 0.0125, 'grad_norm': 6.29556131362915, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.008775190450251102, 'loss_2': 0.00372314453125, 'loss_3': -16.260412216186523, 'loss_4': 2.069871664047241, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 11:06:47,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:47,338 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:36<17:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:54,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015747174620628357, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010383234359323978, 'eval_loss_2': 0.005363941192626953, 'eval_loss_3': -18.261478424072266, 'eval_loss_4': 1.3343379497528076, 'epoch': 24.22}
{'loss': 0.0088, 'grad_norm': 5.716905117034912, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.0060342466458678246, 'loss_2': 0.002727508544921875, 'loss_3': -16.515872955322266, 'loss_4': 1.2857439517974854, 'epoch': 24.22}
{'loss': 0.008, 'grad_norm': 4.509034633636475, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.002099068835377693, 'loss_2': 0.005863189697265625, 'loss_3': -16.42557144165039, 'loss_4': 1.4116895198822021, 'epoch': 24.23}
{'loss': 0.0069, 'grad_norm': 4.972478866577148, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.005409091245383024, 'loss_2': 0.0014505386352539062, 'loss_3': -16.377992630004883, 'loss_4': 1.5334705114364624, 'epoch': 24.23}
{'loss': 0.007, 'grad_norm': 5.417919158935547, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.006890369113534689, 'loss_2': 0.0001327991485595703, 'loss_3': -16.255279541015625, 'loss_4': 1.419590711593628, 'epoch': 24.24}
{'loss': 0.0054, 'grad_norm': 4.257636547088623, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.003542505670338869, 'loss_2': 0.0018587112426757812, 'loss_3': -16.232210159301758, 'loss_4': 1.4070448875427246, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 11:06:54,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:54,688 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:42:44<17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:02,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014262357726693153, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010451569221913815, 'eval_loss_2': 0.0038107894361019135, 'eval_loss_3': -18.261070251464844, 'eval_loss_4': 1.2853084802627563, 'epoch': 24.24}
{'loss': 0.0059, 'grad_norm': 4.550520896911621, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.0018749431474134326, 'loss_2': 0.00400543212890625, 'loss_3': -16.1480655670166, 'loss_4': 0.980699360370636, 'epoch': 24.25}
{'loss': 0.005, 'grad_norm': 4.540003776550293, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.004048376809805632, 'loss_2': 0.0009756088256835938, 'loss_3': -16.284090042114258, 'loss_4': 1.5392733812332153, 'epoch': 24.26}
{'loss': 0.0029, 'grad_norm': 4.450397968292236, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.0019970096182078123, 'loss_2': 0.0009031295776367188, 'loss_3': -16.275718688964844, 'loss_4': 1.0841484069824219, 'epoch': 24.26}
{'loss': 0.0057, 'grad_norm': 4.703028202056885, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.003390755271539092, 'loss_2': 0.002300262451171875, 'loss_3': -16.415498733520508, 'loss_4': 1.9663290977478027, 'epoch': 24.27}
{'loss': 0.0042, 'grad_norm': 4.202582359313965, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.0027171033434569836, 'loss_2': 0.0014801025390625, 'loss_3': -16.318891525268555, 'loss_4': 1.501070261001587, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 11:07:02,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:02,035 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:42:51<16:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:09,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013257240876555443, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.094, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010233049280941486, 'eval_loss_2': 0.003024190664291382, 'eval_loss_3': -18.25342559814453, 'eval_loss_4': 1.295098066329956, 'epoch': 24.27}
{'loss': 0.0069, 'grad_norm': 5.206323623657227, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.0047599016688764095, 'loss_2': 0.00211334228515625, 'loss_3': -16.291057586669922, 'loss_4': 1.5632338523864746, 'epoch': 24.28}
{'loss': 0.0039, 'grad_norm': 4.582340717315674, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.0023871741723269224, 'loss_2': 0.0015239715576171875, 'loss_3': -16.24273109436035, 'loss_4': 1.413295030593872, 'epoch': 24.28}
{'loss': 0.0081, 'grad_norm': 6.902665138244629, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.005750222597271204, 'loss_2': 0.002300262451171875, 'loss_3': -16.335529327392578, 'loss_4': 1.5881558656692505, 'epoch': 24.29}
{'loss': 0.0104, 'grad_norm': 5.521739482879639, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.0063396417535841465, 'loss_2': 0.00406646728515625, 'loss_3': -16.359018325805664, 'loss_4': 1.7753682136535645, 'epoch': 24.3}
{'loss': 0.0068, 'grad_norm': 4.989792346954346, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.005777672864496708, 'loss_2': 0.0009889602661132812, 'loss_3': -16.274885177612305, 'loss_4': 0.7779630422592163, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 11:07:09,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:09,379 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:42:58<16:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:16,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014056493528187275, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.114, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010812094435095787, 'eval_loss_2': 0.0032444000244140625, 'eval_loss_3': -18.25282096862793, 'eval_loss_4': 1.2774152755737305, 'epoch': 24.3}
{'loss': 0.0036, 'grad_norm': 4.464365482330322, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.0019273448269814253, 'loss_2': 0.001697540283203125, 'loss_3': -16.22757339477539, 'loss_4': 1.4920072555541992, 'epoch': 24.31}
{'loss': 0.0106, 'grad_norm': 5.283071041107178, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.0032870243303477764, 'loss_2': 0.00731658935546875, 'loss_3': -16.480655670166016, 'loss_4': 1.519245982170105, 'epoch': 24.31}
{'loss': 0.006, 'grad_norm': 5.599969863891602, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.0055320048704743385, 'loss_2': 0.0004496574401855469, 'loss_3': -16.227128982543945, 'loss_4': 1.4837992191314697, 'epoch': 24.32}
{'loss': 0.0074, 'grad_norm': 4.497101783752441, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.0019958752673119307, 'loss_2': 0.00539398193359375, 'loss_3': -16.311872482299805, 'loss_4': 1.0790222883224487, 'epoch': 24.33}
{'loss': 0.0098, 'grad_norm': 5.440387725830078, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.005920295603573322, 'loss_2': 0.0038471221923828125, 'loss_3': -16.338153839111328, 'loss_4': 1.525434136390686, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 11:07:16,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:16,723 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:06<16:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:24,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01477519515901804, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.279, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011267803609371185, 'eval_loss_2': 0.00350739061832428, 'eval_loss_3': -18.241437911987305, 'eval_loss_4': 1.1944159269332886, 'epoch': 24.33}
{'loss': 0.0079, 'grad_norm': 4.426070213317871, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.001992560690268874, 'loss_2': 0.00594329833984375, 'loss_3': -16.315013885498047, 'loss_4': 1.6506773233413696, 'epoch': 24.34}
{'loss': 0.008, 'grad_norm': 4.896883487701416, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.0032353559508919716, 'loss_2': 0.00479888916015625, 'loss_3': -16.33833885192871, 'loss_4': 1.4458158016204834, 'epoch': 24.34}
{'loss': 0.0047, 'grad_norm': 4.360450744628906, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.0028924867510795593, 'loss_2': 0.001842498779296875, 'loss_3': -16.232879638671875, 'loss_4': 1.2614612579345703, 'epoch': 24.35}
{'loss': 0.0058, 'grad_norm': 4.237306594848633, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.0032631242647767067, 'loss_2': 0.0025234222412109375, 'loss_3': -16.268798828125, 'loss_4': 1.4817187786102295, 'epoch': 24.35}
{'loss': 0.0141, 'grad_norm': 8.419827461242676, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.013557970523834229, 'loss_2': 0.0005598068237304688, 'loss_3': -16.216766357421875, 'loss_4': 1.8381102085113525, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 11:07:24,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:24,071 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:13<16:55,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:07:31,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015039129182696342, 'eval_runtime': 4.005, 'eval_samples_per_second': 255.68, 'eval_steps_per_second': 3.995, 'eval_loss_1': 0.011638444848358631, 'eval_loss_2': 0.0034006834030151367, 'eval_loss_3': -18.224760055541992, 'eval_loss_4': 1.1331827640533447, 'epoch': 24.36}
{'loss': 0.0073, 'grad_norm': 5.407853126525879, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.00608736090362072, 'loss_2': 0.0011835098266601562, 'loss_3': -16.135326385498047, 'loss_4': 1.5218241214752197, 'epoch': 24.37}
{'loss': 0.0091, 'grad_norm': 4.640355110168457, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.0027566873468458652, 'loss_2': 0.00634765625, 'loss_3': -16.149616241455078, 'loss_4': 1.46614408493042, 'epoch': 24.37}
{'loss': 0.0196, 'grad_norm': 10.994026184082031, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.016392329707741737, 'loss_2': 0.003177642822265625, 'loss_3': -16.035430908203125, 'loss_4': 1.6990002393722534, 'epoch': 24.38}
{'loss': 0.0076, 'grad_norm': 6.210103511810303, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.00713766785338521, 'loss_2': 0.0004563331604003906, 'loss_3': -16.42511749267578, 'loss_4': 1.206952691078186, 'epoch': 24.38}
{'loss': 0.0047, 'grad_norm': 4.609036922454834, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0017777750035747886, 'loss_2': 0.002941131591796875, 'loss_3': -16.2413272857666, 'loss_4': 1.5112698078155518, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 11:07:31,622 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:31,622 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:21<16:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:38,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015772560611367226, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012284733355045319, 'eval_loss_2': 0.003487825393676758, 'eval_loss_3': -18.228988647460938, 'eval_loss_4': 1.0966160297393799, 'epoch': 24.39}
{'loss': 0.0125, 'grad_norm': 14.810966491699219, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.010133442468941212, 'loss_2': 0.0023288726806640625, 'loss_3': -16.2803897857666, 'loss_4': 1.9395265579223633, 'epoch': 24.4}
{'loss': 0.0018, 'grad_norm': 4.441361904144287, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.0016105823451653123, 'loss_2': 0.00016808509826660156, 'loss_3': -16.31888198852539, 'loss_4': 1.3215389251708984, 'epoch': 24.4}
{'loss': 0.0081, 'grad_norm': 5.3711442947387695, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.0040254476480185986, 'loss_2': 0.004055023193359375, 'loss_3': -16.246767044067383, 'loss_4': 0.5295004844665527, 'epoch': 24.41}
{'loss': 0.0138, 'grad_norm': 4.431514263153076, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.004254172556102276, 'loss_2': 0.009552001953125, 'loss_3': -16.156505584716797, 'loss_4': 1.3264548778533936, 'epoch': 24.41}
{'loss': 0.0111, 'grad_norm': 5.152232646942139, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.005613321904093027, 'loss_2': 0.005496978759765625, 'loss_3': -16.25965690612793, 'loss_4': 1.1489291191101074, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 11:07:38,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:38,972 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:28<16:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:46,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015006132423877716, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.841, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011609919369220734, 'eval_loss_2': 0.0033962130546569824, 'eval_loss_3': -18.22056770324707, 'eval_loss_4': 1.106048822402954, 'epoch': 24.42}
{'loss': 0.0182, 'grad_norm': 5.173595905303955, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.014646012336015701, 'loss_2': 0.003520965576171875, 'loss_3': -16.247920989990234, 'loss_4': 1.6130516529083252, 'epoch': 24.42}
{'loss': 0.0135, 'grad_norm': 5.159940719604492, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.006612051744014025, 'loss_2': 0.00688934326171875, 'loss_3': -16.355667114257812, 'loss_4': 0.7720613479614258, 'epoch': 24.43}
{'loss': 0.0154, 'grad_norm': 5.48764705657959, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.007432095240801573, 'loss_2': 0.00792694091796875, 'loss_3': -16.27050018310547, 'loss_4': 1.1270387172698975, 'epoch': 24.44}
{'loss': 0.0107, 'grad_norm': 5.218303203582764, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.004085317719727755, 'loss_2': 0.0066375732421875, 'loss_3': -16.04192543029785, 'loss_4': 1.4941964149475098, 'epoch': 24.44}
{'loss': 0.0043, 'grad_norm': 4.56296443939209, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.002987851621583104, 'loss_2': 0.0012989044189453125, 'loss_3': -16.329517364501953, 'loss_4': 1.1952321529388428, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 11:07:46,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:46,326 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:35<16:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:53,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01584506593644619, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.548, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011910534463822842, 'eval_loss_2': 0.003934532403945923, 'eval_loss_3': -18.215492248535156, 'eval_loss_4': 1.1283272504806519, 'epoch': 24.45}
{'loss': 0.0042, 'grad_norm': 4.528891563415527, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.002736210823059082, 'loss_2': 0.0014629364013671875, 'loss_3': -16.443458557128906, 'loss_4': 1.5106127262115479, 'epoch': 24.45}
{'loss': 0.0069, 'grad_norm': 4.741330146789551, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.0030742085073143244, 'loss_2': 0.0037841796875, 'loss_3': -16.207948684692383, 'loss_4': 1.132432460784912, 'epoch': 24.46}
{'loss': 0.0126, 'grad_norm': 5.497306823730469, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.010962462052702904, 'loss_2': 0.0016002655029296875, 'loss_3': -16.085065841674805, 'loss_4': 0.7719129323959351, 'epoch': 24.47}
{'loss': 0.0106, 'grad_norm': 5.3545684814453125, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.0074520292691886425, 'loss_2': 0.003147125244140625, 'loss_3': -16.486034393310547, 'loss_4': 1.146768569946289, 'epoch': 24.47}
{'loss': 0.0038, 'grad_norm': 4.137253761291504, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.00360036245547235, 'loss_2': 0.00021910667419433594, 'loss_3': -16.495391845703125, 'loss_4': 1.1954805850982666, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 11:07:53,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:53,686 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:43:43<16:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:01,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01562933810055256, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.388, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011589664965867996, 'eval_loss_2': 0.004039674997329712, 'eval_loss_3': -18.20578956604004, 'eval_loss_4': 1.0595500469207764, 'epoch': 24.48}
{'loss': 0.013, 'grad_norm': 6.477545738220215, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.011074135079979897, 'loss_2': 0.0019130706787109375, 'loss_3': -16.081872940063477, 'loss_4': 1.5503742694854736, 'epoch': 24.48}
{'loss': 0.002, 'grad_norm': 4.322118759155273, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.0020144691225141287, 'loss_2': 1.609325408935547e-05, 'loss_3': -16.552642822265625, 'loss_4': 1.4864554405212402, 'epoch': 24.49}
{'loss': 0.0138, 'grad_norm': 5.787981033325195, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.004669697489589453, 'loss_2': 0.00916290283203125, 'loss_3': -16.225671768188477, 'loss_4': 1.4498246908187866, 'epoch': 24.49}
{'loss': 0.0047, 'grad_norm': 4.510495185852051, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.003114702645689249, 'loss_2': 0.0015869140625, 'loss_3': -16.493698120117188, 'loss_4': 1.1747257709503174, 'epoch': 24.5}
{'loss': 0.0076, 'grad_norm': 5.3908257484436035, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.0069913361221551895, 'loss_2': 0.0006046295166015625, 'loss_3': -16.295888900756836, 'loss_4': 0.829014778137207, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 11:08:01,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:01,036 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:43:50<16:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:08,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01574847660958767, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.186, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011825567111372948, 'eval_loss_2': 0.003922909498214722, 'eval_loss_3': -18.201740264892578, 'eval_loss_4': 0.9941352009773254, 'epoch': 24.51}
{'loss': 0.0055, 'grad_norm': 4.700899600982666, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.002882604254409671, 'loss_2': 0.002574920654296875, 'loss_3': -16.239736557006836, 'loss_4': 0.6673694252967834, 'epoch': 24.51}
{'loss': 0.0064, 'grad_norm': 5.760521411895752, 'learning_rate': 5.5e-06, 'loss_1': 0.0061567784287035465, 'loss_2': 0.00025177001953125, 'loss_3': -16.26888084411621, 'loss_4': 0.6929579973220825, 'epoch': 24.52}
{'loss': 0.0143, 'grad_norm': 5.779944896697998, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.007752598728984594, 'loss_2': 0.00652313232421875, 'loss_3': -16.19416046142578, 'loss_4': 1.1397960186004639, 'epoch': 24.52}
{'loss': 0.0201, 'grad_norm': 12.480055809020996, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.016863446682691574, 'loss_2': 0.00327301025390625, 'loss_3': -16.468603134155273, 'loss_4': 1.255336046218872, 'epoch': 24.53}
{'loss': 0.0096, 'grad_norm': 4.863015651702881, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.002863314002752304, 'loss_2': 0.006717681884765625, 'loss_3': -16.25870704650879, 'loss_4': 1.4446065425872803, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 11:08:08,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:08,390 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:43:57<16:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:15,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01515178196132183, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011451644822955132, 'eval_loss_2': 0.0037001371383666992, 'eval_loss_3': -18.19575309753418, 'eval_loss_4': 0.9921702146530151, 'epoch': 24.53}
{'loss': 0.004, 'grad_norm': 4.415619373321533, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.003504217369481921, 'loss_2': 0.0005064010620117188, 'loss_3': -16.476057052612305, 'loss_4': 1.2427396774291992, 'epoch': 24.54}
{'loss': 0.0191, 'grad_norm': 5.366125106811523, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.007165020797401667, 'loss_2': 0.011932373046875, 'loss_3': -16.376657485961914, 'loss_4': 0.8638122081756592, 'epoch': 24.55}
{'loss': 0.0102, 'grad_norm': 5.375269412994385, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.007797288708388805, 'loss_2': 0.002353668212890625, 'loss_3': -16.108352661132812, 'loss_4': 1.4865033626556396, 'epoch': 24.55}
{'loss': 0.0057, 'grad_norm': 4.816834926605225, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.004519604612141848, 'loss_2': 0.0011339187622070312, 'loss_3': -16.179210662841797, 'loss_4': 1.1042784452438354, 'epoch': 24.56}
{'loss': 0.0196, 'grad_norm': 6.835597991943359, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.012001248076558113, 'loss_2': 0.00763702392578125, 'loss_3': -16.0750732421875, 'loss_4': 1.13413667678833, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 11:08:15,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:15,742 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:05<16:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:23,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014917666092514992, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011398667469620705, 'eval_loss_2': 0.003518998622894287, 'eval_loss_3': -18.19340705871582, 'eval_loss_4': 0.9925613403320312, 'epoch': 24.56}
{'loss': 0.007, 'grad_norm': 4.853801727294922, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.0057173301465809345, 'loss_2': 0.0012874603271484375, 'loss_3': -16.186635971069336, 'loss_4': 1.0500969886779785, 'epoch': 24.57}
{'loss': 0.0065, 'grad_norm': 5.1987223625183105, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.00546253239735961, 'loss_2': 0.00102996826171875, 'loss_3': -16.151453018188477, 'loss_4': 0.9984867572784424, 'epoch': 24.58}
{'loss': 0.0091, 'grad_norm': 6.363905429840088, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.008634583093225956, 'loss_2': 0.0004508495330810547, 'loss_3': -16.215517044067383, 'loss_4': 1.2486281394958496, 'epoch': 24.58}
{'loss': 0.0128, 'grad_norm': 8.747949600219727, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.00907329935580492, 'loss_2': 0.0037384033203125, 'loss_3': -15.914202690124512, 'loss_4': 1.281348466873169, 'epoch': 24.59}
{'loss': 0.021, 'grad_norm': 24.041501998901367, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.02023916319012642, 'loss_2': 0.0008001327514648438, 'loss_3': -16.252975463867188, 'loss_4': 0.4462566077709198, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 11:08:23,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:23,086 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:12<16:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:30,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014493195340037346, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.544, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010939694941043854, 'eval_loss_2': 0.0035535022616386414, 'eval_loss_3': -18.203996658325195, 'eval_loss_4': 0.9771854281425476, 'epoch': 24.59}
{'loss': 0.0041, 'grad_norm': 4.450960159301758, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.00247039832174778, 'loss_2': 0.0015916824340820312, 'loss_3': -16.206146240234375, 'loss_4': 1.4262142181396484, 'epoch': 24.6}
{'loss': 0.0094, 'grad_norm': 4.9500627517700195, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.004506218247115612, 'loss_2': 0.0048828125, 'loss_3': -16.248279571533203, 'loss_4': 0.988419234752655, 'epoch': 24.6}
{'loss': 0.0231, 'grad_norm': 6.443734645843506, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.016229048371315002, 'loss_2': 0.00682830810546875, 'loss_3': -16.164508819580078, 'loss_4': 1.2482686042785645, 'epoch': 24.61}
{'loss': 0.0101, 'grad_norm': 7.858382225036621, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.008975857868790627, 'loss_2': 0.0011615753173828125, 'loss_3': -16.161142349243164, 'loss_4': 1.4465378522872925, 'epoch': 24.62}
{'loss': 0.0081, 'grad_norm': 5.790124416351318, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.005150493700057268, 'loss_2': 0.002960205078125, 'loss_3': -16.468975067138672, 'loss_4': 0.8147727251052856, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 11:08:30,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:30,433 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:19<15:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:37,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013877770863473415, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.297, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010614095255732536, 'eval_loss_2': 0.0032636746764183044, 'eval_loss_3': -18.211284637451172, 'eval_loss_4': 1.0172276496887207, 'epoch': 24.62}
{'loss': 0.0119, 'grad_norm': 4.873140335083008, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.007874935865402222, 'loss_2': 0.0040283203125, 'loss_3': -16.252613067626953, 'loss_4': 0.9241337776184082, 'epoch': 24.63}
{'loss': 0.0123, 'grad_norm': 8.018216133117676, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.01151569839566946, 'loss_2': 0.000797271728515625, 'loss_3': -16.073772430419922, 'loss_4': 1.335888147354126, 'epoch': 24.63}
{'loss': 0.0064, 'grad_norm': 4.347967624664307, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.003530157497152686, 'loss_2': 0.00284576416015625, 'loss_3': -16.091794967651367, 'loss_4': 1.5183250904083252, 'epoch': 24.64}
{'loss': 0.0111, 'grad_norm': 4.940629005432129, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.007566838525235653, 'loss_2': 0.003570556640625, 'loss_3': -16.364702224731445, 'loss_4': 1.0103816986083984, 'epoch': 24.65}
{'loss': 0.0028, 'grad_norm': 4.6591386795043945, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.002185321180149913, 'loss_2': 0.0005779266357421875, 'loss_3': -16.21163558959961, 'loss_4': 0.5987588763237, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 11:08:37,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:37,778 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:27<15:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:45,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013604434207081795, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.334, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01018542144447565, 'eval_loss_2': 0.0034190118312835693, 'eval_loss_3': -18.21678924560547, 'eval_loss_4': 1.076778531074524, 'epoch': 24.65}
{'loss': 0.008, 'grad_norm': 4.713497638702393, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.002446548081934452, 'loss_2': 0.0055389404296875, 'loss_3': -16.227209091186523, 'loss_4': 1.583508014678955, 'epoch': 24.66}
{'loss': 0.0073, 'grad_norm': 5.25171422958374, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.004520834423601627, 'loss_2': 0.00274658203125, 'loss_3': -16.150066375732422, 'loss_4': 1.116418719291687, 'epoch': 24.66}
{'loss': 0.004, 'grad_norm': 4.616125106811523, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.003919316455721855, 'loss_2': 8.89897346496582e-05, 'loss_3': -16.13839340209961, 'loss_4': 1.2575972080230713, 'epoch': 24.67}
{'loss': 0.0094, 'grad_norm': 5.470803260803223, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.007503035012632608, 'loss_2': 0.00188446044921875, 'loss_3': -16.374391555786133, 'loss_4': 0.6543084979057312, 'epoch': 24.67}
{'loss': 0.0049, 'grad_norm': 4.712088108062744, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.003623450640588999, 'loss_2': 0.001323699951171875, 'loss_3': -16.151599884033203, 'loss_4': 0.5715299844741821, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 11:08:45,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:45,118 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:34<15:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:52,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014235164038836956, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.399, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010053697042167187, 'eval_loss_2': 0.004181466996669769, 'eval_loss_3': -18.227649688720703, 'eval_loss_4': 1.130666732788086, 'epoch': 24.68}
{'loss': 0.0227, 'grad_norm': 12.168661117553711, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.01603705622255802, 'loss_2': 0.006710052490234375, 'loss_3': -16.208740234375, 'loss_4': 1.6966524124145508, 'epoch': 24.69}
{'loss': 0.0124, 'grad_norm': 6.041758060455322, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.01128618698567152, 'loss_2': 0.00109100341796875, 'loss_3': -16.151002883911133, 'loss_4': 1.3799680471420288, 'epoch': 24.69}
{'loss': 0.0096, 'grad_norm': 4.612148284912109, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.0038408818654716015, 'loss_2': 0.0057373046875, 'loss_3': -16.264209747314453, 'loss_4': 1.170988917350769, 'epoch': 24.7}
{'loss': 0.0069, 'grad_norm': 4.756302833557129, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.0033535067923367023, 'loss_2': 0.0035305023193359375, 'loss_3': -16.050609588623047, 'loss_4': 1.4500200748443604, 'epoch': 24.7}
{'loss': 0.0081, 'grad_norm': 5.013980865478516, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.004699146840721369, 'loss_2': 0.00344085693359375, 'loss_3': -16.304006576538086, 'loss_4': 1.1247225999832153, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 11:08:52,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:52,459 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:41<15:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:59,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0141206756234169, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009656415320932865, 'eval_loss_2': 0.00446426123380661, 'eval_loss_3': -18.230676651000977, 'eval_loss_4': 1.128982424736023, 'epoch': 24.71}
{'loss': 0.0243, 'grad_norm': 6.249401569366455, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.014467482455074787, 'loss_2': 0.00980377197265625, 'loss_3': -16.14141082763672, 'loss_4': 0.9482579231262207, 'epoch': 24.72}
{'loss': 0.0067, 'grad_norm': 5.170113563537598, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.005401861388236284, 'loss_2': 0.0013256072998046875, 'loss_3': -16.197166442871094, 'loss_4': 1.5988327264785767, 'epoch': 24.72}
{'loss': 0.0066, 'grad_norm': 4.47197961807251, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.0019700932316482067, 'loss_2': 0.004596710205078125, 'loss_3': -16.270397186279297, 'loss_4': 1.244296908378601, 'epoch': 24.73}
{'loss': 0.009, 'grad_norm': 4.698534965515137, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.0030121051240712404, 'loss_2': 0.00600433349609375, 'loss_3': -16.37185287475586, 'loss_4': 1.3514262437820435, 'epoch': 24.73}
{'loss': 0.0062, 'grad_norm': 5.4529805183410645, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.00574870640411973, 'loss_2': 0.00045680999755859375, 'loss_3': -16.12368392944336, 'loss_4': 1.2344387769699097, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 11:08:59,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:59,808 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:44:49<15:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:07,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011932432651519775, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008790962398052216, 'eval_loss_2': 0.00314147025346756, 'eval_loss_3': -18.234426498413086, 'eval_loss_4': 1.1436939239501953, 'epoch': 24.74}
{'loss': 0.0079, 'grad_norm': 4.560560703277588, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.0052861436270177364, 'loss_2': 0.0025806427001953125, 'loss_3': -16.36138916015625, 'loss_4': 1.520477533340454, 'epoch': 24.74}
{'loss': 0.005, 'grad_norm': 4.410839557647705, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.002064923755824566, 'loss_2': 0.002971649169921875, 'loss_3': -16.223827362060547, 'loss_4': 1.129384994506836, 'epoch': 24.75}
{'loss': 0.0116, 'grad_norm': 6.571974754333496, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.009442073293030262, 'loss_2': 0.002109527587890625, 'loss_3': -16.310535430908203, 'loss_4': 1.5153992176055908, 'epoch': 24.76}
{'loss': 0.0029, 'grad_norm': 4.169511795043945, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.002143504098057747, 'loss_2': 0.0007963180541992188, 'loss_3': -16.206188201904297, 'loss_4': 0.9684003591537476, 'epoch': 24.76}
{'loss': 0.0073, 'grad_norm': 5.539186954498291, 'learning_rate': 5.25e-06, 'loss_1': 0.006000051740556955, 'loss_2': 0.0012969970703125, 'loss_3': -16.139057159423828, 'loss_4': 2.022251605987549, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 11:09:07,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:07,158 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:44:56<15:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:14,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010874703526496887, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.695, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0077136908657848835, 'eval_loss_2': 0.003161013126373291, 'eval_loss_3': -18.23603630065918, 'eval_loss_4': 1.1050233840942383, 'epoch': 24.77}
{'loss': 0.0078, 'grad_norm': 4.559642791748047, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.0031037330627441406, 'loss_2': 0.004734039306640625, 'loss_3': -16.305227279663086, 'loss_4': 1.7965221405029297, 'epoch': 24.77}
{'loss': 0.0119, 'grad_norm': 7.040902137756348, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.00889801699668169, 'loss_2': 0.002986907958984375, 'loss_3': -16.19005584716797, 'loss_4': 1.180064082145691, 'epoch': 24.78}
{'loss': 0.0019, 'grad_norm': 4.554984092712402, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.001639801892451942, 'loss_2': 0.0002536773681640625, 'loss_3': -16.39604949951172, 'loss_4': 1.605615496635437, 'epoch': 24.78}
{'loss': 0.0038, 'grad_norm': 4.675253868103027, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.002591354539617896, 'loss_2': 0.0011959075927734375, 'loss_3': -16.46771812438965, 'loss_4': 1.361302375793457, 'epoch': 24.79}
{'loss': 0.006, 'grad_norm': 4.700871467590332, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.003994490951299667, 'loss_2': 0.00199127197265625, 'loss_3': -16.269622802734375, 'loss_4': 1.6718518733978271, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 11:09:14,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:14,514 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:04<15:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:21,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011091236025094986, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00768630625680089, 'eval_loss_2': 0.0034049302339553833, 'eval_loss_3': -18.244606018066406, 'eval_loss_4': 1.0936516523361206, 'epoch': 24.8}
{'loss': 0.0048, 'grad_norm': 4.144786834716797, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.0036871316842734814, 'loss_2': 0.0011196136474609375, 'loss_3': -16.252079010009766, 'loss_4': 1.4804948568344116, 'epoch': 24.8}
{'loss': 0.0056, 'grad_norm': 4.852216720581055, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.0035506871063262224, 'loss_2': 0.002010345458984375, 'loss_3': -16.226158142089844, 'loss_4': 1.1445560455322266, 'epoch': 24.81}
{'loss': 0.0037, 'grad_norm': 4.965167999267578, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.00304447952657938, 'loss_2': 0.0006704330444335938, 'loss_3': -16.45238494873047, 'loss_4': 1.250160574913025, 'epoch': 24.81}
{'loss': 0.0073, 'grad_norm': 4.683781623840332, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.005376838147640228, 'loss_2': 0.001911163330078125, 'loss_3': -16.30893898010254, 'loss_4': 1.4513134956359863, 'epoch': 24.82}
{'loss': 0.0054, 'grad_norm': 3.933575391769409, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.0024127382785081863, 'loss_2': 0.0029544830322265625, 'loss_3': -16.28016471862793, 'loss_4': 1.4956034421920776, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 11:09:21,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:21,861 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:11<15:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:29,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012011164799332619, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.376, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008211630396544933, 'eval_loss_2': 0.00379953533411026, 'eval_loss_3': -18.23617935180664, 'eval_loss_4': 1.1146320104599, 'epoch': 24.83}
{'loss': 0.0066, 'grad_norm': 4.469211101531982, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.002642047591507435, 'loss_2': 0.00394439697265625, 'loss_3': -16.367267608642578, 'loss_4': 0.9861038327217102, 'epoch': 24.83}
{'loss': 0.0074, 'grad_norm': 5.819447994232178, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.007000418845564127, 'loss_2': 0.0003788471221923828, 'loss_3': -16.092519760131836, 'loss_4': 1.6909829378128052, 'epoch': 24.84}
{'loss': 0.0036, 'grad_norm': 4.330234050750732, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.003000590717419982, 'loss_2': 0.00061798095703125, 'loss_3': -16.278858184814453, 'loss_4': 1.2346653938293457, 'epoch': 24.84}
{'loss': 0.0082, 'grad_norm': 4.741664409637451, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.002993811620399356, 'loss_2': 0.00519561767578125, 'loss_3': -16.20569610595703, 'loss_4': 1.5090161561965942, 'epoch': 24.85}
{'loss': 0.0109, 'grad_norm': 6.081479072570801, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.0057426923885941505, 'loss_2': 0.00511932373046875, 'loss_3': -16.24280548095703, 'loss_4': 1.4662351608276367, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 11:09:29,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:29,214 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:18<15:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:36,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012330958619713783, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.408, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008639056235551834, 'eval_loss_2': 0.0036919042468070984, 'eval_loss_3': -18.226058959960938, 'eval_loss_4': 1.1090000867843628, 'epoch': 24.85}
{'loss': 0.0038, 'grad_norm': 4.268636226654053, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.002179228002205491, 'loss_2': 0.0016260147094726562, 'loss_3': -16.28044891357422, 'loss_4': 1.183271884918213, 'epoch': 24.86}
{'loss': 0.0066, 'grad_norm': 4.73065710067749, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.003621641779318452, 'loss_2': 0.00298309326171875, 'loss_3': -16.299463272094727, 'loss_4': 1.445136547088623, 'epoch': 24.87}
{'loss': 0.0068, 'grad_norm': 6.294332027435303, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.005001929588615894, 'loss_2': 0.0018100738525390625, 'loss_3': -16.28190040588379, 'loss_4': 1.2823593616485596, 'epoch': 24.87}
{'loss': 0.0072, 'grad_norm': 5.044837474822998, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.0037948456592857838, 'loss_2': 0.0033626556396484375, 'loss_3': -16.176342010498047, 'loss_4': 1.0504417419433594, 'epoch': 24.88}
{'loss': 0.0039, 'grad_norm': 4.444668292999268, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.0025705136358737946, 'loss_2': 0.0013675689697265625, 'loss_3': -16.28821563720703, 'loss_4': 1.6996850967407227, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 11:09:36,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:36,559 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:26<15:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:43,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012198306620121002, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.439, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008944818750023842, 'eval_loss_2': 0.0032534897327423096, 'eval_loss_3': -18.225244522094727, 'eval_loss_4': 1.1128544807434082, 'epoch': 24.88}
{'loss': 0.0048, 'grad_norm': 4.9749674797058105, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.0023679325822740793, 'loss_2': 0.00246429443359375, 'loss_3': -16.446834564208984, 'loss_4': 1.633750557899475, 'epoch': 24.89}
{'loss': 0.005, 'grad_norm': 5.064563751220703, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.0036683438811451197, 'loss_2': 0.0013561248779296875, 'loss_3': -16.138885498046875, 'loss_4': 1.4917881488800049, 'epoch': 24.9}
{'loss': 0.0094, 'grad_norm': 4.7374372482299805, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.004520925227552652, 'loss_2': 0.004848480224609375, 'loss_3': -16.22145652770996, 'loss_4': 2.084613561630249, 'epoch': 24.9}
{'loss': 0.0064, 'grad_norm': 4.681769847869873, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.004059655591845512, 'loss_2': 0.002315521240234375, 'loss_3': -16.331653594970703, 'loss_4': 1.6936640739440918, 'epoch': 24.91}
{'loss': 0.0046, 'grad_norm': 4.462807655334473, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.0034763410221785307, 'loss_2': 0.00110626220703125, 'loss_3': -16.366697311401367, 'loss_4': 1.6131277084350586, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 11:09:43,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:43,905 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:33<15:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:51,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011531204916536808, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008387603797018528, 'eval_loss_2': 0.00314360111951828, 'eval_loss_3': -18.22809410095215, 'eval_loss_4': 1.0387035608291626, 'epoch': 24.91}
{'loss': 0.0047, 'grad_norm': 4.952106952667236, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.0034307115711271763, 'loss_2': 0.0013074874877929688, 'loss_3': -16.216081619262695, 'loss_4': 1.4377495050430298, 'epoch': 24.92}
{'loss': 0.0053, 'grad_norm': 4.6412129402160645, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.004768685437738895, 'loss_2': 0.0005269050598144531, 'loss_3': -16.318401336669922, 'loss_4': 1.2279176712036133, 'epoch': 24.92}
{'loss': 0.0107, 'grad_norm': 5.634103298187256, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.005995380692183971, 'loss_2': 0.004665374755859375, 'loss_3': -16.215543746948242, 'loss_4': 1.3715355396270752, 'epoch': 24.93}
{'loss': 0.0069, 'grad_norm': 4.521639823913574, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.003646536497399211, 'loss_2': 0.0032196044921875, 'loss_3': -16.246257781982422, 'loss_4': 1.3173725605010986, 'epoch': 24.94}
{'loss': 0.0073, 'grad_norm': 5.2833452224731445, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.0037136913742870092, 'loss_2': 0.00360107421875, 'loss_3': -16.300235748291016, 'loss_4': 1.3330066204071045, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 11:09:51,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:51,262 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:40<14:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:58,605 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011479335837066174, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008263039402663708, 'eval_loss_2': 0.003216296434402466, 'eval_loss_3': -18.231077194213867, 'eval_loss_4': 1.0188088417053223, 'epoch': 24.94}
{'loss': 0.0054, 'grad_norm': 4.905296802520752, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.004332137294113636, 'loss_2': 0.0010509490966796875, 'loss_3': -16.48482322692871, 'loss_4': 1.548274278640747, 'epoch': 24.95}
{'loss': 0.0093, 'grad_norm': 5.3979902267456055, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.008938285522162914, 'loss_2': 0.0003597736358642578, 'loss_3': -16.179555892944336, 'loss_4': 1.350799798965454, 'epoch': 24.95}
{'loss': 0.0025, 'grad_norm': 4.624687194824219, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.0019649192690849304, 'loss_2': 0.0005512237548828125, 'loss_3': -16.0531005859375, 'loss_4': 1.5369744300842285, 'epoch': 24.96}
{'loss': 0.0074, 'grad_norm': 4.442824840545654, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.0024586536455899477, 'loss_2': 0.00492095947265625, 'loss_3': -16.458961486816406, 'loss_4': 1.4047527313232422, 'epoch': 24.97}
{'loss': 0.0089, 'grad_norm': 7.619256496429443, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.0075408583506941795, 'loss_2': 0.0013637542724609375, 'loss_3': -16.266504287719727, 'loss_4': 1.3837416172027588, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 11:09:58,605 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:58,605 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:45:47<13:23,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 11:10:05,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011979210190474987, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008305714465677738, 'eval_loss_2': 0.0036734938621520996, 'eval_loss_3': -18.239282608032227, 'eval_loss_4': 1.022867202758789, 'epoch': 24.97}
{'loss': 0.0089, 'grad_norm': 4.754010200500488, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.006559115834534168, 'loss_2': 0.002384185791015625, 'loss_3': -16.074832916259766, 'loss_4': 1.3018641471862793, 'epoch': 24.98}
{'loss': 0.0045, 'grad_norm': 4.3227219581604, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.0027482069563120604, 'loss_2': 0.0017223358154296875, 'loss_3': -16.21749496459961, 'loss_4': 1.7058112621307373, 'epoch': 24.98}
{'loss': 0.004, 'grad_norm': 4.600374221801758, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.0023285995703190565, 'loss_2': 0.0016832351684570312, 'loss_3': -16.449909210205078, 'loss_4': 1.805704951286316, 'epoch': 24.99}
{'loss': 0.0054, 'grad_norm': 4.757086753845215, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.004569703713059425, 'loss_2': 0.0007991790771484375, 'loss_3': -16.340152740478516, 'loss_4': 1.1543552875518799, 'epoch': 24.99}
{'loss': 0.0093, 'grad_norm': 5.902032375335693, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.000799229834228754, 'loss_2': 0.0084686279296875, 'loss_3': -16.526107788085938, 'loss_4': 2.1565608978271484, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 11:10:05,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:05,603 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:45:55<14:35,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:10:13,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011876129545271397, 'eval_runtime': 3.8181, 'eval_samples_per_second': 268.195, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.008482121862471104, 'eval_loss_2': 0.003394007682800293, 'eval_loss_3': -18.244844436645508, 'eval_loss_4': 1.0382760763168335, 'epoch': 25.0}
{'loss': 0.0147, 'grad_norm': 4.637665748596191, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.006783956661820412, 'loss_2': 0.0079193115234375, 'loss_3': -16.138668060302734, 'loss_4': 1.2426668405532837, 'epoch': 25.01}
{'loss': 0.008, 'grad_norm': 5.474693775177002, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.005756274331361055, 'loss_2': 0.0022716522216796875, 'loss_3': -16.321224212646484, 'loss_4': 1.5978937149047852, 'epoch': 25.01}
{'loss': 0.0068, 'grad_norm': 4.6699137687683105, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.0022830564994364977, 'loss_2': 0.004520416259765625, 'loss_3': -16.222293853759766, 'loss_4': 1.3942339420318604, 'epoch': 25.02}
{'loss': 0.0119, 'grad_norm': 8.241098403930664, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.00857553817331791, 'loss_2': 0.0033054351806640625, 'loss_3': -16.320720672607422, 'loss_4': 1.603032112121582, 'epoch': 25.02}
{'loss': 0.0115, 'grad_norm': 5.6011128425598145, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.009586636908352375, 'loss_2': 0.001911163330078125, 'loss_3': -16.363140106201172, 'loss_4': 1.1156871318817139, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 11:10:13,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:13,007 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:02<14:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:20,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01177924033254385, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008535881526768208, 'eval_loss_2': 0.003243356943130493, 'eval_loss_3': -18.245529174804688, 'eval_loss_4': 1.040919542312622, 'epoch': 25.03}
{'loss': 0.0152, 'grad_norm': 5.726086616516113, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.006300594191998243, 'loss_2': 0.00894927978515625, 'loss_3': -16.350536346435547, 'loss_4': 1.0098974704742432, 'epoch': 25.03}
{'loss': 0.0173, 'grad_norm': 4.955565929412842, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.005786378402262926, 'loss_2': 0.01146697998046875, 'loss_3': -16.306108474731445, 'loss_4': 1.5663409233093262, 'epoch': 25.04}
{'loss': 0.0065, 'grad_norm': 4.44459867477417, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.0033413514029234648, 'loss_2': 0.003143310546875, 'loss_3': -16.182315826416016, 'loss_4': 1.1452181339263916, 'epoch': 25.05}
{'loss': 0.0097, 'grad_norm': 4.561347007751465, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.00393168069422245, 'loss_2': 0.00579071044921875, 'loss_3': -16.21011734008789, 'loss_4': 1.3821738958358765, 'epoch': 25.05}
{'loss': 0.0125, 'grad_norm': 6.801436901092529, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.0061656455509364605, 'loss_2': 0.006320953369140625, 'loss_3': -16.34185218811035, 'loss_4': 1.118655800819397, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 11:10:20,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:20,348 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:09<14:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:27,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012111996300518513, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00855344906449318, 'eval_loss_2': 0.003558546304702759, 'eval_loss_3': -18.24192237854004, 'eval_loss_4': 0.9643376469612122, 'epoch': 25.06}
{'loss': 0.0064, 'grad_norm': 4.508744239807129, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.0028879304882138968, 'loss_2': 0.003467559814453125, 'loss_3': -16.37213897705078, 'loss_4': 1.001979112625122, 'epoch': 25.06}
{'loss': 0.0025, 'grad_norm': 4.507925033569336, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.0015992042608559132, 'loss_2': 0.0009059906005859375, 'loss_3': -16.286291122436523, 'loss_4': 0.6822731494903564, 'epoch': 25.07}
{'loss': 0.0097, 'grad_norm': 6.003973007202148, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.007474793586879969, 'loss_2': 0.00223541259765625, 'loss_3': -16.292400360107422, 'loss_4': 1.2807605266571045, 'epoch': 25.08}
{'loss': 0.0059, 'grad_norm': 4.3133015632629395, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.002234656596556306, 'loss_2': 0.00363922119140625, 'loss_3': -16.23809051513672, 'loss_4': 0.842197835445404, 'epoch': 25.08}
{'loss': 0.0134, 'grad_norm': 5.748624801635742, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.008203443139791489, 'loss_2': 0.005218505859375, 'loss_3': -16.391132354736328, 'loss_4': 1.512036681175232, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 11:10:27,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:27,691 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:17<14:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:35,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012080943211913109, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008727215230464935, 'eval_loss_2': 0.0033537298440933228, 'eval_loss_3': -18.247896194458008, 'eval_loss_4': 0.8665693402290344, 'epoch': 25.09}
{'loss': 0.0044, 'grad_norm': 4.130174160003662, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.003848209511488676, 'loss_2': 0.000579833984375, 'loss_3': -16.233909606933594, 'loss_4': 1.3576087951660156, 'epoch': 25.09}
{'loss': 0.0052, 'grad_norm': 4.457833766937256, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.004444143269211054, 'loss_2': 0.00074005126953125, 'loss_3': -16.422367095947266, 'loss_4': 1.866172194480896, 'epoch': 25.1}
{'loss': 0.0046, 'grad_norm': 4.604421615600586, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.0026768180541694164, 'loss_2': 0.0018978118896484375, 'loss_3': -16.493961334228516, 'loss_4': 0.8278275728225708, 'epoch': 25.1}
{'loss': 0.006, 'grad_norm': 4.431516647338867, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.0032276136334985495, 'loss_2': 0.002773284912109375, 'loss_3': -16.24017333984375, 'loss_4': 1.1030935049057007, 'epoch': 25.11}
{'loss': 0.0112, 'grad_norm': 4.270750045776367, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.003565722145140171, 'loss_2': 0.00763702392578125, 'loss_3': -16.321001052856445, 'loss_4': 1.4257689714431763, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 11:10:35,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:35,039 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:24<14:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:42,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011572740972042084, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.579, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008512073196470737, 'eval_loss_2': 0.003060668706893921, 'eval_loss_3': -18.255882263183594, 'eval_loss_4': 0.8144282102584839, 'epoch': 25.12}
{'loss': 0.0031, 'grad_norm': 4.416277885437012, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.0023763864301145077, 'loss_2': 0.0007658004760742188, 'loss_3': -16.400196075439453, 'loss_4': 1.1038789749145508, 'epoch': 25.12}
{'loss': 0.0044, 'grad_norm': 4.541846752166748, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.0013710783096030354, 'loss_2': 0.00304412841796875, 'loss_3': -16.413787841796875, 'loss_4': 0.7032407522201538, 'epoch': 25.13}
{'loss': 0.0092, 'grad_norm': 5.4445672035217285, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.006804205011576414, 'loss_2': 0.0024127960205078125, 'loss_3': -16.425209045410156, 'loss_4': 1.1066311597824097, 'epoch': 25.13}
{'loss': 0.0085, 'grad_norm': 5.735137462615967, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.004779335111379623, 'loss_2': 0.0037384033203125, 'loss_3': -16.365753173828125, 'loss_4': 0.6290041208267212, 'epoch': 25.14}
{'loss': 0.0137, 'grad_norm': 5.157950401306152, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.00619206577539444, 'loss_2': 0.007549285888671875, 'loss_3': -16.5101261138916, 'loss_4': 0.9459137916564941, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 11:10:42,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:42,381 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:31<14:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:49,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011576062999665737, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.605, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008205032907426357, 'eval_loss_2': 0.00337103009223938, 'eval_loss_3': -18.26490020751953, 'eval_loss_4': 0.840791642665863, 'epoch': 25.15}
{'loss': 0.0064, 'grad_norm': 4.631224155426025, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.0052580563351511955, 'loss_2': 0.00116729736328125, 'loss_3': -16.24312400817871, 'loss_4': 0.7505406141281128, 'epoch': 25.15}
{'loss': 0.0117, 'grad_norm': 4.433355808258057, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.0021370011381804943, 'loss_2': 0.0095672607421875, 'loss_3': -16.369966506958008, 'loss_4': 1.3339760303497314, 'epoch': 25.16}
{'loss': 0.0111, 'grad_norm': 5.854295253753662, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.005019292701035738, 'loss_2': 0.006114959716796875, 'loss_3': -16.242652893066406, 'loss_4': 1.312451720237732, 'epoch': 25.16}
{'loss': 0.0042, 'grad_norm': 4.24453067779541, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.00261133536696434, 'loss_2': 0.0016145706176757812, 'loss_3': -16.2701473236084, 'loss_4': 1.3156578540802002, 'epoch': 25.17}
{'loss': 0.0049, 'grad_norm': 4.594329357147217, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.0023078112863004208, 'loss_2': 0.00257110595703125, 'loss_3': -16.36135482788086, 'loss_4': 1.1044787168502808, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 11:10:49,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:49,724 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:39<14:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:57,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011626293882727623, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00845388974994421, 'eval_loss_2': 0.0031724050641059875, 'eval_loss_3': -18.27326011657715, 'eval_loss_4': 0.8544570207595825, 'epoch': 25.17}
{'loss': 0.0085, 'grad_norm': 5.185966968536377, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.004434497095644474, 'loss_2': 0.00405120849609375, 'loss_3': -16.157920837402344, 'loss_4': 1.5120011568069458, 'epoch': 25.18}
{'loss': 0.0086, 'grad_norm': 5.978634834289551, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.007256431970745325, 'loss_2': 0.0013751983642578125, 'loss_3': -16.16888427734375, 'loss_4': 1.3827860355377197, 'epoch': 25.19}
{'loss': 0.0105, 'grad_norm': 5.780218124389648, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.004397076088935137, 'loss_2': 0.006072998046875, 'loss_3': -16.396469116210938, 'loss_4': 0.8362508416175842, 'epoch': 25.19}
{'loss': 0.0086, 'grad_norm': 5.420274257659912, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.005914303008466959, 'loss_2': 0.0027256011962890625, 'loss_3': -16.245872497558594, 'loss_4': 1.518738865852356, 'epoch': 25.2}
{'loss': 0.013, 'grad_norm': 5.075892925262451, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.00749319139868021, 'loss_2': 0.005489349365234375, 'loss_3': -16.399959564208984, 'loss_4': 1.3074212074279785, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 11:10:57,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:57,062 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:46:46<14:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:04,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012225976213812828, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.447, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00853552483022213, 'eval_loss_2': 0.0036904513835906982, 'eval_loss_3': -18.274991989135742, 'eval_loss_4': 0.8815462589263916, 'epoch': 25.2}
{'loss': 0.0037, 'grad_norm': 5.278076648712158, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.003362914314493537, 'loss_2': 0.0002884864807128906, 'loss_3': -16.368370056152344, 'loss_4': 1.145172357559204, 'epoch': 25.21}
{'loss': 0.0058, 'grad_norm': 4.55055046081543, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.0026748385280370712, 'loss_2': 0.0030765533447265625, 'loss_3': -16.19269561767578, 'loss_4': 0.7157872915267944, 'epoch': 25.22}
{'loss': 0.0151, 'grad_norm': 5.4283671379089355, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.007845977321267128, 'loss_2': 0.00730133056640625, 'loss_3': -16.30118179321289, 'loss_4': 0.987413227558136, 'epoch': 25.22}
{'loss': 0.008, 'grad_norm': 4.8344526290893555, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.00527317775413394, 'loss_2': 0.0027713775634765625, 'loss_3': -16.09618377685547, 'loss_4': 1.3375575542449951, 'epoch': 25.23}
{'loss': 0.0102, 'grad_norm': 4.70006799697876, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.0032256869599223137, 'loss_2': 0.006984710693359375, 'loss_3': -16.356868743896484, 'loss_4': 1.921960473060608, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 11:11:04,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:04,406 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:46:53<14:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:11,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01329883374273777, 'eval_runtime': 3.8378, 'eval_samples_per_second': 266.818, 'eval_steps_per_second': 4.169, 'eval_loss_1': 0.009258450008928776, 'eval_loss_2': 0.00404038280248642, 'eval_loss_3': -18.270721435546875, 'eval_loss_4': 0.9021531343460083, 'epoch': 25.23}
{'loss': 0.0049, 'grad_norm': 4.439479351043701, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.003984937444329262, 'loss_2': 0.0009250640869140625, 'loss_3': -16.262344360351562, 'loss_4': 0.4000694751739502, 'epoch': 25.24}
{'loss': 0.0124, 'grad_norm': 7.154938220977783, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.011674267239868641, 'loss_2': 0.0007009506225585938, 'loss_3': -16.278785705566406, 'loss_4': 1.0077598094940186, 'epoch': 25.24}
{'loss': 0.0122, 'grad_norm': 4.551860809326172, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.004533345345407724, 'loss_2': 0.00769805908203125, 'loss_3': -16.354211807250977, 'loss_4': 0.7145241498947144, 'epoch': 25.25}
{'loss': 0.0194, 'grad_norm': 6.992825984954834, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.014103013090789318, 'loss_2': 0.005306243896484375, 'loss_3': -16.24394989013672, 'loss_4': 1.5268309116363525, 'epoch': 25.26}
{'loss': 0.0107, 'grad_norm': 5.647963523864746, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.005364265758544207, 'loss_2': 0.0053558349609375, 'loss_3': -16.191036224365234, 'loss_4': 1.6101418733596802, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 11:11:11,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:11,798 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:01<14:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:19,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0138529222458601, 'eval_runtime': 3.8219, 'eval_samples_per_second': 267.927, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.009756181389093399, 'eval_loss_2': 0.0040967389941215515, 'eval_loss_3': -18.264001846313477, 'eval_loss_4': 0.9234718680381775, 'epoch': 25.26}
{'loss': 0.0064, 'grad_norm': 4.84091854095459, 'learning_rate': 4.75e-06, 'loss_1': 0.004848191048949957, 'loss_2': 0.001590728759765625, 'loss_3': -16.280981063842773, 'loss_4': 1.095506191253662, 'epoch': 25.27}
{'loss': 0.0114, 'grad_norm': 4.718528747558594, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.004867827519774437, 'loss_2': 0.006534576416015625, 'loss_3': -16.475990295410156, 'loss_4': 1.3880982398986816, 'epoch': 25.27}
{'loss': 0.0065, 'grad_norm': 4.8340744972229, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.005028632935136557, 'loss_2': 0.00145721435546875, 'loss_3': -16.228965759277344, 'loss_4': 1.0112006664276123, 'epoch': 25.28}
{'loss': 0.0056, 'grad_norm': 4.519816875457764, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.003017075825482607, 'loss_2': 0.0026092529296875, 'loss_3': -16.148834228515625, 'loss_4': 0.9697567820549011, 'epoch': 25.28}
{'loss': 0.0243, 'grad_norm': 16.078968048095703, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.022626135498285294, 'loss_2': 0.0016279220581054688, 'loss_3': -16.01926040649414, 'loss_4': 1.804906964302063, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 11:11:19,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:19,163 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:08<13:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:26,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013979998417198658, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.577, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010165316984057426, 'eval_loss_2': 0.003814682364463806, 'eval_loss_3': -18.267690658569336, 'eval_loss_4': 0.8489134311676025, 'epoch': 25.29}
{'loss': 0.0084, 'grad_norm': 4.529349327087402, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.005027290433645248, 'loss_2': 0.003360748291015625, 'loss_3': -16.24553871154785, 'loss_4': 1.1333467960357666, 'epoch': 25.3}
{'loss': 0.0174, 'grad_norm': 8.982234954833984, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.012761798687279224, 'loss_2': 0.0046844482421875, 'loss_3': -16.237258911132812, 'loss_4': 1.273878574371338, 'epoch': 25.3}
{'loss': 0.0097, 'grad_norm': 4.82112455368042, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.0069971452467143536, 'loss_2': 0.002658843994140625, 'loss_3': -16.129606246948242, 'loss_4': 0.5994821190834045, 'epoch': 25.31}
{'loss': 0.0205, 'grad_norm': 7.240568161010742, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.013835678808391094, 'loss_2': 0.00662994384765625, 'loss_3': -16.295120239257812, 'loss_4': 1.2014169692993164, 'epoch': 25.31}
{'loss': 0.0123, 'grad_norm': 6.251169204711914, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.010054893791675568, 'loss_2': 0.002269744873046875, 'loss_3': -16.21539306640625, 'loss_4': 1.2107737064361572, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 11:11:26,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:26,508 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:16<13:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:33,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013117506168782711, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.715, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00987946055829525, 'eval_loss_2': 0.0032380446791648865, 'eval_loss_3': -18.270702362060547, 'eval_loss_4': 0.8711907267570496, 'epoch': 25.32}
{'loss': 0.008, 'grad_norm': 5.545033931732178, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.00612306222319603, 'loss_2': 0.0019197463989257812, 'loss_3': -16.29037857055664, 'loss_4': 1.137157678604126, 'epoch': 25.33}
{'loss': 0.008, 'grad_norm': 4.930809020996094, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.004274222534149885, 'loss_2': 0.0037689208984375, 'loss_3': -16.13192367553711, 'loss_4': 0.7241278886795044, 'epoch': 25.33}
{'loss': 0.0088, 'grad_norm': 4.846454620361328, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.0045886170119047165, 'loss_2': 0.0042266845703125, 'loss_3': -16.350502014160156, 'loss_4': 0.8336067199707031, 'epoch': 25.34}
{'loss': 0.0053, 'grad_norm': 4.66178035736084, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.004179564770311117, 'loss_2': 0.0010833740234375, 'loss_3': -16.208452224731445, 'loss_4': 1.3876560926437378, 'epoch': 25.34}
{'loss': 0.005, 'grad_norm': 4.680981636047363, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.004382857121527195, 'loss_2': 0.0005960464477539062, 'loss_3': -16.346391677856445, 'loss_4': 1.4042595624923706, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 11:11:33,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:33,845 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:23<13:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:41,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013407391496002674, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009971988387405872, 'eval_loss_2': 0.0034354031085968018, 'eval_loss_3': -18.2725830078125, 'eval_loss_4': 0.876023530960083, 'epoch': 25.35}
{'loss': 0.0108, 'grad_norm': 6.756117820739746, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.0058975256979465485, 'loss_2': 0.00495147705078125, 'loss_3': -16.19081687927246, 'loss_4': 1.4465323686599731, 'epoch': 25.35}
{'loss': 0.0142, 'grad_norm': 5.657805442810059, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.005711559671908617, 'loss_2': 0.00848388671875, 'loss_3': -16.17837905883789, 'loss_4': 1.098359227180481, 'epoch': 25.36}
{'loss': 0.0066, 'grad_norm': 4.251374244689941, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.003211670322343707, 'loss_2': 0.0033817291259765625, 'loss_3': -16.464923858642578, 'loss_4': 1.2822738885879517, 'epoch': 25.37}
{'loss': 0.0127, 'grad_norm': 5.7839274406433105, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.009478947147727013, 'loss_2': 0.003208160400390625, 'loss_3': -16.099130630493164, 'loss_4': 0.8426459431648254, 'epoch': 25.37}
{'loss': 0.0163, 'grad_norm': 5.190417766571045, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.005891201086342335, 'loss_2': 0.01044464111328125, 'loss_3': -16.229040145874023, 'loss_4': 0.5100758671760559, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 11:11:41,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:41,183 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:30<13:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:48,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01351168192923069, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.801, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009920621290802956, 'eval_loss_2': 0.0035910606384277344, 'eval_loss_3': -18.267457962036133, 'eval_loss_4': 0.8081061840057373, 'epoch': 25.38}
{'loss': 0.0144, 'grad_norm': 8.489645957946777, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.01280098594725132, 'loss_2': 0.0015964508056640625, 'loss_3': -16.338348388671875, 'loss_4': 1.154125452041626, 'epoch': 25.38}
{'loss': 0.0035, 'grad_norm': 4.656073093414307, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.0031284834258258343, 'loss_2': 0.0003783702850341797, 'loss_3': -16.40400505065918, 'loss_4': 1.012681245803833, 'epoch': 25.39}
{'loss': 0.0059, 'grad_norm': 5.5201029777526855, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.005741839297115803, 'loss_2': 0.00012230873107910156, 'loss_3': -16.447105407714844, 'loss_4': 0.820209264755249, 'epoch': 25.4}
{'loss': 0.0116, 'grad_norm': 4.739134788513184, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.004137364681810141, 'loss_2': 0.007415771484375, 'loss_3': -16.511962890625, 'loss_4': 0.8714967370033264, 'epoch': 25.4}
{'loss': 0.0044, 'grad_norm': 4.4813313484191895, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.0036854208447039127, 'loss_2': 0.0007200241088867188, 'loss_3': -16.149524688720703, 'loss_4': 1.458046317100525, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 11:11:48,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:48,518 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:38<13:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:55,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013814806938171387, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010526352562010288, 'eval_loss_2': 0.003288455307483673, 'eval_loss_3': -18.251115798950195, 'eval_loss_4': 0.7503848075866699, 'epoch': 25.41}
{'loss': 0.0088, 'grad_norm': 4.430727481842041, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.0032209802884608507, 'loss_2': 0.00553131103515625, 'loss_3': -16.197845458984375, 'loss_4': 1.1874198913574219, 'epoch': 25.41}
{'loss': 0.0033, 'grad_norm': 4.235875606536865, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.002189392689615488, 'loss_2': 0.0011043548583984375, 'loss_3': -16.20576286315918, 'loss_4': 0.985093891620636, 'epoch': 25.42}
{'loss': 0.0061, 'grad_norm': 4.73507022857666, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.004243116360157728, 'loss_2': 0.0018463134765625, 'loss_3': -16.230159759521484, 'loss_4': 0.7775030136108398, 'epoch': 25.42}
{'loss': 0.0091, 'grad_norm': 6.711136817932129, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.006146133411675692, 'loss_2': 0.00290679931640625, 'loss_3': -16.345043182373047, 'loss_4': 0.897400438785553, 'epoch': 25.43}
{'loss': 0.0119, 'grad_norm': 5.113312721252441, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.006090442184358835, 'loss_2': 0.00579071044921875, 'loss_3': -16.398591995239258, 'loss_4': 0.8420196771621704, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 11:11:55,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:55,873 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:45<13:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:03,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014455344527959824, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.403, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010748829692602158, 'eval_loss_2': 0.003706514835357666, 'eval_loss_3': -18.252437591552734, 'eval_loss_4': 0.7189882397651672, 'epoch': 25.44}
{'loss': 0.007, 'grad_norm': 5.58561372756958, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.005371963605284691, 'loss_2': 0.0015840530395507812, 'loss_3': -16.390933990478516, 'loss_4': 1.6167089939117432, 'epoch': 25.44}
{'loss': 0.007, 'grad_norm': 4.982052326202393, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.005200200714170933, 'loss_2': 0.001781463623046875, 'loss_3': -16.4281005859375, 'loss_4': 0.5404748320579529, 'epoch': 25.45}
{'loss': 0.0039, 'grad_norm': 4.500508785247803, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.003532635048031807, 'loss_2': 0.00035190582275390625, 'loss_3': -16.264955520629883, 'loss_4': 0.9381617903709412, 'epoch': 25.45}
{'loss': 0.0121, 'grad_norm': 4.367949962615967, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.0029108254238963127, 'loss_2': 0.0092010498046875, 'loss_3': -16.319381713867188, 'loss_4': 1.083528757095337, 'epoch': 25.46}
{'loss': 0.0046, 'grad_norm': 4.889899730682373, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.0031683705747127533, 'loss_2': 0.001430511474609375, 'loss_3': -16.510257720947266, 'loss_4': 1.2843685150146484, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 11:12:03,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:03,214 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:47:52<13:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:10,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014882470481097698, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011326851323246956, 'eval_loss_2': 0.0035556182265281677, 'eval_loss_3': -18.25457763671875, 'eval_loss_4': 0.7306149005889893, 'epoch': 25.47}
{'loss': 0.0095, 'grad_norm': 4.907128810882568, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.006297646556049585, 'loss_2': 0.003215789794921875, 'loss_3': -16.155961990356445, 'loss_4': 0.6706516742706299, 'epoch': 25.47}
{'loss': 0.0135, 'grad_norm': 4.197545051574707, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.0036115271504968405, 'loss_2': 0.00991058349609375, 'loss_3': -16.35039710998535, 'loss_4': 1.2577131986618042, 'epoch': 25.48}
{'loss': 0.0091, 'grad_norm': 6.844995498657227, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.007337032817304134, 'loss_2': 0.0017871856689453125, 'loss_3': -16.32744026184082, 'loss_4': 0.7370507717132568, 'epoch': 25.48}
{'loss': 0.0066, 'grad_norm': 5.711284160614014, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.006536861415952444, 'loss_2': 4.506111145019531e-05, 'loss_3': -16.225101470947266, 'loss_4': 0.9195035696029663, 'epoch': 25.49}
{'loss': 0.0072, 'grad_norm': 5.000126838684082, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.005601075012236834, 'loss_2': 0.0015764236450195312, 'loss_3': -16.18231964111328, 'loss_4': 1.5262335538864136, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 11:12:10,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:10,555 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:00<13:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:17,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01541527733206749, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.853, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01169302687048912, 'eval_loss_2': 0.003722250461578369, 'eval_loss_3': -18.240869522094727, 'eval_loss_4': 0.7693929672241211, 'epoch': 25.49}
{'loss': 0.0068, 'grad_norm': 5.347580432891846, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.0038844801019877195, 'loss_2': 0.0029544830322265625, 'loss_3': -16.255401611328125, 'loss_4': 1.3467051982879639, 'epoch': 25.5}
{'loss': 0.0087, 'grad_norm': 4.514374732971191, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.004144460894167423, 'loss_2': 0.0045318603515625, 'loss_3': -16.216461181640625, 'loss_4': 0.957034707069397, 'epoch': 25.51}
{'loss': 0.0111, 'grad_norm': 5.1840434074401855, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.007083546370267868, 'loss_2': 0.0039825439453125, 'loss_3': -16.081390380859375, 'loss_4': 1.4258977174758911, 'epoch': 25.51}
{'loss': 0.0107, 'grad_norm': 5.821656703948975, 'learning_rate': 4.5e-06, 'loss_1': 0.007909051142632961, 'loss_2': 0.0027980804443359375, 'loss_3': -16.39168930053711, 'loss_4': 0.8537367582321167, 'epoch': 25.52}
{'loss': 0.0069, 'grad_norm': 4.311417102813721, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.0022136769257485867, 'loss_2': 0.00469970703125, 'loss_3': -16.310951232910156, 'loss_4': 1.0567463636398315, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 11:12:17,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:17,890 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:07<13:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:25,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016166675835847855, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.646, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012140365317463875, 'eval_loss_2': 0.004026308655738831, 'eval_loss_3': -18.231918334960938, 'eval_loss_4': 0.7446832656860352, 'epoch': 25.52}
{'loss': 0.007, 'grad_norm': 4.704391956329346, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.006707917898893356, 'loss_2': 0.0003294944763183594, 'loss_3': -16.09417724609375, 'loss_4': 1.2442600727081299, 'epoch': 25.53}
{'loss': 0.0148, 'grad_norm': 10.585127830505371, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.009583864361047745, 'loss_2': 0.0052490234375, 'loss_3': -16.324871063232422, 'loss_4': 0.7072194814682007, 'epoch': 25.53}
{'loss': 0.0099, 'grad_norm': 4.282209396362305, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.0030485575553029776, 'loss_2': 0.00688934326171875, 'loss_3': -16.304834365844727, 'loss_4': 1.0687174797058105, 'epoch': 25.54}
{'loss': 0.0043, 'grad_norm': 5.21120023727417, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.0035596974194049835, 'loss_2': 0.0007500648498535156, 'loss_3': -16.12525177001953, 'loss_4': 0.7418574690818787, 'epoch': 25.55}
{'loss': 0.0068, 'grad_norm': 4.863982677459717, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.00411262596026063, 'loss_2': 0.002716064453125, 'loss_3': -16.28665542602539, 'loss_4': 1.031736135482788, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 11:12:25,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:25,232 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:14<13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:32,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015916218981146812, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012201212346553802, 'eval_loss_2': 0.003715008497238159, 'eval_loss_3': -18.238670349121094, 'eval_loss_4': 0.7009756565093994, 'epoch': 25.55}
{'loss': 0.0086, 'grad_norm': 5.502781391143799, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.006453250534832478, 'loss_2': 0.002178192138671875, 'loss_3': -16.265579223632812, 'loss_4': 0.8878037929534912, 'epoch': 25.56}
{'loss': 0.0075, 'grad_norm': 4.479382514953613, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.004776205867528915, 'loss_2': 0.002704620361328125, 'loss_3': -16.182573318481445, 'loss_4': 0.4578489065170288, 'epoch': 25.56}
{'loss': 0.0159, 'grad_norm': 4.7665629386901855, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.007427038159221411, 'loss_2': 0.0084991455078125, 'loss_3': -16.15896987915039, 'loss_4': 0.6865907907485962, 'epoch': 25.57}
{'loss': 0.0144, 'grad_norm': 6.079002857208252, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.0069612860679626465, 'loss_2': 0.00743865966796875, 'loss_3': -16.32794189453125, 'loss_4': 0.46488720178604126, 'epoch': 25.58}
{'loss': 0.0028, 'grad_norm': 4.420563220977783, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.0025785043835639954, 'loss_2': 0.00019812583923339844, 'loss_3': -16.119800567626953, 'loss_4': 0.7939360737800598, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 11:12:32,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:32,570 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:22<13:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:39,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016392691060900688, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012340319342911243, 'eval_loss_2': 0.00405237078666687, 'eval_loss_3': -18.2367000579834, 'eval_loss_4': 0.6633429527282715, 'epoch': 25.58}
{'loss': 0.0106, 'grad_norm': 4.572478771209717, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.0029438224155455828, 'loss_2': 0.00769805908203125, 'loss_3': -16.344154357910156, 'loss_4': 1.7095766067504883, 'epoch': 25.59}
{'loss': 0.0133, 'grad_norm': 4.917309761047363, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.005537129007279873, 'loss_2': 0.0077972412109375, 'loss_3': -16.323514938354492, 'loss_4': 0.5963191986083984, 'epoch': 25.59}
{'loss': 0.0065, 'grad_norm': 4.589763641357422, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.004028479568660259, 'loss_2': 0.0024261474609375, 'loss_3': -16.552770614624023, 'loss_4': 0.8581746220588684, 'epoch': 25.6}
{'loss': 0.0132, 'grad_norm': 7.225614547729492, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.007105832453817129, 'loss_2': 0.00612640380859375, 'loss_3': -15.959023475646973, 'loss_4': 0.7817195057868958, 'epoch': 25.6}
{'loss': 0.01, 'grad_norm': 7.513168811798096, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.009446688927710056, 'loss_2': 0.0005168914794921875, 'loss_3': -16.098573684692383, 'loss_4': 1.0536797046661377, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 11:12:39,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:39,909 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:29<12:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:47,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015103152021765709, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.446, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01159161888062954, 'eval_loss_2': 0.0035115331411361694, 'eval_loss_3': -18.223278045654297, 'eval_loss_4': 0.6581986546516418, 'epoch': 25.61}
{'loss': 0.0076, 'grad_norm': 5.177302837371826, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.005375191569328308, 'loss_2': 0.0022716522216796875, 'loss_3': -16.30911636352539, 'loss_4': 1.126720666885376, 'epoch': 25.62}
{'loss': 0.0044, 'grad_norm': 4.560826778411865, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.002216808032244444, 'loss_2': 0.002162933349609375, 'loss_3': -16.41451072692871, 'loss_4': 0.5271627306938171, 'epoch': 25.62}
{'loss': 0.0129, 'grad_norm': 4.622589111328125, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.003311246633529663, 'loss_2': 0.00960540771484375, 'loss_3': -16.259429931640625, 'loss_4': 1.2164344787597656, 'epoch': 25.63}
{'loss': 0.0044, 'grad_norm': 4.623635768890381, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.003243121085688472, 'loss_2': 0.001140594482421875, 'loss_3': -16.283405303955078, 'loss_4': 1.0660293102264404, 'epoch': 25.63}
{'loss': 0.0138, 'grad_norm': 5.145253658294678, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.00831102579832077, 'loss_2': 0.005523681640625, 'loss_3': -16.257125854492188, 'loss_4': 0.8819706439971924, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 11:12:47,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:47,254 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:36<12:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:54,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014962004497647285, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.431, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011482262052595615, 'eval_loss_2': 0.0034797415137290955, 'eval_loss_3': -18.219167709350586, 'eval_loss_4': 0.6482061743736267, 'epoch': 25.64}
{'loss': 0.0063, 'grad_norm': 4.57039213180542, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.002220066962763667, 'loss_2': 0.00408172607421875, 'loss_3': -16.305908203125, 'loss_4': 0.9569976329803467, 'epoch': 25.65}
{'loss': 0.0066, 'grad_norm': 5.793241024017334, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.0058368961326777935, 'loss_2': 0.00074005126953125, 'loss_3': -16.086645126342773, 'loss_4': 0.34590429067611694, 'epoch': 25.65}
{'loss': 0.0228, 'grad_norm': 7.094173908233643, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.016045354306697845, 'loss_2': 0.0067596435546875, 'loss_3': -16.211057662963867, 'loss_4': 0.49248385429382324, 'epoch': 25.66}
{'loss': 0.0081, 'grad_norm': 5.656741142272949, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.006932924035936594, 'loss_2': 0.0011472702026367188, 'loss_3': -16.263668060302734, 'loss_4': 0.6744129657745361, 'epoch': 25.66}
{'loss': 0.0074, 'grad_norm': 4.544839382171631, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.004058141727000475, 'loss_2': 0.003368377685546875, 'loss_3': -16.284059524536133, 'loss_4': 1.102927327156067, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 11:12:54,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:54,595 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:48:44<12:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:01,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0153097715228796, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.691, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01166347973048687, 'eval_loss_2': 0.0036462917923927307, 'eval_loss_3': -18.219730377197266, 'eval_loss_4': 0.6746279001235962, 'epoch': 25.67}
{'loss': 0.0125, 'grad_norm': 6.515592575073242, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.01061938889324665, 'loss_2': 0.0018987655639648438, 'loss_3': -16.237770080566406, 'loss_4': 0.6431543827056885, 'epoch': 25.67}
{'loss': 0.006, 'grad_norm': 4.61043119430542, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.0042680175974965096, 'loss_2': 0.0017080307006835938, 'loss_3': -16.372421264648438, 'loss_4': 0.7546564340591431, 'epoch': 25.68}
{'loss': 0.0071, 'grad_norm': 4.499042510986328, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.004748779349029064, 'loss_2': 0.002315521240234375, 'loss_3': -16.080034255981445, 'loss_4': 1.2791731357574463, 'epoch': 25.69}
{'loss': 0.007, 'grad_norm': 5.016278266906738, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.004455107264220715, 'loss_2': 0.002590179443359375, 'loss_3': -16.128189086914062, 'loss_4': 0.708390474319458, 'epoch': 25.69}
{'loss': 0.0063, 'grad_norm': 4.73422908782959, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.004211757332086563, 'loss_2': 0.002109527587890625, 'loss_3': -16.232084274291992, 'loss_4': 1.4848802089691162, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 11:13:01,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:01,927 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:48:51<12:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:09,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015408875420689583, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011987359263002872, 'eval_loss_2': 0.0034215152263641357, 'eval_loss_3': -18.229328155517578, 'eval_loss_4': 0.7307496666908264, 'epoch': 25.7}
{'loss': 0.0045, 'grad_norm': 5.038546085357666, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.003442243207246065, 'loss_2': 0.0010538101196289062, 'loss_3': -16.233339309692383, 'loss_4': 0.7785724401473999, 'epoch': 25.7}
{'loss': 0.0119, 'grad_norm': 5.364634990692139, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.00644236383959651, 'loss_2': 0.0054779052734375, 'loss_3': -16.304258346557617, 'loss_4': 1.0347356796264648, 'epoch': 25.71}
{'loss': 0.0125, 'grad_norm': 6.431092739105225, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.007104994263499975, 'loss_2': 0.00540924072265625, 'loss_3': -16.343538284301758, 'loss_4': 1.3292710781097412, 'epoch': 25.72}
{'loss': 0.0093, 'grad_norm': 4.436211585998535, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.0020549457985907793, 'loss_2': 0.00726318359375, 'loss_3': -16.300935745239258, 'loss_4': 0.7189632654190063, 'epoch': 25.72}
{'loss': 0.0078, 'grad_norm': 5.4993438720703125, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.006791672669351101, 'loss_2': 0.0009946823120117188, 'loss_3': -16.284683227539062, 'loss_4': 0.4049449861049652, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 11:13:09,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:09,268 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:48:58<12:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:16,615 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015069994144141674, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011863533407449722, 'eval_loss_2': 0.0032064616680145264, 'eval_loss_3': -18.213367462158203, 'eval_loss_4': 0.7499362230300903, 'epoch': 25.73}
{'loss': 0.0067, 'grad_norm': 4.777831554412842, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.0065582627430558205, 'loss_2': 9.644031524658203e-05, 'loss_3': -16.2529354095459, 'loss_4': 0.6445103287696838, 'epoch': 25.73}
{'loss': 0.0198, 'grad_norm': 7.9058661460876465, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.018798038363456726, 'loss_2': 0.0010089874267578125, 'loss_3': -16.148662567138672, 'loss_4': 0.9247874617576599, 'epoch': 25.74}
{'loss': 0.0107, 'grad_norm': 5.271977424621582, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.005596022121608257, 'loss_2': 0.00510406494140625, 'loss_3': -16.310754776000977, 'loss_4': 0.6576849222183228, 'epoch': 25.74}
{'loss': 0.0144, 'grad_norm': 6.805315017700195, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.010883952490985394, 'loss_2': 0.0035190582275390625, 'loss_3': -16.169944763183594, 'loss_4': 1.1735103130340576, 'epoch': 25.75}
{'loss': 0.0162, 'grad_norm': 4.489955425262451, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.0039300862699747086, 'loss_2': 0.01227569580078125, 'loss_3': -16.237293243408203, 'loss_4': 0.650373101234436, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 11:13:16,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:16,615 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:06<12:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:23,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015512648038566113, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012599688023328781, 'eval_loss_2': 0.002912960946559906, 'eval_loss_3': -18.213581085205078, 'eval_loss_4': 0.6959480047225952, 'epoch': 25.76}
{'loss': 0.0081, 'grad_norm': 4.73878288269043, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.0019350374350324273, 'loss_2': 0.0061492919921875, 'loss_3': -16.250438690185547, 'loss_4': 1.2618694305419922, 'epoch': 25.76}
{'loss': 0.0094, 'grad_norm': 4.447393417358398, 'learning_rate': 4.25e-06, 'loss_1': 0.0036592131946235895, 'loss_2': 0.00569915771484375, 'loss_3': -16.267187118530273, 'loss_4': 0.9588819742202759, 'epoch': 25.77}
{'loss': 0.0079, 'grad_norm': 5.137033462524414, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.006191303487867117, 'loss_2': 0.001678466796875, 'loss_3': -16.035015106201172, 'loss_4': 1.043304681777954, 'epoch': 25.77}
{'loss': 0.0051, 'grad_norm': 4.877062797546387, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.004337990190833807, 'loss_2': 0.000728607177734375, 'loss_3': -16.256935119628906, 'loss_4': 0.9473128318786621, 'epoch': 25.78}
{'loss': 0.0145, 'grad_norm': 5.4112772941589355, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.0028965992387384176, 'loss_2': 0.011566162109375, 'loss_3': -16.378080368041992, 'loss_4': 0.8321995139122009, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 11:13:23,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:23,960 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:13<12:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:31,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015429601073265076, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012386329472064972, 'eval_loss_2': 0.0030432716012001038, 'eval_loss_3': -18.217729568481445, 'eval_loss_4': 0.6940994262695312, 'epoch': 25.78}
{'loss': 0.0088, 'grad_norm': 5.251222610473633, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.004405185580253601, 'loss_2': 0.004364013671875, 'loss_3': -16.242406845092773, 'loss_4': 1.6982152462005615, 'epoch': 25.79}
{'loss': 0.0257, 'grad_norm': 13.228273391723633, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.023782704025506973, 'loss_2': 0.0018949508666992188, 'loss_3': -16.19066619873047, 'loss_4': 0.8705618381500244, 'epoch': 25.8}
{'loss': 0.0051, 'grad_norm': 4.6511616706848145, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.0021329259034246206, 'loss_2': 0.0029850006103515625, 'loss_3': -16.428794860839844, 'loss_4': 1.0582067966461182, 'epoch': 25.8}
{'loss': 0.009, 'grad_norm': 5.027647018432617, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.004155173897743225, 'loss_2': 0.0048370361328125, 'loss_3': -16.09133529663086, 'loss_4': 1.0104889869689941, 'epoch': 25.81}
{'loss': 0.0053, 'grad_norm': 6.818697452545166, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.0019676971714943647, 'loss_2': 0.00331878662109375, 'loss_3': -16.257030487060547, 'loss_4': 1.384094476699829, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 11:13:31,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:31,299 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:20<12:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:38,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014735329896211624, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.574, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012070957571268082, 'eval_loss_2': 0.0026643723249435425, 'eval_loss_3': -18.218181610107422, 'eval_loss_4': 0.7175127267837524, 'epoch': 25.81}
{'loss': 0.0052, 'grad_norm': 4.640347480773926, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.0042470116168260574, 'loss_2': 0.000934600830078125, 'loss_3': -16.08966064453125, 'loss_4': 1.3956726789474487, 'epoch': 25.82}
{'loss': 0.0093, 'grad_norm': 4.644363880157471, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.0024256305769085884, 'loss_2': 0.00687408447265625, 'loss_3': -16.076416015625, 'loss_4': 1.103503704071045, 'epoch': 25.83}
{'loss': 0.0237, 'grad_norm': 8.372095108032227, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.009847813285887241, 'loss_2': 0.0138397216796875, 'loss_3': -16.260665893554688, 'loss_4': 1.2189418077468872, 'epoch': 25.83}
{'loss': 0.0056, 'grad_norm': 4.460918426513672, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.003162903944030404, 'loss_2': 0.00238800048828125, 'loss_3': -16.337312698364258, 'loss_4': 0.8393919467926025, 'epoch': 25.84}
{'loss': 0.011, 'grad_norm': 7.417821407318115, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.007485038135200739, 'loss_2': 0.00350189208984375, 'loss_3': -16.107467651367188, 'loss_4': 0.8010777235031128, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 11:13:38,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:38,645 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:28<12:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:45,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014579297974705696, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.746, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011871437542140484, 'eval_loss_2': 0.002707861363887787, 'eval_loss_3': -18.226919174194336, 'eval_loss_4': 0.7538955211639404, 'epoch': 25.84}
{'loss': 0.0097, 'grad_norm': 4.298708915710449, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.003983355592936277, 'loss_2': 0.0057525634765625, 'loss_3': -16.31574058532715, 'loss_4': 1.1155292987823486, 'epoch': 25.85}
{'loss': 0.0048, 'grad_norm': 4.460515022277832, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.001344680436886847, 'loss_2': 0.0034236907958984375, 'loss_3': -16.37666130065918, 'loss_4': 1.1823371648788452, 'epoch': 25.85}
{'loss': 0.0098, 'grad_norm': 5.368133544921875, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.006060540676116943, 'loss_2': 0.003734588623046875, 'loss_3': -16.15660858154297, 'loss_4': 1.174684762954712, 'epoch': 25.86}
{'loss': 0.0032, 'grad_norm': 4.382678985595703, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.0022378533612936735, 'loss_2': 0.0009307861328125, 'loss_3': -16.236919403076172, 'loss_4': 0.9821343421936035, 'epoch': 25.87}
{'loss': 0.0055, 'grad_norm': 4.043173789978027, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.001861118944361806, 'loss_2': 0.003650665283203125, 'loss_3': -16.461559295654297, 'loss_4': 1.0468621253967285, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 11:13:45,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:45,980 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:35<12:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:53,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01491367258131504, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.846, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012173556722700596, 'eval_loss_2': 0.00274011492729187, 'eval_loss_3': -18.227924346923828, 'eval_loss_4': 0.7491939663887024, 'epoch': 25.87}
{'loss': 0.0095, 'grad_norm': 4.610829830169678, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.005564456805586815, 'loss_2': 0.003932952880859375, 'loss_3': -16.26833152770996, 'loss_4': 0.6016217470169067, 'epoch': 25.88}
{'loss': 0.0056, 'grad_norm': 4.45127534866333, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.0033620763570070267, 'loss_2': 0.002239227294921875, 'loss_3': -16.160154342651367, 'loss_4': 0.9209546446800232, 'epoch': 25.88}
{'loss': 0.0145, 'grad_norm': 7.980276584625244, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.014085013419389725, 'loss_2': 0.0003719329833984375, 'loss_3': -16.209148406982422, 'loss_4': 0.7868735790252686, 'epoch': 25.89}
{'loss': 0.0093, 'grad_norm': 5.949930667877197, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.007532906718552113, 'loss_2': 0.00173187255859375, 'loss_3': -16.343170166015625, 'loss_4': 1.073402762413025, 'epoch': 25.9}
{'loss': 0.0069, 'grad_norm': 4.423037528991699, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.004235290456563234, 'loss_2': 0.002674102783203125, 'loss_3': -16.088001251220703, 'loss_4': 1.087027907371521, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 11:13:53,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:53,338 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:49:42<12:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:00,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015065074898302555, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012194790877401829, 'eval_loss_2': 0.0028702840209007263, 'eval_loss_3': -18.21678352355957, 'eval_loss_4': 0.7402856349945068, 'epoch': 25.9}
{'loss': 0.0065, 'grad_norm': 5.884181022644043, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.0054747979156672955, 'loss_2': 0.001033782958984375, 'loss_3': -16.389116287231445, 'loss_4': 1.398850679397583, 'epoch': 25.91}
{'loss': 0.0059, 'grad_norm': 5.149585247039795, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.003373940708115697, 'loss_2': 0.002483367919921875, 'loss_3': -16.404319763183594, 'loss_4': 0.7386590838432312, 'epoch': 25.91}
{'loss': 0.0279, 'grad_norm': 20.808542251586914, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.024057406932115555, 'loss_2': 0.00382232666015625, 'loss_3': -16.28696060180664, 'loss_4': 1.3254115581512451, 'epoch': 25.92}
{'loss': 0.012, 'grad_norm': 7.8807148933410645, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.0111308004707098, 'loss_2': 0.0008759498596191406, 'loss_3': -16.417062759399414, 'loss_4': 1.3953418731689453, 'epoch': 25.92}
{'loss': 0.0034, 'grad_norm': 4.516340255737305, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.003130348166450858, 'loss_2': 0.00029468536376953125, 'loss_3': -16.297269821166992, 'loss_4': 1.3192188739776611, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 11:14:00,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:00,689 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:49:50<11:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:08,021 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015306232497096062, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012468917295336723, 'eval_loss_2': 0.0028373152017593384, 'eval_loss_3': -18.210905075073242, 'eval_loss_4': 0.7546380758285522, 'epoch': 25.93}
{'loss': 0.0179, 'grad_norm': 14.305071830749512, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.015981078147888184, 'loss_2': 0.0019426345825195312, 'loss_3': -16.247297286987305, 'loss_4': 0.9635211825370789, 'epoch': 25.94}
{'loss': 0.0069, 'grad_norm': 4.916171550750732, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.003208443522453308, 'loss_2': 0.003658294677734375, 'loss_3': -16.333683013916016, 'loss_4': 0.4780147671699524, 'epoch': 25.94}
{'loss': 0.007, 'grad_norm': 5.640291213989258, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.006059165112674236, 'loss_2': 0.000946044921875, 'loss_3': -16.33673858642578, 'loss_4': 1.235682725906372, 'epoch': 25.95}
{'loss': 0.0051, 'grad_norm': 5.0551252365112305, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.003758462145924568, 'loss_2': 0.0013036727905273438, 'loss_3': -16.33224868774414, 'loss_4': 1.3224432468414307, 'epoch': 25.95}
{'loss': 0.0089, 'grad_norm': 6.974166393280029, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.008194299414753914, 'loss_2': 0.0007476806640625, 'loss_3': -16.466676712036133, 'loss_4': 1.201055884361267, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 11:14:08,021 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:08,021 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:49:57<11:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:15,354 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014663069508969784, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.653, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012034310027956963, 'eval_loss_2': 0.0026287585496902466, 'eval_loss_3': -18.21150016784668, 'eval_loss_4': 0.7651188969612122, 'epoch': 25.96}
{'loss': 0.0059, 'grad_norm': 4.60146427154541, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.00288878264836967, 'loss_2': 0.0030345916748046875, 'loss_3': -16.554758071899414, 'loss_4': 0.5370743870735168, 'epoch': 25.97}
{'loss': 0.0152, 'grad_norm': 7.346582889556885, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.008752641268074512, 'loss_2': 0.0064239501953125, 'loss_3': -16.270618438720703, 'loss_4': 0.8268436193466187, 'epoch': 25.97}
{'loss': 0.0029, 'grad_norm': 4.466475963592529, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.00220124633051455, 'loss_2': 0.0006771087646484375, 'loss_3': -16.268367767333984, 'loss_4': 0.848596453666687, 'epoch': 25.98}
{'loss': 0.0043, 'grad_norm': 4.610718727111816, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.0036049073096364737, 'loss_2': 0.000652313232421875, 'loss_3': -16.102445602416992, 'loss_4': 1.1013710498809814, 'epoch': 25.98}
{'loss': 0.0065, 'grad_norm': 4.460052967071533, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.002180454321205616, 'loss_2': 0.0043487548828125, 'loss_3': -16.47129249572754, 'loss_4': 0.8263967633247375, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 11:14:15,354 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:15,354 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:04<11:29,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 11:14:22,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01478421688079834, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.404, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011668638326227665, 'eval_loss_2': 0.0031155794858932495, 'eval_loss_3': -18.200056076049805, 'eval_loss_4': 0.8483483791351318, 'epoch': 25.99}
{'loss': 0.0069, 'grad_norm': 4.110214710235596, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.0031631612218916416, 'loss_2': 0.00371551513671875, 'loss_3': -16.084728240966797, 'loss_4': 1.2285301685333252, 'epoch': 25.99}
{'loss': 0.0025, 'grad_norm': 5.7599287033081055, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.0008322221110574901, 'loss_2': 0.0016422271728515625, 'loss_3': -16.259920120239258, 'loss_4': 1.5857757329940796, 'epoch': 26.0}
{'loss': 0.0031, 'grad_norm': 3.988524913787842, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.0028141424991190434, 'loss_2': 0.0002865791320800781, 'loss_3': -16.330974578857422, 'loss_4': 1.2255107164382935, 'epoch': 26.01}
{'loss': 0.0122, 'grad_norm': 5.935920715332031, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.005248927976936102, 'loss_2': 0.00696563720703125, 'loss_3': -16.483980178833008, 'loss_4': 0.6092115044593811, 'epoch': 26.01}
{'loss': 0.0155, 'grad_norm': 10.783736228942871, 'learning_rate': 4e-06, 'loss_1': 0.014092336408793926, 'loss_2': 0.0013866424560546875, 'loss_3': -16.262611389160156, 'loss_4': 1.5700013637542725, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 11:14:22,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:22,384 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:11<11:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:14:29,733 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01470911130309105, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011110838502645493, 'eval_loss_2': 0.0035982728004455566, 'eval_loss_3': -18.19895362854004, 'eval_loss_4': 0.9148674607276917, 'epoch': 26.02}
{'loss': 0.009, 'grad_norm': 4.8018412590026855, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.0034360389690846205, 'loss_2': 0.005523681640625, 'loss_3': -16.191804885864258, 'loss_4': 1.241119146347046, 'epoch': 26.02}
{'loss': 0.0104, 'grad_norm': 5.2137908935546875, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.0026190124917775393, 'loss_2': 0.00778961181640625, 'loss_3': -16.352439880371094, 'loss_4': 0.961460530757904, 'epoch': 26.03}
{'loss': 0.0138, 'grad_norm': 4.560652732849121, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.002387105952948332, 'loss_2': 0.01137542724609375, 'loss_3': -16.291465759277344, 'loss_4': 0.9451446533203125, 'epoch': 26.03}
{'loss': 0.0073, 'grad_norm': 5.012420177459717, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.0023341714404523373, 'loss_2': 0.005008697509765625, 'loss_3': -16.340965270996094, 'loss_4': 1.2571945190429688, 'epoch': 26.04}
{'loss': 0.0125, 'grad_norm': 9.964179039001465, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.007891801185905933, 'loss_2': 0.00460052490234375, 'loss_3': -16.17167854309082, 'loss_4': 1.0583198070526123, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 11:14:29,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:29,734 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:19<11:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:37,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014541041105985641, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.154, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01126022171229124, 'eval_loss_2': 0.003280818462371826, 'eval_loss_3': -18.203874588012695, 'eval_loss_4': 0.9764992594718933, 'epoch': 26.05}
{'loss': 0.0213, 'grad_norm': 10.706523895263672, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.020643530413508415, 'loss_2': 0.0006456375122070312, 'loss_3': -16.45954132080078, 'loss_4': 0.9651390314102173, 'epoch': 26.05}
{'loss': 0.0091, 'grad_norm': 5.444161415100098, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.005605787038803101, 'loss_2': 0.0035419464111328125, 'loss_3': -16.38842010498047, 'loss_4': 1.6611464023590088, 'epoch': 26.06}
{'loss': 0.0182, 'grad_norm': 8.335206985473633, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.01251100655645132, 'loss_2': 0.00572967529296875, 'loss_3': -16.389680862426758, 'loss_4': 1.6116445064544678, 'epoch': 26.06}
{'loss': 0.0063, 'grad_norm': 4.934643745422363, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.0035050136502832174, 'loss_2': 0.002758026123046875, 'loss_3': -16.195823669433594, 'loss_4': 0.9504233002662659, 'epoch': 26.07}
{'loss': 0.0054, 'grad_norm': 4.397276878356934, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.004369871690869331, 'loss_2': 0.0010356903076171875, 'loss_3': -16.2789306640625, 'loss_4': 1.3785922527313232, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 11:14:37,080 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:37,080 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:26<11:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:44,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013714777305722237, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01090698130428791, 'eval_loss_2': 0.002807796001434326, 'eval_loss_3': -18.210758209228516, 'eval_loss_4': 0.9947013854980469, 'epoch': 26.08}
{'loss': 0.0092, 'grad_norm': 4.472762584686279, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.0017470117891207337, 'loss_2': 0.0074615478515625, 'loss_3': -16.39126205444336, 'loss_4': 1.455024242401123, 'epoch': 26.08}
{'loss': 0.0043, 'grad_norm': 4.4591851234436035, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.0025615645572543144, 'loss_2': 0.0017690658569335938, 'loss_3': -16.342082977294922, 'loss_4': 1.1535347700119019, 'epoch': 26.09}
{'loss': 0.0077, 'grad_norm': 5.307775020599365, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.0067999218590557575, 'loss_2': 0.0008745193481445312, 'loss_3': -16.208114624023438, 'loss_4': 1.523327350616455, 'epoch': 26.09}
{'loss': 0.0065, 'grad_norm': 4.775324821472168, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.0022603801917284727, 'loss_2': 0.004230499267578125, 'loss_3': -16.596881866455078, 'loss_4': 0.8556398749351501, 'epoch': 26.1}
{'loss': 0.0063, 'grad_norm': 4.867762565612793, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.002617603400722146, 'loss_2': 0.003688812255859375, 'loss_3': -16.49835777282715, 'loss_4': 0.7098593711853027, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 11:14:44,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:44,423 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:33<11:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:51,767 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012941748835146427, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01022073719650507, 'eval_loss_2': 0.0027210116386413574, 'eval_loss_3': -18.220436096191406, 'eval_loss_4': 1.0219533443450928, 'epoch': 26.1}
{'loss': 0.0051, 'grad_norm': 4.610618591308594, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.004304444417357445, 'loss_2': 0.0008106231689453125, 'loss_3': -16.364524841308594, 'loss_4': 1.6094406843185425, 'epoch': 26.11}
{'loss': 0.0043, 'grad_norm': 4.3501434326171875, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.0019810525700449944, 'loss_2': 0.0023517608642578125, 'loss_3': -16.21761131286621, 'loss_4': 1.2943716049194336, 'epoch': 26.12}
{'loss': 0.0057, 'grad_norm': 4.704991817474365, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.004628515336662531, 'loss_2': 0.0010251998901367188, 'loss_3': -16.336746215820312, 'loss_4': 1.201962947845459, 'epoch': 26.12}
{'loss': 0.0071, 'grad_norm': 5.379644870758057, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.005002421792596579, 'loss_2': 0.0021228790283203125, 'loss_3': -16.257780075073242, 'loss_4': 1.5420266389846802, 'epoch': 26.13}
{'loss': 0.0072, 'grad_norm': 4.534022808074951, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.0041505335830152035, 'loss_2': 0.003082275390625, 'loss_3': -16.41457176208496, 'loss_4': 1.1117573976516724, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 11:14:51,767 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:51,767 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:41<11:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:59,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013244375586509705, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010218922980129719, 'eval_loss_2': 0.0030254535377025604, 'eval_loss_3': -18.229026794433594, 'eval_loss_4': 1.0263129472732544, 'epoch': 26.13}
{'loss': 0.0114, 'grad_norm': 6.574638366699219, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.006055658217519522, 'loss_2': 0.00536346435546875, 'loss_3': -16.256742477416992, 'loss_4': 1.3127543926239014, 'epoch': 26.14}
{'loss': 0.0052, 'grad_norm': 4.315698623657227, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.002793629188090563, 'loss_2': 0.002452850341796875, 'loss_3': -16.360862731933594, 'loss_4': 0.8563807010650635, 'epoch': 26.15}
{'loss': 0.0089, 'grad_norm': 4.650368690490723, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.0040888129733502865, 'loss_2': 0.00479888916015625, 'loss_3': -16.426132202148438, 'loss_4': 1.3084914684295654, 'epoch': 26.15}
{'loss': 0.0088, 'grad_norm': 4.50408935546875, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.004662157967686653, 'loss_2': 0.00409698486328125, 'loss_3': -16.41317367553711, 'loss_4': 1.117786169052124, 'epoch': 26.16}
{'loss': 0.005, 'grad_norm': 4.612864971160889, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.002429687650874257, 'loss_2': 0.0025959014892578125, 'loss_3': -16.532302856445312, 'loss_4': 0.8255174160003662, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 11:14:59,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:59,110 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:50:48<11:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:06,451 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01376863569021225, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.7, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010119952261447906, 'eval_loss_2': 0.0036486834287643433, 'eval_loss_3': -18.229026794433594, 'eval_loss_4': 1.0401880741119385, 'epoch': 26.16}
{'loss': 0.0038, 'grad_norm': 4.743667125701904, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.0033963616006076336, 'loss_2': 0.0004062652587890625, 'loss_3': -16.50891876220703, 'loss_4': 1.461652398109436, 'epoch': 26.17}
{'loss': 0.0152, 'grad_norm': 15.6830472946167, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.009608861990272999, 'loss_2': 0.00560760498046875, 'loss_3': -16.286317825317383, 'loss_4': 1.614271879196167, 'epoch': 26.17}
{'loss': 0.007, 'grad_norm': 4.741805553436279, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.00508599728345871, 'loss_2': 0.0019435882568359375, 'loss_3': -16.196414947509766, 'loss_4': 1.357499361038208, 'epoch': 26.18}
{'loss': 0.0097, 'grad_norm': 4.955459117889404, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.005215869750827551, 'loss_2': 0.00449371337890625, 'loss_3': -16.449134826660156, 'loss_4': 1.3493974208831787, 'epoch': 26.19}
{'loss': 0.0079, 'grad_norm': 8.486563682556152, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.007017564028501511, 'loss_2': 0.0009083747863769531, 'loss_3': -16.47284698486328, 'loss_4': 0.9546984434127808, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 11:15:06,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:06,451 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:50:55<11:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:13,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013664606027305126, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010178091935813427, 'eval_loss_2': 0.0034865140914916992, 'eval_loss_3': -18.23436737060547, 'eval_loss_4': 1.060140609741211, 'epoch': 26.19}
{'loss': 0.0108, 'grad_norm': 4.361451625823975, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.0033719942439347506, 'loss_2': 0.0074310302734375, 'loss_3': -16.406402587890625, 'loss_4': 1.774369478225708, 'epoch': 26.2}
{'loss': 0.0104, 'grad_norm': 7.414577007293701, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.007627847604453564, 'loss_2': 0.002780914306640625, 'loss_3': -16.306949615478516, 'loss_4': 1.1259633302688599, 'epoch': 26.2}
{'loss': 0.004, 'grad_norm': 4.3408708572387695, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.0022731409408152103, 'loss_2': 0.0017147064208984375, 'loss_3': -16.273269653320312, 'loss_4': 1.1299636363983154, 'epoch': 26.21}
{'loss': 0.0089, 'grad_norm': 4.636108875274658, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.004615419544279575, 'loss_2': 0.00426483154296875, 'loss_3': -16.4154109954834, 'loss_4': 1.749569296836853, 'epoch': 26.22}
{'loss': 0.0082, 'grad_norm': 4.37639856338501, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.0023602438159286976, 'loss_2': 0.0058135986328125, 'loss_3': -16.255977630615234, 'loss_4': 0.894730806350708, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 11:15:13,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:13,794 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:03<11:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:21,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012180788442492485, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009497014805674553, 'eval_loss_2': 0.002683773636817932, 'eval_loss_3': -18.24013328552246, 'eval_loss_4': 1.1039879322052002, 'epoch': 26.22}
{'loss': 0.0054, 'grad_norm': 4.540707111358643, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.004419448785483837, 'loss_2': 0.0010137557983398438, 'loss_3': -16.38210678100586, 'loss_4': 1.6576143503189087, 'epoch': 26.23}
{'loss': 0.0068, 'grad_norm': 4.137099266052246, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.002604719018563628, 'loss_2': 0.004222869873046875, 'loss_3': -16.379940032958984, 'loss_4': 1.0818907022476196, 'epoch': 26.23}
{'loss': 0.0077, 'grad_norm': 5.050483703613281, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.006621455308049917, 'loss_2': 0.001068115234375, 'loss_3': -16.221294403076172, 'loss_4': 1.1918481588363647, 'epoch': 26.24}
{'loss': 0.0134, 'grad_norm': 4.507853984832764, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.0054541886784136295, 'loss_2': 0.0079803466796875, 'loss_3': -16.315021514892578, 'loss_4': 1.4620332717895508, 'epoch': 26.24}
{'loss': 0.0073, 'grad_norm': 4.721273899078369, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.003967072814702988, 'loss_2': 0.0033702850341796875, 'loss_3': -16.371883392333984, 'loss_4': 1.0275115966796875, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 11:15:21,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:21,135 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:10<11:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:28,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012046705931425095, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.218, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009321819990873337, 'eval_loss_2': 0.002724885940551758, 'eval_loss_3': -18.23847007751465, 'eval_loss_4': 1.130910873413086, 'epoch': 26.25}
{'loss': 0.0061, 'grad_norm': 4.940320014953613, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.004527484532445669, 'loss_2': 0.0015773773193359375, 'loss_3': -16.198701858520508, 'loss_4': 1.5171246528625488, 'epoch': 26.26}
{'loss': 0.0072, 'grad_norm': 4.754796981811523, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.0027873350773006678, 'loss_2': 0.0044097900390625, 'loss_3': -16.358247756958008, 'loss_4': 2.0244643688201904, 'epoch': 26.26}
{'loss': 0.012, 'grad_norm': 5.3884711265563965, 'learning_rate': 3.75e-06, 'loss_1': 0.004799726884812117, 'loss_2': 0.00716400146484375, 'loss_3': -16.44392967224121, 'loss_4': 1.4325568675994873, 'epoch': 26.27}
{'loss': 0.0082, 'grad_norm': 4.593928337097168, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.003608118509873748, 'loss_2': 0.004547119140625, 'loss_3': -16.34805679321289, 'loss_4': 1.3824424743652344, 'epoch': 26.27}
{'loss': 0.0095, 'grad_norm': 4.609986782073975, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.0034938883036375046, 'loss_2': 0.00605010986328125, 'loss_3': -16.239315032958984, 'loss_4': 1.1906572580337524, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 11:15:28,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:28,478 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:17<10:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:35,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011772148311138153, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009240410290658474, 'eval_loss_2': 0.0025317370891571045, 'eval_loss_3': -18.238882064819336, 'eval_loss_4': 1.1127924919128418, 'epoch': 26.28}
{'loss': 0.0392, 'grad_norm': 27.752548217773438, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.03387434780597687, 'loss_2': 0.00536346435546875, 'loss_3': -16.23472785949707, 'loss_4': 1.5764219760894775, 'epoch': 26.28}
{'loss': 0.0111, 'grad_norm': 5.176950931549072, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.008542417548596859, 'loss_2': 0.0025177001953125, 'loss_3': -16.231170654296875, 'loss_4': 0.9805248379707336, 'epoch': 26.29}
{'loss': 0.0337, 'grad_norm': 16.742063522338867, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.02895575761795044, 'loss_2': 0.004787445068359375, 'loss_3': -16.27610969543457, 'loss_4': 1.315775752067566, 'epoch': 26.3}
{'loss': 0.0042, 'grad_norm': 4.59211540222168, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.0035957321524620056, 'loss_2': 0.0005950927734375, 'loss_3': -16.170690536499023, 'loss_4': 2.018803119659424, 'epoch': 26.3}
{'loss': 0.0062, 'grad_norm': 5.1247453689575195, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.004215594381093979, 'loss_2': 0.0019378662109375, 'loss_3': -16.26593017578125, 'loss_4': 1.1370198726654053, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 11:15:35,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:35,817 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:25<10:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:43,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011771817691624165, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009115000255405903, 'eval_loss_2': 0.0026568174362182617, 'eval_loss_3': -18.244585037231445, 'eval_loss_4': 1.1294939517974854, 'epoch': 26.31}
{'loss': 0.0131, 'grad_norm': 4.416788578033447, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.00368694425560534, 'loss_2': 0.009368896484375, 'loss_3': -16.211288452148438, 'loss_4': 1.1489946842193604, 'epoch': 26.31}
{'loss': 0.0196, 'grad_norm': 9.731375694274902, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.019545942544937134, 'loss_2': 3.4332275390625e-05, 'loss_3': -16.3104248046875, 'loss_4': 2.1153430938720703, 'epoch': 26.32}
{'loss': 0.0058, 'grad_norm': 4.3502702713012695, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.0020787876565009356, 'loss_2': 0.0036830902099609375, 'loss_3': -16.419200897216797, 'loss_4': 1.303433895111084, 'epoch': 26.33}
{'loss': 0.0044, 'grad_norm': 4.561257839202881, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.002685240702703595, 'loss_2': 0.0017175674438476562, 'loss_3': -16.272174835205078, 'loss_4': 1.4610440731048584, 'epoch': 26.33}
{'loss': 0.0026, 'grad_norm': 4.776970863342285, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.0017558288527652621, 'loss_2': 0.0008134841918945312, 'loss_3': -16.344493865966797, 'loss_4': 1.7358012199401855, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 11:15:43,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:43,163 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:32<10:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:50,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011653650552034378, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.546, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009016919881105423, 'eval_loss_2': 0.002636730670928955, 'eval_loss_3': -18.22785186767578, 'eval_loss_4': 1.1512010097503662, 'epoch': 26.34}
{'loss': 0.0092, 'grad_norm': 5.01934814453125, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.0029972775373607874, 'loss_2': 0.00618743896484375, 'loss_3': -16.44476318359375, 'loss_4': 1.0167906284332275, 'epoch': 26.34}
{'loss': 0.0054, 'grad_norm': 4.376202583312988, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.0023665735498070717, 'loss_2': 0.002994537353515625, 'loss_3': -16.39739227294922, 'loss_4': 1.4131959676742554, 'epoch': 26.35}
{'loss': 0.0211, 'grad_norm': 8.168061256408691, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.014975907281041145, 'loss_2': 0.00614166259765625, 'loss_3': -16.195188522338867, 'loss_4': 1.9224432706832886, 'epoch': 26.35}
{'loss': 0.0102, 'grad_norm': 4.847496509552002, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.0037232539616525173, 'loss_2': 0.006500244140625, 'loss_3': -16.170896530151367, 'loss_4': 1.6684918403625488, 'epoch': 26.36}
{'loss': 0.0065, 'grad_norm': 4.826613903045654, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.0038438993506133556, 'loss_2': 0.0027008056640625, 'loss_3': -16.13913345336914, 'loss_4': 1.6285741329193115, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 11:15:50,504 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:50,504 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:40<10:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:57,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011448120698332787, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.248, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009006587788462639, 'eval_loss_2': 0.0024415329098701477, 'eval_loss_3': -18.218576431274414, 'eval_loss_4': 1.1776787042617798, 'epoch': 26.37}
{'loss': 0.0083, 'grad_norm': 4.664431095123291, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.006020004861056805, 'loss_2': 0.002277374267578125, 'loss_3': -16.26936149597168, 'loss_4': 1.3693788051605225, 'epoch': 26.37}
{'loss': 0.005, 'grad_norm': 4.573622226715088, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.004648127127438784, 'loss_2': 0.0003330707550048828, 'loss_3': -16.273115158081055, 'loss_4': 1.488303780555725, 'epoch': 26.38}
{'loss': 0.0182, 'grad_norm': 23.363290786743164, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.01777036115527153, 'loss_2': 0.00047516822814941406, 'loss_3': -16.3734130859375, 'loss_4': 1.3940304517745972, 'epoch': 26.38}
{'loss': 0.0279, 'grad_norm': 8.722955703735352, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.02063419297337532, 'loss_2': 0.007312774658203125, 'loss_3': -16.296226501464844, 'loss_4': 1.1296911239624023, 'epoch': 26.39}
{'loss': 0.0081, 'grad_norm': 5.30388069152832, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.007341968361288309, 'loss_2': 0.00074005126953125, 'loss_3': -16.12809181213379, 'loss_4': 1.5834598541259766, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 11:15:57,857 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:57,857 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:51:47<10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:05,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011594213545322418, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.423, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009119220077991486, 'eval_loss_2': 0.0024749934673309326, 'eval_loss_3': -18.207134246826172, 'eval_loss_4': 1.2151341438293457, 'epoch': 26.4}
{'loss': 0.0036, 'grad_norm': 4.967397212982178, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.0027335078921169043, 'loss_2': 0.000843048095703125, 'loss_3': -16.357450485229492, 'loss_4': 1.0500457286834717, 'epoch': 26.4}
{'loss': 0.0044, 'grad_norm': 4.942587375640869, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.0025283417198807, 'loss_2': 0.00191497802734375, 'loss_3': -16.34036636352539, 'loss_4': 1.8064839839935303, 'epoch': 26.41}
{'loss': 0.0061, 'grad_norm': 4.346228122711182, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.0036922383587807417, 'loss_2': 0.0024204254150390625, 'loss_3': -16.294437408447266, 'loss_4': 1.387163519859314, 'epoch': 26.41}
{'loss': 0.0078, 'grad_norm': 4.7715229988098145, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.003435926279053092, 'loss_2': 0.004322052001953125, 'loss_3': -16.326387405395508, 'loss_4': 0.6399106383323669, 'epoch': 26.42}
{'loss': 0.0103, 'grad_norm': 4.161469459533691, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.0027108059730380774, 'loss_2': 0.0076141357421875, 'loss_3': -16.26521873474121, 'loss_4': 1.352708101272583, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 11:16:05,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:05,209 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:51:54<10:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:12,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01193298865109682, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.833, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009484481066465378, 'eval_loss_2': 0.0024485066533088684, 'eval_loss_3': -18.207765579223633, 'eval_loss_4': 1.317874789237976, 'epoch': 26.42}
{'loss': 0.0077, 'grad_norm': 6.179917335510254, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.007022961042821407, 'loss_2': 0.00069427490234375, 'loss_3': -16.156585693359375, 'loss_4': 1.370285153388977, 'epoch': 26.43}
{'loss': 0.0034, 'grad_norm': 4.858040809631348, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.0033243875950574875, 'loss_2': 0.00011014938354492188, 'loss_3': -16.385116577148438, 'loss_4': 1.71107816696167, 'epoch': 26.44}
{'loss': 0.0109, 'grad_norm': 5.504648208618164, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.005857858806848526, 'loss_2': 0.0050811767578125, 'loss_3': -16.343791961669922, 'loss_4': 1.71242356300354, 'epoch': 26.44}
{'loss': 0.0117, 'grad_norm': 4.526372909545898, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.0027757417410612106, 'loss_2': 0.0088958740234375, 'loss_3': -16.490215301513672, 'loss_4': 1.5061942338943481, 'epoch': 26.45}
{'loss': 0.0069, 'grad_norm': 4.69102668762207, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.004423078615218401, 'loss_2': 0.002452850341796875, 'loss_3': -16.267471313476562, 'loss_4': 1.7416439056396484, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 11:16:12,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:12,547 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:02<10:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:19,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01191890798509121, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009641922079026699, 'eval_loss_2': 0.002276986837387085, 'eval_loss_3': -18.211828231811523, 'eval_loss_4': 1.4127305746078491, 'epoch': 26.45}
{'loss': 0.0053, 'grad_norm': 4.583637714385986, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.00235124584287405, 'loss_2': 0.002941131591796875, 'loss_3': -16.368942260742188, 'loss_4': 2.2494754791259766, 'epoch': 26.46}
{'loss': 0.0058, 'grad_norm': 4.867952346801758, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.003088300582021475, 'loss_2': 0.002727508544921875, 'loss_3': -16.420246124267578, 'loss_4': 1.515245795249939, 'epoch': 26.47}
{'loss': 0.0049, 'grad_norm': 4.625638961791992, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.0019549212884157896, 'loss_2': 0.0028972625732421875, 'loss_3': -16.31458282470703, 'loss_4': 1.8925201892852783, 'epoch': 26.47}
{'loss': 0.0068, 'grad_norm': 4.327925682067871, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.0036957620177417994, 'loss_2': 0.003108978271484375, 'loss_3': -16.406482696533203, 'loss_4': 2.6257071495056152, 'epoch': 26.48}
{'loss': 0.014, 'grad_norm': 8.434773445129395, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.012052685022354126, 'loss_2': 0.0019273757934570312, 'loss_3': -16.193984985351562, 'loss_4': 1.6109611988067627, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 11:16:19,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:19,890 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:09<10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:27,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01195269450545311, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009663354605436325, 'eval_loss_2': 0.0022893399000167847, 'eval_loss_3': -18.20039939880371, 'eval_loss_4': 1.4964513778686523, 'epoch': 26.48}
{'loss': 0.0043, 'grad_norm': 4.621801853179932, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.0017067276639863849, 'loss_2': 0.002574920654296875, 'loss_3': -16.461204528808594, 'loss_4': 2.067504405975342, 'epoch': 26.49}
{'loss': 0.0076, 'grad_norm': 4.961739540100098, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.005558590870350599, 'loss_2': 0.0020294189453125, 'loss_3': -16.3481502532959, 'loss_4': 2.181305170059204, 'epoch': 26.49}
{'loss': 0.0049, 'grad_norm': 4.9297003746032715, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.004862023983150721, 'loss_2': 2.0802021026611328e-05, 'loss_3': -16.42620849609375, 'loss_4': 2.121178150177002, 'epoch': 26.5}
{'loss': 0.0161, 'grad_norm': 12.27629566192627, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.012161494232714176, 'loss_2': 0.003936767578125, 'loss_3': -16.336181640625, 'loss_4': 2.08880615234375, 'epoch': 26.51}
{'loss': 0.0101, 'grad_norm': 4.460385322570801, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.0028779818676412106, 'loss_2': 0.00727081298828125, 'loss_3': -16.488008499145508, 'loss_4': 2.048478603363037, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 11:16:27,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:27,223 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:16<10:26,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:16:34,775 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01229123305529356, 'eval_runtime': 4.0029, 'eval_samples_per_second': 255.811, 'eval_steps_per_second': 3.997, 'eval_loss_1': 0.009406249038875103, 'eval_loss_2': 0.002884984016418457, 'eval_loss_3': -18.201679229736328, 'eval_loss_4': 1.5278419256210327, 'epoch': 26.51}
{'loss': 0.0057, 'grad_norm': 15.596020698547363, 'learning_rate': 3.5e-06, 'loss_1': 0.003617621725425124, 'loss_2': 0.0020771026611328125, 'loss_3': -16.226778030395508, 'loss_4': 1.9226957559585571, 'epoch': 26.52}
{'loss': 0.01, 'grad_norm': 7.063557147979736, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.008437898941338062, 'loss_2': 0.00156402587890625, 'loss_3': -16.29881477355957, 'loss_4': 1.9059072732925415, 'epoch': 26.52}
{'loss': 0.0071, 'grad_norm': 4.41595983505249, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.003450052347034216, 'loss_2': 0.00360107421875, 'loss_3': -16.313335418701172, 'loss_4': 1.9458978176116943, 'epoch': 26.53}
{'loss': 0.0068, 'grad_norm': 4.603281021118164, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.002166242338716984, 'loss_2': 0.00467681884765625, 'loss_3': -16.408161163330078, 'loss_4': 1.380710482597351, 'epoch': 26.53}
{'loss': 0.0124, 'grad_norm': 5.171506881713867, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.006807845551520586, 'loss_2': 0.00563812255859375, 'loss_3': -16.4443302154541, 'loss_4': 1.9199795722961426, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 11:16:34,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:34,775 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:24<10:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:42,127 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012171050533652306, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.852, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009329750202596188, 'eval_loss_2': 0.0028413012623786926, 'eval_loss_3': -18.205228805541992, 'eval_loss_4': 1.5296969413757324, 'epoch': 26.54}
{'loss': 0.011, 'grad_norm': 4.704361915588379, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.0022155779879540205, 'loss_2': 0.008758544921875, 'loss_3': -16.4035701751709, 'loss_4': 1.5685956478118896, 'epoch': 26.55}
{'loss': 0.0129, 'grad_norm': 5.836487770080566, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.009797784499824047, 'loss_2': 0.00313568115234375, 'loss_3': -16.392715454101562, 'loss_4': 1.5867981910705566, 'epoch': 26.55}
{'loss': 0.0116, 'grad_norm': 4.84649658203125, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.005843347869813442, 'loss_2': 0.005733489990234375, 'loss_3': -16.31608009338379, 'loss_4': 1.475198745727539, 'epoch': 26.56}
{'loss': 0.0037, 'grad_norm': 4.266251087188721, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.002472982043400407, 'loss_2': 0.001201629638671875, 'loss_3': -16.160551071166992, 'loss_4': 1.995107650756836, 'epoch': 26.56}
{'loss': 0.0062, 'grad_norm': 5.034786701202393, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.005643676500767469, 'loss_2': 0.0005817413330078125, 'loss_3': -16.293853759765625, 'loss_4': 1.714325189590454, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 11:16:42,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:42,128 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:31<10:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:49,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01135176233947277, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.238, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009028589352965355, 'eval_loss_2': 0.0023231729865074158, 'eval_loss_3': -18.212812423706055, 'eval_loss_4': 1.5530294179916382, 'epoch': 26.57}
{'loss': 0.0203, 'grad_norm': 9.704793930053711, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.016720302402973175, 'loss_2': 0.003604888916015625, 'loss_3': -16.419572830200195, 'loss_4': 2.108469009399414, 'epoch': 26.58}
{'loss': 0.0127, 'grad_norm': 5.462213516235352, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.006570952013134956, 'loss_2': 0.00617218017578125, 'loss_3': -16.468128204345703, 'loss_4': 1.7579245567321777, 'epoch': 26.58}
{'loss': 0.0074, 'grad_norm': 4.735454559326172, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.0032772256527096033, 'loss_2': 0.00409698486328125, 'loss_3': -16.185588836669922, 'loss_4': 2.078202247619629, 'epoch': 26.59}
{'loss': 0.0364, 'grad_norm': 24.033626556396484, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.030540501698851585, 'loss_2': 0.00585174560546875, 'loss_3': -16.237464904785156, 'loss_4': 1.4726977348327637, 'epoch': 26.59}
{'loss': 0.0064, 'grad_norm': 4.1631693840026855, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.0031162367668002844, 'loss_2': 0.003307342529296875, 'loss_3': -16.424575805664062, 'loss_4': 2.2107648849487305, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 11:16:49,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:49,470 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:38<10:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:56,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011075391434133053, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.227, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009096985682845116, 'eval_loss_2': 0.0019784048199653625, 'eval_loss_3': -18.226531982421875, 'eval_loss_4': 1.5460706949234009, 'epoch': 26.6}
{'loss': 0.0062, 'grad_norm': 4.424172401428223, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.0031474921852350235, 'loss_2': 0.00305938720703125, 'loss_3': -16.352615356445312, 'loss_4': 1.8063509464263916, 'epoch': 26.6}
{'loss': 0.0058, 'grad_norm': 4.3975396156311035, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.0029806867241859436, 'loss_2': 0.002841949462890625, 'loss_3': -16.199966430664062, 'loss_4': 1.884474754333496, 'epoch': 26.61}
{'loss': 0.0045, 'grad_norm': 4.88245153427124, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.002515024272724986, 'loss_2': 0.001964569091796875, 'loss_3': -16.291305541992188, 'loss_4': 1.9270960092544556, 'epoch': 26.62}
{'loss': 0.0132, 'grad_norm': 5.16590690612793, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.005483077839016914, 'loss_2': 0.00766754150390625, 'loss_3': -16.36039924621582, 'loss_4': 1.6440680027008057, 'epoch': 26.62}
{'loss': 0.003, 'grad_norm': 4.458928108215332, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.0016483227955177426, 'loss_2': 0.0013380050659179688, 'loss_3': -16.224597930908203, 'loss_4': 1.790982961654663, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 11:16:56,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:56,816 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:52:46<09:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:04,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011803414672613144, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.626, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00879661738872528, 'eval_loss_2': 0.003006797283887863, 'eval_loss_3': -18.228845596313477, 'eval_loss_4': 1.476328730583191, 'epoch': 26.63}
{'loss': 0.0119, 'grad_norm': 4.549335956573486, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.00537077896296978, 'loss_2': 0.006526947021484375, 'loss_3': -16.397809982299805, 'loss_4': 2.4890875816345215, 'epoch': 26.63}
{'loss': 0.0141, 'grad_norm': 5.134040355682373, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.005803038366138935, 'loss_2': 0.00833892822265625, 'loss_3': -16.41312599182129, 'loss_4': 1.5762742757797241, 'epoch': 26.64}
{'loss': 0.0073, 'grad_norm': 4.492504119873047, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.004441140219569206, 'loss_2': 0.002880096435546875, 'loss_3': -16.254409790039062, 'loss_4': 1.5884907245635986, 'epoch': 26.65}
{'loss': 0.0055, 'grad_norm': 5.109756946563721, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.003251218469813466, 'loss_2': 0.002277374267578125, 'loss_3': -16.24474334716797, 'loss_4': 1.4600666761398315, 'epoch': 26.65}
{'loss': 0.0278, 'grad_norm': 9.686062812805176, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.022137178108096123, 'loss_2': 0.00567626953125, 'loss_3': -16.273691177368164, 'loss_4': 1.7943048477172852, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 11:17:04,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:04,159 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:52:53<09:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:11,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012024518102407455, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008883350528776646, 'eval_loss_2': 0.003141164779663086, 'eval_loss_3': -18.230504989624023, 'eval_loss_4': 1.3934125900268555, 'epoch': 26.66}
{'loss': 0.0052, 'grad_norm': 4.486708641052246, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.004655295051634312, 'loss_2': 0.0005922317504882812, 'loss_3': -16.339061737060547, 'loss_4': 1.9704833030700684, 'epoch': 26.66}
{'loss': 0.0071, 'grad_norm': 4.813797950744629, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.005095022264868021, 'loss_2': 0.0019989013671875, 'loss_3': -16.510412216186523, 'loss_4': 1.2964181900024414, 'epoch': 26.67}
{'loss': 0.0069, 'grad_norm': 4.577160835266113, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.002707384992390871, 'loss_2': 0.004207611083984375, 'loss_3': -16.114028930664062, 'loss_4': 1.6266354322433472, 'epoch': 26.67}
{'loss': 0.0057, 'grad_norm': 4.64833402633667, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.0024130905512720346, 'loss_2': 0.0032901763916015625, 'loss_3': -16.492664337158203, 'loss_4': 1.8696829080581665, 'epoch': 26.68}
{'loss': 0.0064, 'grad_norm': 5.219388008117676, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.003870740532875061, 'loss_2': 0.0025234222412109375, 'loss_3': -16.362804412841797, 'loss_4': 1.6278088092803955, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 11:17:11,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:11,511 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:01<09:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:18,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012333942577242851, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008942044340074062, 'eval_loss_2': 0.003391895443201065, 'eval_loss_3': -18.247243881225586, 'eval_loss_4': 1.320812463760376, 'epoch': 26.69}
{'loss': 0.0083, 'grad_norm': 5.284881114959717, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.0037134503945708275, 'loss_2': 0.00460052490234375, 'loss_3': -16.471179962158203, 'loss_4': 1.5428920984268188, 'epoch': 26.69}
{'loss': 0.0113, 'grad_norm': 5.230778694152832, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.005425581242889166, 'loss_2': 0.005825042724609375, 'loss_3': -16.236492156982422, 'loss_4': 1.4300928115844727, 'epoch': 26.7}
{'loss': 0.0089, 'grad_norm': 4.482884407043457, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.0071434262208640575, 'loss_2': 0.0017948150634765625, 'loss_3': -16.216026306152344, 'loss_4': 1.409822702407837, 'epoch': 26.7}
{'loss': 0.0111, 'grad_norm': 6.382521629333496, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.00966696161776781, 'loss_2': 0.0014791488647460938, 'loss_3': -16.32949447631836, 'loss_4': 1.2950050830841064, 'epoch': 26.71}
{'loss': 0.0187, 'grad_norm': 5.0877180099487305, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.01433546096086502, 'loss_2': 0.004364013671875, 'loss_3': -16.194162368774414, 'loss_4': 1.5265812873840332, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 11:17:18,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:18,867 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:08<09:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:26,222 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011897147633135319, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.536, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008929654955863953, 'eval_loss_2': 0.0029674917459487915, 'eval_loss_3': -18.24802589416504, 'eval_loss_4': 1.3093905448913574, 'epoch': 26.72}
{'loss': 0.0083, 'grad_norm': 4.9474005699157715, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.0036338979844003916, 'loss_2': 0.0046539306640625, 'loss_3': -16.319149017333984, 'loss_4': 1.8048568964004517, 'epoch': 26.72}
{'loss': 0.005, 'grad_norm': 3.946234941482544, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.0035415377933532, 'loss_2': 0.001438140869140625, 'loss_3': -16.507429122924805, 'loss_4': 1.6742899417877197, 'epoch': 26.73}
{'loss': 0.0145, 'grad_norm': 8.327474594116211, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.007724625989794731, 'loss_2': 0.006801605224609375, 'loss_3': -16.217302322387695, 'loss_4': 2.006948947906494, 'epoch': 26.73}
{'loss': 0.004, 'grad_norm': 4.253720760345459, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.0026426194235682487, 'loss_2': 0.0013828277587890625, 'loss_3': -16.370433807373047, 'loss_4': 1.7813249826431274, 'epoch': 26.74}
{'loss': 0.0048, 'grad_norm': 4.957452774047852, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.004288872238248587, 'loss_2': 0.0005450248718261719, 'loss_3': -16.46481704711914, 'loss_4': 1.459728479385376, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 11:17:26,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:26,223 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:15<09:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:33,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01134287379682064, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008795460686087608, 'eval_loss_2': 0.0025474131107330322, 'eval_loss_3': -18.249162673950195, 'eval_loss_4': 1.288449764251709, 'epoch': 26.74}
{'loss': 0.0119, 'grad_norm': 4.459203243255615, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.004457158502191305, 'loss_2': 0.0074920654296875, 'loss_3': -16.187911987304688, 'loss_4': 1.758000135421753, 'epoch': 26.75}
{'loss': 0.0055, 'grad_norm': 4.585082530975342, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.0023387097753584385, 'loss_2': 0.003139495849609375, 'loss_3': -16.394575119018555, 'loss_4': 1.598192811012268, 'epoch': 26.76}
{'loss': 0.0042, 'grad_norm': 4.225564479827881, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.0021073666866868734, 'loss_2': 0.00209808349609375, 'loss_3': -16.374412536621094, 'loss_4': 1.6637215614318848, 'epoch': 26.76}
{'loss': 0.0119, 'grad_norm': 4.778824329376221, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.004691493697464466, 'loss_2': 0.007190704345703125, 'loss_3': -16.26485824584961, 'loss_4': 1.65928053855896, 'epoch': 26.77}
{'loss': 0.014, 'grad_norm': 10.198522567749023, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.00868239626288414, 'loss_2': 0.0052947998046875, 'loss_3': -16.38228988647461, 'loss_4': 1.6162934303283691, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 11:17:33,563 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:33,563 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:23<09:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:40,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011908142827451229, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009127609431743622, 'eval_loss_2': 0.002780534327030182, 'eval_loss_3': -18.240018844604492, 'eval_loss_4': 1.28756844997406, 'epoch': 26.77}
{'loss': 0.0072, 'grad_norm': 4.252634525299072, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.003026423044502735, 'loss_2': 0.0041961669921875, 'loss_3': -16.080854415893555, 'loss_4': 1.5437450408935547, 'epoch': 26.78}
{'loss': 0.0054, 'grad_norm': 4.575741291046143, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.0031082117930054665, 'loss_2': 0.00229644775390625, 'loss_3': -16.389402389526367, 'loss_4': 2.045048952102661, 'epoch': 26.78}
{'loss': 0.0071, 'grad_norm': 4.576045989990234, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.0032544280402362347, 'loss_2': 0.003875732421875, 'loss_3': -16.469314575195312, 'loss_4': 1.4812707901000977, 'epoch': 26.79}
{'loss': 0.0087, 'grad_norm': 5.097264289855957, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.004700512625277042, 'loss_2': 0.0040130615234375, 'loss_3': -16.20047950744629, 'loss_4': 1.5417530536651611, 'epoch': 26.8}
{'loss': 0.0066, 'grad_norm': 4.44183874130249, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.004824305884540081, 'loss_2': 0.001766204833984375, 'loss_3': -16.218379974365234, 'loss_4': 2.0430591106414795, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 11:17:40,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:40,909 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:30<09:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:48,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012514209374785423, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.636, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00974416732788086, 'eval_loss_2': 0.002770043909549713, 'eval_loss_3': -18.235477447509766, 'eval_loss_4': 1.2884266376495361, 'epoch': 26.8}
{'loss': 0.0107, 'grad_norm': 5.1489129066467285, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.006462303455919027, 'loss_2': 0.00420379638671875, 'loss_3': -16.291580200195312, 'loss_4': 1.589408278465271, 'epoch': 26.81}
{'loss': 0.0081, 'grad_norm': 5.008172988891602, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.006019881460815668, 'loss_2': 0.0020771026611328125, 'loss_3': -16.22420310974121, 'loss_4': 1.4755754470825195, 'epoch': 26.81}
{'loss': 0.0043, 'grad_norm': 4.956170082092285, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.003089155303314328, 'loss_2': 0.0011692047119140625, 'loss_3': -16.363300323486328, 'loss_4': 1.3401427268981934, 'epoch': 26.82}
{'loss': 0.0125, 'grad_norm': 8.002969741821289, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.011513499543070793, 'loss_2': 0.0009469985961914062, 'loss_3': -16.312442779541016, 'loss_4': 1.4081759452819824, 'epoch': 26.83}
{'loss': 0.0067, 'grad_norm': 4.555477142333984, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.0031375493854284286, 'loss_2': 0.0035953521728515625, 'loss_3': -16.167680740356445, 'loss_4': 1.3416547775268555, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 11:17:48,252 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:48,252 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:37<09:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:55,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01242426224052906, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009877506643533707, 'eval_loss_2': 0.002546757459640503, 'eval_loss_3': -18.233440399169922, 'eval_loss_4': 1.290339469909668, 'epoch': 26.83}
{'loss': 0.0031, 'grad_norm': 4.8479790687561035, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.0025440833996981382, 'loss_2': 0.0005941390991210938, 'loss_3': -16.198585510253906, 'loss_4': 1.5209901332855225, 'epoch': 26.84}
{'loss': 0.0067, 'grad_norm': 4.722116947174072, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.004009166732430458, 'loss_2': 0.0027103424072265625, 'loss_3': -16.187068939208984, 'loss_4': 2.479053258895874, 'epoch': 26.84}
{'loss': 0.0056, 'grad_norm': 5.380547523498535, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.004095469135791063, 'loss_2': 0.0015163421630859375, 'loss_3': -16.061004638671875, 'loss_4': 1.6066374778747559, 'epoch': 26.85}
{'loss': 0.0046, 'grad_norm': 4.095653057098389, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.0025068088434636593, 'loss_2': 0.0020599365234375, 'loss_3': -16.553504943847656, 'loss_4': 1.2122942209243774, 'epoch': 26.85}
{'loss': 0.0097, 'grad_norm': 4.515917778015137, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.0049209254793822765, 'loss_2': 0.004795074462890625, 'loss_3': -16.33393096923828, 'loss_4': 1.6322283744812012, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 11:17:55,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:55,591 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:53:45<09:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:02,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012698911130428314, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010150707326829433, 'eval_loss_2': 0.002548202872276306, 'eval_loss_3': -18.2315673828125, 'eval_loss_4': 1.3205316066741943, 'epoch': 26.86}
{'loss': 0.0075, 'grad_norm': 6.370267391204834, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.0064956871792674065, 'loss_2': 0.0009975433349609375, 'loss_3': -16.264415740966797, 'loss_4': 1.7603113651275635, 'epoch': 26.87}
{'loss': 0.0072, 'grad_norm': 4.705456256866455, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.00582945765927434, 'loss_2': 0.001384735107421875, 'loss_3': -16.280258178710938, 'loss_4': 1.7909715175628662, 'epoch': 26.87}
{'loss': 0.0033, 'grad_norm': 4.473935604095459, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.003229374997317791, 'loss_2': 0.00011134147644042969, 'loss_3': -16.10283660888672, 'loss_4': 1.9531104564666748, 'epoch': 26.88}
{'loss': 0.0073, 'grad_norm': 4.2939653396606445, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.0021498273126780987, 'loss_2': 0.005130767822265625, 'loss_3': -16.329866409301758, 'loss_4': 1.96486234664917, 'epoch': 26.88}
{'loss': 0.0241, 'grad_norm': 12.358213424682617, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.019938448444008827, 'loss_2': 0.00417327880859375, 'loss_3': -16.249061584472656, 'loss_4': 1.9970712661743164, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 11:18:02,943 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:02,943 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:53:52<09:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:10,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012943534180521965, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010467229411005974, 'eval_loss_2': 0.002476304769515991, 'eval_loss_3': -18.24209976196289, 'eval_loss_4': 1.371415615081787, 'epoch': 26.89}
{'loss': 0.0059, 'grad_norm': 4.854238510131836, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.002969750203192234, 'loss_2': 0.002941131591796875, 'loss_3': -16.29413604736328, 'loss_4': 1.7150187492370605, 'epoch': 26.9}
{'loss': 0.0024, 'grad_norm': 4.8052754402160645, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.0020230417139828205, 'loss_2': 0.0003452301025390625, 'loss_3': -16.265886306762695, 'loss_4': 1.5079877376556396, 'epoch': 26.9}
{'loss': 0.0079, 'grad_norm': 4.495187282562256, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.0023948338348418474, 'loss_2': 0.005550384521484375, 'loss_3': -16.140098571777344, 'loss_4': 1.5497616529464722, 'epoch': 26.91}
{'loss': 0.0134, 'grad_norm': 4.622692584991455, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.006523961666971445, 'loss_2': 0.00691986083984375, 'loss_3': -16.32724380493164, 'loss_4': 1.6318851709365845, 'epoch': 26.91}
{'loss': 0.0032, 'grad_norm': 4.322157859802246, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.00228261761367321, 'loss_2': 0.0009241104125976562, 'loss_3': -16.36983871459961, 'loss_4': 1.8754431009292603, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 11:18:10,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:10,280 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:53:59<09:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:17,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013182263821363449, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010653160512447357, 'eval_loss_2': 0.002529103308916092, 'eval_loss_3': -18.235782623291016, 'eval_loss_4': 1.4006991386413574, 'epoch': 26.92}
{'loss': 0.011, 'grad_norm': 4.382449626922607, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.002444951329380274, 'loss_2': 0.008575439453125, 'loss_3': -16.238067626953125, 'loss_4': 1.1990814208984375, 'epoch': 26.92}
{'loss': 0.0051, 'grad_norm': 4.307923316955566, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.002373765455558896, 'loss_2': 0.002716064453125, 'loss_3': -16.295024871826172, 'loss_4': 1.889392375946045, 'epoch': 26.93}
{'loss': 0.0054, 'grad_norm': 4.27731990814209, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.004005735274404287, 'loss_2': 0.0013885498046875, 'loss_3': -16.45441436767578, 'loss_4': 2.0528323650360107, 'epoch': 26.94}
{'loss': 0.0078, 'grad_norm': 4.307632923126221, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.0022895564325153828, 'loss_2': 0.0055389404296875, 'loss_3': -16.26947021484375, 'loss_4': 1.7837679386138916, 'epoch': 26.94}
{'loss': 0.019, 'grad_norm': 6.1168084144592285, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.010820760391652584, 'loss_2': 0.00815582275390625, 'loss_3': -16.300743103027344, 'loss_4': 1.5388312339782715, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 11:18:17,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:17,619 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:07<08:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:24,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013047749176621437, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.553, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01037471555173397, 'eval_loss_2': 0.0026730336248874664, 'eval_loss_3': -18.239521026611328, 'eval_loss_4': 1.4031484127044678, 'epoch': 26.95}
{'loss': 0.0048, 'grad_norm': 5.05801248550415, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.004448717460036278, 'loss_2': 0.00036525726318359375, 'loss_3': -16.329607009887695, 'loss_4': 1.486033320426941, 'epoch': 26.95}
{'loss': 0.0062, 'grad_norm': 4.708230018615723, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.004868922755122185, 'loss_2': 0.0013599395751953125, 'loss_3': -16.288921356201172, 'loss_4': 1.7406411170959473, 'epoch': 26.96}
{'loss': 0.0051, 'grad_norm': 4.524294376373291, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.004545611795037985, 'loss_2': 0.000598907470703125, 'loss_3': -16.302200317382812, 'loss_4': 1.6338040828704834, 'epoch': 26.97}
{'loss': 0.0132, 'grad_norm': 6.731807231903076, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.00845201127231121, 'loss_2': 0.004730224609375, 'loss_3': -16.329837799072266, 'loss_4': 1.408488392829895, 'epoch': 26.97}
{'loss': 0.005, 'grad_norm': 4.889832973480225, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.004064318723976612, 'loss_2': 0.0009450912475585938, 'loss_3': -16.218788146972656, 'loss_4': 2.0537309646606445, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 11:18:24,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:24,962 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:14<08:22,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 11:18:31,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012792084366083145, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010322440415620804, 'eval_loss_2': 0.0024696439504623413, 'eval_loss_3': -18.239295959472656, 'eval_loss_4': 1.3909788131713867, 'epoch': 26.98}
{'loss': 0.005, 'grad_norm': 4.623997211456299, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0028016562573611736, 'loss_2': 0.002201080322265625, 'loss_3': -16.424694061279297, 'loss_4': 1.9732544422149658, 'epoch': 26.98}
{'loss': 0.0054, 'grad_norm': 4.637483596801758, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.003183392807841301, 'loss_2': 0.0022220611572265625, 'loss_3': -16.363588333129883, 'loss_4': 1.1198049783706665, 'epoch': 26.99}
{'loss': 0.0083, 'grad_norm': 6.196697235107422, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.008109031245112419, 'loss_2': 0.000217437744140625, 'loss_3': -16.2614688873291, 'loss_4': 2.0250275135040283, 'epoch': 26.99}
{'loss': 0.0077, 'grad_norm': 7.561776161193848, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.005960138980299234, 'loss_2': 0.0017852783203125, 'loss_3': -16.035432815551758, 'loss_4': 2.115917205810547, 'epoch': 27.0}
{'loss': 0.0036, 'grad_norm': 4.337243556976318, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.002055105287581682, 'loss_2': 0.001583099365234375, 'loss_3': -16.374788284301758, 'loss_4': 1.7567403316497803, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 11:18:31,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:31,985 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:21<08:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:18:39,331 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012729192152619362, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.51, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010325157083570957, 'eval_loss_2': 0.00240403413772583, 'eval_loss_3': -18.24028205871582, 'eval_loss_4': 1.3686119318008423, 'epoch': 27.01}
{'loss': 0.0047, 'grad_norm': 5.288942813873291, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.0037305662408471107, 'loss_2': 0.0009937286376953125, 'loss_3': -16.209606170654297, 'loss_4': 1.8505079746246338, 'epoch': 27.01}
{'loss': 0.0046, 'grad_norm': 4.499385356903076, 'learning_rate': 3e-06, 'loss_1': 0.0030330647714436054, 'loss_2': 0.0016155242919921875, 'loss_3': -16.64019775390625, 'loss_4': 1.1421000957489014, 'epoch': 27.02}
{'loss': 0.0086, 'grad_norm': 4.424685001373291, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.00508161773905158, 'loss_2': 0.003520965576171875, 'loss_3': -16.31727409362793, 'loss_4': 1.3905601501464844, 'epoch': 27.02}
{'loss': 0.0107, 'grad_norm': 5.815563201904297, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.008191944099962711, 'loss_2': 0.002552032470703125, 'loss_3': -16.374189376831055, 'loss_4': 1.8742120265960693, 'epoch': 27.03}
{'loss': 0.0176, 'grad_norm': 12.567071914672852, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.014406759291887283, 'loss_2': 0.003147125244140625, 'loss_3': -16.19753646850586, 'loss_4': 1.753722906112671, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 11:18:39,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:39,331 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:28<08:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:46,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012625724077224731, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.812, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01029336266219616, 'eval_loss_2': 0.002332359552383423, 'eval_loss_3': -18.246545791625977, 'eval_loss_4': 1.3416848182678223, 'epoch': 27.03}
{'loss': 0.006, 'grad_norm': 5.05822229385376, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.0043152207508683205, 'loss_2': 0.0016498565673828125, 'loss_3': -16.28679084777832, 'loss_4': 1.763453722000122, 'epoch': 27.04}
{'loss': 0.0072, 'grad_norm': 4.34909200668335, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.0037882779724895954, 'loss_2': 0.003452301025390625, 'loss_3': -16.3121337890625, 'loss_4': 1.3219681978225708, 'epoch': 27.05}
{'loss': 0.0072, 'grad_norm': 4.716522216796875, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.004434037487953901, 'loss_2': 0.0027675628662109375, 'loss_3': -16.497451782226562, 'loss_4': 1.627467393875122, 'epoch': 27.05}
{'loss': 0.0102, 'grad_norm': 4.647402763366699, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.0038132218178361654, 'loss_2': 0.006420135498046875, 'loss_3': -16.325912475585938, 'loss_4': 1.3351304531097412, 'epoch': 27.06}
{'loss': 0.0169, 'grad_norm': 8.277244567871094, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.013388419523835182, 'loss_2': 0.003543853759765625, 'loss_3': -16.304901123046875, 'loss_4': 1.6399850845336914, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 11:18:46,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:46,681 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:36<08:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:54,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012974054552614689, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.301, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010575324296951294, 'eval_loss_2': 0.0023987293243408203, 'eval_loss_3': -18.252012252807617, 'eval_loss_4': 1.294365406036377, 'epoch': 27.06}
{'loss': 0.0043, 'grad_norm': 4.780426502227783, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.0034100019838660955, 'loss_2': 0.0008940696716308594, 'loss_3': -16.27049446105957, 'loss_4': 1.6452664136886597, 'epoch': 27.07}
{'loss': 0.0055, 'grad_norm': 5.012206554412842, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.0034517827443778515, 'loss_2': 0.0019989013671875, 'loss_3': -15.998903274536133, 'loss_4': 2.0622007846832275, 'epoch': 27.08}
{'loss': 0.0047, 'grad_norm': 4.321061134338379, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.0018580796895548701, 'loss_2': 0.00287628173828125, 'loss_3': -16.52217674255371, 'loss_4': 1.1485049724578857, 'epoch': 27.08}
{'loss': 0.0081, 'grad_norm': 4.726843357086182, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.0026651923544704914, 'loss_2': 0.00539398193359375, 'loss_3': -16.206645965576172, 'loss_4': 2.0434489250183105, 'epoch': 27.09}
{'loss': 0.0121, 'grad_norm': 5.242538928985596, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.006518958136439323, 'loss_2': 0.005584716796875, 'loss_3': -16.213581085205078, 'loss_4': 1.9364197254180908, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 11:18:54,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:54,027 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:54:43<08:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:01,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012671287171542645, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00999867171049118, 'eval_loss_2': 0.0026726126670837402, 'eval_loss_3': -18.258554458618164, 'eval_loss_4': 1.25443434715271, 'epoch': 27.09}
{'loss': 0.0124, 'grad_norm': 4.324387550354004, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.006238026078790426, 'loss_2': 0.006134033203125, 'loss_3': -16.34129524230957, 'loss_4': 1.982404351234436, 'epoch': 27.1}
{'loss': 0.0074, 'grad_norm': 4.8371429443359375, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.003820840734988451, 'loss_2': 0.00362396240234375, 'loss_3': -16.045516967773438, 'loss_4': 1.36790132522583, 'epoch': 27.1}
{'loss': 0.0105, 'grad_norm': 4.226657390594482, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.0031429666560143232, 'loss_2': 0.007335662841796875, 'loss_3': -16.441259384155273, 'loss_4': 1.715864896774292, 'epoch': 27.11}
{'loss': 0.0081, 'grad_norm': 4.468685150146484, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.004300420638173819, 'loss_2': 0.003818511962890625, 'loss_3': -16.308820724487305, 'loss_4': 1.4479063749313354, 'epoch': 27.12}
{'loss': 0.0083, 'grad_norm': 5.022587299346924, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.003047835547477007, 'loss_2': 0.005268096923828125, 'loss_3': -16.211265563964844, 'loss_4': 1.4876827001571655, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 11:19:01,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:01,362 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:54:50<08:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:08,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012577420100569725, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009627796709537506, 'eval_loss_2': 0.002949625253677368, 'eval_loss_3': -18.254785537719727, 'eval_loss_4': 1.2489268779754639, 'epoch': 27.12}
{'loss': 0.0069, 'grad_norm': 4.730244159698486, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.0052680340595543385, 'loss_2': 0.00164794921875, 'loss_3': -16.388376235961914, 'loss_4': 1.217012643814087, 'epoch': 27.13}
{'loss': 0.0028, 'grad_norm': 4.296248435974121, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.0020341831259429455, 'loss_2': 0.0008001327514648438, 'loss_3': -16.3237247467041, 'loss_4': 1.8930970430374146, 'epoch': 27.13}
{'loss': 0.0028, 'grad_norm': 4.942678928375244, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.0018625138327479362, 'loss_2': 0.0009784698486328125, 'loss_3': -16.26311492919922, 'loss_4': 1.4785335063934326, 'epoch': 27.14}
{'loss': 0.0093, 'grad_norm': 4.8486456871032715, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.004823198541998863, 'loss_2': 0.00446319580078125, 'loss_3': -16.330188751220703, 'loss_4': 1.5890467166900635, 'epoch': 27.15}
{'loss': 0.0042, 'grad_norm': 4.662774562835693, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.0030618691816926003, 'loss_2': 0.0011310577392578125, 'loss_3': -16.319597244262695, 'loss_4': 1.6239020824432373, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 11:19:08,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:08,701 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:54:58<08:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:16,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012650003656744957, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009382037445902824, 'eval_loss_2': 0.0032679662108421326, 'eval_loss_3': -18.2427978515625, 'eval_loss_4': 1.2880746126174927, 'epoch': 27.15}
{'loss': 0.0144, 'grad_norm': 6.445465564727783, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.006315898150205612, 'loss_2': 0.00809478759765625, 'loss_3': -16.22862434387207, 'loss_4': 2.021418571472168, 'epoch': 27.16}
{'loss': 0.0106, 'grad_norm': 4.928769111633301, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.004732068628072739, 'loss_2': 0.00591278076171875, 'loss_3': -16.278940200805664, 'loss_4': 1.7391607761383057, 'epoch': 27.16}
{'loss': 0.0072, 'grad_norm': 5.941413879394531, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.006042336113750935, 'loss_2': 0.0011882781982421875, 'loss_3': -16.172006607055664, 'loss_4': 1.7397255897521973, 'epoch': 27.17}
{'loss': 0.0089, 'grad_norm': 4.525831699371338, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.005646424368023872, 'loss_2': 0.003292083740234375, 'loss_3': -16.064252853393555, 'loss_4': 1.5590778589248657, 'epoch': 27.17}
{'loss': 0.0113, 'grad_norm': 9.392666816711426, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.009179872460663319, 'loss_2': 0.0020904541015625, 'loss_3': -16.338138580322266, 'loss_4': 1.4239503145217896, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 11:19:16,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:16,037 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:05<08:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:23,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012741221114993095, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.853, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009504511021077633, 'eval_loss_2': 0.003236711025238037, 'eval_loss_3': -18.24871253967285, 'eval_loss_4': 1.3386727571487427, 'epoch': 27.18}
{'loss': 0.0038, 'grad_norm': 5.057291507720947, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.0024490836076438427, 'loss_2': 0.0013866424560546875, 'loss_3': -16.305028915405273, 'loss_4': 2.2760133743286133, 'epoch': 27.19}
{'loss': 0.0126, 'grad_norm': 4.917906761169434, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.0037312328349798918, 'loss_2': 0.0088348388671875, 'loss_3': -16.29684829711914, 'loss_4': 1.8259214162826538, 'epoch': 27.19}
{'loss': 0.0073, 'grad_norm': 4.7347259521484375, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.004309974145144224, 'loss_2': 0.0029811859130859375, 'loss_3': -16.357168197631836, 'loss_4': 2.0225613117218018, 'epoch': 27.2}
{'loss': 0.0092, 'grad_norm': 5.060547828674316, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.0032432693988084793, 'loss_2': 0.005992889404296875, 'loss_3': -16.235830307006836, 'loss_4': 1.4458329677581787, 'epoch': 27.2}
{'loss': 0.01, 'grad_norm': 5.151832580566406, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.003425316186621785, 'loss_2': 0.00661468505859375, 'loss_3': -16.28131866455078, 'loss_4': 2.001387357711792, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 11:19:23,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:23,394 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:12<08:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:30,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012799179181456566, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009565925225615501, 'eval_loss_2': 0.0032332539558410645, 'eval_loss_3': -18.25502586364746, 'eval_loss_4': 1.3870856761932373, 'epoch': 27.21}
{'loss': 0.0114, 'grad_norm': 5.780853271484375, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.009340704418718815, 'loss_2': 0.0020751953125, 'loss_3': -16.386444091796875, 'loss_4': 1.8968192338943481, 'epoch': 27.22}
{'loss': 0.0187, 'grad_norm': 5.391434192657471, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.008371630683541298, 'loss_2': 0.01032257080078125, 'loss_3': -16.18973731994629, 'loss_4': 1.8490867614746094, 'epoch': 27.22}
{'loss': 0.0099, 'grad_norm': 4.855207443237305, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.006031388882547617, 'loss_2': 0.0038661956787109375, 'loss_3': -16.322628021240234, 'loss_4': 2.1734533309936523, 'epoch': 27.23}
{'loss': 0.0049, 'grad_norm': 4.176292896270752, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.004308747593313456, 'loss_2': 0.000614166259765625, 'loss_3': -16.42501449584961, 'loss_4': 1.591662883758545, 'epoch': 27.23}
{'loss': 0.0094, 'grad_norm': 4.747318267822266, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.0030938321724534035, 'loss_2': 0.00632476806640625, 'loss_3': -16.339828491210938, 'loss_4': 1.8816977739334106, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 11:19:30,736 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:30,736 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:20<08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:38,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012106390669941902, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.324, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00977064948529005, 'eval_loss_2': 0.0023357421159744263, 'eval_loss_3': -18.256725311279297, 'eval_loss_4': 1.4285624027252197, 'epoch': 27.24}
{'loss': 0.0035, 'grad_norm': 4.228638648986816, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.0030984675977379084, 'loss_2': 0.0004482269287109375, 'loss_3': -16.2906551361084, 'loss_4': 1.967923879623413, 'epoch': 27.24}
{'loss': 0.005, 'grad_norm': 4.612682819366455, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.004126600455492735, 'loss_2': 0.0009169578552246094, 'loss_3': -16.567249298095703, 'loss_4': 1.4788068532943726, 'epoch': 27.25}
{'loss': 0.0078, 'grad_norm': 5.682994842529297, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.006831177044659853, 'loss_2': 0.000995635986328125, 'loss_3': -16.198501586914062, 'loss_4': 1.9201090335845947, 'epoch': 27.26}
{'loss': 0.0046, 'grad_norm': 4.826448440551758, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.003187623107805848, 'loss_2': 0.0013866424560546875, 'loss_3': -16.311115264892578, 'loss_4': 1.5212650299072266, 'epoch': 27.26}
{'loss': 0.0049, 'grad_norm': 4.319236755371094, 'learning_rate': 2.75e-06, 'loss_1': 0.0032783360220491886, 'loss_2': 0.0016040802001953125, 'loss_3': -16.421772003173828, 'loss_4': 1.7924602031707764, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 11:19:38,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:38,082 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:27<08:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:45,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012388891540467739, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.5, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010189278982579708, 'eval_loss_2': 0.002199612557888031, 'eval_loss_3': -18.25404930114746, 'eval_loss_4': 1.4534821510314941, 'epoch': 27.27}
{'loss': 0.0119, 'grad_norm': 5.816061973571777, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.008191565051674843, 'loss_2': 0.003711700439453125, 'loss_3': -16.22064781188965, 'loss_4': 1.8485075235366821, 'epoch': 27.27}
{'loss': 0.0193, 'grad_norm': 7.481149673461914, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.012728511355817318, 'loss_2': 0.00653839111328125, 'loss_3': -16.31984519958496, 'loss_4': 1.964687705039978, 'epoch': 27.28}
{'loss': 0.0071, 'grad_norm': 5.390442848205566, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.0056155407801270485, 'loss_2': 0.0014638900756835938, 'loss_3': -15.95669937133789, 'loss_4': 1.8414522409439087, 'epoch': 27.28}
{'loss': 0.0122, 'grad_norm': 5.674771785736084, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.009983416646718979, 'loss_2': 0.00220489501953125, 'loss_3': -16.319290161132812, 'loss_4': 1.9652433395385742, 'epoch': 27.29}
{'loss': 0.0044, 'grad_norm': 5.14599609375, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.0031464113853871822, 'loss_2': 0.00122833251953125, 'loss_3': -16.175447463989258, 'loss_4': 1.4732993841171265, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 11:19:45,422 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:45,422 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:34<07:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:52,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012430409900844097, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.42, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010273920372128487, 'eval_loss_2': 0.002156488597393036, 'eval_loss_3': -18.254854202270508, 'eval_loss_4': 1.430436611175537, 'epoch': 27.3}
{'loss': 0.0095, 'grad_norm': 5.6235222816467285, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.004069202113896608, 'loss_2': 0.00543975830078125, 'loss_3': -16.525331497192383, 'loss_4': 2.1649413108825684, 'epoch': 27.3}
{'loss': 0.0264, 'grad_norm': 12.514174461364746, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.020998092368245125, 'loss_2': 0.0054168701171875, 'loss_3': -16.375, 'loss_4': 2.3336477279663086, 'epoch': 27.31}
{'loss': 0.0047, 'grad_norm': 4.51235294342041, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.003713733982294798, 'loss_2': 0.0009479522705078125, 'loss_3': -16.24338150024414, 'loss_4': 2.142850399017334, 'epoch': 27.31}
{'loss': 0.0097, 'grad_norm': 5.201213836669922, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.006109870970249176, 'loss_2': 0.0036182403564453125, 'loss_3': -16.32721710205078, 'loss_4': 1.663549780845642, 'epoch': 27.32}
{'loss': 0.0068, 'grad_norm': 4.693427562713623, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.0035106183495372534, 'loss_2': 0.0032501220703125, 'loss_3': -16.497533798217773, 'loss_4': 1.698951244354248, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 11:19:52,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:52,766 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:55:42<07:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:00,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01264209859073162, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01055094413459301, 'eval_loss_2': 0.002091154456138611, 'eval_loss_3': -18.246334075927734, 'eval_loss_4': 1.4092062711715698, 'epoch': 27.33}
{'loss': 0.0113, 'grad_norm': 4.915037631988525, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.004661399405449629, 'loss_2': 0.0066680908203125, 'loss_3': -16.329513549804688, 'loss_4': 2.244266986846924, 'epoch': 27.33}
{'loss': 0.0045, 'grad_norm': 4.311098575592041, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.00322107900865376, 'loss_2': 0.0012950897216796875, 'loss_3': -16.258020401000977, 'loss_4': 2.0171525478363037, 'epoch': 27.34}
{'loss': 0.0096, 'grad_norm': 4.0525898933410645, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.004595814738422632, 'loss_2': 0.00504302978515625, 'loss_3': -16.25139045715332, 'loss_4': 1.237194299697876, 'epoch': 27.34}
{'loss': 0.0184, 'grad_norm': 6.656652450561523, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.012089071795344353, 'loss_2': 0.006313323974609375, 'loss_3': -16.267757415771484, 'loss_4': 1.8836919069290161, 'epoch': 27.35}
{'loss': 0.0072, 'grad_norm': 5.37896728515625, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.006391279865056276, 'loss_2': 0.0008401870727539062, 'loss_3': -16.223194122314453, 'loss_4': 1.640411138534546, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 11:20:00,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:00,112 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:55:49<07:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:07,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012278186157345772, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.502, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010243493132293224, 'eval_loss_2': 0.002034693956375122, 'eval_loss_3': -18.243906021118164, 'eval_loss_4': 1.3646899461746216, 'epoch': 27.35}
{'loss': 0.0037, 'grad_norm': 4.283863544464111, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.001594453933648765, 'loss_2': 0.0020999908447265625, 'loss_3': -16.35637664794922, 'loss_4': 1.1481670141220093, 'epoch': 27.36}
{'loss': 0.0087, 'grad_norm': 6.324008464813232, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.008439715951681137, 'loss_2': 0.0003101825714111328, 'loss_3': -16.21588897705078, 'loss_4': 1.9741684198379517, 'epoch': 27.37}
{'loss': 0.0044, 'grad_norm': 4.302709579467773, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.0027960045263171196, 'loss_2': 0.0016002655029296875, 'loss_3': -16.156734466552734, 'loss_4': 1.4675053358078003, 'epoch': 27.37}
{'loss': 0.0072, 'grad_norm': 4.72220516204834, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.0029813137371093035, 'loss_2': 0.0042266845703125, 'loss_3': -16.21670913696289, 'loss_4': 1.6607381105422974, 'epoch': 27.38}
{'loss': 0.0143, 'grad_norm': 8.0863037109375, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.009529112838208675, 'loss_2': 0.0047607421875, 'loss_3': -16.47760581970215, 'loss_4': 2.096003770828247, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 11:20:07,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:07,474 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:55:56<07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:14,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011898208409547806, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.348, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01001039519906044, 'eval_loss_2': 0.0018878132104873657, 'eval_loss_3': -18.241113662719727, 'eval_loss_4': 1.3513381481170654, 'epoch': 27.38}
{'loss': 0.0075, 'grad_norm': 4.6061110496521, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.004999001044780016, 'loss_2': 0.002506256103515625, 'loss_3': -16.311290740966797, 'loss_4': 1.6004782915115356, 'epoch': 27.39}
{'loss': 0.0113, 'grad_norm': 5.555934906005859, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.006058616563677788, 'loss_2': 0.00527191162109375, 'loss_3': -16.256303787231445, 'loss_4': 1.2640643119812012, 'epoch': 27.4}
{'loss': 0.0311, 'grad_norm': 14.859838485717773, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.027446480467915535, 'loss_2': 0.003696441650390625, 'loss_3': -16.31481170654297, 'loss_4': 1.7976224422454834, 'epoch': 27.4}
{'loss': 0.0238, 'grad_norm': 13.049797058105469, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.018279697746038437, 'loss_2': 0.00553131103515625, 'loss_3': -16.175262451171875, 'loss_4': 1.4126250743865967, 'epoch': 27.41}
{'loss': 0.0081, 'grad_norm': 5.141609191894531, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.0047240485437214375, 'loss_2': 0.003345489501953125, 'loss_3': -16.482046127319336, 'loss_4': 1.500760555267334, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 11:20:14,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:14,819 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:04<07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:22,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011581579223275185, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.606, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00963709969073534, 'eval_loss_2': 0.00194447860121727, 'eval_loss_3': -18.236286163330078, 'eval_loss_4': 1.338686466217041, 'epoch': 27.41}
{'loss': 0.0089, 'grad_norm': 4.5419464111328125, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.003107072552666068, 'loss_2': 0.0057830810546875, 'loss_3': -16.242881774902344, 'loss_4': 1.6087818145751953, 'epoch': 27.42}
{'loss': 0.0085, 'grad_norm': 4.609351634979248, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.005263898987323046, 'loss_2': 0.003192901611328125, 'loss_3': -16.617332458496094, 'loss_4': 1.8575530052185059, 'epoch': 27.42}
{'loss': 0.009, 'grad_norm': 6.601207256317139, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.0073540485464036465, 'loss_2': 0.0016584396362304688, 'loss_3': -16.207015991210938, 'loss_4': 1.62391996383667, 'epoch': 27.43}
{'loss': 0.0081, 'grad_norm': 4.047122478485107, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.0029918996151536703, 'loss_2': 0.00506591796875, 'loss_3': -16.23094940185547, 'loss_4': 1.994431495666504, 'epoch': 27.44}
{'loss': 0.0078, 'grad_norm': 5.79150390625, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.006687873508781195, 'loss_2': 0.0011444091796875, 'loss_3': -16.44853973388672, 'loss_4': 1.593000888824463, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 11:20:22,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:22,155 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:11<07:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:29,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012327146716415882, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010089588351547718, 'eval_loss_2': 0.002237558364868164, 'eval_loss_3': -18.239017486572266, 'eval_loss_4': 1.3299516439437866, 'epoch': 27.44}
{'loss': 0.0072, 'grad_norm': 4.836062431335449, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.0037225177511572838, 'loss_2': 0.0034961700439453125, 'loss_3': -16.346080780029297, 'loss_4': 1.3345423936843872, 'epoch': 27.45}
{'loss': 0.0043, 'grad_norm': 4.25075101852417, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.002876998856663704, 'loss_2': 0.00139617919921875, 'loss_3': -16.33078384399414, 'loss_4': 1.6967628002166748, 'epoch': 27.45}
{'loss': 0.0138, 'grad_norm': 9.050846099853516, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.011697901412844658, 'loss_2': 0.0021209716796875, 'loss_3': -16.265506744384766, 'loss_4': 1.9079580307006836, 'epoch': 27.46}
{'loss': 0.0034, 'grad_norm': 4.543672561645508, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.0031293511856347322, 'loss_2': 0.0002570152282714844, 'loss_3': -16.3966064453125, 'loss_4': 1.6153658628463745, 'epoch': 27.47}
{'loss': 0.0097, 'grad_norm': 5.190609455108643, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.006102449726313353, 'loss_2': 0.00354766845703125, 'loss_3': -16.3721923828125, 'loss_4': 1.5100479125976562, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 11:20:29,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:29,499 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:19<07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:36,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012607784010469913, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.402, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010341606102883816, 'eval_loss_2': 0.0022661760449409485, 'eval_loss_3': -18.242591857910156, 'eval_loss_4': 1.3360129594802856, 'epoch': 27.47}
{'loss': 0.0109, 'grad_norm': 7.798560619354248, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.008664905093610287, 'loss_2': 0.002223968505859375, 'loss_3': -16.36880111694336, 'loss_4': 2.0257339477539062, 'epoch': 27.48}
{'loss': 0.0091, 'grad_norm': 4.810880661010742, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.0023534924257546663, 'loss_2': 0.00676727294921875, 'loss_3': -16.462261199951172, 'loss_4': 1.7407695055007935, 'epoch': 27.48}
{'loss': 0.0071, 'grad_norm': 4.884158611297607, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.004720200318843126, 'loss_2': 0.00237274169921875, 'loss_3': -16.232952117919922, 'loss_4': 1.6375573873519897, 'epoch': 27.49}
{'loss': 0.0089, 'grad_norm': 5.615821838378906, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.006469164043664932, 'loss_2': 0.0024433135986328125, 'loss_3': -16.22511100769043, 'loss_4': 1.6501010656356812, 'epoch': 27.49}
{'loss': 0.0061, 'grad_norm': 5.660904407501221, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.005681308452039957, 'loss_2': 0.0003952980041503906, 'loss_3': -16.113651275634766, 'loss_4': 1.3848932981491089, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 11:20:36,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:36,844 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:26<07:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:44,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012010371312499046, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.959, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010009278543293476, 'eval_loss_2': 0.0020010918378829956, 'eval_loss_3': -18.23779296875, 'eval_loss_4': 1.3666000366210938, 'epoch': 27.5}
{'loss': 0.0056, 'grad_norm': 5.473406791687012, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.004055510740727186, 'loss_2': 0.001506805419921875, 'loss_3': -16.09955596923828, 'loss_4': 2.052917957305908, 'epoch': 27.51}
{'loss': 0.0085, 'grad_norm': 4.705014705657959, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.006088972557336092, 'loss_2': 0.0024318695068359375, 'loss_3': -16.171295166015625, 'loss_4': 1.5485265254974365, 'epoch': 27.51}
{'loss': 0.01, 'grad_norm': 5.904139041900635, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.005292520392686129, 'loss_2': 0.004665374755859375, 'loss_3': -16.40422821044922, 'loss_4': 1.5045554637908936, 'epoch': 27.52}
{'loss': 0.0071, 'grad_norm': 5.438999176025391, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.006863350514322519, 'loss_2': 0.00024700164794921875, 'loss_3': -16.384111404418945, 'loss_4': 1.6865427494049072, 'epoch': 27.52}
{'loss': 0.0086, 'grad_norm': 5.156322479248047, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.004881019704043865, 'loss_2': 0.0037555694580078125, 'loss_3': -16.426355361938477, 'loss_4': 1.4503421783447266, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 11:20:44,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:44,200 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:33<07:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:51,582 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011892402544617653, 'eval_runtime': 3.82, 'eval_samples_per_second': 268.064, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.009755694307386875, 'eval_loss_2': 0.002136707305908203, 'eval_loss_3': -18.231897354125977, 'eval_loss_4': 1.4040178060531616, 'epoch': 27.53}
{'loss': 0.0059, 'grad_norm': 4.564765930175781, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.0026453109458088875, 'loss_2': 0.003261566162109375, 'loss_3': -16.257673263549805, 'loss_4': 1.7671964168548584, 'epoch': 27.53}
{'loss': 0.007, 'grad_norm': 4.315346717834473, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.0034222633112221956, 'loss_2': 0.003566741943359375, 'loss_3': -16.517406463623047, 'loss_4': 1.9854016304016113, 'epoch': 27.54}
{'loss': 0.0056, 'grad_norm': 4.728841304779053, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.0055458941496908665, 'loss_2': 9.369850158691406e-05, 'loss_3': -16.62091827392578, 'loss_4': 1.5219508409500122, 'epoch': 27.55}
{'loss': 0.0071, 'grad_norm': 4.887345314025879, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.00405650632455945, 'loss_2': 0.0030727386474609375, 'loss_3': -16.491743087768555, 'loss_4': 1.4843159914016724, 'epoch': 27.55}
{'loss': 0.0101, 'grad_norm': 7.729552745819092, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.00788081530481577, 'loss_2': 0.0022411346435546875, 'loss_3': -16.123851776123047, 'loss_4': 1.8855146169662476, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 11:20:51,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:51,583 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:56:41<07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:58,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012017260305583477, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.725, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009774606674909592, 'eval_loss_2': 0.00224265456199646, 'eval_loss_3': -18.238191604614258, 'eval_loss_4': 1.4435033798217773, 'epoch': 27.56}
{'loss': 0.0085, 'grad_norm': 4.7248101234436035, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.0027623020578175783, 'loss_2': 0.00571441650390625, 'loss_3': -16.25624656677246, 'loss_4': 1.6773015260696411, 'epoch': 27.56}
{'loss': 0.0095, 'grad_norm': 5.547542572021484, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.007865546271204948, 'loss_2': 0.00167083740234375, 'loss_3': -16.31533432006836, 'loss_4': 1.424983024597168, 'epoch': 27.57}
{'loss': 0.0108, 'grad_norm': 5.845024585723877, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.010007352568209171, 'loss_2': 0.0007581710815429688, 'loss_3': -16.260042190551758, 'loss_4': 1.5059518814086914, 'epoch': 27.58}
{'loss': 0.0104, 'grad_norm': 5.527134418487549, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.007261253427714109, 'loss_2': 0.003116607666015625, 'loss_3': -16.34088134765625, 'loss_4': 1.975771188735962, 'epoch': 27.58}
{'loss': 0.0368, 'grad_norm': 14.911826133728027, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.03387144207954407, 'loss_2': 0.0029354095458984375, 'loss_3': -16.184328079223633, 'loss_4': 1.2801313400268555, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 11:20:58,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:58,940 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:56:48<07:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:06,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012072280049324036, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.614, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010017664171755314, 'eval_loss_2': 0.0020546168088912964, 'eval_loss_3': -18.238994598388672, 'eval_loss_4': 1.4492374658584595, 'epoch': 27.59}
{'loss': 0.008, 'grad_norm': 5.916269302368164, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.00520033435896039, 'loss_2': 0.0027980804443359375, 'loss_3': -16.359289169311523, 'loss_4': 1.8667019605636597, 'epoch': 27.59}
{'loss': 0.0128, 'grad_norm': 5.260354995727539, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.00937395915389061, 'loss_2': 0.003398895263671875, 'loss_3': -16.27657699584961, 'loss_4': 1.6506860256195068, 'epoch': 27.6}
{'loss': 0.0039, 'grad_norm': 4.945888042449951, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.003863885533064604, 'loss_2': 6.842613220214844e-05, 'loss_3': -16.356861114501953, 'loss_4': 1.7946066856384277, 'epoch': 27.6}
{'loss': 0.0072, 'grad_norm': 5.696329593658447, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.005234901327639818, 'loss_2': 0.0019435882568359375, 'loss_3': -16.3580265045166, 'loss_4': 1.4698753356933594, 'epoch': 27.61}
{'loss': 0.0023, 'grad_norm': 4.771505355834961, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.0021408353932201862, 'loss_2': 0.0002014636993408203, 'loss_3': -16.28207015991211, 'loss_4': 1.7307562828063965, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 11:21:06,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:06,296 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:56:55<07:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:13,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011662665754556656, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.33, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009773660451173782, 'eval_loss_2': 0.0018890053033828735, 'eval_loss_3': -18.23652458190918, 'eval_loss_4': 1.4219050407409668, 'epoch': 27.62}
{'loss': 0.0095, 'grad_norm': 4.8222784996032715, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0035845977254211903, 'loss_2': 0.00591278076171875, 'loss_3': -16.290042877197266, 'loss_4': 1.2866828441619873, 'epoch': 27.62}
{'loss': 0.0022, 'grad_norm': 4.784099102020264, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.0019124875543639064, 'loss_2': 0.0002701282501220703, 'loss_3': -16.371318817138672, 'loss_4': 1.640021800994873, 'epoch': 27.63}
{'loss': 0.0058, 'grad_norm': 4.1939191818237305, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.002096196636557579, 'loss_2': 0.0037078857421875, 'loss_3': -16.345022201538086, 'loss_4': 1.8452739715576172, 'epoch': 27.63}
{'loss': 0.0086, 'grad_norm': 8.841354370117188, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.007773763034492731, 'loss_2': 0.0008077621459960938, 'loss_3': -16.1276798248291, 'loss_4': 1.0971729755401611, 'epoch': 27.64}
{'loss': 0.0049, 'grad_norm': 4.404813289642334, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.0016954150050878525, 'loss_2': 0.00321197509765625, 'loss_3': -16.307353973388672, 'loss_4': 1.639927864074707, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 11:21:13,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:13,645 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:03<06:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:21,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011587324552237988, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.496, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009792271070182323, 'eval_loss_2': 0.001795053482055664, 'eval_loss_3': -18.2313289642334, 'eval_loss_4': 1.4169729948043823, 'epoch': 27.65}
{'loss': 0.0077, 'grad_norm': 4.627732753753662, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.0027968394570052624, 'loss_2': 0.004871368408203125, 'loss_3': -16.39019012451172, 'loss_4': 1.6526378393173218, 'epoch': 27.65}
{'loss': 0.0096, 'grad_norm': 8.530965805053711, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.009469505399465561, 'loss_2': 0.00010073184967041016, 'loss_3': -16.24036979675293, 'loss_4': 1.3175454139709473, 'epoch': 27.66}
{'loss': 0.0203, 'grad_norm': 10.844430923461914, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.016501162201166153, 'loss_2': 0.003814697265625, 'loss_3': -16.334671020507812, 'loss_4': 1.942228078842163, 'epoch': 27.66}
{'loss': 0.0054, 'grad_norm': 4.729156970977783, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.002062248531728983, 'loss_2': 0.003330230712890625, 'loss_3': -16.24744415283203, 'loss_4': 0.9927839040756226, 'epoch': 27.67}
{'loss': 0.0105, 'grad_norm': 5.574285984039307, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.0058691962622106075, 'loss_2': 0.00466156005859375, 'loss_3': -16.281784057617188, 'loss_4': 1.5544177293777466, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 11:21:21,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:21,002 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:10<06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:28,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01153978705406189, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00982465036213398, 'eval_loss_2': 0.0017151348292827606, 'eval_loss_3': -18.22981834411621, 'eval_loss_4': 1.4369617700576782, 'epoch': 27.67}
{'loss': 0.0049, 'grad_norm': 4.509186744689941, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.003548297332599759, 'loss_2': 0.001392364501953125, 'loss_3': -16.32709503173828, 'loss_4': 2.0403213500976562, 'epoch': 27.68}
{'loss': 0.008, 'grad_norm': 4.129965782165527, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.0023478965740650892, 'loss_2': 0.00563812255859375, 'loss_3': -16.236032485961914, 'loss_4': 1.8081591129302979, 'epoch': 27.69}
{'loss': 0.0066, 'grad_norm': 4.801193714141846, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.004329041577875614, 'loss_2': 0.002269744873046875, 'loss_3': -16.14078712463379, 'loss_4': 1.66683828830719, 'epoch': 27.69}
{'loss': 0.0188, 'grad_norm': 11.165590286254883, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.015599094331264496, 'loss_2': 0.003154754638671875, 'loss_3': -16.264720916748047, 'loss_4': 1.425156593322754, 'epoch': 27.7}
{'loss': 0.0095, 'grad_norm': 5.517075538635254, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.005795135162770748, 'loss_2': 0.0036869049072265625, 'loss_3': -16.480045318603516, 'loss_4': 1.3567758798599243, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 11:21:28,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:28,364 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:17<06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:35,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01178903877735138, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.376, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009730064310133457, 'eval_loss_2': 0.002058975398540497, 'eval_loss_3': -18.229883193969727, 'eval_loss_4': 1.427140235900879, 'epoch': 27.7}
{'loss': 0.0084, 'grad_norm': 4.3727641105651855, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.0023696105927228928, 'loss_2': 0.006008148193359375, 'loss_3': -16.43560791015625, 'loss_4': 1.5348771810531616, 'epoch': 27.71}
{'loss': 0.0033, 'grad_norm': 4.618648052215576, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.0031493499409407377, 'loss_2': 0.00011473894119262695, 'loss_3': -16.292936325073242, 'loss_4': 2.1455161571502686, 'epoch': 27.72}
{'loss': 0.008, 'grad_norm': 4.485512733459473, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.0023395915050059557, 'loss_2': 0.005706787109375, 'loss_3': -16.474998474121094, 'loss_4': 1.344550609588623, 'epoch': 27.72}
{'loss': 0.0107, 'grad_norm': 5.548306941986084, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.007356175687164068, 'loss_2': 0.00337982177734375, 'loss_3': -16.275331497192383, 'loss_4': 1.3921412229537964, 'epoch': 27.73}
{'loss': 0.0062, 'grad_norm': 4.927369117736816, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.004773755557835102, 'loss_2': 0.0014133453369140625, 'loss_3': -16.211788177490234, 'loss_4': 1.371006965637207, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 11:21:35,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:35,710 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:25<06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:43,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012051982805132866, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.695, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009833230637013912, 'eval_loss_2': 0.0022187530994415283, 'eval_loss_3': -18.221467971801758, 'eval_loss_4': 1.4054769277572632, 'epoch': 27.73}
{'loss': 0.0069, 'grad_norm': 4.666971206665039, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.003546689869835973, 'loss_2': 0.00336456298828125, 'loss_3': -16.342327117919922, 'loss_4': 1.7015544176101685, 'epoch': 27.74}
{'loss': 0.0024, 'grad_norm': 4.647435188293457, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.0023671698290854692, 'loss_2': 7.718801498413086e-05, 'loss_3': -16.337352752685547, 'loss_4': 1.721181869506836, 'epoch': 27.74}
{'loss': 0.0114, 'grad_norm': 4.9966278076171875, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.00563470646739006, 'loss_2': 0.00579833984375, 'loss_3': -16.261356353759766, 'loss_4': 1.6805167198181152, 'epoch': 27.75}
{'loss': 0.0087, 'grad_norm': 4.057127475738525, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.0027243653312325478, 'loss_2': 0.0059661865234375, 'loss_3': -16.4661865234375, 'loss_4': 1.8318291902542114, 'epoch': 27.76}
{'loss': 0.0187, 'grad_norm': 13.165596961975098, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.017085900530219078, 'loss_2': 0.0016269683837890625, 'loss_3': -16.137226104736328, 'loss_4': 2.2313122749328613, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 11:21:43,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:43,053 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:32<06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:50,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01200791634619236, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009845012798905373, 'eval_loss_2': 0.0021629035472869873, 'eval_loss_3': -18.224353790283203, 'eval_loss_4': 1.3894050121307373, 'epoch': 27.76}
{'loss': 0.0137, 'grad_norm': 5.334029197692871, 'learning_rate': 2.25e-06, 'loss_1': 0.0052938987500965595, 'loss_2': 0.0084228515625, 'loss_3': -16.3566837310791, 'loss_4': 1.4644373655319214, 'epoch': 27.77}
{'loss': 0.0035, 'grad_norm': 4.8903398513793945, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.0022054037544876337, 'loss_2': 0.0012569427490234375, 'loss_3': -16.334854125976562, 'loss_4': 2.120612144470215, 'epoch': 27.77}
{'loss': 0.0065, 'grad_norm': 4.677148818969727, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.0042601339519023895, 'loss_2': 0.0022735595703125, 'loss_3': -16.32241439819336, 'loss_4': 1.785490870475769, 'epoch': 27.78}
{'loss': 0.0064, 'grad_norm': 5.309552192687988, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.006048621144145727, 'loss_2': 0.0003650188446044922, 'loss_3': -16.433448791503906, 'loss_4': 1.7479615211486816, 'epoch': 27.78}
{'loss': 0.0095, 'grad_norm': 8.604270935058594, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.007471716031432152, 'loss_2': 0.001979827880859375, 'loss_3': -16.396268844604492, 'loss_4': 1.5985175371170044, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 11:21:50,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:50,401 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:39<06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:57,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012014403939247131, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009807981550693512, 'eval_loss_2': 0.0022064223885536194, 'eval_loss_3': -18.226741790771484, 'eval_loss_4': 1.3722361326217651, 'epoch': 27.79}
{'loss': 0.0071, 'grad_norm': 4.9936347007751465, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.003282749792560935, 'loss_2': 0.00380706787109375, 'loss_3': -16.231201171875, 'loss_4': 1.943891167640686, 'epoch': 27.8}
{'loss': 0.0113, 'grad_norm': 5.169360637664795, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.0058949189260602, 'loss_2': 0.005401611328125, 'loss_3': -16.344024658203125, 'loss_4': 1.4881627559661865, 'epoch': 27.8}
{'loss': 0.0039, 'grad_norm': 5.079983711242676, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.0030803929548710585, 'loss_2': 0.0008497238159179688, 'loss_3': -16.300371170043945, 'loss_4': 1.577775239944458, 'epoch': 27.81}
{'loss': 0.0113, 'grad_norm': 5.256429672241211, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.00531486002728343, 'loss_2': 0.0059967041015625, 'loss_3': -16.392974853515625, 'loss_4': 1.6065223217010498, 'epoch': 27.81}
{'loss': 0.0121, 'grad_norm': 6.8012919425964355, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.005772608332335949, 'loss_2': 0.00637054443359375, 'loss_3': -16.0644588470459, 'loss_4': 1.5217971801757812, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 11:21:57,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:57,743 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:57:47<06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:05,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011784978210926056, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009675629436969757, 'eval_loss_2': 0.002109348773956299, 'eval_loss_3': -18.221837997436523, 'eval_loss_4': 1.3562519550323486, 'epoch': 27.82}
{'loss': 0.0062, 'grad_norm': 5.082192420959473, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.004440986085683107, 'loss_2': 0.0017375946044921875, 'loss_3': -16.29639434814453, 'loss_4': 1.7161835432052612, 'epoch': 27.83}
{'loss': 0.0182, 'grad_norm': 10.391775131225586, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.01707027480006218, 'loss_2': 0.0011234283447265625, 'loss_3': -16.193164825439453, 'loss_4': 1.586417317390442, 'epoch': 27.83}
{'loss': 0.0051, 'grad_norm': 4.834455490112305, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.004411123692989349, 'loss_2': 0.0007386207580566406, 'loss_3': -16.298879623413086, 'loss_4': 2.055170774459839, 'epoch': 27.84}
{'loss': 0.0162, 'grad_norm': 9.168349266052246, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.012093635275959969, 'loss_2': 0.00411224365234375, 'loss_3': -16.42232322692871, 'loss_4': 1.4946370124816895, 'epoch': 27.84}
{'loss': 0.0131, 'grad_norm': 6.0645432472229, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.00804961659014225, 'loss_2': 0.00508880615234375, 'loss_3': -16.194305419921875, 'loss_4': 1.7417783737182617, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 11:22:05,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:05,087 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:57:54<06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:12,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011994718573987484, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009838960133492947, 'eval_loss_2': 0.0021557584404945374, 'eval_loss_3': -18.218433380126953, 'eval_loss_4': 1.3648655414581299, 'epoch': 27.85}
{'loss': 0.006, 'grad_norm': 4.768834590911865, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.005076482892036438, 'loss_2': 0.0009603500366210938, 'loss_3': -16.109703063964844, 'loss_4': 1.3879916667938232, 'epoch': 27.85}
{'loss': 0.0201, 'grad_norm': 16.911195755004883, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.01459934189915657, 'loss_2': 0.00554656982421875, 'loss_3': -16.297422409057617, 'loss_4': 1.7595419883728027, 'epoch': 27.86}
{'loss': 0.0174, 'grad_norm': 7.567646503448486, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.012486347928643227, 'loss_2': 0.004863739013671875, 'loss_3': -16.398284912109375, 'loss_4': 1.6558418273925781, 'epoch': 27.87}
{'loss': 0.0082, 'grad_norm': 4.621370315551758, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.0037688345182687044, 'loss_2': 0.00444793701171875, 'loss_3': -16.2838191986084, 'loss_4': 1.841551423072815, 'epoch': 27.87}
{'loss': 0.0066, 'grad_norm': 4.942276954650879, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.002169940620660782, 'loss_2': 0.004425048828125, 'loss_3': -16.20826530456543, 'loss_4': 1.856611967086792, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 11:22:12,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:12,432 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:01<06:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:19,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01207887101918459, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010032597929239273, 'eval_loss_2': 0.0020462721586227417, 'eval_loss_3': -18.21453285217285, 'eval_loss_4': 1.3635042905807495, 'epoch': 27.88}
{'loss': 0.0173, 'grad_norm': 9.99681568145752, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.009433934465050697, 'loss_2': 0.00791168212890625, 'loss_3': -16.39063262939453, 'loss_4': 2.599959373474121, 'epoch': 27.88}
{'loss': 0.0053, 'grad_norm': 4.5413312911987305, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.004253983497619629, 'loss_2': 0.0010738372802734375, 'loss_3': -16.16714096069336, 'loss_4': 2.094721794128418, 'epoch': 27.89}
{'loss': 0.0048, 'grad_norm': 4.828008651733398, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.0028649058658629656, 'loss_2': 0.0018939971923828125, 'loss_3': -16.142616271972656, 'loss_4': 1.5331465005874634, 'epoch': 27.9}
{'loss': 0.0144, 'grad_norm': 6.0747504234313965, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.007949248887598515, 'loss_2': 0.006439208984375, 'loss_3': -16.331663131713867, 'loss_4': 1.394010305404663, 'epoch': 27.9}
{'loss': 0.01, 'grad_norm': 7.2486114501953125, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.009005854837596416, 'loss_2': 0.0009860992431640625, 'loss_3': -16.307758331298828, 'loss_4': 1.2023484706878662, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 11:22:19,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:19,783 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:09<06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:27,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012140225619077682, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.223, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010204904712736607, 'eval_loss_2': 0.0019353218376636505, 'eval_loss_3': -18.214982986450195, 'eval_loss_4': 1.3489038944244385, 'epoch': 27.91}
{'loss': 0.0109, 'grad_norm': 5.685762405395508, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.005343432072550058, 'loss_2': 0.00559234619140625, 'loss_3': -16.16695785522461, 'loss_4': 2.002511501312256, 'epoch': 27.91}
{'loss': 0.0041, 'grad_norm': 4.4356465339660645, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.0027713081799447536, 'loss_2': 0.001331329345703125, 'loss_3': -16.496063232421875, 'loss_4': 1.7135149240493774, 'epoch': 27.92}
{'loss': 0.0091, 'grad_norm': 4.995682716369629, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.005520093720406294, 'loss_2': 0.003543853759765625, 'loss_3': -16.432506561279297, 'loss_4': 1.3683574199676514, 'epoch': 27.92}
{'loss': 0.0202, 'grad_norm': 10.438713073730469, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.013418893329799175, 'loss_2': 0.00682830810546875, 'loss_3': -16.18703269958496, 'loss_4': 1.5644173622131348, 'epoch': 27.93}
{'loss': 0.0107, 'grad_norm': 6.2697577476501465, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.008382994681596756, 'loss_2': 0.0023345947265625, 'loss_3': -16.408641815185547, 'loss_4': 1.1315624713897705, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 11:22:27,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:27,137 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:16<06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:34,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012103189714252949, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010174710303544998, 'eval_loss_2': 0.001928478479385376, 'eval_loss_3': -18.21293830871582, 'eval_loss_4': 1.353501796722412, 'epoch': 27.94}
{'loss': 0.0018, 'grad_norm': 4.337897300720215, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.0015461945440620184, 'loss_2': 0.00021588802337646484, 'loss_3': -16.394256591796875, 'loss_4': 1.71436607837677, 'epoch': 27.94}
{'loss': 0.007, 'grad_norm': 5.748053073883057, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.006786012090742588, 'loss_2': 0.00023543834686279297, 'loss_3': -16.207801818847656, 'loss_4': 1.5379191637039185, 'epoch': 27.95}
{'loss': 0.0104, 'grad_norm': 5.448579788208008, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.007128053344786167, 'loss_2': 0.003246307373046875, 'loss_3': -16.404476165771484, 'loss_4': 2.114194393157959, 'epoch': 27.95}
{'loss': 0.0102, 'grad_norm': 4.230775356292725, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.0024341002572327852, 'loss_2': 0.0077362060546875, 'loss_3': -16.34772300720215, 'loss_4': 1.158198595046997, 'epoch': 27.96}
{'loss': 0.0154, 'grad_norm': 7.529808044433594, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.008992742747068405, 'loss_2': 0.006378173828125, 'loss_3': -16.28692626953125, 'loss_4': 2.1931209564208984, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 11:22:34,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:34,487 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:23<05:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:22:41,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011954662390053272, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.645, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010180564597249031, 'eval_loss_2': 0.0017740987241268158, 'eval_loss_3': -18.211414337158203, 'eval_loss_4': 1.356597900390625, 'epoch': 27.97}
{'loss': 0.0059, 'grad_norm': 5.106237888336182, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.004031078424304724, 'loss_2': 0.001895904541015625, 'loss_3': -16.45578384399414, 'loss_4': 1.5714442729949951, 'epoch': 27.97}
{'loss': 0.0094, 'grad_norm': 4.827558994293213, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.003836550284177065, 'loss_2': 0.00553131103515625, 'loss_3': -16.306549072265625, 'loss_4': 1.8061697483062744, 'epoch': 27.98}
{'loss': 0.018, 'grad_norm': 6.032003402709961, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.01463934313505888, 'loss_2': 0.003398895263671875, 'loss_3': -16.43199920654297, 'loss_4': 1.36735200881958, 'epoch': 27.98}
{'loss': 0.0048, 'grad_norm': 4.472363471984863, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.001981559442356229, 'loss_2': 0.0028476715087890625, 'loss_3': -16.29971694946289, 'loss_4': 1.2560975551605225, 'epoch': 27.99}
{'loss': 0.002, 'grad_norm': 4.183627605438232, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0015220892382785678, 'loss_2': 0.00045013427734375, 'loss_3': -16.453449249267578, 'loss_4': 1.503724455833435, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 11:22:41,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:41,813 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:31<05:46,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:22:48,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012082028202712536, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.829, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.010367857292294502, 'eval_loss_2': 0.001714169979095459, 'eval_loss_3': -18.208269119262695, 'eval_loss_4': 1.3637019395828247, 'epoch': 27.99}
{'loss': 0.0026, 'grad_norm': 6.56155252456665, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.0019750178325921297, 'loss_2': 0.0006628036499023438, 'loss_3': -16.307710647583008, 'loss_4': 1.483795166015625, 'epoch': 28.0}
{'loss': 0.0175, 'grad_norm': 8.77792739868164, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.012276718392968178, 'loss_2': 0.00522613525390625, 'loss_3': -16.1660099029541, 'loss_4': 1.7919477224349976, 'epoch': 28.01}
{'loss': 0.0062, 'grad_norm': 4.772110462188721, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.002671281574293971, 'loss_2': 0.003574371337890625, 'loss_3': -16.315670013427734, 'loss_4': 1.833873987197876, 'epoch': 28.01}
{'loss': 0.0136, 'grad_norm': 5.6468729972839355, 'learning_rate': 2e-06, 'loss_1': 0.008163969032466412, 'loss_2': 0.00547027587890625, 'loss_3': -16.122303009033203, 'loss_4': 2.103546619415283, 'epoch': 28.02}
{'loss': 0.0065, 'grad_norm': 4.578317642211914, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.0029921147506684065, 'loss_2': 0.0035400390625, 'loss_3': -16.299604415893555, 'loss_4': 1.3164751529693604, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 11:22:48,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:48,878 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:38<05:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:22:56,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011697912588715553, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010190464556217194, 'eval_loss_2': 0.0015074461698532104, 'eval_loss_3': -18.203475952148438, 'eval_loss_4': 1.3936949968338013, 'epoch': 28.02}
{'loss': 0.0032, 'grad_norm': 4.158909797668457, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.0031054175924509764, 'loss_2': 4.9591064453125e-05, 'loss_3': -16.417617797851562, 'loss_4': 2.4647045135498047, 'epoch': 28.03}
{'loss': 0.0067, 'grad_norm': 5.259724140167236, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.004956054501235485, 'loss_2': 0.0017213821411132812, 'loss_3': -16.27040672302246, 'loss_4': 2.3415472507476807, 'epoch': 28.03}
{'loss': 0.0057, 'grad_norm': 5.096396446228027, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.002736595692113042, 'loss_2': 0.0029449462890625, 'loss_3': -16.293607711791992, 'loss_4': 1.6351851224899292, 'epoch': 28.04}
{'loss': 0.0034, 'grad_norm': 4.314286708831787, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.0028241961263120174, 'loss_2': 0.0006079673767089844, 'loss_3': -16.3452205657959, 'loss_4': 2.0080056190490723, 'epoch': 28.05}
{'loss': 0.0064, 'grad_norm': 4.713230609893799, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.001807896769605577, 'loss_2': 0.00457763671875, 'loss_3': -16.395971298217773, 'loss_4': 1.832301139831543, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 11:22:56,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:56,227 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:58:45<05:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:03,571 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011665535159409046, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.557, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010374724864959717, 'eval_loss_2': 0.0012908093631267548, 'eval_loss_3': -18.202898025512695, 'eval_loss_4': 1.422863483428955, 'epoch': 28.05}
{'loss': 0.0073, 'grad_norm': 4.647710800170898, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.002744599012658, 'loss_2': 0.00450897216796875, 'loss_3': -16.401229858398438, 'loss_4': 1.600792407989502, 'epoch': 28.06}
{'loss': 0.0096, 'grad_norm': 4.6074042320251465, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.0024594657588750124, 'loss_2': 0.007106781005859375, 'loss_3': -16.279661178588867, 'loss_4': 1.4655935764312744, 'epoch': 28.06}
{'loss': 0.0114, 'grad_norm': 5.187761306762695, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.005803692154586315, 'loss_2': 0.0056304931640625, 'loss_3': -16.337783813476562, 'loss_4': 1.6317263841629028, 'epoch': 28.07}
{'loss': 0.0054, 'grad_norm': 5.164852619171143, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.005099855363368988, 'loss_2': 0.00027680397033691406, 'loss_3': -16.203107833862305, 'loss_4': 1.4331146478652954, 'epoch': 28.08}
{'loss': 0.0028, 'grad_norm': 4.437717437744141, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.0020333880092948675, 'loss_2': 0.0007300376892089844, 'loss_3': -16.3607177734375, 'loss_4': 1.5728503465652466, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 11:23:03,571 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:03,571 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:58:53<05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:10,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011581016704440117, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010185777209699154, 'eval_loss_2': 0.0013952404260635376, 'eval_loss_3': -18.20460319519043, 'eval_loss_4': 1.4365001916885376, 'epoch': 28.08}
{'loss': 0.0052, 'grad_norm': 4.77052116394043, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.0019338654819875956, 'loss_2': 0.003299713134765625, 'loss_3': -16.310791015625, 'loss_4': 1.6348111629486084, 'epoch': 28.09}
{'loss': 0.0038, 'grad_norm': 4.627616882324219, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.0035997172817587852, 'loss_2': 0.00023031234741210938, 'loss_3': -16.26607894897461, 'loss_4': 2.371471405029297, 'epoch': 28.09}
{'loss': 0.0039, 'grad_norm': 4.38840913772583, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.002694405848160386, 'loss_2': 0.0011587142944335938, 'loss_3': -16.418590545654297, 'loss_4': 1.4136826992034912, 'epoch': 28.1}
{'loss': 0.0106, 'grad_norm': 6.309911727905273, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.007016611285507679, 'loss_2': 0.003604888916015625, 'loss_3': -16.458314895629883, 'loss_4': 1.2947429418563843, 'epoch': 28.1}
{'loss': 0.0075, 'grad_norm': 6.247629642486572, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.004591172095388174, 'loss_2': 0.00293731689453125, 'loss_3': -16.116243362426758, 'loss_4': 1.9291507005691528, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 11:23:10,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:10,922 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:00<05:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:18,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011729281395673752, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010166163556277752, 'eval_loss_2': 0.0015631169080734253, 'eval_loss_3': -18.19866943359375, 'eval_loss_4': 1.4352041482925415, 'epoch': 28.11}
{'loss': 0.0088, 'grad_norm': 4.0858354568481445, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.001917805289849639, 'loss_2': 0.006923675537109375, 'loss_3': -16.308622360229492, 'loss_4': 1.369969129562378, 'epoch': 28.12}
{'loss': 0.0039, 'grad_norm': 4.492799758911133, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.0025970162823796272, 'loss_2': 0.0013332366943359375, 'loss_3': -16.257984161376953, 'loss_4': 1.8947718143463135, 'epoch': 28.12}
{'loss': 0.0062, 'grad_norm': 4.998475074768066, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.003998741041868925, 'loss_2': 0.002155303955078125, 'loss_3': -16.33855628967285, 'loss_4': 1.8771302700042725, 'epoch': 28.13}
{'loss': 0.0117, 'grad_norm': 9.944964408874512, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.010811946354806423, 'loss_2': 0.0009088516235351562, 'loss_3': -16.367984771728516, 'loss_4': 1.6024796962738037, 'epoch': 28.13}
{'loss': 0.0046, 'grad_norm': 4.638341903686523, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.0019480345072224736, 'loss_2': 0.00262451171875, 'loss_3': -16.273590087890625, 'loss_4': 1.4317854642868042, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 11:23:18,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:18,261 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:07<05:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:25,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011985057964920998, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010195242241024971, 'eval_loss_2': 0.0017898157238960266, 'eval_loss_3': -18.19246482849121, 'eval_loss_4': 1.4188940525054932, 'epoch': 28.14}
{'loss': 0.0075, 'grad_norm': 5.304319381713867, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.005013524554669857, 'loss_2': 0.00247955322265625, 'loss_3': -16.246448516845703, 'loss_4': 1.1021509170532227, 'epoch': 28.15}
{'loss': 0.0122, 'grad_norm': 6.268139362335205, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.008405638858675957, 'loss_2': 0.0037784576416015625, 'loss_3': -16.191295623779297, 'loss_4': 1.9089819192886353, 'epoch': 28.15}
{'loss': 0.0071, 'grad_norm': 4.663069248199463, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.0036410107277333736, 'loss_2': 0.00347137451171875, 'loss_3': -16.296838760375977, 'loss_4': 2.0144009590148926, 'epoch': 28.16}
{'loss': 0.0242, 'grad_norm': 7.028883457183838, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.022106008604168892, 'loss_2': 0.0020904541015625, 'loss_3': -16.35843849182129, 'loss_4': 2.226663589477539, 'epoch': 28.16}
{'loss': 0.0123, 'grad_norm': 4.71478271484375, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.005479105748236179, 'loss_2': 0.00681304931640625, 'loss_3': -16.43175506591797, 'loss_4': 1.9418911933898926, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 11:23:25,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:25,602 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:15<05:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:32,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012315701693296432, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.932, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010301868431270123, 'eval_loss_2': 0.0020138323307037354, 'eval_loss_3': -18.19210433959961, 'eval_loss_4': 1.39921236038208, 'epoch': 28.17}
{'loss': 0.0043, 'grad_norm': 4.8655476570129395, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.0026595951057970524, 'loss_2': 0.001682281494140625, 'loss_3': -16.225934982299805, 'loss_4': 1.6209315061569214, 'epoch': 28.17}
{'loss': 0.0062, 'grad_norm': 4.73128604888916, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.0038895460311323404, 'loss_2': 0.00235748291015625, 'loss_3': -16.51485252380371, 'loss_4': 1.5633577108383179, 'epoch': 28.18}
{'loss': 0.0067, 'grad_norm': 4.739901542663574, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.003423407208174467, 'loss_2': 0.003231048583984375, 'loss_3': -16.348262786865234, 'loss_4': 1.4437038898468018, 'epoch': 28.19}
{'loss': 0.0087, 'grad_norm': 5.2036943435668945, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.00770368380472064, 'loss_2': 0.0009737014770507812, 'loss_3': -16.163578033447266, 'loss_4': 1.5342392921447754, 'epoch': 28.19}
{'loss': 0.0303, 'grad_norm': 12.10573673248291, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.021175386384129524, 'loss_2': 0.0091552734375, 'loss_3': -16.24557876586914, 'loss_4': 1.8743478059768677, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 11:23:32,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:32,949 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:22<05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:40,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012502486817538738, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.518, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010161112993955612, 'eval_loss_2': 0.0023413747549057007, 'eval_loss_3': -18.190292358398438, 'eval_loss_4': 1.3640636205673218, 'epoch': 28.2}
{'loss': 0.0051, 'grad_norm': 4.144134998321533, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.002239817986264825, 'loss_2': 0.002895355224609375, 'loss_3': -16.227872848510742, 'loss_4': 1.722522258758545, 'epoch': 28.2}
{'loss': 0.0038, 'grad_norm': 4.601816177368164, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.0037804816383868456, 'loss_2': 4.2498111724853516e-05, 'loss_3': -16.35329818725586, 'loss_4': 1.6223639249801636, 'epoch': 28.21}
{'loss': 0.0049, 'grad_norm': 5.226771831512451, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.004087876994162798, 'loss_2': 0.0007982254028320312, 'loss_3': -16.428380966186523, 'loss_4': 1.769660472869873, 'epoch': 28.22}
{'loss': 0.0017, 'grad_norm': 4.442618370056152, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.0015789340250194073, 'loss_2': 0.00016498565673828125, 'loss_3': -16.363876342773438, 'loss_4': 1.5088276863098145, 'epoch': 28.22}
{'loss': 0.0057, 'grad_norm': 5.031215667724609, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.00351207354106009, 'loss_2': 0.002185821533203125, 'loss_3': -16.39036750793457, 'loss_4': 1.7906187772750854, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 11:23:40,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:40,287 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:29<05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:47,639 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01236722245812416, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.369, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009877268224954605, 'eval_loss_2': 0.0024899542331695557, 'eval_loss_3': -18.191253662109375, 'eval_loss_4': 1.3448911905288696, 'epoch': 28.23}
{'loss': 0.0026, 'grad_norm': 4.628348350524902, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.002043759450316429, 'loss_2': 0.0005693435668945312, 'loss_3': -16.405029296875, 'loss_4': 1.6028883457183838, 'epoch': 28.23}
{'loss': 0.0045, 'grad_norm': 4.588593006134033, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.0033400794491171837, 'loss_2': 0.0011119842529296875, 'loss_3': -16.373146057128906, 'loss_4': 1.2652506828308105, 'epoch': 28.24}
{'loss': 0.0059, 'grad_norm': 4.600948810577393, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.004150604363530874, 'loss_2': 0.0017242431640625, 'loss_3': -16.184410095214844, 'loss_4': 1.3361799716949463, 'epoch': 28.24}
{'loss': 0.0034, 'grad_norm': 4.583791255950928, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.0029123269487172365, 'loss_2': 0.0005254745483398438, 'loss_3': -16.330049514770508, 'loss_4': 1.305396318435669, 'epoch': 28.25}
{'loss': 0.0096, 'grad_norm': 5.471344947814941, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.007206644397228956, 'loss_2': 0.002346038818359375, 'loss_3': -16.11139678955078, 'loss_4': 1.6579068899154663, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 11:23:47,639 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:47,639 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:37<05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:54,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012392103672027588, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.46, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009908701293170452, 'eval_loss_2': 0.002483401447534561, 'eval_loss_3': -18.188186645507812, 'eval_loss_4': 1.3254624605178833, 'epoch': 28.26}
{'loss': 0.0102, 'grad_norm': 7.167713165283203, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.008459426462650299, 'loss_2': 0.0017070770263671875, 'loss_3': -16.551725387573242, 'loss_4': 1.7693512439727783, 'epoch': 28.26}
{'loss': 0.0076, 'grad_norm': 4.178769588470459, 'learning_rate': 1.75e-06, 'loss_1': 0.002520602662116289, 'loss_2': 0.005035400390625, 'loss_3': -16.251384735107422, 'loss_4': 1.1485373973846436, 'epoch': 28.27}
{'loss': 0.0058, 'grad_norm': 4.652011871337891, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.0034325288143008947, 'loss_2': 0.002399444580078125, 'loss_3': -16.437129974365234, 'loss_4': 1.786712884902954, 'epoch': 28.27}
{'loss': 0.0038, 'grad_norm': 4.4824323654174805, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.0029315210413187742, 'loss_2': 0.00086212158203125, 'loss_3': -16.356769561767578, 'loss_4': 1.0073211193084717, 'epoch': 28.28}
{'loss': 0.0092, 'grad_norm': 5.015235424041748, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.004035093821585178, 'loss_2': 0.00511932373046875, 'loss_3': -16.379100799560547, 'loss_4': 1.873227834701538, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 11:23:54,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:54,981 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [1:59:44<05:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:02,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012416742742061615, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010036683641374111, 'eval_loss_2': 0.002380058169364929, 'eval_loss_3': -18.187061309814453, 'eval_loss_4': 1.3111367225646973, 'epoch': 28.28}
{'loss': 0.0228, 'grad_norm': 11.586256980895996, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.01666310988366604, 'loss_2': 0.006134033203125, 'loss_3': -16.254016876220703, 'loss_4': 1.952149510383606, 'epoch': 28.29}
{'loss': 0.0073, 'grad_norm': 4.548211097717285, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.0030380210373550653, 'loss_2': 0.004283905029296875, 'loss_3': -16.02666473388672, 'loss_4': 1.7653158903121948, 'epoch': 28.3}
{'loss': 0.0071, 'grad_norm': 4.351059436798096, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.003147686365991831, 'loss_2': 0.003910064697265625, 'loss_3': -16.429590225219727, 'loss_4': 1.3953783512115479, 'epoch': 28.3}
{'loss': 0.007, 'grad_norm': 4.94313383102417, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.003913084976375103, 'loss_2': 0.00312042236328125, 'loss_3': -16.334415435791016, 'loss_4': 1.4048465490341187, 'epoch': 28.31}
{'loss': 0.0062, 'grad_norm': 4.231540203094482, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.0031125973910093307, 'loss_2': 0.00312042236328125, 'loss_3': -16.356590270996094, 'loss_4': 1.2180230617523193, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 11:24:02,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:02,323 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [1:59:51<04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:09,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012255552224814892, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.69, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009955882094800472, 'eval_loss_2': 0.0022996701300144196, 'eval_loss_3': -18.188308715820312, 'eval_loss_4': 1.3164243698120117, 'epoch': 28.31}
{'loss': 0.0087, 'grad_norm': 4.39024019241333, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.0032983175478875637, 'loss_2': 0.005374908447265625, 'loss_3': -16.164575576782227, 'loss_4': 1.5200459957122803, 'epoch': 28.32}
{'loss': 0.043, 'grad_norm': 13.264045715332031, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.035472992807626724, 'loss_2': 0.007503509521484375, 'loss_3': -16.282089233398438, 'loss_4': 2.041285991668701, 'epoch': 28.33}
{'loss': 0.0034, 'grad_norm': 5.416788101196289, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.0029110668692737818, 'loss_2': 0.0004515647888183594, 'loss_3': -16.330764770507812, 'loss_4': 0.9491887092590332, 'epoch': 28.33}
{'loss': 0.0105, 'grad_norm': 5.063083648681641, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.0069284578785300255, 'loss_2': 0.0035991668701171875, 'loss_3': -16.3129940032959, 'loss_4': 1.5588619709014893, 'epoch': 28.34}
{'loss': 0.0054, 'grad_norm': 4.410336017608643, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.0025239759124815464, 'loss_2': 0.0028839111328125, 'loss_3': -16.323360443115234, 'loss_4': 1.2813372611999512, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 11:24:09,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:09,677 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [1:59:59<04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:17,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012143995612859726, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.665, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009940240532159805, 'eval_loss_2': 0.0022037550806999207, 'eval_loss_3': -18.186119079589844, 'eval_loss_4': 1.3233425617218018, 'epoch': 28.34}
{'loss': 0.007, 'grad_norm': 4.334766387939453, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.0019488511607050896, 'loss_2': 0.0050811767578125, 'loss_3': -16.159561157226562, 'loss_4': 1.5842585563659668, 'epoch': 28.35}
{'loss': 0.0084, 'grad_norm': 6.3996686935424805, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.005036626476794481, 'loss_2': 0.0033721923828125, 'loss_3': -16.398120880126953, 'loss_4': 1.842109203338623, 'epoch': 28.35}
{'loss': 0.0063, 'grad_norm': 5.428195953369141, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.00509647885337472, 'loss_2': 0.0012359619140625, 'loss_3': -16.12135124206543, 'loss_4': 2.134316921234131, 'epoch': 28.36}
{'loss': 0.0084, 'grad_norm': 4.634646415710449, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.003225246910005808, 'loss_2': 0.005146026611328125, 'loss_3': -16.24797821044922, 'loss_4': 1.7350962162017822, 'epoch': 28.37}
{'loss': 0.009, 'grad_norm': 5.240786075592041, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.006012212485074997, 'loss_2': 0.00301361083984375, 'loss_3': -16.48906135559082, 'loss_4': 1.4008440971374512, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 11:24:17,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:17,020 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:06<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:24,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012051715515553951, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.114, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010038858279585838, 'eval_loss_2': 0.0020128563046455383, 'eval_loss_3': -18.182697296142578, 'eval_loss_4': 1.3371458053588867, 'epoch': 28.37}
{'loss': 0.0049, 'grad_norm': 4.161958694458008, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.0007967756246216595, 'loss_2': 0.0041046142578125, 'loss_3': -16.569446563720703, 'loss_4': 1.1968426704406738, 'epoch': 28.38}
{'loss': 0.0065, 'grad_norm': 4.542796611785889, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.0019589283037930727, 'loss_2': 0.0045013427734375, 'loss_3': -16.655006408691406, 'loss_4': 1.4400625228881836, 'epoch': 28.38}
{'loss': 0.0081, 'grad_norm': 5.126375198364258, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.004669799469411373, 'loss_2': 0.003406524658203125, 'loss_3': -16.219833374023438, 'loss_4': 1.7313157320022583, 'epoch': 28.39}
{'loss': 0.0042, 'grad_norm': 4.512115478515625, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.001276002498343587, 'loss_2': 0.0029582977294921875, 'loss_3': -16.20550537109375, 'loss_4': 1.1649036407470703, 'epoch': 28.4}
{'loss': 0.0063, 'grad_norm': 4.949334621429443, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.0021210848353803158, 'loss_2': 0.00415802001953125, 'loss_3': -16.33505630493164, 'loss_4': 1.6034200191497803, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 11:24:24,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:24,367 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:13<04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:31,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011893580667674541, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.499, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009972664527595043, 'eval_loss_2': 0.0019209161400794983, 'eval_loss_3': -18.17889404296875, 'eval_loss_4': 1.3439135551452637, 'epoch': 28.4}
{'loss': 0.009, 'grad_norm': 6.977174758911133, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.0069496603682637215, 'loss_2': 0.002044677734375, 'loss_3': -16.23953628540039, 'loss_4': 1.6023119688034058, 'epoch': 28.41}
{'loss': 0.0125, 'grad_norm': 7.081785678863525, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.0075312224216759205, 'loss_2': 0.00495147705078125, 'loss_3': -16.296621322631836, 'loss_4': 1.2432924509048462, 'epoch': 28.41}
{'loss': 0.0215, 'grad_norm': 7.059040546417236, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.015507024712860584, 'loss_2': 0.006011962890625, 'loss_3': -16.18816566467285, 'loss_4': 2.062077760696411, 'epoch': 28.42}
{'loss': 0.0023, 'grad_norm': 3.8800289630889893, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.0013185428688302636, 'loss_2': 0.0009870529174804688, 'loss_3': -16.288625717163086, 'loss_4': 1.3820557594299316, 'epoch': 28.42}
{'loss': 0.0096, 'grad_norm': 4.617710113525391, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.00312708574347198, 'loss_2': 0.0064239501953125, 'loss_3': -16.399045944213867, 'loss_4': 1.739990472793579, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 11:24:31,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:31,714 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:21<04:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:39,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012025580741465092, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.624, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009958704002201557, 'eval_loss_2': 0.0020668767392635345, 'eval_loss_3': -18.177858352661133, 'eval_loss_4': 1.330617070198059, 'epoch': 28.43}
{'loss': 0.0054, 'grad_norm': 4.614153861999512, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.003537988755851984, 'loss_2': 0.0018320083618164062, 'loss_3': -16.31721305847168, 'loss_4': 1.8935853242874146, 'epoch': 28.44}
{'loss': 0.0017, 'grad_norm': 4.442383289337158, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.001630435697734356, 'loss_2': 0.00010800361633300781, 'loss_3': -16.330427169799805, 'loss_4': 1.557753086090088, 'epoch': 28.44}
{'loss': 0.0081, 'grad_norm': 4.838816165924072, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.003355227643623948, 'loss_2': 0.0047607421875, 'loss_3': -16.27646255493164, 'loss_4': 1.9468843936920166, 'epoch': 28.45}
{'loss': 0.0307, 'grad_norm': 26.96746826171875, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.022522974759340286, 'loss_2': 0.0081939697265625, 'loss_3': -16.253326416015625, 'loss_4': 1.7882232666015625, 'epoch': 28.45}
{'loss': 0.0057, 'grad_norm': 4.764934062957764, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.0034364478196948767, 'loss_2': 0.00228118896484375, 'loss_3': -16.22179412841797, 'loss_4': 1.1499710083007812, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 11:24:39,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:39,055 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:28<04:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:46,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012109767645597458, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010001923888921738, 'eval_loss_2': 0.00210784375667572, 'eval_loss_3': -18.178430557250977, 'eval_loss_4': 1.3189021348953247, 'epoch': 28.46}
{'loss': 0.0035, 'grad_norm': 4.819095611572266, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.002080562524497509, 'loss_2': 0.001384735107421875, 'loss_3': -16.227039337158203, 'loss_4': 1.983137845993042, 'epoch': 28.47}
{'loss': 0.0097, 'grad_norm': 5.324278354644775, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.0061895172111690044, 'loss_2': 0.0035247802734375, 'loss_3': -16.263294219970703, 'loss_4': 1.6336991786956787, 'epoch': 28.47}
{'loss': 0.0109, 'grad_norm': 6.262003421783447, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.0069010453298687935, 'loss_2': 0.0040283203125, 'loss_3': -16.103391647338867, 'loss_4': 2.105792760848999, 'epoch': 28.48}
{'loss': 0.0063, 'grad_norm': 4.754806995391846, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.004502919968217611, 'loss_2': 0.0018291473388671875, 'loss_3': -16.27259063720703, 'loss_4': 1.3135151863098145, 'epoch': 28.48}
{'loss': 0.0099, 'grad_norm': 4.618974685668945, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.005051532294601202, 'loss_2': 0.00482177734375, 'loss_3': -16.260650634765625, 'loss_4': 1.7096738815307617, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 11:24:46,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:46,397 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:35<04:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:53,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012103759683668613, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01014200784265995, 'eval_loss_2': 0.001961752772331238, 'eval_loss_3': -18.182621002197266, 'eval_loss_4': 1.3131028413772583, 'epoch': 28.49}
{'loss': 0.0074, 'grad_norm': 5.439614295959473, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0063497829250991344, 'loss_2': 0.0010976791381835938, 'loss_3': -16.32906723022461, 'loss_4': 1.6451472043991089, 'epoch': 28.49}
{'loss': 0.0041, 'grad_norm': 5.0857696533203125, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.002993109170347452, 'loss_2': 0.0010595321655273438, 'loss_3': -16.213985443115234, 'loss_4': 1.4444316625595093, 'epoch': 28.5}
{'loss': 0.0048, 'grad_norm': 4.076328277587891, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0018447170732542872, 'loss_2': 0.0029544830322265625, 'loss_3': -16.368013381958008, 'loss_4': 1.6158037185668945, 'epoch': 28.51}
{'loss': 0.0056, 'grad_norm': 4.645165920257568, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.0021954814437776804, 'loss_2': 0.00341796875, 'loss_3': -16.13262939453125, 'loss_4': 1.722041130065918, 'epoch': 28.51}
{'loss': 0.0085, 'grad_norm': 4.49060583114624, 'learning_rate': 1.5e-06, 'loss_1': 0.0016957921907305717, 'loss_2': 0.006816864013671875, 'loss_3': -16.224504470825195, 'loss_4': 1.6884006261825562, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 11:24:53,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:53,748 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:00:43<04:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:01,097 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01188269816339016, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01004923228174448, 'eval_loss_2': 0.0018334649503231049, 'eval_loss_3': -18.193531036376953, 'eval_loss_4': 1.2934818267822266, 'epoch': 28.52}
{'loss': 0.0084, 'grad_norm': 4.4049153327941895, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.0012325574643909931, 'loss_2': 0.007122039794921875, 'loss_3': -16.33123016357422, 'loss_4': 1.6000995635986328, 'epoch': 28.52}
{'loss': 0.0059, 'grad_norm': 5.149600982666016, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.005415233317762613, 'loss_2': 0.00046443939208984375, 'loss_3': -16.365354537963867, 'loss_4': 1.6619375944137573, 'epoch': 28.53}
{'loss': 0.0139, 'grad_norm': 5.504618167877197, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.009018603712320328, 'loss_2': 0.0048675537109375, 'loss_3': -16.231998443603516, 'loss_4': 1.495800256729126, 'epoch': 28.53}
{'loss': 0.0069, 'grad_norm': 4.604466915130615, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.0025148126296699047, 'loss_2': 0.00435638427734375, 'loss_3': -16.2852783203125, 'loss_4': 1.8684672117233276, 'epoch': 28.54}
{'loss': 0.0082, 'grad_norm': 4.9697747230529785, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.006614540237933397, 'loss_2': 0.0015583038330078125, 'loss_3': -16.213674545288086, 'loss_4': 2.082589626312256, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 11:25:01,097 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:01,097 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:00:50<04:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:08,443 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011753413826227188, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010032999329268932, 'eval_loss_2': 0.0017204135656356812, 'eval_loss_3': -18.19342041015625, 'eval_loss_4': 1.2715821266174316, 'epoch': 28.55}
{'loss': 0.0062, 'grad_norm': 4.633388996124268, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.0025535468012094498, 'loss_2': 0.0036029815673828125, 'loss_3': -16.403589248657227, 'loss_4': 2.022744655609131, 'epoch': 28.55}
{'loss': 0.0097, 'grad_norm': 5.309334754943848, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.0012552563566714525, 'loss_2': 0.008453369140625, 'loss_3': -16.432228088378906, 'loss_4': 1.5762674808502197, 'epoch': 28.56}
{'loss': 0.0084, 'grad_norm': 4.392823696136475, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.002740302588790655, 'loss_2': 0.005680084228515625, 'loss_3': -16.368680953979492, 'loss_4': 1.5694198608398438, 'epoch': 28.56}
{'loss': 0.0123, 'grad_norm': 4.680145740509033, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.0038112825714051723, 'loss_2': 0.0085296630859375, 'loss_3': -16.188779830932617, 'loss_4': 1.4731831550598145, 'epoch': 28.57}
{'loss': 0.0049, 'grad_norm': 4.439135551452637, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.003084619762375951, 'loss_2': 0.001800537109375, 'loss_3': -16.28327178955078, 'loss_4': 1.9563689231872559, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 11:25:08,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:08,443 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:00:57<04:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:15,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011789103038609028, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010017301887273788, 'eval_loss_2': 0.0017718002200126648, 'eval_loss_3': -18.191383361816406, 'eval_loss_4': 1.2618134021759033, 'epoch': 28.58}
{'loss': 0.0097, 'grad_norm': 4.436619758605957, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.0021340912207961082, 'loss_2': 0.00757598876953125, 'loss_3': -16.328540802001953, 'loss_4': 1.5601046085357666, 'epoch': 28.58}
{'loss': 0.0054, 'grad_norm': 4.38479471206665, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.0020190118812024593, 'loss_2': 0.003360748291015625, 'loss_3': -16.242393493652344, 'loss_4': 1.585371971130371, 'epoch': 28.59}
{'loss': 0.0014, 'grad_norm': 4.499482154846191, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.0011066729202866554, 'loss_2': 0.00031113624572753906, 'loss_3': -16.271390914916992, 'loss_4': 1.599740743637085, 'epoch': 28.59}
{'loss': 0.0145, 'grad_norm': 4.678598880767822, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.004054608754813671, 'loss_2': 0.01042938232421875, 'loss_3': -16.490577697753906, 'loss_4': 1.6555832624435425, 'epoch': 28.6}
{'loss': 0.0061, 'grad_norm': 4.661755561828613, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.0034135496243834496, 'loss_2': 0.00264739990234375, 'loss_3': -16.366695404052734, 'loss_4': 1.8903770446777344, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 11:25:15,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:15,788 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:05<04:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:23,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011779256165027618, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.353, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010005704127252102, 'eval_loss_2': 0.001773551106452942, 'eval_loss_3': -18.183738708496094, 'eval_loss_4': 1.2716244459152222, 'epoch': 28.6}
{'loss': 0.0086, 'grad_norm': 4.155198574066162, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.0017212784150615335, 'loss_2': 0.006877899169921875, 'loss_3': -16.318843841552734, 'loss_4': 1.7151837348937988, 'epoch': 28.61}
{'loss': 0.0072, 'grad_norm': 4.176239490509033, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.004307691007852554, 'loss_2': 0.0028743743896484375, 'loss_3': -16.36896324157715, 'loss_4': 1.174938440322876, 'epoch': 28.62}
{'loss': 0.0086, 'grad_norm': 5.042835712432861, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.005114967003464699, 'loss_2': 0.00351715087890625, 'loss_3': -16.40083122253418, 'loss_4': 1.1362736225128174, 'epoch': 28.62}
{'loss': 0.0051, 'grad_norm': 4.735494613647461, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.0037955360021442175, 'loss_2': 0.0012950897216796875, 'loss_3': -16.136817932128906, 'loss_4': 1.6691901683807373, 'epoch': 28.63}
{'loss': 0.0052, 'grad_norm': 4.853306770324707, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.0023460339289158583, 'loss_2': 0.0028438568115234375, 'loss_3': -16.429065704345703, 'loss_4': 1.6794185638427734, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 11:25:23,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:23,136 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:12<03:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:30,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012046553194522858, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.468, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010111235082149506, 'eval_loss_2': 0.001935318112373352, 'eval_loss_3': -18.178482055664062, 'eval_loss_4': 1.2707240581512451, 'epoch': 28.63}
{'loss': 0.0077, 'grad_norm': 4.7939863204956055, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.0024629966355860233, 'loss_2': 0.00524139404296875, 'loss_3': -16.310298919677734, 'loss_4': 1.2785978317260742, 'epoch': 28.64}
{'loss': 0.0072, 'grad_norm': 4.91285514831543, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.0021146340295672417, 'loss_2': 0.00508880615234375, 'loss_3': -16.624149322509766, 'loss_4': 1.6387317180633545, 'epoch': 28.65}
{'loss': 0.0092, 'grad_norm': 9.343663215637207, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.0065137287601828575, 'loss_2': 0.002696990966796875, 'loss_3': -16.313385009765625, 'loss_4': 1.6876232624053955, 'epoch': 28.65}
{'loss': 0.0134, 'grad_norm': 4.3447394371032715, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.0028952218126505613, 'loss_2': 0.01047515869140625, 'loss_3': -16.393064498901367, 'loss_4': 1.7457817792892456, 'epoch': 28.66}
{'loss': 0.0067, 'grad_norm': 4.799088478088379, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.004916822537779808, 'loss_2': 0.0018329620361328125, 'loss_3': -16.242950439453125, 'loss_4': 1.6227540969848633, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 11:25:30,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:30,485 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:19<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:37,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01227575447410345, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.461, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010194546543061733, 'eval_loss_2': 0.0020812079310417175, 'eval_loss_3': -18.18153190612793, 'eval_loss_4': 1.260106086730957, 'epoch': 28.66}
{'loss': 0.005, 'grad_norm': 4.890326499938965, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.003946550656110048, 'loss_2': 0.001071929931640625, 'loss_3': -16.42562484741211, 'loss_4': 1.4659192562103271, 'epoch': 28.67}
{'loss': 0.0123, 'grad_norm': 5.031466960906982, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.005325521342456341, 'loss_2': 0.00698089599609375, 'loss_3': -16.261762619018555, 'loss_4': 1.8003406524658203, 'epoch': 28.67}
{'loss': 0.0111, 'grad_norm': 5.090961933135986, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.00653527257964015, 'loss_2': 0.004596710205078125, 'loss_3': -16.23617172241211, 'loss_4': 1.9213860034942627, 'epoch': 28.68}
{'loss': 0.0074, 'grad_norm': 4.2555365562438965, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.0012741412501782179, 'loss_2': 0.00614166259765625, 'loss_3': -16.428295135498047, 'loss_4': 1.7897030115127563, 'epoch': 28.69}
{'loss': 0.003, 'grad_norm': 4.739076614379883, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.002450476633384824, 'loss_2': 0.0005731582641601562, 'loss_3': -16.057785034179688, 'loss_4': 1.0549882650375366, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 11:25:37,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:37,834 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:27<03:51,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:25:45,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012593640945851803, 'eval_runtime': 4.0131, 'eval_samples_per_second': 255.163, 'eval_steps_per_second': 3.987, 'eval_loss_1': 0.010292556136846542, 'eval_loss_2': 0.002301085740327835, 'eval_loss_3': -18.18572425842285, 'eval_loss_4': 1.2421095371246338, 'epoch': 28.69}
{'loss': 0.0045, 'grad_norm': 5.116904258728027, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.004248455166816711, 'loss_2': 0.000301361083984375, 'loss_3': -15.965216636657715, 'loss_4': 1.1601077318191528, 'epoch': 28.7}
{'loss': 0.0103, 'grad_norm': 4.537364482879639, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.0023488285951316357, 'loss_2': 0.00794219970703125, 'loss_3': -16.30095100402832, 'loss_4': 1.113393783569336, 'epoch': 28.7}
{'loss': 0.0071, 'grad_norm': 4.440829277038574, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.0050162337720394135, 'loss_2': 0.002079010009765625, 'loss_3': -16.130104064941406, 'loss_4': 1.407570481300354, 'epoch': 28.71}
{'loss': 0.0091, 'grad_norm': 4.291914463043213, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.0022416969295591116, 'loss_2': 0.006885528564453125, 'loss_3': -16.234683990478516, 'loss_4': 1.570652961730957, 'epoch': 28.72}
{'loss': 0.0051, 'grad_norm': 4.929181098937988, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.0030339390505105257, 'loss_2': 0.0021114349365234375, 'loss_3': -16.234249114990234, 'loss_4': 1.1301237344741821, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 11:25:45,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:45,395 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:34<03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:52,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012709606438875198, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.841, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010340099222958088, 'eval_loss_2': 0.002369508147239685, 'eval_loss_3': -18.18467140197754, 'eval_loss_4': 1.218298077583313, 'epoch': 28.72}
{'loss': 0.0091, 'grad_norm': 4.61650276184082, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.003985254559665918, 'loss_2': 0.0051422119140625, 'loss_3': -16.36330223083496, 'loss_4': 1.6086193323135376, 'epoch': 28.73}
{'loss': 0.0044, 'grad_norm': 4.649758338928223, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.0028057661838829517, 'loss_2': 0.001636505126953125, 'loss_3': -16.41433334350586, 'loss_4': 1.3069190979003906, 'epoch': 28.73}
{'loss': 0.0072, 'grad_norm': 4.143026351928711, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.0014004483819007874, 'loss_2': 0.00582122802734375, 'loss_3': -16.239652633666992, 'loss_4': 1.5086033344268799, 'epoch': 28.74}
{'loss': 0.0025, 'grad_norm': 4.4745049476623535, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.002324746921658516, 'loss_2': 0.0001995563507080078, 'loss_3': -16.297588348388672, 'loss_4': 1.5864448547363281, 'epoch': 28.74}
{'loss': 0.0048, 'grad_norm': 4.723968029022217, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.00252812122926116, 'loss_2': 0.002307891845703125, 'loss_3': -16.301424026489258, 'loss_4': 1.3833138942718506, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 11:25:52,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:52,744 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:01:42<03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:00,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01271731499582529, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.574, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010298577137291431, 'eval_loss_2': 0.0024187378585338593, 'eval_loss_3': -18.183792114257812, 'eval_loss_4': 1.1959404945373535, 'epoch': 28.75}
{'loss': 0.0059, 'grad_norm': 4.312514305114746, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.0019657860975712538, 'loss_2': 0.003963470458984375, 'loss_3': -16.22270965576172, 'loss_4': 1.3303667306900024, 'epoch': 28.76}
{'loss': 0.0068, 'grad_norm': 4.664488315582275, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.004989132285118103, 'loss_2': 0.0017757415771484375, 'loss_3': -16.456340789794922, 'loss_4': 1.426000714302063, 'epoch': 28.76}
{'loss': 0.0081, 'grad_norm': 7.461739540100098, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.008014521561563015, 'loss_2': 4.863739013671875e-05, 'loss_3': -16.489788055419922, 'loss_4': 1.3157734870910645, 'epoch': 28.77}
{'loss': 0.0035, 'grad_norm': 4.1269450187683105, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.0024713336024433374, 'loss_2': 0.0010623931884765625, 'loss_3': -16.40048599243164, 'loss_4': 1.4263160228729248, 'epoch': 28.77}
{'loss': 0.0088, 'grad_norm': 4.51969575881958, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.0033817323856055737, 'loss_2': 0.0053863525390625, 'loss_3': -16.406082153320312, 'loss_4': 1.831117868423462, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 11:26:00,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:00,087 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:01:49<03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:07,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012758469209074974, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.563, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010100518353283405, 'eval_loss_2': 0.002657949924468994, 'eval_loss_3': -18.178478240966797, 'eval_loss_4': 1.1940574645996094, 'epoch': 28.78}
{'loss': 0.0108, 'grad_norm': 4.5014753341674805, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.00228051096200943, 'loss_2': 0.008514404296875, 'loss_3': -16.28573226928711, 'loss_4': 1.7800772190093994, 'epoch': 28.78}
{'loss': 0.0084, 'grad_norm': 4.6116042137146, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.0019258813699707389, 'loss_2': 0.006496429443359375, 'loss_3': -16.300045013427734, 'loss_4': 1.7003307342529297, 'epoch': 28.79}
{'loss': 0.0048, 'grad_norm': 4.5099005699157715, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.0036982381716370583, 'loss_2': 0.0011348724365234375, 'loss_3': -16.442909240722656, 'loss_4': 1.0732917785644531, 'epoch': 28.8}
{'loss': 0.0038, 'grad_norm': 4.481994152069092, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.0033320432994514704, 'loss_2': 0.0004520416259765625, 'loss_3': -16.18497085571289, 'loss_4': 1.3308697938919067, 'epoch': 28.8}
{'loss': 0.0175, 'grad_norm': 7.550609111785889, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.011190751567482948, 'loss_2': 0.0063323974609375, 'loss_3': -16.37681770324707, 'loss_4': 1.5140602588653564, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 11:26:07,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:07,426 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:01:56<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:14,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012841673567891121, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010041910223662853, 'eval_loss_2': 0.0027997642755508423, 'eval_loss_3': -18.17844581604004, 'eval_loss_4': 1.1921460628509521, 'epoch': 28.81}
{'loss': 0.0091, 'grad_norm': 5.240645885467529, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.005738936830312014, 'loss_2': 0.0033893585205078125, 'loss_3': -16.19980239868164, 'loss_4': 1.9006725549697876, 'epoch': 28.81}
{'loss': 0.009, 'grad_norm': 4.251953125, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.004433035384863615, 'loss_2': 0.0045623779296875, 'loss_3': -16.3150634765625, 'loss_4': 1.7271666526794434, 'epoch': 28.82}
{'loss': 0.0083, 'grad_norm': 4.668283462524414, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.0024500959552824497, 'loss_2': 0.005809783935546875, 'loss_3': -16.392560958862305, 'loss_4': 1.2975120544433594, 'epoch': 28.83}
{'loss': 0.0051, 'grad_norm': 4.574484348297119, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.002882609376683831, 'loss_2': 0.00225067138671875, 'loss_3': -16.293304443359375, 'loss_4': 1.187485694885254, 'epoch': 28.83}
{'loss': 0.0058, 'grad_norm': 5.59047269821167, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.004569985903799534, 'loss_2': 0.0012655258178710938, 'loss_3': -16.483631134033203, 'loss_4': 1.7696934938430786, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 11:26:14,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:14,789 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:04<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:22,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01292759831994772, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010048395954072475, 'eval_loss_2': 0.002879202365875244, 'eval_loss_3': -18.177978515625, 'eval_loss_4': 1.2022773027420044, 'epoch': 28.84}
{'loss': 0.0099, 'grad_norm': 4.490836143493652, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.004640115890651941, 'loss_2': 0.005298614501953125, 'loss_3': -16.368181228637695, 'loss_4': 1.645174264907837, 'epoch': 28.84}
{'loss': 0.0075, 'grad_norm': 4.581851005554199, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.003950248472392559, 'loss_2': 0.003582000732421875, 'loss_3': -16.39458465576172, 'loss_4': 1.467445731163025, 'epoch': 28.85}
{'loss': 0.0042, 'grad_norm': 5.285133361816406, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.003789961338043213, 'loss_2': 0.0003771781921386719, 'loss_3': -16.218334197998047, 'loss_4': 1.4918235540390015, 'epoch': 28.85}
{'loss': 0.0063, 'grad_norm': 4.563243865966797, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.0026953278575092554, 'loss_2': 0.003620147705078125, 'loss_3': -16.29473114013672, 'loss_4': 1.398997187614441, 'epoch': 28.86}
{'loss': 0.0141, 'grad_norm': 4.52097749710083, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.0023448853753507137, 'loss_2': 0.011749267578125, 'loss_3': -16.144615173339844, 'loss_4': 1.256983757019043, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 11:26:22,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:22,135 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:11<03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:29,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012554068118333817, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009946856647729874, 'eval_loss_2': 0.002607211470603943, 'eval_loss_3': -18.174633026123047, 'eval_loss_4': 1.1993911266326904, 'epoch': 28.87}
{'loss': 0.0054, 'grad_norm': 4.527757167816162, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.0025871344842016697, 'loss_2': 0.002788543701171875, 'loss_3': -16.309776306152344, 'loss_4': 1.5261558294296265, 'epoch': 28.87}
{'loss': 0.0018, 'grad_norm': 4.317013740539551, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.0016651262994855642, 'loss_2': 9.906291961669922e-05, 'loss_3': -16.222314834594727, 'loss_4': 1.367882251739502, 'epoch': 28.88}
{'loss': 0.0078, 'grad_norm': 4.480844974517822, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.0029688465874642134, 'loss_2': 0.00484466552734375, 'loss_3': -16.40772819519043, 'loss_4': 1.2200031280517578, 'epoch': 28.88}
{'loss': 0.0108, 'grad_norm': 4.970991611480713, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.006247628480195999, 'loss_2': 0.0045166015625, 'loss_3': -16.37209701538086, 'loss_4': 0.7365957498550415, 'epoch': 28.89}
{'loss': 0.0079, 'grad_norm': 4.770016670227051, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.004520190879702568, 'loss_2': 0.003330230712890625, 'loss_3': -16.117088317871094, 'loss_4': 1.5075786113739014, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 11:26:29,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:29,473 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:18<03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:36,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012120500206947327, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009865195490419865, 'eval_loss_2': 0.0022553056478500366, 'eval_loss_3': -18.17128562927246, 'eval_loss_4': 1.197434902191162, 'epoch': 28.9}
{'loss': 0.011, 'grad_norm': 5.213873863220215, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.004684229381382465, 'loss_2': 0.00634002685546875, 'loss_3': -16.330650329589844, 'loss_4': 1.4219787120819092, 'epoch': 28.9}
{'loss': 0.0044, 'grad_norm': 5.033463478088379, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.0043299091048538685, 'loss_2': 6.890296936035156e-05, 'loss_3': -16.171470642089844, 'loss_4': 1.1164970397949219, 'epoch': 28.91}
{'loss': 0.0038, 'grad_norm': 4.404778480529785, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.003553025657311082, 'loss_2': 0.00020813941955566406, 'loss_3': -16.343250274658203, 'loss_4': 1.2305418252944946, 'epoch': 28.91}
{'loss': 0.0098, 'grad_norm': 4.566343784332275, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.0012110864045098424, 'loss_2': 0.00859832763671875, 'loss_3': -16.50107192993164, 'loss_4': 1.7193657159805298, 'epoch': 28.92}
{'loss': 0.0058, 'grad_norm': 5.604609966278076, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.005112743936479092, 'loss_2': 0.0006532669067382812, 'loss_3': -16.405410766601562, 'loss_4': 1.5488684177398682, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 11:26:36,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:36,822 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:26<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:44,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0118486313149333, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.298, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00995379313826561, 'eval_loss_2': 0.001894839107990265, 'eval_loss_3': -18.17214012145996, 'eval_loss_4': 1.1836347579956055, 'epoch': 28.92}
{'loss': 0.0072, 'grad_norm': 4.893873691558838, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.0028384646866470575, 'loss_2': 0.0043182373046875, 'loss_3': -16.23426055908203, 'loss_4': 2.006826877593994, 'epoch': 28.93}
{'loss': 0.0088, 'grad_norm': 5.36679744720459, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.005355149041861296, 'loss_2': 0.0034503936767578125, 'loss_3': -16.344058990478516, 'loss_4': 1.4213874340057373, 'epoch': 28.94}
{'loss': 0.0052, 'grad_norm': 5.589025497436523, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.003524265717715025, 'loss_2': 0.0016803741455078125, 'loss_3': -16.15825653076172, 'loss_4': 0.8777830600738525, 'epoch': 28.94}
{'loss': 0.0081, 'grad_norm': 5.8300065994262695, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.0063234008848667145, 'loss_2': 0.001796722412109375, 'loss_3': -16.448490142822266, 'loss_4': 1.8541091680526733, 'epoch': 28.95}
{'loss': 0.0083, 'grad_norm': 4.51386833190918, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.002874423749744892, 'loss_2': 0.00543975830078125, 'loss_3': -16.604936599731445, 'loss_4': 1.3930031061172485, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 11:26:44,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:44,164 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:33<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:51,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011862874031066895, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.37, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010132759809494019, 'eval_loss_2': 0.001730114221572876, 'eval_loss_3': -18.174352645874023, 'eval_loss_4': 1.1689084768295288, 'epoch': 28.95}
{'loss': 0.0023, 'grad_norm': 4.527836322784424, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.0021262094378471375, 'loss_2': 0.0001405477523803711, 'loss_3': -16.436004638671875, 'loss_4': 1.3844618797302246, 'epoch': 28.96}
{'loss': 0.0079, 'grad_norm': 4.642044544219971, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.0036772217135876417, 'loss_2': 0.004241943359375, 'loss_3': -16.33016014099121, 'loss_4': 0.9393945932388306, 'epoch': 28.97}
{'loss': 0.0033, 'grad_norm': 4.649757385253906, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.003015735885128379, 'loss_2': 0.0003342628479003906, 'loss_3': -16.246885299682617, 'loss_4': 1.4186856746673584, 'epoch': 28.97}
{'loss': 0.0025, 'grad_norm': 4.430561542510986, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0017104271100834012, 'loss_2': 0.0007505416870117188, 'loss_3': -16.335113525390625, 'loss_4': 1.5755043029785156, 'epoch': 28.98}
{'loss': 0.0024, 'grad_norm': 4.311725616455078, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.00200506579130888, 'loss_2': 0.0003676414489746094, 'loss_3': -16.487918853759766, 'loss_4': 1.1961017847061157, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 11:26:51,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:51,512 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:02:40<02:49,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 11:26:58,549 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011882446706295013, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.901, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01014785561710596, 'eval_loss_2': 0.0017345920205116272, 'eval_loss_3': -18.1737003326416, 'eval_loss_4': 1.164592981338501, 'epoch': 28.98}
{'loss': 0.0103, 'grad_norm': 5.068119525909424, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.0053148153237998486, 'loss_2': 0.00501251220703125, 'loss_3': -16.26676368713379, 'loss_4': 1.4118022918701172, 'epoch': 28.99}
{'loss': 0.0043, 'grad_norm': 4.4907450675964355, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.0021326278802007437, 'loss_2': 0.002124786376953125, 'loss_3': -16.355009078979492, 'loss_4': 1.403458595275879, 'epoch': 28.99}
{'loss': 0.01, 'grad_norm': 5.917224884033203, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.004889005795121193, 'loss_2': 0.0051116943359375, 'loss_3': -16.404094696044922, 'loss_4': 1.8126121759414673, 'epoch': 29.0}
{'loss': 0.0069, 'grad_norm': 4.449916839599609, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.0023415752220898867, 'loss_2': 0.004528045654296875, 'loss_3': -16.16411018371582, 'loss_4': 1.5037044286727905, 'epoch': 29.01}
{'loss': 0.0034, 'grad_norm': 4.854502201080322, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.002618933329358697, 'loss_2': 0.0007333755493164062, 'loss_3': -16.385517120361328, 'loss_4': 0.9980983138084412, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 11:26:58,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:58,550 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:02:48<02:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:27:05,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011830506846308708, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01004685927182436, 'eval_loss_2': 0.0017836466431617737, 'eval_loss_3': -18.17308235168457, 'eval_loss_4': 1.156085729598999, 'epoch': 29.01}
{'loss': 0.0061, 'grad_norm': 4.6644086837768555, 'learning_rate': 1e-06, 'loss_1': 0.0027456546667963266, 'loss_2': 0.00334930419921875, 'loss_3': -16.393617630004883, 'loss_4': 1.5004544258117676, 'epoch': 29.02}
{'loss': 0.0047, 'grad_norm': 4.487732410430908, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.0020790263079106808, 'loss_2': 0.0025787353515625, 'loss_3': -16.35536766052246, 'loss_4': 1.4949908256530762, 'epoch': 29.02}
{'loss': 0.0102, 'grad_norm': 4.621326446533203, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.006793240085244179, 'loss_2': 0.00339508056640625, 'loss_3': -16.099233627319336, 'loss_4': 1.4051826000213623, 'epoch': 29.03}
{'loss': 0.0081, 'grad_norm': 8.931756973266602, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.00681597413495183, 'loss_2': 0.00128173828125, 'loss_3': -16.190858840942383, 'loss_4': 0.7753891944885254, 'epoch': 29.03}
{'loss': 0.0089, 'grad_norm': 5.391848087310791, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.004429670982062817, 'loss_2': 0.0045013427734375, 'loss_3': -16.269371032714844, 'loss_4': 1.0584250688552856, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 11:27:05,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:05,901 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:02:55<02:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:13,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011820623651146889, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010016589425504208, 'eval_loss_2': 0.0018040351569652557, 'eval_loss_3': -18.175867080688477, 'eval_loss_4': 1.1538130044937134, 'epoch': 29.04}
{'loss': 0.0112, 'grad_norm': 6.518459796905518, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.009550966322422028, 'loss_2': 0.00162506103515625, 'loss_3': -16.074920654296875, 'loss_4': 1.6093920469284058, 'epoch': 29.05}
{'loss': 0.0134, 'grad_norm': 5.6581268310546875, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.007454235572367907, 'loss_2': 0.00591278076171875, 'loss_3': -16.404802322387695, 'loss_4': 1.2823460102081299, 'epoch': 29.05}
{'loss': 0.0041, 'grad_norm': 4.562190532684326, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.0014131213538348675, 'loss_2': 0.0026702880859375, 'loss_3': -16.35593605041504, 'loss_4': 1.438576579093933, 'epoch': 29.06}
{'loss': 0.0135, 'grad_norm': 7.198238372802734, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.009971086867153645, 'loss_2': 0.00356292724609375, 'loss_3': -16.126815795898438, 'loss_4': 1.6632771492004395, 'epoch': 29.06}
{'loss': 0.0094, 'grad_norm': 5.383248805999756, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.0038544817361980677, 'loss_2': 0.00556182861328125, 'loss_3': -16.295976638793945, 'loss_4': 0.763526201248169, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 11:27:13,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:13,247 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:02<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:20,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011849537491798401, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.488, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010030061937868595, 'eval_loss_2': 0.0018194764852523804, 'eval_loss_3': -18.173919677734375, 'eval_loss_4': 1.1595789194107056, 'epoch': 29.07}
{'loss': 0.0055, 'grad_norm': 4.494526386260986, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.0042627789080142975, 'loss_2': 0.0012645721435546875, 'loss_3': -16.384851455688477, 'loss_4': 1.2178711891174316, 'epoch': 29.08}
{'loss': 0.0068, 'grad_norm': 4.137601852416992, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.0013717844849452376, 'loss_2': 0.005435943603515625, 'loss_3': -16.50653076171875, 'loss_4': 1.4727742671966553, 'epoch': 29.08}
{'loss': 0.0079, 'grad_norm': 5.953212261199951, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.006107704248279333, 'loss_2': 0.00176239013671875, 'loss_3': -16.100526809692383, 'loss_4': 1.63037109375, 'epoch': 29.09}
{'loss': 0.0175, 'grad_norm': 9.623345375061035, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.01566382311284542, 'loss_2': 0.0018138885498046875, 'loss_3': -16.52901840209961, 'loss_4': 1.442822813987732, 'epoch': 29.09}
{'loss': 0.0089, 'grad_norm': 4.512833595275879, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.003049889113754034, 'loss_2': 0.0058746337890625, 'loss_3': -16.277687072753906, 'loss_4': 1.6216018199920654, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 11:27:20,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:20,592 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:10<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:27,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01187828928232193, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.821, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010074526071548462, 'eval_loss_2': 0.001803763210773468, 'eval_loss_3': -18.169837951660156, 'eval_loss_4': 1.166170358657837, 'epoch': 29.1}
{'loss': 0.0063, 'grad_norm': 4.016916751861572, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.004068336449563503, 'loss_2': 0.002201080322265625, 'loss_3': -16.24475860595703, 'loss_4': 1.575418472290039, 'epoch': 29.1}
{'loss': 0.0067, 'grad_norm': 4.7836785316467285, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.0029595454689115286, 'loss_2': 0.0037021636962890625, 'loss_3': -16.345895767211914, 'loss_4': 1.4786264896392822, 'epoch': 29.11}
{'loss': 0.0132, 'grad_norm': 7.606942176818848, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.012144094333052635, 'loss_2': 0.0010747909545898438, 'loss_3': -16.396541595458984, 'loss_4': 1.6146254539489746, 'epoch': 29.12}
{'loss': 0.0075, 'grad_norm': 4.506889343261719, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.004233256913721561, 'loss_2': 0.0033016204833984375, 'loss_3': -16.55562973022461, 'loss_4': 1.890036702156067, 'epoch': 29.12}
{'loss': 0.0073, 'grad_norm': 4.526274681091309, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.0025930264964699745, 'loss_2': 0.0047149658203125, 'loss_3': -16.318191528320312, 'loss_4': 1.0283257961273193, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 11:27:27,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:27,932 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:17<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:35,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011925369501113892, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010063981637358665, 'eval_loss_2': 0.001861386001110077, 'eval_loss_3': -18.167274475097656, 'eval_loss_4': 1.1747336387634277, 'epoch': 29.13}
{'loss': 0.0055, 'grad_norm': 4.716150283813477, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.0049197678454220295, 'loss_2': 0.0006189346313476562, 'loss_3': -16.341115951538086, 'loss_4': 1.4383082389831543, 'epoch': 29.13}
{'loss': 0.0031, 'grad_norm': 4.391192436218262, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.001715639140456915, 'loss_2': 0.0013780593872070312, 'loss_3': -16.375734329223633, 'loss_4': 1.6204993724822998, 'epoch': 29.14}
{'loss': 0.007, 'grad_norm': 4.917630672454834, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.004713164176791906, 'loss_2': 0.0023136138916015625, 'loss_3': -16.31352996826172, 'loss_4': 0.9125900864601135, 'epoch': 29.15}
{'loss': 0.0041, 'grad_norm': 4.560110092163086, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0023292796686291695, 'loss_2': 0.0017757415771484375, 'loss_3': -16.016645431518555, 'loss_4': 1.4075510501861572, 'epoch': 29.15}
{'loss': 0.0027, 'grad_norm': 4.391932964324951, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.002118058269843459, 'loss_2': 0.0006046295166015625, 'loss_3': -16.315614700317383, 'loss_4': 1.3870277404785156, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 11:27:35,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:35,285 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:24<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:42,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01188489980995655, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010070862248539925, 'eval_loss_2': 0.001814037561416626, 'eval_loss_3': -18.166717529296875, 'eval_loss_4': 1.1760514974594116, 'epoch': 29.16}
{'loss': 0.0039, 'grad_norm': 4.784064769744873, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.0035025877878069878, 'loss_2': 0.0003726482391357422, 'loss_3': -16.310161590576172, 'loss_4': 1.4396803379058838, 'epoch': 29.16}
{'loss': 0.0061, 'grad_norm': 4.608242511749268, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.0024269940331578255, 'loss_2': 0.003643035888671875, 'loss_3': -16.265539169311523, 'loss_4': 1.124800682067871, 'epoch': 29.17}
{'loss': 0.0058, 'grad_norm': 4.576198577880859, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.002835639985278249, 'loss_2': 0.00298309326171875, 'loss_3': -16.28127098083496, 'loss_4': 1.562326431274414, 'epoch': 29.17}
{'loss': 0.0051, 'grad_norm': 4.891720771789551, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.004624000284820795, 'loss_2': 0.000514984130859375, 'loss_3': -16.235103607177734, 'loss_4': 0.7895117998123169, 'epoch': 29.18}
{'loss': 0.0086, 'grad_norm': 4.540140628814697, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.002736670197919011, 'loss_2': 0.005878448486328125, 'loss_3': -16.15569305419922, 'loss_4': 1.3218519687652588, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 11:27:42,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:42,628 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:32<02:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:49,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011771893128752708, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010031971149146557, 'eval_loss_2': 0.0017399229109287262, 'eval_loss_3': -18.16775894165039, 'eval_loss_4': 1.170697808265686, 'epoch': 29.19}
{'loss': 0.0057, 'grad_norm': 4.711533546447754, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.0027405789587646723, 'loss_2': 0.002971649169921875, 'loss_3': -16.36208152770996, 'loss_4': 1.591562271118164, 'epoch': 29.19}
{'loss': 0.0029, 'grad_norm': 4.350795269012451, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.002822964685037732, 'loss_2': 0.00010633468627929688, 'loss_3': -16.345151901245117, 'loss_4': 1.3693609237670898, 'epoch': 29.2}
{'loss': 0.0134, 'grad_norm': 6.278417587280273, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.009634090587496758, 'loss_2': 0.003765106201171875, 'loss_3': -16.028791427612305, 'loss_4': 0.9070636034011841, 'epoch': 29.2}
{'loss': 0.0057, 'grad_norm': 4.456106662750244, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.002767271362245083, 'loss_2': 0.00296783447265625, 'loss_3': -16.320716857910156, 'loss_4': 1.5181530714035034, 'epoch': 29.21}
{'loss': 0.0076, 'grad_norm': 4.765726089477539, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.004534067586064339, 'loss_2': 0.0030841827392578125, 'loss_3': -16.390399932861328, 'loss_4': 0.7504300475120544, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 11:27:49,978 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:49,978 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:39<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:57,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01182981301099062, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.411, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009981339797377586, 'eval_loss_2': 0.001848474144935608, 'eval_loss_3': -18.165611267089844, 'eval_loss_4': 1.1722166538238525, 'epoch': 29.22}
{'loss': 0.0029, 'grad_norm': 4.680384159088135, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.0020682760514318943, 'loss_2': 0.000789642333984375, 'loss_3': -16.44160270690918, 'loss_4': 1.3065249919891357, 'epoch': 29.22}
{'loss': 0.0109, 'grad_norm': 5.924924850463867, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.005959420930594206, 'loss_2': 0.0048980712890625, 'loss_3': -16.268157958984375, 'loss_4': 1.2341679334640503, 'epoch': 29.23}
{'loss': 0.0065, 'grad_norm': 4.524518013000488, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.0028424644842743874, 'loss_2': 0.0037059783935546875, 'loss_3': -16.312772750854492, 'loss_4': 1.414762020111084, 'epoch': 29.23}
{'loss': 0.0034, 'grad_norm': 4.588216304779053, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.002343641361221671, 'loss_2': 0.0010528564453125, 'loss_3': -16.17074966430664, 'loss_4': 1.6298818588256836, 'epoch': 29.24}
{'loss': 0.0057, 'grad_norm': 4.982152462005615, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.003126847790554166, 'loss_2': 0.00255584716796875, 'loss_3': -16.381261825561523, 'loss_4': 1.6513214111328125, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 11:27:57,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:57,323 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:03:46<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:04,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01199384219944477, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010032299906015396, 'eval_loss_2': 0.001961544156074524, 'eval_loss_3': -18.163951873779297, 'eval_loss_4': 1.1807234287261963, 'epoch': 29.24}
{'loss': 0.0126, 'grad_norm': 9.673150062561035, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.010195901617407799, 'loss_2': 0.00238800048828125, 'loss_3': -16.18062400817871, 'loss_4': 0.956824541091919, 'epoch': 29.25}
{'loss': 0.0172, 'grad_norm': 11.231185913085938, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.009323866106569767, 'loss_2': 0.00788116455078125, 'loss_3': -16.503137588500977, 'loss_4': 1.0808322429656982, 'epoch': 29.26}
{'loss': 0.0304, 'grad_norm': 10.773107528686523, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.0220574289560318, 'loss_2': 0.00830078125, 'loss_3': -16.150590896606445, 'loss_4': 1.0644323825836182, 'epoch': 29.26}
{'loss': 0.0064, 'grad_norm': 5.133737564086914, 'learning_rate': 7.5e-07, 'loss_1': 0.004267707001417875, 'loss_2': 0.0021305084228515625, 'loss_3': -16.156360626220703, 'loss_4': 1.5638465881347656, 'epoch': 29.27}
{'loss': 0.0112, 'grad_norm': 4.6856369972229, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.0071160513907670975, 'loss_2': 0.0040740966796875, 'loss_3': -16.30634880065918, 'loss_4': 1.1862996816635132, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 11:28:04,669 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:04,669 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:03:54<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:12,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011869754642248154, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.329, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009989066980779171, 'eval_loss_2': 0.0018806904554367065, 'eval_loss_3': -18.16522979736328, 'eval_loss_4': 1.1746227741241455, 'epoch': 29.27}
{'loss': 0.0069, 'grad_norm': 4.619765758514404, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.0021603978238999844, 'loss_2': 0.004730224609375, 'loss_3': -16.216026306152344, 'loss_4': 1.2461268901824951, 'epoch': 29.28}
{'loss': 0.0167, 'grad_norm': 7.947013854980469, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.012980821542441845, 'loss_2': 0.003673553466796875, 'loss_3': -16.151020050048828, 'loss_4': 0.807860255241394, 'epoch': 29.28}
{'loss': 0.0078, 'grad_norm': 5.89450740814209, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.007647456601262093, 'loss_2': 0.00020134449005126953, 'loss_3': -16.365625381469727, 'loss_4': 1.476906180381775, 'epoch': 29.29}
{'loss': 0.0082, 'grad_norm': 4.562228202819824, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.004100900609046221, 'loss_2': 0.00411224365234375, 'loss_3': -16.119604110717773, 'loss_4': 1.0858745574951172, 'epoch': 29.3}
{'loss': 0.0095, 'grad_norm': 4.25208044052124, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.003663139184936881, 'loss_2': 0.005832672119140625, 'loss_3': -16.408578872680664, 'loss_4': 1.6881041526794434, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 11:28:12,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:12,017 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:01<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:19,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011878889985382557, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.007, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010000098496675491, 'eval_loss_2': 0.001878790557384491, 'eval_loss_3': -18.166051864624023, 'eval_loss_4': 1.1637418270111084, 'epoch': 29.3}
{'loss': 0.0065, 'grad_norm': 4.751492977142334, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.002286713570356369, 'loss_2': 0.00421905517578125, 'loss_3': -16.21395492553711, 'loss_4': 1.3359237909317017, 'epoch': 29.31}
{'loss': 0.0018, 'grad_norm': 4.35128927230835, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.001216680626384914, 'loss_2': 0.0005998611450195312, 'loss_3': -16.454387664794922, 'loss_4': 1.6090365648269653, 'epoch': 29.31}
{'loss': 0.0032, 'grad_norm': 4.2552080154418945, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.002728073624894023, 'loss_2': 0.0004572868347167969, 'loss_3': -16.244991302490234, 'loss_4': 2.098543882369995, 'epoch': 29.32}
{'loss': 0.0055, 'grad_norm': 5.339311122894287, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.004550594370812178, 'loss_2': 0.00098419189453125, 'loss_3': -16.207468032836914, 'loss_4': 1.1188766956329346, 'epoch': 29.33}
{'loss': 0.0077, 'grad_norm': 6.1139140129089355, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.0054396213963627815, 'loss_2': 0.0022792816162109375, 'loss_3': -16.330352783203125, 'loss_4': 1.179560899734497, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 11:28:19,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:19,372 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:08<01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:26,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011886472813785076, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010037731379270554, 'eval_loss_2': 0.0018487423658370972, 'eval_loss_3': -18.166749954223633, 'eval_loss_4': 1.1547528505325317, 'epoch': 29.33}
{'loss': 0.0056, 'grad_norm': 4.570067405700684, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.001152113312855363, 'loss_2': 0.0044403076171875, 'loss_3': -16.37295913696289, 'loss_4': 1.3067209720611572, 'epoch': 29.34}
{'loss': 0.0029, 'grad_norm': 4.460538387298584, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.002588002709671855, 'loss_2': 0.0003581047058105469, 'loss_3': -16.083452224731445, 'loss_4': 1.4762778282165527, 'epoch': 29.34}
{'loss': 0.014, 'grad_norm': 4.948500156402588, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.0032873277086764574, 'loss_2': 0.01068115234375, 'loss_3': -16.195392608642578, 'loss_4': 1.3594036102294922, 'epoch': 29.35}
{'loss': 0.0155, 'grad_norm': 7.826594829559326, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.01442828681319952, 'loss_2': 0.001087188720703125, 'loss_3': -16.5012149810791, 'loss_4': 1.4943655729293823, 'epoch': 29.35}
{'loss': 0.0052, 'grad_norm': 4.116780757904053, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.0012580410111695528, 'loss_2': 0.0039825439453125, 'loss_3': -16.35572052001953, 'loss_4': 1.1645644903182983, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 11:28:26,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:26,717 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:16<01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:34,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011949127539992332, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01002577692270279, 'eval_loss_2': 0.001923348754644394, 'eval_loss_3': -18.165496826171875, 'eval_loss_4': 1.1512868404388428, 'epoch': 29.36}
{'loss': 0.0039, 'grad_norm': 4.451204776763916, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0028492482379078865, 'loss_2': 0.001010894775390625, 'loss_3': -16.420528411865234, 'loss_4': 1.4689970016479492, 'epoch': 29.37}
{'loss': 0.005, 'grad_norm': 4.67838191986084, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.0027866496238857508, 'loss_2': 0.002166748046875, 'loss_3': -16.147991180419922, 'loss_4': 1.3963203430175781, 'epoch': 29.37}
{'loss': 0.0079, 'grad_norm': 5.382503986358643, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.007519006263464689, 'loss_2': 0.00035834312438964844, 'loss_3': -16.418331146240234, 'loss_4': 1.9368737936019897, 'epoch': 29.38}
{'loss': 0.0043, 'grad_norm': 5.01112174987793, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.001978906337171793, 'loss_2': 0.002288818359375, 'loss_3': -16.216480255126953, 'loss_4': 0.934356689453125, 'epoch': 29.38}
{'loss': 0.0075, 'grad_norm': 4.8635945320129395, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.0042937383987009525, 'loss_2': 0.0031585693359375, 'loss_3': -16.26315689086914, 'loss_4': 1.4537031650543213, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 11:28:34,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:34,062 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:23<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:41,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011996997520327568, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.643, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009986920282244682, 'eval_loss_2': 0.0020100772380828857, 'eval_loss_3': -18.16819953918457, 'eval_loss_4': 1.1408697366714478, 'epoch': 29.39}
{'loss': 0.0044, 'grad_norm': 5.09234619140625, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.002219982212409377, 'loss_2': 0.002162933349609375, 'loss_3': -16.134037017822266, 'loss_4': 1.1202291250228882, 'epoch': 29.4}
{'loss': 0.0065, 'grad_norm': 4.412106513977051, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.00416772672906518, 'loss_2': 0.0023746490478515625, 'loss_3': -16.304162979125977, 'loss_4': 1.6924126148223877, 'epoch': 29.4}
{'loss': 0.0066, 'grad_norm': 4.6127824783325195, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.0016290541971102357, 'loss_2': 0.00498199462890625, 'loss_3': -16.230152130126953, 'loss_4': 1.3182463645935059, 'epoch': 29.41}
{'loss': 0.0081, 'grad_norm': 6.704822063446045, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.006262681446969509, 'loss_2': 0.0018405914306640625, 'loss_3': -16.21166229248047, 'loss_4': 1.4787566661834717, 'epoch': 29.41}
{'loss': 0.0025, 'grad_norm': 5.002175807952881, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.0023820677306503057, 'loss_2': 0.00012862682342529297, 'loss_3': -16.211851119995117, 'loss_4': 1.2136682271957397, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 11:28:41,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:41,404 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:30<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:48,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012016402557492256, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00994071550667286, 'eval_loss_2': 0.002075687050819397, 'eval_loss_3': -18.170503616333008, 'eval_loss_4': 1.1277527809143066, 'epoch': 29.42}
{'loss': 0.0025, 'grad_norm': 4.363997459411621, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.0018505161860957742, 'loss_2': 0.0006513595581054688, 'loss_3': -16.34450340270996, 'loss_4': 1.766664743423462, 'epoch': 29.42}
{'loss': 0.0174, 'grad_norm': 8.941584587097168, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.015363198705017567, 'loss_2': 0.002002716064453125, 'loss_3': -16.261343002319336, 'loss_4': 1.5706253051757812, 'epoch': 29.43}
{'loss': 0.0051, 'grad_norm': 4.36764669418335, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.0012402991997078061, 'loss_2': 0.0038700103759765625, 'loss_3': -16.273746490478516, 'loss_4': 1.307645320892334, 'epoch': 29.44}
{'loss': 0.0041, 'grad_norm': 5.677089214324951, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.004031726624816656, 'loss_2': 5.412101745605469e-05, 'loss_3': -16.19377326965332, 'loss_4': 1.5704412460327148, 'epoch': 29.44}
{'loss': 0.0102, 'grad_norm': 4.726560592651367, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.0032054174225777388, 'loss_2': 0.0070037841796875, 'loss_3': -16.3321475982666, 'loss_4': 0.9674476385116577, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 11:28:48,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:48,750 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:38<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:56,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01208244264125824, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.995, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009992938488721848, 'eval_loss_2': 0.002089504152536392, 'eval_loss_3': -18.170339584350586, 'eval_loss_4': 1.1253191232681274, 'epoch': 29.45}
{'loss': 0.0047, 'grad_norm': 4.928163528442383, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.0028441704344004393, 'loss_2': 0.0018301010131835938, 'loss_3': -16.254745483398438, 'loss_4': 1.351243257522583, 'epoch': 29.45}
{'loss': 0.0098, 'grad_norm': 8.148244857788086, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.008848370984196663, 'loss_2': 0.0009212493896484375, 'loss_3': -16.198991775512695, 'loss_4': 1.5692670345306396, 'epoch': 29.46}
{'loss': 0.0086, 'grad_norm': 5.33457088470459, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.005050759296864271, 'loss_2': 0.0035648345947265625, 'loss_3': -16.30224609375, 'loss_4': 1.5233912467956543, 'epoch': 29.47}
{'loss': 0.0055, 'grad_norm': 4.557065486907959, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.003128478769212961, 'loss_2': 0.002330780029296875, 'loss_3': -16.414966583251953, 'loss_4': 1.520836353302002, 'epoch': 29.47}
{'loss': 0.0077, 'grad_norm': 5.559326648712158, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.005246202927082777, 'loss_2': 0.00247955322265625, 'loss_3': -16.332321166992188, 'loss_4': 1.7740044593811035, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 11:28:56,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:56,106 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:04:45<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:03,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012081789784133434, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.485, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009990669786930084, 'eval_loss_2': 0.0020911209285259247, 'eval_loss_3': -18.170555114746094, 'eval_loss_4': 1.1153717041015625, 'epoch': 29.48}
{'loss': 0.0102, 'grad_norm': 5.388010025024414, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.008270127698779106, 'loss_2': 0.0019397735595703125, 'loss_3': -16.231237411499023, 'loss_4': 1.583566427230835, 'epoch': 29.48}
{'loss': 0.0025, 'grad_norm': 4.536194324493408, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.0016592260217294097, 'loss_2': 0.0007996559143066406, 'loss_3': -16.441253662109375, 'loss_4': 1.5831222534179688, 'epoch': 29.49}
{'loss': 0.0071, 'grad_norm': 4.217884540557861, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.0019341778242960572, 'loss_2': 0.0052032470703125, 'loss_3': -16.13102912902832, 'loss_4': 1.508429765701294, 'epoch': 29.49}
{'loss': 0.0079, 'grad_norm': 4.327230453491211, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.0034244523849338293, 'loss_2': 0.0045166015625, 'loss_3': -16.261917114257812, 'loss_4': 1.6920428276062012, 'epoch': 29.5}
{'loss': 0.0085, 'grad_norm': 4.320545673370361, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.0026364692021161318, 'loss_2': 0.00582122802734375, 'loss_3': -16.185684204101562, 'loss_4': 1.3146965503692627, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 11:29:03,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:03,460 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:04:52<01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:10,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012050379998981953, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009972230531275272, 'eval_loss_2': 0.0020781494677066803, 'eval_loss_3': -18.169105529785156, 'eval_loss_4': 1.1131398677825928, 'epoch': 29.51}
{'loss': 0.0023, 'grad_norm': 4.263739585876465, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.0016399315791204572, 'loss_2': 0.0006551742553710938, 'loss_3': -16.360877990722656, 'loss_4': 1.243504524230957, 'epoch': 29.51}
{'loss': 0.0035, 'grad_norm': 4.461948871612549, 'learning_rate': 5e-07, 'loss_1': 0.0030697777401655912, 'loss_2': 0.00045418739318847656, 'loss_3': -16.24239730834961, 'loss_4': 0.8744074106216431, 'epoch': 29.52}
{'loss': 0.0068, 'grad_norm': 4.7511725425720215, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.003782865358516574, 'loss_2': 0.0030364990234375, 'loss_3': -16.40821647644043, 'loss_4': 0.9254758358001709, 'epoch': 29.52}
{'loss': 0.0017, 'grad_norm': 4.265137672424316, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.0015563395572826266, 'loss_2': 0.00014519691467285156, 'loss_3': -16.382164001464844, 'loss_4': 1.7928805351257324, 'epoch': 29.53}
{'loss': 0.0071, 'grad_norm': 5.416983127593994, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.004410619381815195, 'loss_2': 0.0026702880859375, 'loss_3': -16.176742553710938, 'loss_4': 1.5848066806793213, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 11:29:10,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:10,808 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:00<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:18,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01198388822376728, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009908103384077549, 'eval_loss_2': 0.002075783908367157, 'eval_loss_3': -18.169282913208008, 'eval_loss_4': 1.1165331602096558, 'epoch': 29.53}
{'loss': 0.0075, 'grad_norm': 4.436220645904541, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.003293232060968876, 'loss_2': 0.004180908203125, 'loss_3': -16.31728744506836, 'loss_4': 1.44283926486969, 'epoch': 29.54}
{'loss': 0.0136, 'grad_norm': 4.923507213592529, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.005168026313185692, 'loss_2': 0.00846099853515625, 'loss_3': -16.211965560913086, 'loss_4': 1.5393829345703125, 'epoch': 29.55}
{'loss': 0.0104, 'grad_norm': 4.45974588394165, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.003931797109544277, 'loss_2': 0.00646209716796875, 'loss_3': -16.248184204101562, 'loss_4': 1.7066941261291504, 'epoch': 29.55}
{'loss': 0.0055, 'grad_norm': 4.7537455558776855, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.002431615022942424, 'loss_2': 0.00310516357421875, 'loss_3': -16.198753356933594, 'loss_4': 1.2534031867980957, 'epoch': 29.56}
{'loss': 0.01, 'grad_norm': 4.582180500030518, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.0028691182378679514, 'loss_2': 0.007144927978515625, 'loss_3': -16.252471923828125, 'loss_4': 1.009706735610962, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 11:29:18,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:18,156 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:07<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:25,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011892459355294704, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.239, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009841594845056534, 'eval_loss_2': 0.0020508654415607452, 'eval_loss_3': -18.169761657714844, 'eval_loss_4': 1.1226475238800049, 'epoch': 29.56}
{'loss': 0.0036, 'grad_norm': 4.606390476226807, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.001889455015771091, 'loss_2': 0.001750946044921875, 'loss_3': -16.50918197631836, 'loss_4': 1.8031530380249023, 'epoch': 29.57}
{'loss': 0.009, 'grad_norm': 4.972380638122559, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.0025863542687147856, 'loss_2': 0.00643157958984375, 'loss_3': -16.095447540283203, 'loss_4': 1.5202735662460327, 'epoch': 29.58}
{'loss': 0.0075, 'grad_norm': 4.560355186462402, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.0023464690893888474, 'loss_2': 0.005146026611328125, 'loss_3': -16.466176986694336, 'loss_4': 1.7952550649642944, 'epoch': 29.58}
{'loss': 0.0058, 'grad_norm': 4.87721586227417, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.002966932952404022, 'loss_2': 0.00286102294921875, 'loss_3': -16.371807098388672, 'loss_4': 1.6017814874649048, 'epoch': 29.59}
{'loss': 0.0068, 'grad_norm': 6.041828155517578, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.0032136496156454086, 'loss_2': 0.0036106109619140625, 'loss_3': -16.213815689086914, 'loss_4': 1.2167636156082153, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 11:29:25,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:25,498 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:15<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:32,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011863265186548233, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009843600913882256, 'eval_loss_2': 0.0020196661353111267, 'eval_loss_3': -18.17013931274414, 'eval_loss_4': 1.1288950443267822, 'epoch': 29.59}
{'loss': 0.0066, 'grad_norm': 4.798315525054932, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.0016131683951243758, 'loss_2': 0.0049896240234375, 'loss_3': -16.30095863342285, 'loss_4': 1.5122660398483276, 'epoch': 29.6}
{'loss': 0.0045, 'grad_norm': 4.573334217071533, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.0028430011589080095, 'loss_2': 0.001678466796875, 'loss_3': -16.16942596435547, 'loss_4': 1.3898797035217285, 'epoch': 29.6}
{'loss': 0.0074, 'grad_norm': 4.320953369140625, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.003946529235690832, 'loss_2': 0.0034732818603515625, 'loss_3': -16.28856086730957, 'loss_4': 1.4019947052001953, 'epoch': 29.61}
{'loss': 0.0061, 'grad_norm': 4.362362384796143, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.0020204936154186726, 'loss_2': 0.00408172607421875, 'loss_3': -16.402141571044922, 'loss_4': 1.672684669494629, 'epoch': 29.62}
{'loss': 0.0113, 'grad_norm': 4.6895952224731445, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.0027510307263582945, 'loss_2': 0.00855255126953125, 'loss_3': -16.225078582763672, 'loss_4': 1.3558542728424072, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 11:29:32,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:32,848 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:22<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:40,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011868954636156559, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.728, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00986227486282587, 'eval_loss_2': 0.0020066797733306885, 'eval_loss_3': -18.17098617553711, 'eval_loss_4': 1.1322855949401855, 'epoch': 29.62}
{'loss': 0.0072, 'grad_norm': 5.807119846343994, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.004856128245592117, 'loss_2': 0.002300262451171875, 'loss_3': -16.17938232421875, 'loss_4': 1.6023612022399902, 'epoch': 29.63}
{'loss': 0.0043, 'grad_norm': 4.384695529937744, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.001480288919992745, 'loss_2': 0.0028285980224609375, 'loss_3': -16.32813835144043, 'loss_4': 1.76890230178833, 'epoch': 29.63}
{'loss': 0.0041, 'grad_norm': 4.665307998657227, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.003447147784754634, 'loss_2': 0.000606536865234375, 'loss_3': -16.262998580932617, 'loss_4': 1.3170757293701172, 'epoch': 29.64}
{'loss': 0.0052, 'grad_norm': 4.519387245178223, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.004130090586841106, 'loss_2': 0.0010833740234375, 'loss_3': -16.292896270751953, 'loss_4': 1.964216947555542, 'epoch': 29.65}
{'loss': 0.0088, 'grad_norm': 4.304488182067871, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.0030826637521386147, 'loss_2': 0.00569915771484375, 'loss_3': -16.326061248779297, 'loss_4': 1.559136986732483, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 11:29:40,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:40,195 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:29<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:47,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011884354054927826, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.544, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009855514392256737, 'eval_loss_2': 0.00202883780002594, 'eval_loss_3': -18.171293258666992, 'eval_loss_4': 1.1348280906677246, 'epoch': 29.65}
{'loss': 0.0167, 'grad_norm': 7.0126190185546875, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.010274250991642475, 'loss_2': 0.0064239501953125, 'loss_3': -16.307371139526367, 'loss_4': 1.581955909729004, 'epoch': 29.66}
{'loss': 0.0078, 'grad_norm': 5.925046920776367, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.007044787984341383, 'loss_2': 0.0007610321044921875, 'loss_3': -16.28856086730957, 'loss_4': 1.47493314743042, 'epoch': 29.66}
{'loss': 0.0072, 'grad_norm': 4.5191473960876465, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.0027307618875056505, 'loss_2': 0.00449371337890625, 'loss_3': -16.024242401123047, 'loss_4': 1.2831251621246338, 'epoch': 29.67}
{'loss': 0.0074, 'grad_norm': 7.366572380065918, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.005566669162362814, 'loss_2': 0.001800537109375, 'loss_3': -16.273582458496094, 'loss_4': 1.3119173049926758, 'epoch': 29.67}
{'loss': 0.0057, 'grad_norm': 4.7762556076049805, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.003684551455080509, 'loss_2': 0.001983642578125, 'loss_3': -16.338319778442383, 'loss_4': 0.9887183904647827, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 11:29:47,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:47,541 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:37<00:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:54,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011874360963702202, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.684, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009844934567809105, 'eval_loss_2': 0.002029426395893097, 'eval_loss_3': -18.171222686767578, 'eval_loss_4': 1.1378264427185059, 'epoch': 29.68}
{'loss': 0.0092, 'grad_norm': 4.759051322937012, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.003397787921130657, 'loss_2': 0.005832672119140625, 'loss_3': -16.144573211669922, 'loss_4': 1.474816083908081, 'epoch': 29.69}
{'loss': 0.0048, 'grad_norm': 4.511939525604248, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.0020380113273859024, 'loss_2': 0.0027141571044921875, 'loss_3': -16.238971710205078, 'loss_4': 1.2096832990646362, 'epoch': 29.69}
{'loss': 0.0187, 'grad_norm': 13.407259941101074, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.012737449258565903, 'loss_2': 0.005947113037109375, 'loss_3': -16.30071258544922, 'loss_4': 1.2555513381958008, 'epoch': 29.7}
{'loss': 0.0048, 'grad_norm': 4.719021797180176, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.0026605708990246058, 'loss_2': 0.0021228790283203125, 'loss_3': -16.200822830200195, 'loss_4': 1.0550616979599, 'epoch': 29.7}
{'loss': 0.006, 'grad_norm': 5.857686519622803, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.0045488737523555756, 'loss_2': 0.0014858245849609375, 'loss_3': -16.398698806762695, 'loss_4': 1.5626246929168701, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 11:29:54,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:54,890 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:05:44<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:02,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011882464401423931, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.815, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009850854054093361, 'eval_loss_2': 0.0020316094160079956, 'eval_loss_3': -18.171640396118164, 'eval_loss_4': 1.1401500701904297, 'epoch': 29.71}
{'loss': 0.0057, 'grad_norm': 4.653433799743652, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.004040244966745377, 'loss_2': 0.001617431640625, 'loss_3': -16.147918701171875, 'loss_4': 1.1071860790252686, 'epoch': 29.72}
{'loss': 0.0134, 'grad_norm': 5.6840362548828125, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.008994627743959427, 'loss_2': 0.00441741943359375, 'loss_3': -16.234325408935547, 'loss_4': 1.6199108362197876, 'epoch': 29.72}
{'loss': 0.0048, 'grad_norm': 5.358778953552246, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.00342352781444788, 'loss_2': 0.0013484954833984375, 'loss_3': -16.44811248779297, 'loss_4': 1.2074611186981201, 'epoch': 29.73}
{'loss': 0.0067, 'grad_norm': 4.709218978881836, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.0035782295744866133, 'loss_2': 0.00308990478515625, 'loss_3': -16.290321350097656, 'loss_4': 0.9245330095291138, 'epoch': 29.73}
{'loss': 0.0126, 'grad_norm': 7.873960971832275, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.009479375556111336, 'loss_2': 0.003082275390625, 'loss_3': -16.298307418823242, 'loss_4': 2.2470970153808594, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 11:30:02,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:02,232 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:05:51<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:09,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011930777691304684, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009884148836135864, 'eval_loss_2': 0.002046629786491394, 'eval_loss_3': -18.17178726196289, 'eval_loss_4': 1.138828158378601, 'epoch': 29.74}
{'loss': 0.0055, 'grad_norm': 5.2592010498046875, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.004660867154598236, 'loss_2': 0.0007920265197753906, 'loss_3': -16.26704978942871, 'loss_4': 1.5195729732513428, 'epoch': 29.74}
{'loss': 0.0105, 'grad_norm': 9.051050186157227, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.008718276396393776, 'loss_2': 0.0017757415771484375, 'loss_3': -16.27200698852539, 'loss_4': 1.747536063194275, 'epoch': 29.75}
{'loss': 0.0064, 'grad_norm': 4.233107566833496, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.004835441242903471, 'loss_2': 0.0015773773193359375, 'loss_3': -16.48395347595215, 'loss_4': 1.1819143295288086, 'epoch': 29.76}
{'loss': 0.0041, 'grad_norm': 4.975600242614746, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.0026943881530314684, 'loss_2': 0.0014362335205078125, 'loss_3': -16.52341079711914, 'loss_4': 1.3917073011398315, 'epoch': 29.76}
{'loss': 0.0081, 'grad_norm': 4.359297752380371, 'learning_rate': 2.5e-07, 'loss_1': 0.0017511770129203796, 'loss_2': 0.006378173828125, 'loss_3': -16.38568878173828, 'loss_4': 1.6430444717407227, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 11:30:09,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:09,567 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:05:59<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:16,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011931582354009151, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009940861724317074, 'eval_loss_2': 0.0019907206296920776, 'eval_loss_3': -18.171010971069336, 'eval_loss_4': 1.1375898122787476, 'epoch': 29.77}
{'loss': 0.0105, 'grad_norm': 8.03587532043457, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.007108285557478666, 'loss_2': 0.003391265869140625, 'loss_3': -16.039844512939453, 'loss_4': 1.7148494720458984, 'epoch': 29.77}
{'loss': 0.0116, 'grad_norm': 13.599770545959473, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.010266520082950592, 'loss_2': 0.0012941360473632812, 'loss_3': -16.416908264160156, 'loss_4': 1.749098300933838, 'epoch': 29.78}
{'loss': 0.0113, 'grad_norm': 4.661276817321777, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.002696083392947912, 'loss_2': 0.00862884521484375, 'loss_3': -16.267539978027344, 'loss_4': 1.3312160968780518, 'epoch': 29.78}
{'loss': 0.0051, 'grad_norm': 4.689375877380371, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.0022183277178555727, 'loss_2': 0.002895355224609375, 'loss_3': -16.335895538330078, 'loss_4': 1.7532734870910645, 'epoch': 29.79}
{'loss': 0.0141, 'grad_norm': 5.4679412841796875, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.0073121157474815845, 'loss_2': 0.00678253173828125, 'loss_3': -16.44900131225586, 'loss_4': 1.494333267211914, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 11:30:16,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:16,913 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:06<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:24,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011923708021640778, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.952, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009939870797097683, 'eval_loss_2': 0.00198383629322052, 'eval_loss_3': -18.170238494873047, 'eval_loss_4': 1.1376556158065796, 'epoch': 29.8}
{'loss': 0.0131, 'grad_norm': 5.49600076675415, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.008950646966695786, 'loss_2': 0.004138946533203125, 'loss_3': -16.315221786499023, 'loss_4': 1.3047490119934082, 'epoch': 29.8}
{'loss': 0.0104, 'grad_norm': 5.8827900886535645, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.004670836962759495, 'loss_2': 0.0057220458984375, 'loss_3': -16.356807708740234, 'loss_4': 1.4055278301239014, 'epoch': 29.81}
{'loss': 0.0026, 'grad_norm': 4.631600856781006, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.00248366454616189, 'loss_2': 8.994340896606445e-05, 'loss_3': -16.31946563720703, 'loss_4': 1.0607054233551025, 'epoch': 29.81}
{'loss': 0.0081, 'grad_norm': 4.61445951461792, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.0014001175295561552, 'loss_2': 0.00670623779296875, 'loss_3': -16.353153228759766, 'loss_4': 1.3425872325897217, 'epoch': 29.82}
{'loss': 0.013, 'grad_norm': 6.2804694175720215, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.010714074596762657, 'loss_2': 0.002246856689453125, 'loss_3': -16.130117416381836, 'loss_4': 1.5215120315551758, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 11:30:24,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:24,246 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:13<00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:31,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011925017461180687, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.762, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009942455217242241, 'eval_loss_2': 0.001982562243938446, 'eval_loss_3': -18.17042350769043, 'eval_loss_4': 1.1380537748336792, 'epoch': 29.83}
{'loss': 0.0088, 'grad_norm': 4.594292163848877, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.0038506845012307167, 'loss_2': 0.0049591064453125, 'loss_3': -16.286434173583984, 'loss_4': 1.6219892501831055, 'epoch': 29.83}
{'loss': 0.0069, 'grad_norm': 4.92369270324707, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.0025172594469040632, 'loss_2': 0.0043487548828125, 'loss_3': -16.524017333984375, 'loss_4': 1.4984369277954102, 'epoch': 29.84}
{'loss': 0.0044, 'grad_norm': 4.647113800048828, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.0025374360848218203, 'loss_2': 0.0018596649169921875, 'loss_3': -16.562885284423828, 'loss_4': 1.2423115968704224, 'epoch': 29.84}
{'loss': 0.0028, 'grad_norm': 4.618235111236572, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.0019409885862842202, 'loss_2': 0.0008707046508789062, 'loss_3': -16.53237533569336, 'loss_4': 1.2499717473983765, 'epoch': 29.85}
{'loss': 0.0063, 'grad_norm': 4.282646656036377, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.0025642511900514364, 'loss_2': 0.0037631988525390625, 'loss_3': -16.461015701293945, 'loss_4': 1.3438591957092285, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 11:30:31,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:31,592 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:21<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:38,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011930695734918118, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.749, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009945913217961788, 'eval_loss_2': 0.0019847825169563293, 'eval_loss_3': -18.17015266418457, 'eval_loss_4': 1.1364034414291382, 'epoch': 29.85}
{'loss': 0.0102, 'grad_norm': 5.595818996429443, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.008334078826010227, 'loss_2': 0.0018310546875, 'loss_3': -16.537940979003906, 'loss_4': 1.8142876625061035, 'epoch': 29.86}
{'loss': 0.0071, 'grad_norm': 5.312819004058838, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.0070711774751544, 'loss_2': 4.9591064453125e-05, 'loss_3': -16.310222625732422, 'loss_4': 1.923187017440796, 'epoch': 29.87}
{'loss': 0.0052, 'grad_norm': 4.595716953277588, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.004097534343600273, 'loss_2': 0.0011234283447265625, 'loss_3': -16.241275787353516, 'loss_4': 1.0890095233917236, 'epoch': 29.87}
{'loss': 0.01, 'grad_norm': 4.48551082611084, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.0032151960767805576, 'loss_2': 0.006748199462890625, 'loss_3': -16.3614501953125, 'loss_4': 1.2597901821136475, 'epoch': 29.88}
{'loss': 0.006, 'grad_norm': 4.410984039306641, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.003283150726929307, 'loss_2': 0.002689361572265625, 'loss_3': -16.338577270507812, 'loss_4': 1.4413478374481201, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 11:30:38,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:38,928 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:28<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:46,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011957397684454918, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.012, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009941372089087963, 'eval_loss_2': 0.0020160265266895294, 'eval_loss_3': -18.16984748840332, 'eval_loss_4': 1.1355749368667603, 'epoch': 29.88}
{'loss': 0.0059, 'grad_norm': 4.258846282958984, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.0025091818533837795, 'loss_2': 0.00335693359375, 'loss_3': -16.461410522460938, 'loss_4': 1.833327054977417, 'epoch': 29.89}
{'loss': 0.0123, 'grad_norm': 6.208168983459473, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.007486959919333458, 'loss_2': 0.00479888916015625, 'loss_3': -16.128299713134766, 'loss_4': 0.8345067501068115, 'epoch': 29.9}
{'loss': 0.0125, 'grad_norm': 10.553217887878418, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.012264805845916271, 'loss_2': 0.00023496150970458984, 'loss_3': -16.227500915527344, 'loss_4': 1.1406002044677734, 'epoch': 29.9}
{'loss': 0.0046, 'grad_norm': 5.3183770179748535, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.004025425761938095, 'loss_2': 0.00052642822265625, 'loss_3': -16.246532440185547, 'loss_4': 1.1388168334960938, 'epoch': 29.91}
{'loss': 0.0079, 'grad_norm': 7.409050941467285, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.006918100640177727, 'loss_2': 0.0009975433349609375, 'loss_3': -16.09300994873047, 'loss_4': 1.5922861099243164, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 11:30:46,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:46,265 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:35<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:53,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01197501365095377, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009934891946613789, 'eval_loss_2': 0.002040121704339981, 'eval_loss_3': -18.169902801513672, 'eval_loss_4': 1.1350921392440796, 'epoch': 29.91}
{'loss': 0.0087, 'grad_norm': 6.683592796325684, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.005856468342244625, 'loss_2': 0.002796173095703125, 'loss_3': -16.401275634765625, 'loss_4': 1.5192608833312988, 'epoch': 29.92}
{'loss': 0.0077, 'grad_norm': 4.908171653747559, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.0045295599848032, 'loss_2': 0.003192901611328125, 'loss_3': -16.214832305908203, 'loss_4': 0.7136368155479431, 'epoch': 29.92}
{'loss': 0.0057, 'grad_norm': 5.087916374206543, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.0029490881133824587, 'loss_2': 0.002704620361328125, 'loss_3': -16.27946662902832, 'loss_4': 1.2162747383117676, 'epoch': 29.93}
{'loss': 0.0101, 'grad_norm': 8.687359809875488, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.009189733304083347, 'loss_2': 0.0009050369262695312, 'loss_3': -16.29840850830078, 'loss_4': 1.189131259918213, 'epoch': 29.94}
{'loss': 0.0168, 'grad_norm': 9.545446395874023, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.011123919859528542, 'loss_2': 0.00569915771484375, 'loss_3': -16.41394805908203, 'loss_4': 1.800884485244751, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 11:30:53,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:53,616 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:06:43<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:31:00,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012012923136353493, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.483, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009943935088813305, 'eval_loss_2': 0.0020689889788627625, 'eval_loss_3': -18.169851303100586, 'eval_loss_4': 1.1335275173187256, 'epoch': 29.94}
{'loss': 0.0064, 'grad_norm': 4.334466457366943, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.004078844096511602, 'loss_2': 0.002368927001953125, 'loss_3': -16.43973159790039, 'loss_4': 1.5206698179244995, 'epoch': 29.95}
{'loss': 0.005, 'grad_norm': 4.92058801651001, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.003706828923895955, 'loss_2': 0.0012502670288085938, 'loss_3': -16.409006118774414, 'loss_4': 1.6357676982879639, 'epoch': 29.95}
{'loss': 0.0068, 'grad_norm': 4.602725982666016, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.0018877404509112239, 'loss_2': 0.0048828125, 'loss_3': -16.30059814453125, 'loss_4': 1.1685495376586914, 'epoch': 29.96}
{'loss': 0.0043, 'grad_norm': 6.772680759429932, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.0020441070664674044, 'loss_2': 0.002216339111328125, 'loss_3': -16.274076461791992, 'loss_4': 1.46159029006958, 'epoch': 29.97}
{'loss': 0.0043, 'grad_norm': 5.191793918609619, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.0017716182628646493, 'loss_2': 0.002490997314453125, 'loss_3': -16.294322967529297, 'loss_4': 1.546297311782837, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 11:31:00,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:00,960 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:50<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 11:31:07,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012009422294795513, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009943556971848011, 'eval_loss_2': 0.0020658671855926514, 'eval_loss_3': -18.16939926147461, 'eval_loss_4': 1.1315240859985352, 'epoch': 29.97}
{'loss': 0.0044, 'grad_norm': 5.044513702392578, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.0041551776230335236, 'loss_2': 0.00024318695068359375, 'loss_3': -16.27082633972168, 'loss_4': 1.274096965789795, 'epoch': 29.98}
{'loss': 0.0108, 'grad_norm': 4.9498291015625, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.007459748536348343, 'loss_2': 0.003292083740234375, 'loss_3': -16.272436141967773, 'loss_4': 1.6528396606445312, 'epoch': 29.98}
{'loss': 0.0047, 'grad_norm': 4.737146854400635, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.004444975405931473, 'loss_2': 0.000274658203125, 'loss_3': -16.198471069335938, 'loss_4': 1.8479430675506592, 'epoch': 29.99}
{'loss': 0.0119, 'grad_norm': 6.294597148895264, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.005891585722565651, 'loss_2': 0.00597381591796875, 'loss_3': -16.17333221435547, 'loss_4': 2.049102306365967, 'epoch': 29.99}
{'loss': 0.0047, 'grad_norm': 6.54904842376709, 'learning_rate': 1.744186046511628e-08, 'loss_1': 0.003023118246346712, 'loss_2': 0.0016279220581054688, 'loss_3': -16.200824737548828, 'loss_4': 1.4024837017059326, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 11:31:07,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:07,950 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:53<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 11:31:11,810 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.012006850913167, 'eval_runtime': 3.8597, 'eval_samples_per_second': 265.307, 'eval_steps_per_second': 4.145, 'eval_loss_1': 0.009929568506777287, 'eval_loss_2': 0.0020772814750671387, 'eval_loss_3': -18.16969871520996, 'eval_loss_4': 1.1303430795669556, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 11:31:11,810 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/checkpoint-3010 (score: 0.0055117118172347546).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:54<00:00,  1.48s/it]
{'train_runtime': 7614.9741, 'train_samples_per_second': 43.249, 'train_steps_per_second': 0.678, 'train_loss': 0.030786653654063266, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 11:31:11,911 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1
[INFO|configuration_utils.py:420] 2025-01-21 11:31:11,913 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 11:31:12,603 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:31:12,604 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:31:12,604 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg1/special_tokens_map.json
01/21/2025 11:31:12 - INFO - __main__ -   ***** Train results *****
01/21/2025 11:31:12 - INFO - __main__ -     epoch = 30.0
01/21/2025 11:31:12 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 11:31:12 - INFO - __main__ -     train_loss = 0.030786653654063266
01/21/2025 11:31:12 - INFO - __main__ -     train_runtime = 7614.9741
01/21/2025 11:31:12 - INFO - __main__ -     train_samples_per_second = 43.249
01/21/2025 11:31:12 - INFO - __main__ -     train_steps_per_second = 0.678
01/21/2025 11:31:12 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 11:31:12,841 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:31:12,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:12,841 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.47it/s]
01/21/2025 11:31:16 - INFO - __main__ -   ***** Eval results *****
01/21/2025 11:31:16 - INFO - __main__ -     epoch = 30.0
01/21/2025 11:31:16 - INFO - __main__ -     eval_loss = 0.0055117118172347546
01/21/2025 11:31:16 - INFO - __main__ -     eval_loss_1 = 0.0034921872429549694
01/21/2025 11:31:16 - INFO - __main__ -     eval_loss_2 = 0.002019524574279785
01/21/2025 11:31:16 - INFO - __main__ -     eval_loss_3 = -18.329883575439453
01/21/2025 11:31:16 - INFO - __main__ -     eval_loss_4 = 1.0981287956237793
01/21/2025 11:31:16 - INFO - __main__ -     eval_runtime = 3.8622
01/21/2025 11:31:16 - INFO - __main__ -     eval_samples_per_second = 265.136
01/21/2025 11:31:16 - INFO - __main__ -     eval_steps_per_second = 4.143
